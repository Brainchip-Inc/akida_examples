

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>QuantizeML toolkit &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=c4c4e161" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      <script src="../_static/leadlander_tag.js?v=d65c0df8"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN2SNN toolkit" href="cnn2snn.html" />
    <link rel="prev" title="Akida user guide" href="akida.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #000000" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="user_guide.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#performance-measurement">Performance measurement</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tf-keras-support">TF-Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="#onnx-support">ONNX support</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#analysis-module">Analysis module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="#metrics">Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#command-line">Command line</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-to-display-sparsity">Command-line interface to display sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide.html#akida-hw-capabilities">Akida HW capabilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware/1.0.html">Akida 1.0 capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware/2.0.html">Akida 2.0 capabilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida.__version__"><code class="docutils literal notranslate"><span class="pre">__version__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#model">Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida-layers">Akida layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#layer-api">Layer API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#common-layer">Common layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#activationtype">ActivationType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#optimizers">Optimizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.core.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.AkidaUnsupervised"><code class="docutils literal notranslate"><span class="pre">AkidaUnsupervised</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id1">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id2">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id3">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#powermeter">PowerMeter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.PowerMeter"><code class="docutils literal notranslate"><span class="pre">PowerMeter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.PowerEvent"><code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#np">NP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Mesh"><code class="docutils literal notranslate"><span class="pre">Mesh</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Info"><code class="docutils literal notranslate"><span class="pre">Info</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Ident"><code class="docutils literal notranslate"><span class="pre">Ident</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.NpSpace"><code class="docutils literal notranslate"><span class="pre">NpSpace</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Type"><code class="docutils literal notranslate"><span class="pre">Type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.MemoryInfo"><code class="docutils literal notranslate"><span class="pre">MemoryInfo</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Component"><code class="docutils literal notranslate"><span class="pre">Component</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.SramSize"><code class="docutils literal notranslate"><span class="pre">SramSize</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#mapping">Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.MapMode"><code class="docutils literal notranslate"><span class="pre">MapMode</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.MapConstraints"><code class="docutils literal notranslate"><span class="pre">MapConstraints</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#akida-version">Akida version</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.AkidaVersion"><code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.get_akida_version"><code class="docutils literal notranslate"><span class="pre">get_akida_version()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.set_akida_version"><code class="docutils literal notranslate"><span class="pre">set_akida_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#conversion">Conversion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.convert"><code class="docutils literal notranslate"><span class="pre">convert()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.check_model_compatibility"><code class="docutils literal notranslate"><span class="pre">check_model_compatibility()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#temporal-convolution">Temporal convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#reset-buffers">Reset buffers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#id2">Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#custom-patterns">Custom patterns</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizeml.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizeml.save_model"><code class="docutils literal notranslate"><span class="pre">save_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#analysis">Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#metrics">Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#spatiotemporal-blocks">Spatiotemporal blocks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.distiller.Distiller"><code class="docutils literal notranslate"><span class="pre">Distiller</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#sparsity">Sparsity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.sparsity.compute_sparsity"><code class="docutils literal notranslate"><span class="pre">compute_sparsity()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.load_weights"><code class="docutils literal notranslate"><span class="pre">load_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.save_weights"><code class="docutils literal notranslate"><span class="pre">save_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.get_model_path"><code class="docutils literal notranslate"><span class="pre">get_model_path()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#utils">Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.fetch_file"><code class="docutils literal notranslate"><span class="pre">fetch_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.get_tensorboard_callback"><code class="docutils literal notranslate"><span class="pre">get_tensorboard_callback()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.get_params_by_version"><code class="docutils literal notranslate"><span class="pre">get_params_by_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#spatiotemporal-tenns">Spatiotemporal TENNs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/tenns_modules_apis.html">TENNs modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#spatiotemporal-blocks">Spatiotemporal blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.SpatialBlock"><code class="docutils literal notranslate"><span class="pre">SpatialBlock</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.TemporalBlock"><code class="docutils literal notranslate"><span class="pre">TemporalBlock</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.SpatioTemporalBlock"><code class="docutils literal notranslate"><span class="pre">SpatioTemporalBlock</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#export">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.export_to_onnx"><code class="docutils literal notranslate"><span class="pre">export_to_onnx()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#convert">3. Convert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-tf-keras-model">3. Load a pre-trained quantized TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-tf-keras-model">3. Load a pre-trained quantized TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#convert-to-akida">5. Convert to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html">Advanced ONNX models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#get-model-and-data">1. Get model and data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#conversion">3. Conversion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#spatiotemporal-examples">Spatiotemporal examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html">Gesture recognition with spatiotemporal models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#introduction-why-spatiotemporal-models">1. Introduction: why spatiotemporal models?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#spatiotemporal-blocks-the-core-concept">2. Spatiotemporal blocks: the core concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#building-the-model-from-blocks-to-network">3. Building the model: from blocks to network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#gesture-classification-in-videos">4. Gesture classification in videos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#training-and-evaluating-the-model">5. Training and evaluating the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#streaming-inference-making-real-time-predictions">6. Streaming inference: making real-time predictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#visualizing-the-predictions-of-the-model-in-real-time">7. Visualizing the predictions of the model in real time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#quantizing-the-model-and-convertion-to-akida">8. Quantizing the model and convertion to akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#final-thoughts-generalizing-the-approach">9. Final thoughts: generalizing the approach</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html">Efficient online eye tracking with a lightweight spatiotemporal network and event cameras</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#network-architecture">2. Network architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#dataset-and-preprocessing">3. Dataset and preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#model-training-evaluation">4. Model training &amp; evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#official-competition-results">5. Official competition results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#ablation-studies-and-efficiency-optimization">6. Ablation studies and efficiency optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#fifo-buffering-for-streaming-inference">7. FIFO buffering for streaming inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#quantization-and-conversion-to-akida">8. Quantization and conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id4">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id5">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id6">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id8"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id9">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id10"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id11">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#tenns-icon-ref-tenns"> TENNs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#gesture-recognition">Gesture recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#eye-tracking">Eye tracking</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #000000" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="user_guide.html">User guide</a></li>
      <li class="breadcrumb-item active">QuantizeML toolkit</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quantizeml-toolkit">
<h1>QuantizeML toolkit<a class="headerlink" href="#quantizeml-toolkit" title="Link to this heading"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>QuantizeML package provides base layers and quantization tools for deep-learning models. It allows
the quantization of CNN models using low-bitwidth weights and outputs. Once quantized with the
provided tools, CNN2SNN toolkit will be able to convert the model and execute it with Akida runtime.</p>
</section>
<section id="the-fixedpoint-representation">
<h2>The FixedPoint representation<a class="headerlink" href="#the-fixedpoint-representation" title="Link to this heading"></a></h2>
<p>QuantizeML uses a FixedPoint representation in place of float values for layers inputs, outputs and
weights.</p>
<p>FixedPoint numbers are actually integers with a static number of fractional bits so that:</p>
<div class="math notranslate nohighlight">
\[x_{float} \approx x_{int}.2^{-x_{frac\_bits}}\]</div>
<p>The precision of the representation is directly related to the number of fractional bits. For
example, representing PI using an 8-bit FixedPoint with varying fractional bits:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>frac_bits</p></th>
<th class="head"><p>x_int</p></th>
<th class="head"><p>float value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>6</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>25</p></td>
<td><p>3.125</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>201</p></td>
<td><p>3.140625</p></td>
</tr>
</tbody>
</table>
<p>Further details are available in the
<a class="reference external" href="../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint API</a> documentation.</p>
<p>Thanks to the FixedPoint representation, all operations within layers are implemented as integer
only operations <a class="footnote-reference brackets" href="#fn-1" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="quantization-flow">
<h2>Quantization flow<a class="headerlink" href="#quantization-flow" title="Link to this heading"></a></h2>
<p>The first step in the workflow is to train a model. The trained model is the starting point for the
quantization stage. Once it is established that the overall model configuration prior to
quantization yields a satisfactory performance on the task, one can proceed with quantization.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For simplicity, the following leverages the TF-Keras API to define a model, but QuantizeML
also comes with ONNX support, see the <a class="reference external" href="../examples/general/plot_7_global_pytorch_workflow.html#sphx-glr-examples-general-plot-7-global-pytorch-workflow-py">PyTorch to Akida</a>
or <a class="reference external" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#sphx-glr-examples-quantization-plot-2-off-the-shelf-quantization-py">off-the-shelf models</a>
examples for more information.</p>
</div>
<p>Lets take the <a class="reference external" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a> model from our zoo that
targets KWS task as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">akida_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_file</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">quantizeml</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model</span>
<span class="n">model_file</span> <span class="o">=</span> <span class="n">fetch_file</span><span class="p">(</span><span class="s2">&quot;https://data.brainchip.com/models/AkidaV2/ds_cnn/ds_cnn_kws.h5&quot;</span><span class="p">,</span>
                        <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;ds_cnn_kws.h5&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The QuantizeML toolkit offers a turnkey solution to quantize a model: the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function. It
replaces the TF-Keras layers (or custom QuantizeML layers) with quantized, integer only layers. The
obtained quantized model is still a TF-Keras model that can be evaluated with a standard TF-Keras
pipeline.</p>
<p>The quantization scheme used by
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> can be configured
using
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.QuantizationParams">QuantizationParams</a>.
If none is given, an 8-bit configuration scheme will be selected.</p>
<p>Heres an example for 8-bit quantization:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">quantizeml.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationParams</span>
<span class="n">qparams8</span> <span class="o">=</span> <span class="n">QuantizationParams</span><span class="p">(</span><span class="n">input_weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
<p>Heres an example for 4-bit quantization (with first layer weights set to 8-bit):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">quantizeml.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationParams</span>
<span class="n">qparams4</span> <span class="o">=</span> <span class="n">QuantizationParams</span><span class="p">(</span><span class="n">input_weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">weight_bits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation_bits</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that quantizating the first weights to 8-bit helps preserving accuracy.</p>
<p>QuantizeML uses a uniform quantization scheme centered on zero. During quantization, the floating
point values are mapped to a given bitwidth quantization space of the form:</p>
<div class="math notranslate nohighlight">
\[data_{float32} = data_{fixed\_point} * scales\]</div>
<p><cite>scales</cite> is a real number used to map the FixedPoint numbers to a quantization space. It is
calculated as follows:</p>
<div class="math notranslate nohighlight">
\[scales = \frac {max(abs(data))}{2^{bitwidth} - 1}\]</div>
<p>Inputs, weights and outputs scales are folded into a single output scale vector.</p>
<p>To avoid saturation in downstream operations throughout a model graph, the bitwidth of intermediary
results is decreased using
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a>. The
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function has
built-in rules to automatically isolate building blocks of layers after which such quantization is
required and will insert the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a>
objects during the quantization process.</p>
<p>To properly operate, an
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a> must
be calibrated so that it determines an adequate quantization range. Calibration will determine the
quantization range statistically. It is possible to pass down samples to the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function so that
calibration and quantization are performed simultaneously.</p>
<p>Calibration samples are available on
<a class="reference external" href="https://data.brainchip.com/dataset-mirror/samples/">Brainchip data server</a> for datasets used in
our zoo. They must be downloaded and deserialized before being used for calibration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">akida_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_file</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">fetch_file</span><span class="p">(</span><span class="s2">&quot;https://data.brainchip.com/dataset-mirror/samples/kws/kws_batch1024.npz&quot;</span><span class="p">,</span>
                     <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;kws_batch1024.npz&quot;</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">samples</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">files</span><span class="p">])</span>
</pre></div>
</div>
<p>Quantizing the DS-CNN model to 8-bit is then done with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">quantizeml.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">quantize</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">qparams</span><span class="o">=</span><span class="n">qparams8</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.calibrate">calibrate</a>
for more details on calibration.</p>
<p>Direct quantization of a standard TF-Keras model (also called Post Training Quantization, PTQ)
generally introduces a drop in performance. This drop is usually small for 8-bit or even 4-bit
quantization of simple models, but it can be very significant for low quantization bitwidth and
complex models (<a class="reference external" href="../api_reference/akida_models_apis.html#akida_models.akidanet_imagenet">AkidaNet</a>
architecture).</p>
<p>If the quantized model offers acceptable performance, it can be directly converted into an Akida
model (see the <a class="reference external" href="../api_reference/cnn2snn_apis.html#cnn2snn.convert">convert</a> function).</p>
<p>However, if the performance drop is too high, a Quantization Aware Training (QAT) step is required
to recover the performance prior to quantization. Since the quantized model is a TF-Keras model, it
can then be trained using the standard TF-Keras API.</p>
<p>Check out the <a class="reference external" href="../examples/index.html">examples section</a> for tutorials on quantization, PTQ and
QAT.</p>
<section id="compatibility-constraints">
<h3>Compatibility constraints<a class="headerlink" href="#compatibility-constraints" title="Link to this heading"></a></h3>
<p>The tookit supports a wide range of layers (see the
<a class="reference external" href="./quantizeml.html#supported-layer-types">supported type section</a>). When hitting a non-compatible
layer, QuantizeML will simply stop the quantization before this layer and add a
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.Dequantizer">Dequantizer</a> before it so
that inference is still possible. When such an event occurs, a warning is raised to the user with the
faulty layer name.</p>
<p>While quantization comes with some restrictions on layer order (e.g. MaxPool2D operation should be
placed before ReLU activation), the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.transforms.sanitize">sanitize</a> helper is
called before quantization to deal with such restrictions and edit the model accordingly.
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.transforms.sanitize">sanitize</a> will also
handle some layers that are not in the
<a class="reference external" href="./quantizeml.html#supported-layer-types">supported layer types</a> such as:</p>
<ul class="simple">
<li><p>ZeroPadding2D which is replaced with same padding convolution when possible</p></li>
<li><dl class="simple">
<dt>Lambda layers:</dt><dd><ul>
<li><p>Lambda(relu) or Activation(relu)  ReLU,</p></li>
<li><p>Lambda(transpose)  Permute,</p></li>
<li><p>Lambda(reshape)  Reshape,</p></li>
<li><p>Lambda(add)  Add.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="model-loading">
<h3>Model loading<a class="headerlink" href="#model-loading" title="Link to this heading"></a></h3>
<p>The toolkit offers a helper that allows to load float and quantized models from TF-Keras or ONNX
frameworks: <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.load_model">quantizeml.load_model</a>.</p>
</section>
</section>
<section id="command-line-interface">
<h2>Command line interface<a class="headerlink" href="#command-line-interface" title="Link to this heading"></a></h2>
<p>In addition to the programming interface, QuantizeML toolkit also provides a command-line interface
to perform quantization, dump a quantized model configuration, check a quantized model and insert a
rescaling layer.</p>
<section id="quantize-cli">
<h3>quantize CLI<a class="headerlink" href="#quantize-cli" title="Link to this heading"></a></h3>
<p>Quantizing a model through the CLI uses almost the same arguments as the programming interface but
the quantization parameters are split into the parameters: input weight quantization with -i,
weight bitwidth with -w and activation bitwidth with the -a options.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">8</span><span class="w"> </span>-a<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
<p>Note that without calibration options explicitly given, calibration will happen with 1024 randomly
generated samples. It is generally advised to use real samples serialized in a numpy <cite>.npz</cite> file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">8</span><span class="w"> </span>-a<span class="w"> </span><span class="m">8</span><span class="w"> </span>-sa<span class="w"> </span>some_samples.npz<span class="w"> </span>-bs<span class="w"> </span><span class="m">128</span><span class="w"> </span>-e<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<p>For akida 1.0 compatibility, it is mandatory to have activations quantized per-tensor instead of
the default per-axis quantization:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">4</span><span class="w"> </span>-a<span class="w"> </span><span class="m">4</span><span class="w"> </span>--per_tensor_activations
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The quantize CLI is the same for Keras and ONNX models.</p>
</div>
</section>
<section id="config-cli">
<h3>config CLI<a class="headerlink" href="#config-cli" title="Link to this heading"></a></h3>
<p>Advanced users might want to customize the default quantization pattern and this is made possible by
dumping a quantized model configuration to a <cite>.json</cite> file and quantizing again using the -c
option.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>config<span class="w"> </span>-m<span class="w"> </span>model_keras_i8_w8_a8.h5<span class="w"> </span>-o<span class="w"> </span>config.json

...<span class="w"> </span>manual<span class="w"> </span>configuration<span class="w"> </span>changes<span class="w"> </span>...

quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-c<span class="w"> </span>config.json
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Editing a model configuration can be complicated and might have negative effects on quantized
accuracy or even model graph. This should be reserved to users deeply familiar with QuantizeML
concepts.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is only available for TF-Keras models.</p>
</div>
</section>
<section id="check-cli">
<h3>check CLI<a class="headerlink" href="#check-cli" title="Link to this heading"></a></h3>
<p>It is possible to check for quantization errors using the <cite>check</cite> CLI that will report inaccurate
weight scales quantization or saturation in integer operations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>check<span class="w"> </span>-m<span class="w"> </span>model_keras_i8_w8_a8.h5
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is only available for TF-Keras models.</p>
</div>
</section>
<section id="insert-rescaling-cli">
<h3>insert_rescaling CLI<a class="headerlink" href="#insert-rescaling-cli" title="Link to this heading"></a></h3>
<p>Some models might not include a Rescaling layer in their architecture and have a separated
preprocessing pipeline (ie. moving from [0, 255] images to a [-1, 1] normalized representation). As
having a rescaling layer might be useful, QuantizeML offers the <cite>insert_rescaling</cite> CLI that will add
a Rescaling layer at the beginning of a given model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>insert_rescaling<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-s<span class="w"> </span><span class="m">0</span>.007843<span class="w"> </span>-o<span class="w"> </span>-1<span class="w"> </span>-d<span class="w"> </span>model_updated.h5
</pre></div>
</div>
<p>where <span class="math notranslate nohighlight">\(0.007843 = 1/127.5\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is only available for TF-Keras models.</p>
</div>
</section>
</section>
<section id="supported-layer-types">
<h2>Supported layer types<a class="headerlink" href="#supported-layer-types" title="Link to this heading"></a></h2>
<section id="tf-keras-support">
<h3>TF-Keras support<a class="headerlink" href="#tf-keras-support" title="Link to this heading"></a></h3>
<p>The QuantizeML toolkit provides quantization of the following layer types which are standard
TF-Keras layers for most part and custom QuantizeML layers for some of them:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Neural layers</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConv2D">Conv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConv2DTranspose">Conv2DTranspose</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDepthwiseConv2D">DepthwiseConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDepthwiseConv2DTranspose">DepthwiseConv2DTranspose</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedBufferTempConv">BufferTempConv</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDepthwiseBufferTempConv">DepthwiseBufferTempConv</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedSeparableConv2D">SeparableConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDense">Dense</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Skip connections</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedAdd">Add</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConcatenate">Concatenate</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Activations</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedReLU">ReLU</a>
(both unbounded and with a max value)</p></li>
<li><p>GeLU, SiLU(Swish), HardSiLU, LeakyReLU and PReLU (with a fixed slope) through
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedActivation">QuantizedActivation</a>
(custom QuantizeML layer)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Pooling</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedMaxPool2D">MaxPool2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedGlobalAveragePooling2D">GlobalAveragePooling2D</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Reshaping</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedFlatten">Flatten</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedPermute">Permute</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedReshape">Reshape</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Others</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedRescaling">Rescaling</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDropout">Dropout</a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="onnx-support">
<h3>ONNX support<a class="headerlink" href="#onnx-support" title="Link to this heading"></a></h3>
<p>The QuantizeML toolkit will identify groups of ONNX operations, or patterns and quantize towards:</p>
<ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedConv2D">QuantizedConv2D</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;Conv, Activation, GlobalAveragePool&gt;</p></li>
<li><p>&lt;Conv, MaxPool, Relu/Clip&gt;</p></li>
<li><p>&lt;Conv, GlobalAveragePool&gt;</p></li>
<li><p>&lt;Conv, Activation&gt;</p></li>
<li><p>&lt;Conv&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedDepthwise2D">QuantizedDepthwise2D</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;Conv, Activation&gt;</p></li>
<li><p>&lt;Conv&gt;</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>and groups=input_channels.</p>
<ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedConv2DTranspose">QuantizedConv2DTranspose</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;ConvTranspose, Activation&gt;</p></li>
<li><p>&lt;ConvTranspose&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedDepthwise2DTranspose">QuantizedDepthwise2DTranspose</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;ConvTranspose, Activation&gt;</p></li>
<li><p>&lt;ConvTranspose&gt;</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>and groups=input_channels.</p>
<ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedBufferTempConv">QuantizedBufferTempConv</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;BufferTempConv, Relu&gt;</p></li>
<li><p>&lt;BufferTempConv&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedDepthwiseBufferTempConv">QuantizedDepthwiseBufferTempConv</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;DepthwiseBufferTempConv, Relu&gt;</p></li>
<li><p>&lt;DepthwiseBufferTempConv&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedDense1D">QuantizedDense1D</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;Flatten, Gemm, Relu/Clip&gt;</p></li>
<li><p>&lt;Flatten, Gemm&gt;</p></li>
<li><p>&lt;Gemm, Relu/Clip&gt;</p></li>
<li><p>&lt;Gemm&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedAdd">QuantizedAdd</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;Add, Relu&gt;</p></li>
<li><p>&lt;Add&gt;</p></li>
</ul>
</div></blockquote>
</li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.layers.QuantizedConcat">QuantizedConcat</a>
when the pattern is:</p>
<blockquote>
<div><ul class="simple">
<li><p>&lt;Concat&gt;</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>While Akida directly supports the most important models, it is not feasible to support all
possibilities. There might occasionally be models which are nearly compatible with Akida but which
will fail to quantize due to just a few incompatibilities. The <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.onnx_support.quantization.custom_pattern_scope">custom pattern feature</a>
allows to handle such models as illustrated in <a class="reference external" href="../examples/quantization/plot_3_custom_patterns.html#sphx-glr-examples-quantization-plot-3-custom-patterns-py">the dedicated advanced example</a>.</p>
</section>
</section>
<section id="analysis-module">
<h2>Analysis module<a class="headerlink" href="#analysis-module" title="Link to this heading"></a></h2>
<p>The QuantizeML toolit comes with an <a class="reference external" href="../api_reference/quantizeml_apis.html#analysis">analysis</a>
submodule that provides tools to better analyze the impact of quantization on a model. Quantization
errors and minimal accuracy drops are an expected behavior going from float to integer (8-bits).
While no simple and generic solution can be provided to solve larger accuracy issues, the analyis
tool can help pinpoint faulty layers or kernels that might be poorly quantized and thus harm
accuracy. Once the culprit is found, adding regularization or training constraints can help tackle
the issue, quantizing per-tensor or per-axis can also help.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><cite>analysis</cite> is shipped as an optional submodule and might not be installed by default. To install
it, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">quantizeml</span><span class="p">[</span><span class="n">analysis</span><span class="p">]</span>
</pre></div>
</div>
</div>
<section id="kernel-distribution">
<h3>Kernel distribution<a class="headerlink" href="#kernel-distribution" title="Link to this heading"></a></h3>
<p>This tool leverages the <a class="reference external" href="https://www.tensorflow.org/tensorboard">Tensorboard visualization toolkit</a> to draw the kernel distributions of a given model. The
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.plot_kernel_distribution">plot_kernel_distribution</a> API takes as
inputs the model of interest and a path to save a preset Tensorboard configuration to display. The
following command line will enable the histogram and boxplot displays:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="o">=</span><span class="sb">`</span>logdir<span class="sb">`</span>
</pre></div>
</div>
<p>Since QuantizeML is based on a uniform quantization scheme centered on zero, the kernel distribution
tool can be used to check for large outliers or oddly distributed kernels that might be poorly
quantized.</p>
<p>Example output for the classification layer of the <a class="reference external" href="../model_zoo_performance.html#id11">DS-CNN/KWS</a> model:</p>
<a class="reference internal image-reference" href="../_images/kernel_distrib.png"><img alt="../_images/kernel_distrib.png" src="../_images/kernel_distrib.png" style="width: 1041.0px; height: 412.5px;" />
</a>
</section>
<section id="quantization-error">
<h3>Quantization error<a class="headerlink" href="#quantization-error" title="Link to this heading"></a></h3>
<p>The tool offers 2 possible ways to check quantization error in a model:</p>
<blockquote>
<div><ul class="simple">
<li><p>for all layers: a quantization error is computed on each layer output</p></li>
<li><p>for a single layer: per-channel error is then reported</p></li>
</ul>
</div></blockquote>
<p>This is accessible using the <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.measure_layer_quantization_error">measure_layer_quantization_error</a> API.
The quantization error is then computed independently for each layer or channel accordingly. The
cumulative error, that is the error propagated from the input to each layer, is computed with the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.measure_cumulative_quantization_error">measure_cumulative_quantization_error</a>
dedicated API. Both APIs will return a python dictionary containing the metrics that can be
displayed using the <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.tools.print_metric_table">print_metric_table</a> function.</p>
<p>A <cite>batch_size</cite> parameter is present in the quantization error functions and can be used to better
refine the computed error by averaging error on more data.</p>
<p>It is also possible to compute weight quantization error (model or layer wise) using the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.measure_weight_quantization_error">measure_weight_quantization_error</a>
helper.</p>
</section>
<section id="metrics">
<h3>Metrics<a class="headerlink" href="#metrics" title="Link to this heading"></a></h3>
<p>The quantization error tools will report <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.tools.SMAPE">SMAPE</a> and <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.analysis.tools.Saturation">saturation</a> metrics.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error">symmetric mean absolute percentage error</a> (SMAPE) measures error
as:</p>
<div class="math notranslate nohighlight">
\[SMAPE = \frac{1}{n}\sum_{n}{\frac{|x_{float} - x_{quantized}|}{|x_{float}| + |x_{quantized}|}}\]</div>
<p>The saturation metric is the percentage of saturated values for a given layer or channel. A value
is saturated when it is equal to the minimum or maximum value allowed by a given bitwidth.</p>
</section>
<section id="command-line">
<h3>Command line<a class="headerlink" href="#command-line" title="Link to this heading"></a></h3>
<p>The analysis tools are accessible via command-line using the <cite>analysis</cite> action:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>-h

usage:<span class="w"> </span>quantizeml<span class="w"> </span>analysis<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">{</span>kernel_distribution,quantization_error<span class="o">}</span><span class="w"> </span>...

positional<span class="w"> </span>arguments:
<span class="o">{</span>kernel_distribution,quantization_error<span class="o">}</span>
<span class="w">    </span>kernel_distribution<span class="w"> </span>Plot<span class="w"> </span>kernel<span class="w"> </span>distribution
<span class="w">    </span>quantization_error<span class="w">  </span>Measure<span class="w"> </span>quantization<span class="w"> </span>error

options:
-h,<span class="w"> </span>--help<span class="w">              </span>Show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The sections below use the <a class="reference external" href="../model_zoo_performance.html#id11">DS-CNN/KWS</a> model for
illustration purposes, but this model does not exhibit quantization issues.</p>
</div>
<section id="kernel-distribution-from-command-line">
<h4>Kernel distribution from command-line<a class="headerlink" href="#kernel-distribution-from-command-line" title="Link to this heading"></a></h4>
<p>A model and a directory must be provided:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>kernel_distribution<span class="w"> </span>-h

usage:<span class="w"> </span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>kernel_distribution<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>-m<span class="w"> </span>MODEL<span class="w"> </span>-l<span class="w"> </span>LOGDIR

options:
-h,<span class="w"> </span>--help<span class="w">                 </span>Show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
-m<span class="w"> </span>MODEL,<span class="w"> </span>--model<span class="w"> </span>MODEL<span class="w">    </span>Model<span class="w"> </span>to<span class="w"> </span>analyze
-l<span class="w"> </span>LOGDIR,<span class="w"> </span>--logdir<span class="w"> </span>LOGDIR<span class="w"> </span>Log<span class="w"> </span>directory<span class="w"> </span>to<span class="w"> </span>save<span class="w"> </span>plots
</pre></div>
</div>
<p>Tensorboard called on the log directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>kernel_distribution<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws.h5<span class="w"> </span>-l<span class="w"> </span>.<span class="se">\l</span>ogs
tensorboard<span class="w"> </span>--logdir<span class="o">=</span>.<span class="se">\l</span>ogs
</pre></div>
</div>
</section>
<section id="quantization-error-from-command-line">
<h4>Quantization error from command-line<a class="headerlink" href="#quantization-error-from-command-line" title="Link to this heading"></a></h4>
<p>All the options described in the previous section are accessible through parameters:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage:<span class="w"> </span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>quantization_error<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>-m<span class="w"> </span>MODEL<span class="w"> </span>-qm<span class="w"> </span>QUANTIZED_MODEL<span class="w"> </span><span class="o">[</span>-tl<span class="w"> </span>TARGET_LAYER<span class="o">]</span><span class="w"> </span><span class="o">[</span>-bs<span class="w"> </span>BATCH_SIZE<span class="o">]</span><span class="w"> </span><span class="o">[</span>-c<span class="o">]</span>

options:
-h,<span class="w"> </span>--help<span class="w">                                             </span>Show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
-m<span class="w"> </span>MODEL,<span class="w"> </span>--model<span class="w"> </span>MODEL<span class="w">                                </span>Model<span class="w"> </span>to<span class="w"> </span>analyze
-qm<span class="w"> </span>QUANTIZED_MODEL,<span class="w"> </span>--quantized_model<span class="w"> </span>QUANTIZED_MODEL<span class="w"> </span>The<span class="w"> </span>quantized<span class="w"> </span>model<span class="w"> </span>to<span class="w"> </span>analyze
-tl<span class="w"> </span>TARGET_LAYER,<span class="w"> </span>--target_layer<span class="w"> </span>TARGET_LAYER<span class="w">          </span>Compute<span class="w"> </span>per_channel<span class="w"> </span>error<span class="w"> </span><span class="k">for</span><span class="w"> </span>a<span class="w"> </span>specific
<span class="w">                                                       </span>layer/node.<span class="w"> </span>Defaults<span class="w"> </span>to<span class="w"> </span>None
-bs<span class="w"> </span>BATCH_SIZE,<span class="w"> </span>--batch_size<span class="w"> </span>BATCH_SIZE<span class="w">                </span>Batch<span class="w"> </span>size<span class="w"> </span>to<span class="w"> </span>generate<span class="w"> </span>samples.<span class="w"> </span>Defaults
<span class="w">                                                       </span>to<span class="w"> </span><span class="m">16</span>
-c,<span class="w"> </span>--cumulative<span class="w">                                       </span>Compute<span class="w"> </span>cumulative<span class="w"> </span>quantization<span class="w"> </span>error
<span class="w">                                                       </span>instead<span class="w"> </span>of<span class="w"> </span>isolated<span class="w"> </span>one.<span class="w"> </span>Defaults<span class="w"> </span>to
<span class="w">                                                       </span>False
</pre></div>
</div>
<p>Providing only a model and its quantized version will print out quantization error per-layer
individually:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>quantization_error<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws.h5<span class="w"> </span>-qm<span class="w"> </span>ds_cnn_kws_i8_w8_a8.h5

Quantization<span class="w"> </span>error<span class="w"> </span><span class="k">for</span><span class="w"> </span>ds_cnn_kws:
<span class="o">=====================================================================================</span>
Layer/node<span class="w">                                                  </span><span class="p">|</span><span class="w"> </span>SMAPE<span class="w">  </span><span class="p">|</span><span class="w"> </span>Saturation<span class="w"> </span><span class="o">(</span>%<span class="o">)</span>
<span class="o">=====================================================================================</span>
conv_0<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                                    </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0182<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
conv_0/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                                 </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0054<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">5</span>.3266
dw_separable_1<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0623<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.5328
pw_separable_1<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0138<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_1/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0042<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">7</span>.5719
dw_separable_2<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0277<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">2</span>.1156
pw_separable_2<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0140<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_2/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0050<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">2</span>.6492
dw_separable_3<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0330<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.3859
pw_separable_3<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0162<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_3/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0062<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.3547
dw_separable_4<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0570<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0445
pw_separable_4<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0194<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_4/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0001<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_4/global_avg<span class="w"> </span><span class="o">(</span>QuantizedGlobalAveragePooling2D<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0041<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">1</span>.1719
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span><span class="w">                                    </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0078<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
<span class="o">=====================================================================================</span>
</pre></div>
</div>
<p>Using the <cite>cumulative</cite> option will display a similar report where error is cumulated top-down from
layer to layer:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>quantization_error<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws.h5<span class="w"> </span>-qm<span class="w"> </span>ds_cnn_kws_i8_w8_a8.h5<span class="w"> </span>-c

Quantization<span class="w"> </span>error<span class="w"> </span><span class="k">for</span><span class="w"> </span>ds_cnn_kws:
<span class="o">=====================================================================================</span>
Layer/node<span class="w">                                                  </span><span class="p">|</span><span class="w"> </span>SMAPE<span class="w">  </span><span class="p">|</span><span class="w"> </span>Saturation<span class="w"> </span><span class="o">(</span>%<span class="o">)</span>
<span class="o">=====================================================================================</span>
conv_0<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                                    </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0180<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
conv_0/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                                 </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0106<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">5</span>.1937
dw_separable_1<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.1053<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.5594
pw_separable_1<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.1862<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_1/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.1121<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">7</span>.7031
dw_separable_2<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2173<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">2</span>.1727
pw_separable_2<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2353<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_2/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.1344<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">2</span>.6430
dw_separable_3<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2131<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.3906
pw_separable_3<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2515<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_3/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.1335<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.3875
dw_separable_4<span class="w"> </span><span class="o">(</span>QuantizedDepthwiseConv2D<span class="o">)</span><span class="w">                   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2528<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0695
pw_separable_4<span class="w"> </span><span class="o">(</span>QuantizedConv2D<span class="o">)</span><span class="w">                            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.3366<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_4/relu<span class="w"> </span><span class="o">(</span>QuantizedReLU<span class="o">)</span><span class="w">                         </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2310<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
pw_separable_4/global_avg<span class="w"> </span><span class="o">(</span>QuantizedGlobalAveragePooling2D<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0860<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">1</span>.5625
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span><span class="w">                                    </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0962<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
<span class="o">=====================================================================================</span>
</pre></div>
</div>
<p>The <cite>target_layer</cite> allows to focus on a given layer and display a per-axis error on all output
channels for this layer, for example on the classification dense layer:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>analysis<span class="w"> </span>quantization_error<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws.h5<span class="w"> </span>-qm<span class="w"> </span>ds_cnn_kws_i8_w8_a8.h5<span class="w"> </span>-tl<span class="w"> </span>dense_5

Quantization<span class="w"> </span>error<span class="w"> </span><span class="k">for</span><span class="w"> </span>ds_cnn_kws:
<span class="o">=====================================================</span>
Layer/node<span class="w">                  </span><span class="p">|</span><span class="w"> </span>SMAPE<span class="w">  </span><span class="p">|</span><span class="w"> </span>Saturation<span class="w"> </span><span class="o">(</span>%<span class="o">)</span>
<span class="o">=====================================================</span>
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:1<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0011<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:2<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0003<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:3<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0002<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:4<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0032<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:5<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0190<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:6<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:7<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0025<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:8<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0053<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:9<span class="w">  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:10<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0018<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:11<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0041<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:12<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0004<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:13<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0009<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:14<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0019<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:15<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0006<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:16<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0039<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:17<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0018<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:18<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0090<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:19<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0057<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:20<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0007<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:21<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:22<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0012<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:23<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:24<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0039<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:25<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0627<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:26<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0030<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:27<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:28<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0016<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:29<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0026<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:30<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0004<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:31<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:32<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0005<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
dense_5<span class="w"> </span><span class="o">(</span>QuantizedDense<span class="o">)</span>:33<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0010<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.0000
<span class="o">=====================================================</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since random samples are used, results in the above tables may slightly change.</p>
</div>
<hr class="docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="fn-1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>See <a class="reference external" href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic">https://en.wikipedia.org/wiki/Fixed-point_arithmetic</a> for more details on the
arithmetics.</p>
</aside>
</aside>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="akida.html" class="btn btn-neutral float-left" title="Akida user guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnn2snn.html" class="btn btn-neutral float-right" title="CNN2SNN toolkit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>