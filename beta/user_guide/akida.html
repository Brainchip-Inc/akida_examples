

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Akida user guide &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=c4c4e161" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../_static/leadlander_tag.js?v=d65c0df8"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="QuantizeML toolkit" href="quantizeml.html" />
    <link rel="prev" title="User guide" href="user_guide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #000000" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="user_guide.html">User guide</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#performance-measurement">Performance measurement</a></li>
<li class="toctree-l4"><a class="reference internal" href="#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#tf-keras-support">TF-Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#onnx-support">ONNX support</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml.html#analysis-module">Analysis module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#metrics">Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml.html#command-line">Command line</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-to-display-sparsity">Command-line interface to display sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide.html#akida-hw-capabilities">Akida HW capabilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hardware/1.0.html">Akida 1.0 capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="hardware/2.0.html">Akida 2.0 capabilities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida.__version__"><code class="docutils literal notranslate"><span class="pre">__version__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#model">Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida-layers">Akida layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#layer-api">Layer API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#common-layer">Common layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#activationtype">ActivationType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#optimizers">Optimizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.core.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.AkidaUnsupervised"><code class="docutils literal notranslate"><span class="pre">AkidaUnsupervised</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id1">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id2">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#hwdevice">HwDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id3">HwDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#powermeter">PowerMeter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.PowerMeter"><code class="docutils literal notranslate"><span class="pre">PowerMeter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.PowerEvent"><code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#np">NP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Mesh"><code class="docutils literal notranslate"><span class="pre">Mesh</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Info"><code class="docutils literal notranslate"><span class="pre">Info</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Ident"><code class="docutils literal notranslate"><span class="pre">Ident</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.NpSpace"><code class="docutils literal notranslate"><span class="pre">NpSpace</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Type"><code class="docutils literal notranslate"><span class="pre">Type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.MemoryInfo"><code class="docutils literal notranslate"><span class="pre">MemoryInfo</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.Component"><code class="docutils literal notranslate"><span class="pre">Component</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.NP.SramSize"><code class="docutils literal notranslate"><span class="pre">SramSize</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#mapping">Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.MapMode"><code class="docutils literal notranslate"><span class="pre">MapMode</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#akida.MapConstraints"><code class="docutils literal notranslate"><span class="pre">MapConstraints</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#akida-version">Akida version</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.AkidaVersion"><code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.get_akida_version"><code class="docutils literal notranslate"><span class="pre">get_akida_version()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.set_akida_version"><code class="docutils literal notranslate"><span class="pre">set_akida_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#conversion">Conversion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.convert"><code class="docutils literal notranslate"><span class="pre">convert()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#cnn2snn.check_model_compatibility"><code class="docutils literal notranslate"><span class="pre">check_model_compatibility()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#temporal-convolution">Temporal convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizer-dequantizer">Quantizer/Dequantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#reset-buffers">Reset buffers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#id2">Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizeml.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizeml.save_model"><code class="docutils literal notranslate"><span class="pre">save_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#analysis">Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#metrics">Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#spatiotemporal-blocks">Spatiotemporal blocks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.distiller.Distiller"><code class="docutils literal notranslate"><span class="pre">Distiller</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#sparsity">Sparsity</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.sparsity.compute_sparsity"><code class="docutils literal notranslate"><span class="pre">compute_sparsity()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.load_weights"><code class="docutils literal notranslate"><span class="pre">load_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.save_weights"><code class="docutils literal notranslate"><span class="pre">save_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.model_io.get_model_path"><code class="docutils literal notranslate"><span class="pre">get_model_path()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#utils">Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.fetch_file"><code class="docutils literal notranslate"><span class="pre">fetch_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.get_tensorboard_callback"><code class="docutils literal notranslate"><span class="pre">get_tensorboard_callback()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akida_models.utils.get_params_by_version"><code class="docutils literal notranslate"><span class="pre">get_params_by_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#mobilenet">MobileNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#spatiotemporal-tenns">Spatiotemporal TENNs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/tenns_modules_apis.html">TENNs modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#spatiotemporal-blocks">Spatiotemporal blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.SpatialBlock"><code class="docutils literal notranslate"><span class="pre">SpatialBlock</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.TemporalBlock"><code class="docutils literal notranslate"><span class="pre">TemporalBlock</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.SpatioTemporalBlock"><code class="docutils literal notranslate"><span class="pre">SpatioTemporalBlock</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#export">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/tenns_modules_apis.html#tenns_modules.export_to_onnx"><code class="docutils literal notranslate"><span class="pre">export_to_onnx()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#convert">3. Convert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-tf-keras-model">3. Load a pre-trained quantized TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-tf-keras-model">3. Load a pre-trained quantized TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-native-tf-keras-model">2. Load a pre-trained native TF-Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#handling-input-types">3. Handling input types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#convert-to-akida">5. Convert to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#spatiotemporal-examples">Spatiotemporal examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html">Gesture recognition with spatiotemporal models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#introduction-why-spatiotemporal-models">1. Introduction: why spatiotemporal models?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#spatiotemporal-blocks-the-core-concept">2. Spatiotemporal blocks: the core concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#building-the-model-from-blocks-to-network">3. Building the model: from blocks to network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#gesture-classification-in-videos">4. Gesture classification in videos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#training-and-evaluating-the-model">5. Training and evaluating the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#streaming-inference-making-real-time-predictions">6. Streaming inference: making real-time predictions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#visualizing-the-predictions-of-the-model-in-real-time">7. Visualizing the predictions of the model in real time</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#quantizing-the-model-and-convertion-to-akida">8. Quantizing the model and convertion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_0_introduction_to_spatiotemporal_models.html#final-thoughts-generalizing-the-approach">9. Final thoughts: generalizing the approach</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html">Efficient online eye tracking with a lightweight spatiotemporal network and event cameras</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#network-architecture">2. Network architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#dataset-and-preprocessing">3. Dataset and preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#model-training-evaluation">4. Model training &amp; evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#official-competition-results">5. Official competition results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#ablation-studies-and-efficiency-optimization">6. Ablation studies and efficiency optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#fifo-buffering-for-streaming-inference">7. FIFO buffering for streaming inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/spatiotemporal/plot_1_eye_tracking_cvpr.html#quantization-and-conversion-to-akida">8. Quantization and conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples-akida-1-0-only">Edge examples (Akida 1.0 only)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id4">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id11">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id12"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id13">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#tenns-icon-ref-tenns"> TENNs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#gesture-recognition">Gesture recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#eye-tracking">Eye tracking</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#metatf-beta">MetaTF Beta</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://developer.brainchip.com/support/">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #000000" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="user_guide.html">User guide</a></li>
      <li class="breadcrumb-item active">Akida user guide</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="akida-user-guide">
<h1>Akida user guide<a class="headerlink" href="#akida-user-guide" title="Link to this heading"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>Like many other machine learning frameworks, the core data structures of Akida are layers and
models, and users familiar with Keras, Tensorflow or Pytorch should be on familiar ground.</p>
<p>The main difference between Akida and other machine learning networks is that inputs and weights are
integers and it only performs integer operations, so that it can further reduce the power
consumption and memory footprint. Since quantization and ReLU activation functions lead to a
substantial sparsity, Akida takes advantage of this by implementing operations in biologically
inspired event-based calculations. However, to simplify the user experience, the model weights and
the inputs are represented as integer tensors (Numpy arrays), similar to what you would see in other
machine learning frameworks.</p>
<p>Going from the standard deep learning world to Akida world is done by following simple steps:</p>
<ul class="simple">
<li><p>build a model using TF-Keras or optionally using a model from the
<a class="reference external" href="./akida_models.html">Brainchip zoo</a></p></li>
<li><p>quantize the model using the <a class="reference external" href="./quantizeml.html">QuantizeML toolkit</a></p></li>
<li><p>convert the model to Akida using the <a class="reference external" href="./cnn2snn.html">CNN2SNN toolkit</a></p></li>
</ul>
<figure class="align-center" id="id1">
<a class="reference external image-reference" href="../_images/overall_flow.png"><img alt="Overall flow" src="../_images/overall_flow.png" style="width: 846.6px; height: 323.4px;" />
</a>
<figcaption>
<p><span class="caption-text">Akida workflow</span><a class="headerlink" href="#id1" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>A practical example of the overall flow is given in the examples section, see the <a class="reference external" href="../examples/general/plot_0_global_workflow.html#sphx-glr-examples-general-plot-0-global-workflow-py">workflow tutorial</a>.</p>
</section>
<section id="programming-interface">
<h2>Programming interface<a class="headerlink" href="#programming-interface" title="Link to this heading"></a></h2>
<section id="the-akida-model">
<h3>The Akida Model<a class="headerlink" href="#the-akida-model" title="Link to this heading"></a></h3>
<p>Similar to other deep learning frameworks, Akida offers a
<a class="reference external" href="../api_reference/akida_apis.html#model">Model</a> grouping layers into an object with inference
features.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> object has basic features such as:</p>
<ul>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Model.summary">summary()</a> method that prints a
description of the model architecture.</p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Model.save">save()</a> method that needs a path for the
model and that allows saving to disk for future use. The model will be saved as a file with an
<code class="docutils literal notranslate"><span class="pre">.fbz</span></code> extension. A saved model can be reloaded using the <code class="docutils literal notranslate"><span class="pre">Model</span></code> object constructor with the
full path of the saved file as a string argument. This will automatically load the model weights.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">akida</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;my_model.fbz&quot;</span><span class="p">)</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="s2">&quot;my_model.fbz&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Model.forward">forward</a> method to generate the outputs
for a specific set of inputs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Prepare one sample</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="c1"># Inference</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Model.predict">predict</a> method is very similar to the
forward method, but is specifically designed to replicate the float outputs of a converted CNN.</p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Model.statistics">statistics</a> member provides relevant
inference statistics.</p></li>
</ul>
</section>
<section id="akida-layers">
<h3>Akida layers<a class="headerlink" href="#akida-layers" title="Link to this heading"></a></h3>
<p>The sections below list the available layers for Akida 1.0 and Akida 2.0. Those layers are obtained
from converting a quantized model to Akida and are thus automatically defined during conversion.
Akida layers only perform integer operations using 8-bit or 4-bit quantized inputs and weights. The
exception is FullyConnected layers performing edge learning (1.0 only), where both inputs and
weights are 1-bit.</p>
<section id="akida-1-0-layers">
<h4>Akida 1.0 layers<a class="headerlink" href="#akida-1-0-layers" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.InputData">InputData</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.InputConvolutional">InputConvolutional</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.FullyConnected">FullyConnected</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Convolutional">Convolutional</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.SeparableConvolutional">SeparableConvolutional</a></p></li>
</ul>
</section>
<section id="akida-2-0-layers">
<h4>Akida 2.0 layers<a class="headerlink" href="#akida-2-0-layers" title="Link to this heading"></a></h4>
<ul class="simple">
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.InputData">InputData</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.InputConv2D">InputConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Conv2D">Conv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Conv2DTranspose">Conv2DTranspose</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Dense1D">Dense1D</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.DepthwiseConv2D">DepthwiseConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.DepthwiseConv2DTranspose">DepthwiseConv2DTranspose</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.BufferTempConv">BufferTempConv</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.DepthwiseBufferTempConv">DepthwiseBufferTempConv</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Add">Add</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Concatenate">Concatenate</a></p></li>
<li><p><a class="reference external" href="../api_reference/akida_apis.html#akida.Dequantizer">Dequantizer</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While Akida 1.0 layers only supported bounded ReLU activations, Akida 2.0 layers support unbounded
ReLU as well as a wider range of activation functions through a look-up-table (LUT): GeLU, SiLU
(Swish), HardSiLU, LeakyReLU and PReLU (with a fixed slope).</p>
</div>
</section>
</section>
</section>
<section id="model-hardware-mapping">
<h2>Model Hardware Mapping<a class="headerlink" href="#model-hardware-mapping" title="Link to this heading"></a></h2>
<p>By default, Akida models are implicitly mapped on a software backend: in other words, their
inference is computed on the host CPU.</p>
<section id="devices">
<h3>Devices<a class="headerlink" href="#devices" title="Link to this heading"></a></h3>
<p>In order to perform model inference on hardware, the corresponding <code class="docutils literal notranslate"><span class="pre">Model</span></code> object must first be
mapped on a specific <code class="docutils literal notranslate"><span class="pre">Device</span></code>.</p>
<p>The Akida <code class="docutils literal notranslate"><span class="pre">Device</span></code> represents a device object that holds a version and the hardware topology of the
mesh. The main properties of such object are:</p>
<ul class="simple">
<li><p>its <a class="reference external" href="../api_reference/akida_apis.html#hwversion">hardware version</a>,</p></li>
<li><p>the description of its <a class="reference external" href="../api_reference/akida_apis.html#akida.NP.Mesh">mesh</a> of
processing nodes.</p></li>
</ul>
<section id="discovering-hardware-devices">
<h4>Discovering Hardware Devices<a class="headerlink" href="#discovering-hardware-devices" title="Link to this heading"></a></h4>
<p>The list of hardware devices detected on a specific host is available using the
<a class="reference external" href="../api_reference/akida_apis.html#akida.devices">devices()</a> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">akida</span><span class="w"> </span><span class="kn">import</span> <span class="n">devices</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
</pre></div>
</div>
<p>It is also possible to list the available devices using a command in a terminal:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>akida<span class="w"> </span>devices
</pre></div>
</div>
</section>
<section id="virtual-devices">
<h4>Virtual Devices<a class="headerlink" href="#virtual-devices" title="Link to this heading"></a></h4>
<p>Most of the time, <code class="docutils literal notranslate"><span class="pre">Device</span></code> objects are real hardware devices, but virtual devices can also be
created to allow the mapping of a <code class="docutils literal notranslate"><span class="pre">Model</span></code> on a host that is not connected to a hardware device.</p>
<p>It is possible to build a virtual device for known hardware devices, by calling functions
<a class="reference external" href="../api_reference/akida_apis.html#akida.AKD1000">AKD1000()</a>,
<a class="reference external" href="../api_reference/akida_apis.html#akida.AKD1500">AKD1500()</a> and
<a class="reference external" href="../api_reference/akida_apis.html#akida.TwoNodesIPv1">TwoNodesIPv1()</a> for 1.0 or
<a class="reference external" href="../api_reference/akida_apis.html#akida.TwoNodesIPv2">TwoNodesIPv2()</a>, and
<a class="reference external" href="../api_reference/akida_apis.html#akida.SixNodesIPv2">SixNodesIPv2()</a>, for 2.0. Alternatively,
a custom virtual device can be created using <a class="reference external" href="../api_reference/akida_apis.html#akida.create_device">create_device</a>.</p>
</section>
</section>
<section id="model-mapping">
<h3>Model mapping<a class="headerlink" href="#model-mapping" title="Link to this heading"></a></h3>
<p>Mapping a model on a specific device is as simple as calling the <code class="docutils literal notranslate"><span class="pre">Model</span></code>
<a class="reference external" href="../api_reference/akida_apis.html#akida.Model.map">.map()</a> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>When mapping a model on a device, if the Model is too big to fit on the device or contains layers
that are not hardware compatible, it will be split into multiple parts called sequences.</p>
<p>The number of sequences, program size for each and how they are mapped are included in
the <code class="docutils literal notranslate"><span class="pre">Model</span></code> <a class="reference external" href="../api_reference/akida_apis.html#akida.Model.summary">.summary()</a> output after it
has been mapped on a device.</p>
</section>
<section id="advanced-mapping-details-and-hardware-devices-usage">
<h3>Advanced Mapping Details and Hardware Devices Usage<a class="headerlink" href="#advanced-mapping-details-and-hardware-devices-usage" title="Link to this heading"></a></h3>
<p>When <code class="docutils literal notranslate"><span class="pre">Model</span></code> <a class="reference external" href="../api_reference/akida_apis.html#akida.Model.map">.map()</a>  results in more than
one hardware sequence, on inference each sequence will be chain loaded onto the device to process a
given input. Sequences can be obtained using the <code class="docutils literal notranslate"><span class="pre">Model</span></code>
<a class="reference external" href="../api_reference/akida_apis.html#akida.Model.sequences">.sequences()</a> property, that will return
a list of sequence objects. The program used to load one sequence can be obtained programmatically.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">sequences</span><span class="p">))</span>
<span class="c1"># Assume there is at least one sequence.</span>
<span class="n">sequence</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sequences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Check program size</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="o">.</span><span class="n">program</span><span class="p">))</span>
</pre></div>
</div>
<p>Once the model has been mapped, the sequences mapped in the Hardware run on the device,
and the sequences mapped in the Software run on the CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Where mapping to a single on-hardware sequence is necessary, one can force an exception to be
raised if that fails by setting the <code class="docutils literal notranslate"><span class="pre">hw_only</span></code> parameter to True (default False). See the
<a class="reference external" href="../api_reference/akida_apis.html#akida.Model.map">.map()</a> method API for more details.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">hw_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>By default, the mapping uses the <a class="reference external" href="../api_reference/akida_apis.html#akida.MapMode.AllNps">MapMode.AllNps</a> mode that targets a higher throughput,
lower latency, and better NP concurrent utilization but an optimal mapping depends on the system
characteristics. The other modes <a class="reference external" href="../api_reference/akida_apis.html#akida.MapMode.HwPr">MapMode.HwPr</a> and <a class="reference external" href="../api_reference/akida_apis.html#akida.MapMode.Minimal">MapMode.Minimal</a> will respectively leverage the NP
concurrent utilization along with partial reconfiguration (multipass) and use as few hardware
resources as possible.</p>
<p>Once the model has been mapped, the inference happens only on the device, and not on the host
CPU except for passing inputs and fetching outputs.</p>
</section>
<section id="performance-measurement">
<h3>Performance measurement<a class="headerlink" href="#performance-measurement" title="Link to this heading"></a></h3>
<p>Performance measures (FPS and power) are available for on-device inference.</p>
<p>Enabling power measurement is simply done by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span><span class="o">.</span><span class="n">soc</span><span class="o">.</span><span class="n">power_measurement_enabled</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<p>After sending data for inference, performance measurements can be retrieved
from the <a class="reference external" href="../api_reference/akida_apis.html#akida.Model.statistics">model statistics</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_akida</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_akida</span><span class="o">.</span><span class="n">statistics</span><span class="p">)</span>
</pre></div>
</div>
<p>An example of power and FPS measurements is given in the <a class="reference external" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">AkidaNet/ImageNet
tutorial</a>.</p>
</section>
<section id="command-line-interface-for-model-evaluation">
<h3>Command-line interface for model evaluation<a class="headerlink" href="#command-line-interface-for-model-evaluation" title="Link to this heading"></a></h3>
<p>In addition to the aforementioned APIs, the akida python package provides a command-line interface
for <a class="reference external" href="../api_reference/akida_apis.html#akida.Model.map">mapping</a> a model to the available
<a class="reference external" href="../api_reference/akida_apis.html#akida.devices">device</a> and sending data for inference so that
hardware details can be retrieved.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>akida<span class="w"> </span>run<span class="w"> </span>-h

usage:<span class="w"> </span>akida<span class="w"> </span>run<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span>-m<span class="w"> </span>MODEL<span class="w"> </span><span class="o">[</span>-i<span class="w"> </span>INPUT<span class="o">]</span>

options:
<span class="w">    </span>-h,<span class="w"> </span>--help<span class="w">              </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">    </span>-m<span class="w"> </span>MODEL,<span class="w"> </span>--model<span class="w"> </span>MODEL<span class="w"> </span>The<span class="w"> </span><span class="nb">source</span><span class="w"> </span>model<span class="w"> </span>path
<span class="w">    </span>-i<span class="w"> </span>INPUT,<span class="w"> </span>--input<span class="w"> </span>INPUT<span class="w"> </span>Input<span class="w"> </span>image<span class="w"> </span>or<span class="w"> </span>a<span class="w"> </span>numpy<span class="w"> </span>array
</pre></div>
</div>
<div class="line-block">
<div class="line">If no input data is provided a random sample will be generated and used for inference.</div>
<div class="line">CLI outputs a summary of the mapped model with details regarding NP units allocation,
<a class="reference external" href="../api_reference/akida_apis.html#akida.Model.statistics">statistics</a> and
<a class="reference external" href="../api_reference/akida_apis.html#akida.HardwareDevice.metrics">metrics</a>.</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>About the model statistics:</p>
<ul class="simple">
<li><p>it shows the inference power/energy when measurable (i.e. whenever the inference
is lasting long enough to collect meaningful data),</p></li>
<li><p>displayed numbers include the floor power.</p></li>
</ul>
</div>
<div class="line-block">
<div class="line">The two examples below show:</div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>the CLI output using a pretrained DS-CNN model and a random input</p></li>
<li><p>the CLI output using a pretrained AkidaNet model and a 10 images input</p></li>
</ul>
</div></blockquote>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://data.brainchip.com/models/AkidaV1/ds_cnn/ds_cnn_kws_i8_w4_a4_laq1.h5
<span class="nv">CNN2SNN_TARGET_AKIDA_VERSION</span><span class="o">=</span>v1<span class="w"> </span>cnn2snn<span class="w"> </span>convert<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws_i8_w4_a4_laq1.h5
akida<span class="w"> </span>run<span class="w"> </span>-m<span class="w"> </span>ds_cnn_kws_i8_w4_a4_laq1.fbz

<span class="w">     </span>Model<span class="w"> </span>Summary<span class="w"> </span><span class="c1"># Summary with NP units allocation</span>
<span class="w">     </span>_______________________________________________________________________________________
<span class="w">     </span>Input<span class="w"> </span>shape<span class="w">  </span>Output<span class="w"> </span>shape<span class="w">  </span>Sequences<span class="w">  </span>Layers<span class="w">  </span>NPs<span class="w">  </span>Skip<span class="w"> </span>DMAs<span class="w">  </span>External<span class="w"> </span>Memory<span class="w"> </span><span class="o">(</span>Bytes<span class="o">)</span>
<span class="w">     </span><span class="o">=======================================================================================</span>
<span class="w">     </span><span class="o">[</span><span class="m">49</span>,<span class="w"> </span><span class="m">10</span>,<span class="w"> </span><span class="m">1</span><span class="o">]</span><span class="w">  </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">33</span><span class="o">]</span><span class="w">    </span><span class="m">1</span><span class="w">          </span><span class="m">6</span><span class="w">       </span><span class="m">65</span><span class="w">   </span><span class="m">0</span><span class="w">          </span><span class="m">0</span>
<span class="w">     </span>_______________________________________________________________________________________

<span class="w">     </span>_________________________
<span class="w">     </span>Component<span class="w"> </span><span class="o">(</span><span class="nb">type</span><span class="o">)</span><span class="w">  </span><span class="nv">Count</span>
<span class="w">     </span><span class="o">=========================</span>
<span class="w">     </span>HRC<span class="w">               </span><span class="m">1</span>
<span class="w">     </span>_________________________
<span class="w">     </span>CNP1<span class="w">              </span><span class="m">64</span>
<span class="w">     </span>_________________________
<span class="w">     </span>FNP3<span class="w">              </span><span class="m">1</span>
<span class="w">     </span>_________________________

<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>Layer<span class="w"> </span><span class="o">(</span><span class="nb">type</span><span class="o">)</span><span class="w">             </span>Output<span class="w"> </span>shape<span class="w">  </span>Kernel<span class="w"> </span>shape<span class="w">    </span><span class="nv">Components</span>

<span class="w">     </span><span class="o">=========</span><span class="w"> </span>HW/conv_0-dense_5<span class="w"> </span><span class="o">(</span>Hardware<span class="o">)</span><span class="w"> </span>-<span class="w"> </span>size:<span class="w"> </span><span class="m">88748</span><span class="w"> </span><span class="nv">bytes</span><span class="w"> </span><span class="o">========</span>

<span class="w">     </span>conv_0<span class="w"> </span><span class="o">(</span>InputConv.<span class="o">)</span><span class="w">      </span><span class="o">[</span><span class="m">25</span>,<span class="w"> </span><span class="m">5</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">5</span>,<span class="w"> </span><span class="m">5</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span><span class="w">   </span><span class="m">1</span><span class="w"> </span>HRC
<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>separable_1<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">25</span>,<span class="w"> </span><span class="m">5</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">   </span><span class="m">16</span><span class="w"> </span>CNP1
<span class="w">     </span>___________________________________________________________________
<span class="w">                                           </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span>
<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>separable_2<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">25</span>,<span class="w"> </span><span class="m">5</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">   </span><span class="m">16</span><span class="w"> </span>CNP1
<span class="w">     </span>___________________________________________________________________
<span class="w">                                           </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span>
<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>separable_3<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">25</span>,<span class="w"> </span><span class="m">5</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">   </span><span class="m">16</span><span class="w"> </span>CNP1
<span class="w">     </span>___________________________________________________________________
<span class="w">                                           </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span>
<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>separable_4<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">    </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">   </span><span class="m">16</span><span class="w"> </span>CNP1
<span class="w">     </span>___________________________________________________________________
<span class="w">                                           </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span>
<span class="w">     </span>___________________________________________________________________
<span class="w">     </span>dense_5<span class="w"> </span><span class="o">(</span>Fully.<span class="o">)</span><span class="w">         </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">33</span><span class="o">]</span><span class="w">    </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">33</span><span class="o">)</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>FNP3
<span class="w">     </span>___________________________________________________________________


<span class="w">     </span>No<span class="w"> </span>input<span class="w"> </span>provided,<span class="w"> </span>using<span class="w"> </span>random<span class="w"> </span>data.

<span class="w">     </span>Floor<span class="w"> </span>power<span class="w"> </span><span class="o">(</span>mW<span class="o">)</span>:<span class="w"> </span><span class="m">914</span>.03<span class="w">                </span><span class="c1"># Reference board floor power</span>
<span class="w">     </span>Average<span class="w"> </span><span class="nv">framerate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">62</span>.50<span class="w"> </span>fps<span class="w">           </span><span class="c1"># Model statistics</span>

<span class="w">     </span>Model<span class="w"> </span>metrics:<span class="w">                          </span><span class="c1"># Model metrics:</span>
<span class="w">       </span>inference_frames:<span class="w"> </span><span class="m">1</span><span class="w">                   </span><span class="c1">#  - number of frames sent for inference</span>
<span class="w">       </span>inference_clk:<span class="w"> </span><span class="m">93965</span><span class="w">                  </span><span class="c1">#  - number of hardware clocks used for inference</span>
<span class="w">       </span>program_clk:<span class="w"> </span><span class="m">152396</span><span class="w">                   </span><span class="c1">#  - number of hardware clocks used for model programming</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>https://data.brainchip.com/models/AkidaV1/akidanet/akidanet_imagenet_224_alpha_50_iq8_wq4_aq4.h5
wget<span class="w"> </span>https://data.brainchip.com/dataset-mirror/imagenet_like/imagenet_like.npy
<span class="nv">CNN2SNN_TARGET_AKIDA_VERSION</span><span class="o">=</span>v1<span class="w"> </span>cnn2snn<span class="w"> </span>convert<span class="w"> </span>-m<span class="w"> </span>akidanet_imagenet_224_alpha_50_iq8_wq4_aq4.h5
akida<span class="w"> </span>run<span class="w"> </span>-m<span class="w"> </span>akidanet_imagenet_224_alpha_50_iq8_wq4_aq4.fbz<span class="w"> </span>-i<span class="w"> </span>imagenet_like.npy

<span class="w">     </span>Model<span class="w"> </span>Summary<span class="w"> </span><span class="c1"># Summary with NP units allocation</span>
<span class="w">     </span>_________________________________________________________________________________________
<span class="w">     </span>Input<span class="w"> </span>shape<span class="w">    </span>Output<span class="w"> </span>shape<span class="w">  </span>Sequences<span class="w">  </span>Layers<span class="w">  </span>NPs<span class="w">  </span>Skip<span class="w"> </span>DMAs<span class="w">  </span>External<span class="w"> </span>Memory<span class="w"> </span><span class="o">(</span>Bytes<span class="o">)</span>
<span class="w">     </span><span class="o">=========================================================================================</span>
<span class="w">     </span><span class="o">[</span><span class="m">224</span>,<span class="w"> </span><span class="m">224</span>,<span class="w"> </span><span class="m">3</span><span class="o">]</span><span class="w">  </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1000</span><span class="o">]</span><span class="w">  </span><span class="m">1</span><span class="w">          </span><span class="m">15</span><span class="w">      </span><span class="m">68</span><span class="w">   </span><span class="m">0</span><span class="w">          </span><span class="m">400000</span>
<span class="w">     </span>_________________________________________________________________________________________

<span class="w">     </span>_________________________
<span class="w">     </span>Component<span class="w"> </span><span class="o">(</span><span class="nb">type</span><span class="o">)</span><span class="w">  </span><span class="nv">Count</span>
<span class="w">     </span><span class="o">=========================</span>
<span class="w">     </span>HRC<span class="w">               </span><span class="m">1</span>
<span class="w">     </span>_________________________
<span class="w">     </span>CNP1<span class="w">              </span><span class="m">67</span>
<span class="w">     </span>_________________________
<span class="w">     </span>FNP2<span class="w">              </span><span class="m">1</span>
<span class="w">     </span>_________________________

<span class="w">               </span>External<span class="w"> </span>Memory<span class="w"> </span>Summary
<span class="w">     </span>______________________________________________
<span class="w">     </span>Layer<span class="w"> </span><span class="o">(</span><span class="nb">type</span><span class="o">)</span><span class="w">         </span>External<span class="w"> </span>Memory<span class="w"> </span><span class="o">(</span>Bytes<span class="o">)</span>
<span class="w">     </span><span class="o">==============================================</span>
<span class="w">     </span>classifier<span class="w"> </span><span class="o">(</span>Fully.<span class="o">)</span><span class="w">  </span><span class="m">400000</span>
<span class="w">     </span>______________________________________________

<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>Layer<span class="w"> </span><span class="o">(</span><span class="nb">type</span><span class="o">)</span><span class="w">              </span>Output<span class="w"> </span>shape<span class="w">    </span>Kernel<span class="w"> </span>shape<span class="w">       </span><span class="nv">Components</span>

<span class="w">     </span><span class="o">=========</span><span class="w"> </span>HW/conv_0-classifier<span class="w"> </span><span class="o">(</span>Hardware<span class="o">)</span><span class="w"> </span>-<span class="w"> </span>size:<span class="w"> </span><span class="m">1361244</span><span class="w"> </span><span class="nv">bytes</span><span class="w"> </span><span class="o">=========</span>

<span class="w">     </span>conv_0<span class="w"> </span><span class="o">(</span>InputConv.<span class="o">)</span><span class="w">       </span><span class="o">[</span><span class="m">112</span>,<span class="w"> </span><span class="m">112</span>,<span class="w"> </span><span class="m">16</span><span class="o">]</span><span class="w">  </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">16</span><span class="o">)</span><span class="w">      </span><span class="m">1</span><span class="w"> </span>HRC
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>conv_1<span class="w"> </span><span class="o">(</span>Conv.<span class="o">)</span><span class="w">            </span><span class="o">[</span><span class="m">112</span>,<span class="w"> </span><span class="m">112</span>,<span class="w"> </span><span class="m">32</span><span class="o">]</span><span class="w">  </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">16</span>,<span class="w"> </span><span class="m">32</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>conv_2<span class="w"> </span><span class="o">(</span>Conv.<span class="o">)</span><span class="w">            </span><span class="o">[</span><span class="m">56</span>,<span class="w"> </span><span class="m">56</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">    </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">32</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span><span class="w">     </span><span class="m">6</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>conv_3<span class="w"> </span><span class="o">(</span>Conv.<span class="o">)</span><span class="w">            </span><span class="o">[</span><span class="m">56</span>,<span class="w"> </span><span class="m">56</span>,<span class="w"> </span><span class="m">64</span><span class="o">]</span><span class="w">    </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">64</span><span class="o">)</span><span class="w">     </span><span class="m">3</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_4<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">28</span>,<span class="w"> </span><span class="m">28</span>,<span class="w"> </span><span class="m">128</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">      </span><span class="m">6</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">64</span>,<span class="w"> </span><span class="m">128</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_5<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">28</span>,<span class="w"> </span><span class="m">28</span>,<span class="w"> </span><span class="m">128</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">128</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">128</span>,<span class="w"> </span><span class="m">128</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_6<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">128</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">8</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">128</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_7<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_8<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_9<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">   </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_10<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_11<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">14</span>,<span class="w"> </span><span class="m">14</span>,<span class="w"> </span><span class="m">256</span><span class="o">]</span><span class="w">   </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">4</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">256</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_12<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">7</span>,<span class="w"> </span><span class="m">7</span>,<span class="w"> </span><span class="m">512</span><span class="o">]</span><span class="w">     </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">8</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="m">512</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>separable_13<span class="w"> </span><span class="o">(</span>Sep.Conv.<span class="o">)</span><span class="w">  </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">512</span><span class="o">]</span><span class="w">     </span><span class="o">(</span><span class="m">3</span>,<span class="w"> </span><span class="m">3</span>,<span class="w"> </span><span class="m">512</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="w">     </span><span class="m">8</span><span class="w"> </span>CNP1
<span class="w">     </span>_________________________________________________________________________
<span class="w">                                               </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">512</span>,<span class="w"> </span><span class="m">512</span><span class="o">)</span>
<span class="w">     </span>_________________________________________________________________________
<span class="w">     </span>classifier<span class="w"> </span><span class="o">(</span>Fully.<span class="o">)</span><span class="w">       </span><span class="o">[</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">1000</span><span class="o">]</span><span class="w">    </span><span class="o">(</span><span class="m">1</span>,<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="m">512</span>,<span class="w"> </span><span class="m">1000</span><span class="o">)</span><span class="w">  </span><span class="m">1</span><span class="w"> </span>FNP2
<span class="w">     </span>_________________________________________________________________________



<span class="w">     </span>Floor<span class="w"> </span>power<span class="w"> </span><span class="o">(</span>mW<span class="o">)</span>:<span class="w"> </span><span class="m">912</span>.23<span class="w">                </span><span class="c1"># Reference board floor power</span>
<span class="w">     </span>Average<span class="w"> </span><span class="nv">framerate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">43</span>.48<span class="w"> </span>fps<span class="w">           </span><span class="c1"># Model statistics</span>
<span class="w">     </span>Last<span class="w"> </span>inference<span class="w"> </span>power<span class="w"> </span>range<span class="w"> </span><span class="o">(</span>mW<span class="o">)</span>:<span class="w">  </span>Avg<span class="w"> </span><span class="m">1021</span>.00<span class="w"> </span>/<span class="w"> </span>Min<span class="w"> </span><span class="m">925</span>.00<span class="w"> </span>/<span class="w"> </span>Max<span class="w"> </span><span class="m">1117</span>.00<span class="w"> </span>/<span class="w"> </span>Std<span class="w"> </span><span class="m">135</span>.76
<span class="w">     </span>Last<span class="w"> </span>inference<span class="w"> </span>energy<span class="w"> </span>consumed<span class="w"> </span><span class="o">(</span>mJ/frame<span class="o">)</span>:<span class="w"> </span><span class="m">23</span>.48

<span class="w">     </span>Model<span class="w"> </span>metrics:<span class="w">                          </span><span class="c1"># Model metrics:</span>
<span class="w">       </span>inference_frames:<span class="w"> </span><span class="m">10</span><span class="w">                  </span><span class="c1">#  - number of frames sent for inference</span>
<span class="w">       </span>inference_clk:<span class="w"> </span><span class="m">43000636</span><span class="w">               </span><span class="c1">#  - number of hardware clocks used for inference</span>
<span class="w">       </span>program_clk:<span class="w"> </span><span class="m">998079</span><span class="w">                   </span><span class="c1">#  - number of hardware clocks used for model programming</span>
</pre></div>
</div>
</section>
</section>
<section id="using-akida-edge-learning">
<h2>Using Akida Edge learning<a class="headerlink" href="#using-akida-edge-learning" title="Link to this heading"></a></h2>
<p>Akida Edge learning is a unique feature of the Akida IP, whereby a classifier layer is enabled for
ongoing (continual) learning in the on-device setting, allowing the addition of new classes in the
wild. As with any transfer learning or domain adaptation task, best results will be obtained if the
Akida Edge layer is added as the final layer of a standard pretrained CNN backbone. An unusual
aspect is that the backbone needs an extra layer added and trained, to generate binary inputs to the
Edge layer.</p>
<p>In this mode, an Akida Layer will typically be compiled with specific learning parameters and then
undergo a period of feed-forward unsupervised or semi-supervised training by letting it process
inputs generated by previous layers from a relevant dataset.</p>
<p>Once a layer has been compiled, new learning episodes can be resumed at any time, even after the
model has been saved and reloaded.</p>
<section id="learning-constraints">
<h3>Learning constraints<a class="headerlink" href="#learning-constraints" title="Link to this heading"></a></h3>
<p>Only the last layer of a model can be trained with Akida Edge Learning and must fulfill the
following constraints:</p>
<ul class="simple">
<li><p>must be of type <a class="reference external" href="../api_reference/akida_apis.html#akida.FullyConnected">FullyConnected</a>,</p></li>
<li><p>must have binary weight,</p></li>
<li><p>must receive binary inputs.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>a FullyConnected layer can only be added to a model defined using Akida 1.0 layers</p></li>
<li><p>it is only possible to obtain a FullyConnected layer from conversion when target version is
set to <a class="reference external" href="../api_reference/cnn2snn_apis.html#cnn2snn.AkidaVersion.AkidaVersion.v1">AkidaVersion.v1</a></p></li>
</ul>
</div>
</section>
<section id="compiling-a-layer">
<h3>Compiling a layer<a class="headerlink" href="#compiling-a-layer" title="Link to this heading"></a></h3>
<p>For a layer to learn using Akida Edge Learning, it must first be compiled using
the <code class="docutils literal notranslate"><span class="pre">Model</span></code> <a class="reference external" href="../api_reference/akida_apis.html#akida.Model.compile">.compile</a> method.</p>
<p>There is only one optimizer available for the compile method which is
<a class="reference external" href="../api_reference/akida_apis.html#akida.AkidaUnsupervised">AkidaUnsupervised</a> and it offers the
following learning parameters that can be specified when compiling a layer:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_weights</span></code>: integer value which defines the number of connections for
each neuron and is constant across neurons. When determining a value for
<code class="docutils literal notranslate"><span class="pre">num_weights</span></code> note that the total number of available connections for a
<a class="reference external" href="../api_reference/akida_apis.html#akida.Convolutional">Convolutional</a>
layer is not set by the dimensions of the input to the layer, but by the
dimensions of the kernel. Total connections = <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code> x
<code class="docutils literal notranslate"><span class="pre">num_features</span></code>, where <code class="docutils literal notranslate"><span class="pre">num_features</span></code> is typically the <code class="docutils literal notranslate"><span class="pre">filters</span></code> or
<code class="docutils literal notranslate"><span class="pre">units</span></code> of the preceding layer. <code class="docutils literal notranslate"><span class="pre">num_weights</span></code> should be much smaller
than this value  not more than half, and often much less.</p></li>
<li><p>[optional] <code class="docutils literal notranslate"><span class="pre">num_classes</span></code>: integer value, representing the number of
classes in the dataset. Defining this value sets the learning to a labeled
mode, when the layer is initialized. The neurons are divided into groups of
equal size, one for each input data class. When an input packet is sent with a
label included, only the neurons corresponding to that input class are allowed
to learn.</p></li>
<li><p>[optional] <code class="docutils literal notranslate"><span class="pre">initial_plasticity</span></code>: floating-point value, range 01 inclusive
(defaults to 1). It defines the initial plasticity of each neurons
connections or how easily the weights will change when learning occurs;
similar in some ways to a learning rate. Typically, this can be set to 1,
especially if the model is initialized with random weights. Plasticity can
only decrease over time, never increase; if set to 0 learning will never occur
in the model.</p></li>
<li><p>[optional] <code class="docutils literal notranslate"><span class="pre">min_plasticity</span></code>: floating-point value, range 01 inclusive
(defaults to 0.1). It defines the minimum level to which plasticity will decay.</p></li>
<li><p>[optional] <code class="docutils literal notranslate"><span class="pre">plasticity_decay</span></code>: floating-point value, range 01 inclusive
(defaults to 0.25). It defines the decay of plasticity with each learning
step, relative to the <code class="docutils literal notranslate"><span class="pre">initial_plasticity</span></code>.</p></li>
<li><p>[optional] <code class="docutils literal notranslate"><span class="pre">learning_competition</span></code>: floating-point value, range 01 inclusive
(defaults to 0). It controls competition between neurons. This is a rather
subtle parameter since there is always substantial competition in learning
between neurons. This parameter controls the competition from neurons that
have already learned  when set to zero, a neuron that has already learned a
given feature will not prevent other neurons from learning similar features.
As <code class="docutils literal notranslate"><span class="pre">learning_competition</span></code> increases such neurons will exert more
competition. This parameter can, however, have serious unintended consequences
for learning stability; we recommend that it should be kept low, and probably
never exceed 0.5.</p></li>
</ul>
<p>The only mandatory parameter is the number of active (non-zero) connections that
each of the layer neurons has with the previous layer, expressed as the number
of active <code class="docutils literal notranslate"><span class="pre">weights</span></code> for each neuron.</p>
<p>Optimizing this value is key to achieving high accuracy in the Akida NSoC.
Broadly speaking, the number of weights should be related to the number of
events expected to compose the items or items sub-features of interest.</p>
<p>Tips to set Akida learning parameters are detailed in <a class="reference external" href="../examples/edge/plot_2_edge_learning_parameters.html">the dedicated example</a>.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="user_guide.html" class="btn btn-neutral float-left" title="User guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quantizeml.html" class="btn btn-neutral float-right" title="QuantizeML toolkit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>