<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>QuantizeML toolkit &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN2SNN toolkit" href="cnn2snn.html" />
    <link rel="prev" title="Akida user guide" href="akida.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="user_guide.html">User guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#performances-measurement">Performances measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#supported-layer-types">Supported layer types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#yolo-training">YOLO training</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models.html#id1">Layer Blocks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#sparsity">Sparsity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#stdperaxisquantizer">StdPerAxisQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/index.html">General examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html">Regression tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/index.html">CNN2SNN tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/index.html">Edge examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id11">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id12"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../zoo_performances.html#id13">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="user_guide.html">User guide</a></li>
      <li class="breadcrumb-item active">QuantizeML toolkit</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quantizeml-toolkit">
<h1>QuantizeML toolkit<a class="headerlink" href="#quantizeml-toolkit" title="Permalink to this headline"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>QuantizeML package provides base layers and quantization tools for deep-learning models. It  allows
the quantization of CNN, Transformer and TENN models using low-bitwidth weights and outputs. Once
quantized with the provided tools, CNN2SNN toolkit will be able to convert the model and execute it
with Akida runtime.</p>
</section>
<section id="the-fixedpoint-representation">
<h2>The FixedPoint representation<a class="headerlink" href="#the-fixedpoint-representation" title="Permalink to this headline"></a></h2>
<p>QuantizeML uses a FixedPoint representation in place of float values for layers inputs, outputs and
weights.</p>
<p>FixedPoint numbers are actually integers with a static number of fractional bits so that:</p>
<div class="math notranslate nohighlight">
\[x_{float} \approx x_{int}.2^{-x_{frac\_bits}}\]</div>
<p>The precision of the representation is directly related to the number of fractional bits. For
example, representing PI using an 8bit FixedPoint with varying fractional bits:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 23%" />
<col style="width: 42%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>frac_bits</p></th>
<th class="head"><p>x_int</p></th>
<th class="head"><p>float value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>6</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>25</p></td>
<td><p>3.125</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>201</p></td>
<td><p>3.140625</p></td>
</tr>
</tbody>
</table>
<p>Further details are available in the
<a class="reference external" href="../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint API</a> documentation.</p>
<p>Thanks to the FixedPoint representation, all operations within layers are implemented as integer
only operations <a class="footnote-reference brackets" href="#fn-1" id="id1">1</a>.</p>
</section>
<section id="quantization-flow">
<h2>Quantization flow<a class="headerlink" href="#quantization-flow" title="Permalink to this headline"></a></h2>
<p>The first step in the workflow is to train a standard Keras model. This trained model is the
starting point for the quantization stage. Once it is established that the overall model
configuration prior to quantization yields a satisfactory performance on the task, one can proceed
with quantization.</p>
<p>Let’s take the <a class="reference external" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a> model from our zoo that
targets KWS task as an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">fetch_file</span>
<span class="kn">from</span> <span class="nn">quantizeml.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="n">model_file</span> <span class="o">=</span> <span class="n">fetch_file</span><span class="p">(</span><span class="s2">&quot;https://data.brainchip.com/models/AkidaV2/ds_cnn/ds_cnn_kws.h5&quot;</span><span class="p">,</span>
                        <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;ds_cnn_kws.h5&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
</pre></div>
</div>
<p>The QuantizeML toolkit offers a turnkey solution to quantize a model: the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function. It
replaces the Keras layers (or custom QuantizeML layers) with quantized, integer only layers. The
obtained quantized model is still a Keras model that can be evaluated with a standard Keras
pipeline.</p>
<p>The quantization scheme used by
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> can be configured
using
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizationParams">QuantizationParams</a>.
If none is given, an 8bit configuration scheme will be selected.</p>
<p>Here’s an example for 8bit quantization:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">quantizeml.layers</span> <span class="kn">import</span> <span class="n">QuantizationParams</span>
<span class="n">qparams8</span> <span class="o">=</span> <span class="n">QuantizationParams</span><span class="p">(</span><span class="n">input_weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
<p>Here’s an example for 4bit quantization (with first layer weights set to 8bit):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">quantizeml.layers</span> <span class="kn">import</span> <span class="n">QuantizationParams</span>
<span class="n">qparams4</span> <span class="o">=</span> <span class="n">QuantizationParams</span><span class="p">(</span><span class="n">input_weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">weight_bits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation_bits</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that quantizating the first weights to 8bit helps preserving accuracy.</p>
<p>QuantizeML uses a uniform quantization scheme centered on zero. During quantization, the floating
point values are mapped to a given bitwidth quantization space of the form:</p>
<div class="math notranslate nohighlight">
\[data_{float32} = data_{fixed\_point} * scales\]</div>
<p><cite>scales</cite> is a real number used to map the FixedPoint numbers to a quantization space. It is
calculated as follows:</p>
<div class="math notranslate nohighlight">
\[scales = \frac {max(abs(data))}{2^{bitwidth} - 1}\]</div>
<p>Inputs, weights and outputs scales are folded into a single output scale vector.</p>
<p>To avoid saturation in downstream operations throughout a model graph, the bitwidth of intermediary
results is decreased using
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a>. The
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function has
built-in rules to automatically isolate building blocks of layers after which such quantization is
required and will insert the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a>
objects during the quantization process.</p>
<p>To properly operate, an
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.OutputQuantizer">OutputQuantizer</a> must
be calibrated so that it determines an adequate quantization range. Calibration will dertermine the
quantization range statistically. It is possible to pass down samples to the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.quantize">quantize</a> function so that
calibration and quantization are performed simultaneously.</p>
<p>Calibration samples are available on
<a class="reference external" href="https://data.brainchip.com/dataset-mirror/samples/">Brainchip data server</a> for datasets used in
our zoo. They must be downloaded and deserialized before being used for calibration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">fetch_file</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">fetch_file</span><span class="p">(</span><span class="s2">&quot;https://data.brainchip.com/dataset-mirror/samples/kws/kws_batch1024.npz&quot;</span><span class="p">,</span>
                     <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;kws_batch1024.npz&quot;</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">samples</span><span class="p">[</span><span class="n">item</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">files</span><span class="p">])</span>
</pre></div>
</div>
<p>Quantizing the DS-CNN model to 8bit is then done with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">quantizeml.models</span> <span class="kn">import</span> <span class="n">quantize</span>
<span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">qparams</span><span class="o">=</span><span class="n">qparams8</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Please refer to <a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.calibrate">calibrate</a>
for more details on calibration.</p>
<p>Direct quantization of a standard Keras model (also called post-training quantization, PTQ)
generally introduces a drop in performance. This drop is usually small for 8bit or even 4bit
quantization of simple models, but it can be very significant for low quantization bitwidth and
complex models (<a class="reference external" href="../api_reference/akida_models_apis.html#akida_models.akidanet_imagenet">AkidaNet</a>
or <a class="reference external" href="../api_reference/akida_models_apis.html#transformers">transformers</a> architectures).</p>
<p>If the quantized model offers acceptable performance, it can be directly converted into an Akida
model (see the <a class="reference external" href="../api_reference/cnn2snn_apis.html#convert">convert</a> function).</p>
<p>However, if the performance drop is too high, a quantization-aware training (QAT) step is required
to recover the performance prior to quantization. Since the quantized model is a Keras model, it can
then be trained using the standard Keras API.</p>
<p>Check out the <a class="reference external" href="../examples/index.html">examples section</a> for tutorials on quantization, PTQ and
QAT.</p>
<section id="compatibility-constraints">
<h3>Compatibility constraints<a class="headerlink" href="#compatibility-constraints" title="Permalink to this headline"></a></h3>
<p>The tookit supports a wide range of layers (see the
<a class="reference external" href="quantizeml.html#supported-layer-types">supported type section</a>). When hitting a non-compatible
layer, QuantizeML will simply stop the quantization before this layer and add a
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.Dequantizer">Dequantizer</a> before it so
that inference is still possible. When such an event occurs, a warning is raised to the user with the
faulty layer name.</p>
<p>While quantization comes with some restrictions on layer order (e.g. MaxPool2D operation should be
placed before ReLU activation), the
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.transforms.sanitize">sanitize</a> helper is
called before quantization to deal with such restrictions and edit the model accordingly.
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.transforms.sanitize">sanitize</a> will also
handle some layers that are not in the
<a class="reference external" href="quantizeml.html#supported-layer-types">supported layer types</a> such as:</p>
<ul class="simple">
<li><p>ZeroPadding2D which is replaced with ‘same’ padding convolution when possible</p></li>
<li><dl class="simple">
<dt>Lambda layers:</dt><dd><ul>
<li><p>Lambda(relu) or Activation(‘relu’) → ReLU,</p></li>
<li><p>Lambda(transpose) → Permute,</p></li>
<li><p>Lambda(reshape) → Reshape,</p></li>
<li><p>Lambda(add) → Add.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="model-loading">
<h3>Model loading<a class="headerlink" href="#model-loading" title="Permalink to this headline"></a></h3>
<p>The toolkit offers a
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/saving/load_model">keras.models.load_model</a>
wrapper that allows to load models with quantized layers:
<a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.models.load_model">quantizeml.models.load_model</a></p>
</section>
</section>
<section id="command-line-interface">
<h2>Command line interface<a class="headerlink" href="#command-line-interface" title="Permalink to this headline"></a></h2>
<p>In addition to the programming interface, QuantizeML toolkit also provides a command-line interface
to perform quantization, dump a quantized model configuration, check a quantized model and insert a
rescaling layer.</p>
<section id="quantize-cli">
<h3>quantize CLI<a class="headerlink" href="#quantize-cli" title="Permalink to this headline"></a></h3>
<p>Quantizing a model through the CLI uses almost the same arguments as the programing interface but
the quantization parameters are split into the parameters: input weight quantization with “-i”,
weight bitwidth with “-w” and activation bitwidth with the “-a” options.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">8</span><span class="w"> </span>-a<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
<p>Note that without calibration options explicitly given, calibration will happen with 1024 randomly
generated samples. It is generally advised to use real samples serialized in a numpy <cite>.npz</cite> file.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">8</span><span class="w"> </span>-a<span class="w"> </span><span class="m">8</span><span class="w"> </span>-sa<span class="w"> </span>some_samples.npz<span class="w"> </span>-bs<span class="w"> </span><span class="m">128</span><span class="w"> </span>-e<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<p>For akida 1.0 compatibility, it is mandatory to have activations quantized per-tensor instead of
the default per-axis quantization:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-i<span class="w"> </span><span class="m">8</span><span class="w"> </span>-w<span class="w"> </span><span class="m">4</span><span class="w"> </span>-a<span class="w"> </span><span class="m">4</span><span class="w"> </span>--per_tensor_activations
</pre></div>
</div>
</section>
<section id="config-cli">
<h3>config CLI<a class="headerlink" href="#config-cli" title="Permalink to this headline"></a></h3>
<p>Advanced users might want to customize the default quantization pattern and this is made possible by
dumping a quantized model configuration to a <cite>.json</cite> file and quantizing again using the “-c”
option.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>config<span class="w"> </span>-m<span class="w"> </span>model_keras_i8_w8_a8.h5<span class="w"> </span>-o<span class="w"> </span>config.json

...<span class="w"> </span>manual<span class="w"> </span>configuration<span class="w"> </span>changes<span class="w"> </span>...

quantizeml<span class="w"> </span>quantize<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-c<span class="w"> </span>config.json
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Editing a model configuration can be complicated and might have negative effects on quantized
accuracy or even model graph. This should be reserved to users deeply familiar with QuantizeML
concepts.</p>
</div>
</section>
<section id="check-cli">
<h3>check CLI<a class="headerlink" href="#check-cli" title="Permalink to this headline"></a></h3>
<p>It is possible to check for quantization errors using the <cite>check</cite> CLI that will report inaccurate
weight scales quantization or saturation in integer operations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>check<span class="w"> </span>-m<span class="w"> </span>model_keras_i8_w8_a8.h5
</pre></div>
</div>
</section>
<section id="insert-rescaling-cli">
<h3>insert_rescaling CLI<a class="headerlink" href="#insert-rescaling-cli" title="Permalink to this headline"></a></h3>
<p>Some models might not include a Rescaling layer in their architecture and have a separated
preprocessing pipeline (ie. moving from [0, 255] images to a [-1, 1] normalized representation). As
having a rescaling layer might be useful, QuantizeML offers the <cite>insert_rescaling</cite> CLI that will add
a Rescaling layer at the beginning of a given model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>quantizeml<span class="w"> </span>insert_rescaling<span class="w"> </span>-m<span class="w"> </span>model_keras.h5<span class="w"> </span>-s<span class="w"> </span><span class="m">0</span>.007843<span class="w"> </span>-o<span class="w"> </span>-1<span class="w"> </span>-d<span class="w"> </span>model_updated.h5
</pre></div>
</div>
<p>where <span class="math notranslate nohighlight">\(0.007843 = 1/127.5\)</span>.</p>
</section>
</section>
<section id="supported-layer-types">
<h2>Supported layer types<a class="headerlink" href="#supported-layer-types" title="Permalink to this headline"></a></h2>
<p>The QuantizeML toolkit provides quantization of the following layer types which are standard Keras
layers for most part and custom QuantizeML layers for some of them:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Neural layers</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConv2D">Conv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConv2DTranspose">Conv2DTranspose</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDepthwiseConv2D">DepthwiseConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDepthwiseConv2DTranspose">DepthwiseConv2DTranspose</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedSeparableConv2D">SeparableConv2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDense">Dense</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Transformers</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedAttention">Attention</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedClassToken">ClassToken</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedAddPositionEmbs">AddPositionEmbs</a>
(custom QuantizeML layer)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedExtractToken">ExtractToken</a>
(custom QuantizeML layer)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Skip connections</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedAdd">Add</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedConcatenate">Concatenate</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Normalization</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedBatchNormalization">BatchNormalization</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedLayerNormalization">LayerMadNormalization</a>
(custom QuantizeML layer)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Activations</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedReLU">ReLU</a>
(both unbounded and with a max value)</p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedShiftmax">Shiftmax</a>
(custom QuantizeML layer)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Pooling</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedMaxPool2D">MaxPool2D</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedGlobalAveragePooling2D">GlobalAveragePooling2D</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Reshaping</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedFlatten">Flatten</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedPermute">Permute</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedReshape">Reshape</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Others</dt><dd><ul>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedRescaling">Rescaling</a></p></li>
<li><p><a class="reference external" href="../api_reference/quantizeml_apis.html#quantizeml.layers.QuantizedDropout">Dropout</a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="fn-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>See <a class="reference external" href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic">https://en.wikipedia.org/wiki/Fixed-point_arithmetic</a> for more details on the
arithmetics.</p>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="akida.html" class="btn btn-neutral float-left" title="Akida user guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnn2snn.html" class="btn btn-neutral float-right" title="CNN2SNN toolkit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>