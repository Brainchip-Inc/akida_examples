<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>cnn2snn.quantization_ops &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#performances-measurement">Performances measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#yolo-training">YOLO training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#id1">Layer Blocks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#sparsity">Sparsity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#stdperaxisquantizer">StdPerAxisQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#general-examples">General examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../examples/general/index.html">General examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_3_regression.html">Regression tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/cnn2snn/index.html">CNN2SNN tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../examples/edge/index.html">Edge examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id11">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#id12"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zoo_performances.html#id13">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">cnn2snn.quantization_ops</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for cnn2snn.quantization_ops</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># ******************************************************************************</span>
<span class="c1"># Copyright 2020 Brainchip Holdings Ltd.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ******************************************************************************</span>
<span class="sd">&quot;&quot;&quot;Weight quantizers API&quot;&quot;&quot;</span>

<span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Layer</span>


<div class="viewcode-block" id="WeightQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.WeightQuantizer">[docs]</a><span class="k">class</span> <span class="nc">WeightQuantizer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base class for all weight quantizers.</span>

<span class="sd">    This base class must be overloaded as well as the two functions `quantize`</span>
<span class="sd">    and `scale_factor`.</span>

<span class="sd">    Quantizers derived from this class must be symmetric uniform mid-tread</span>
<span class="sd">    quantizers, in order to be compatible with the conversion into an Akida</span>
<span class="sd">    model. Quantization is usually done in two steps:</span>

<span class="sd">    #. The weights must be first quantized on integer values in the</span>
<span class="sd">       range imposed by the bitwidth, e.g. from -7 to 7 for a 4-bit</span>
<span class="sd">       quantization.</span>
<span class="sd">    #. These integer weights are then reconstructed to float discretized</span>
<span class="sd">       values, in the range of the original weights. For example, 4-bit integer</span>
<span class="sd">       weights are reconstructed on a grid from -7*qstep to 7*qstep, where</span>
<span class="sd">       qstep is the quantization step size between two levels of the uniform</span>
<span class="sd">       grid.</span>

<span class="sd">    For a full explanation about mid-tread uniform quantization, one can take a</span>
<span class="sd">    look at `the Wikipedia page &lt;https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Example&gt;`_.</span>

<span class="sd">    The `quantize` function takes as inputs the original weights and must</span>
<span class="sd">    return the reconstructed float values after quantization. The</span>
<span class="sd">    `scale_factor` function must return the factor used to transform the float</span>
<span class="sd">    reconstructed weights into the integer values obtained after step 1. In other</span>
<span class="sd">    words, given a set of float weights &quot;w&quot;:</span>

<span class="sd">     quantize(w) * scale_factor(w) is a set of integer weights.</span>

<span class="sd">    The bitwidth defines the number of quantization levels on which the</span>
<span class="sd">    weights will be quantized. For instance, a 4-bit quantization gives</span>
<span class="sd">    integer values between -7 and 7. More generally, for a n-bit</span>
<span class="sd">    quantization, values are ranged from -kmax to kmax where kmax is</span>
<span class="sd">    (2^(n-1) - 1).</span>

<span class="sd">    Args:</span>
<span class="sd">        bitwidth (int): the quantization bitwidth.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bitwidth</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">bitwidth</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The quantization bitwidth should be higher than 1.</span><span class="se">\</span>
<span class="s2">                    Receives bitwidth </span><span class="si">{</span><span class="n">bitwidth</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bitwidth_</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bitwidth</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kmax_</span> <span class="o">=</span> <span class="p">(</span><span class="mf">2.</span><span class="o">**</span><span class="p">(</span><span class="n">bitwidth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="WeightQuantizer.quantize"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.WeightQuantizer.quantize">[docs]</a>    <span class="k">def</span> <span class="nf">quantize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Quantizes the specified weights Tensor.</span>

<span class="sd">        This function must return a tf.Tensor containing float weights</span>
<span class="sd">        discretized on a uniform grid based on the scale factor &quot;sf&quot;.</span>
<span class="sd">        In other words, the discretized weights must be values among:</span>
<span class="sd">        -kmax/sf, ..., -2/sf, -1/sf, 0, 1/sf, 2/sf, ..., kmax/sf</span>

<span class="sd">        Args:</span>
<span class="sd">            w (:obj:`tensorflow.Tensor`): the weights Tensor to quantize.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`tensorflow.Tensor`: a Tensor of quantized weights.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="WeightQuantizer.scale_factor"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.WeightQuantizer.scale_factor">[docs]</a>    <span class="k">def</span> <span class="nf">scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluates the scale factor for the specified weights tf.Tensor.</span>

<span class="sd">        This function returns the scale factor to get the quantized integer</span>
<span class="sd">        weights from the reconstructed float weights. It is equal to the</span>
<span class="sd">        inverse of the quantization step size.</span>

<span class="sd">        The scale factor can be a scalar that is applied on the whole tensor</span>
<span class="sd">        of weights. It can also be a vector of length the number of filters,</span>
<span class="sd">        where each value applies to the weights of the corresponding output</span>
<span class="sd">        filter. This is called a per-axis quantization, as opposed to a</span>
<span class="sd">        per-tensor quantization. The number of filters is usually the last</span>
<span class="sd">        dimension of the weights tensor. More details are given</span>
<span class="sd">        `here &lt;https://www.tensorflow.org/lite/performance/quantization_spec?hl=sv#per-axis_vs_per-tensor&gt;`__</span>

<span class="sd">        Note that the `quantizer_dw` of a depthwise convolution in a</span>
<span class="sd">        QuantizedSeparableConv2D layer must imperatively return a scalar scale</span>
<span class="sd">        factor.</span>

<span class="sd">        Args:</span>
<span class="sd">          w (:obj:`tensorflow.Tensor`): the weights Tensor to quantize.</span>

<span class="sd">        Returns:</span>
<span class="sd">          :obj:`tensorflow.Tensor`: a Tensor containing a list of scalar values</span>
<span class="sd">          (1 or more).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bitwidth</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the bitwidth of the quantizer&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bitwidth_</span>

<div class="viewcode-block" id="WeightQuantizer.get_config"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.WeightQuantizer.get_config">[docs]</a>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;bitwidth&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bitwidth_</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="LinearWeightQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.LinearWeightQuantizer">[docs]</a><span class="k">class</span> <span class="nc">LinearWeightQuantizer</span><span class="p">(</span><span class="n">WeightQuantizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract linear weight quantizer</span>

<span class="sd">    This abstract class proposes a linear symmetric and uniform quantization</span>
<span class="sd">    function. The &quot;linear&quot; term here means that there is no non-linear</span>
<span class="sd">    transformation of the weights before the uniform quantization.</span>

<span class="sd">    The `scale_factor` function must be overloaded.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LinearWeightQuantizer.scale_factor"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.LinearWeightQuantizer.scale_factor">[docs]</a>    <span class="k">def</span> <span class="nf">scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="LinearWeightQuantizer.quantize"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.LinearWeightQuantizer.quantize">[docs]</a>    <span class="k">def</span> <span class="nf">quantize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Linearly quantizes the input weights on a symmetric uniform grid</span>
<span class="sd">        based on the scale factor.</span>

<span class="sd">        The input weights are directly rounded to the closest discretized</span>
<span class="sd">        value, without any transformation on the input weights.</span>

<span class="sd">        The gradient is estimated using the Straight-Through Estimator (STE),</span>
<span class="sd">        i.e. the gradient is computed as if there were no quantization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">round_through</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">sf</span><span class="p">),</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">kmax_</span><span class="p">,</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">kmax_</span><span class="p">)</span> <span class="o">/</span> <span class="n">sf</span></div></div>


<div class="viewcode-block" id="StdWeightQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdWeightQuantizer">[docs]</a><span class="k">class</span> <span class="nc">StdWeightQuantizer</span><span class="p">(</span><span class="n">LinearWeightQuantizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A uniform quantizer based on weights standard deviation.</span>

<span class="sd">    Quantizes the specified weights into 2^bitwidth-1 values centered on zero.</span>
<span class="sd">    E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep</span>
<span class="sd">    with qstep being the quantization step. The quantization step is defined by:</span>

<span class="sd">     qstep = threshold * std(W) / max_value</span>

<span class="sd">    with max_value being 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</span>

<span class="sd">    All values below or above threshold * std(W) are automatically assigned to</span>
<span class="sd">    the min (resp max) value.</span>

<span class="sd">    Args:</span>
<span class="sd">        threshold (int): the standard deviation multiplier used to exclude</span>
<span class="sd">            outliers.</span>
<span class="sd">        bitwidth (int): the quantizer bitwidth defining the number of</span>
<span class="sd">            quantized values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bitwidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Having a cast guarantees a check when the parameters are not numbers</span>
        <span class="c1"># (e.g.: None)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold_</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">threshold</span><span class="p">)</span>
        <span class="c1"># Initialize parent to store the bitwidth</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">bitwidth</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="StdWeightQuantizer.sigma_"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdWeightQuantizer.sigma_">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sigma_</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the standard deviation(s) of a set of weights&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">w</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the threshold of the std quantizer&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_</span>

<div class="viewcode-block" id="StdWeightQuantizer.scale_factor"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdWeightQuantizer.scale_factor">[docs]</a>    <span class="k">def</span> <span class="nf">scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="n">sigma_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_</span>
        <span class="k">return</span> <span class="n">clip_scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kmax_</span> <span class="o">/</span> <span class="n">sigma_scaled</span><span class="p">)</span></div>

<div class="viewcode-block" id="StdWeightQuantizer.get_config"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdWeightQuantizer.get_config">[docs]</a>    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;threshold&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">config</span></div></div>


<div class="viewcode-block" id="StdPerAxisQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdPerAxisQuantizer">[docs]</a><span class="k">class</span> <span class="nc">StdPerAxisQuantizer</span><span class="p">(</span><span class="n">StdWeightQuantizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A quantizer that relies on weights standard deviation per axis.</span>

<span class="sd">    Quantizes the specified weights into 2^bitwidth-1 values centered on zero.</span>
<span class="sd">    E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep</span>
<span class="sd">    with qstep being the quantization step. The quantization step is defined by:</span>

<span class="sd">     qstep = max_range / max_value</span>

<span class="sd">    with:</span>

<span class="sd">     - max_range = max(abs(W))</span>
<span class="sd">     - max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</span>

<span class="sd">    This is an evolution of the StdWeightQuantizer that defines the weights</span>
<span class="sd">    range per axis.</span>

<span class="sd">    The last dimension is used as axis, meaning that the scaling factor is a</span>
<span class="sd">    vector with as many values as &quot;filters&quot;, or &quot;neurons&quot;.</span>

<span class="sd">    Note: for a DepthwiseConv2D layer that has a single filter, this</span>
<span class="sd">    quantizer is strictly equivalent to the StdWeightQuantizer.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="StdPerAxisQuantizer.sigma_"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.StdPerAxisQuantizer.sigma_">[docs]</a>    <span class="k">def</span> <span class="nf">sigma_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="n">red_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">red_range</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MaxQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.MaxQuantizer">[docs]</a><span class="k">class</span> <span class="nc">MaxQuantizer</span><span class="p">(</span><span class="n">LinearWeightQuantizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A quantizer that relies on maximum range.</span>

<span class="sd">    Quantizes the specified weights into 2^bitwidth-1 values centered on zero.</span>
<span class="sd">    E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep</span>
<span class="sd">    with qstep being the quantization step. The quantization step is defined by:</span>

<span class="sd">     qstep = max_range / max_value</span>

<span class="sd">    with:</span>

<span class="sd">     - max_range = max(abs(W))</span>
<span class="sd">     - max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</span>

<span class="sd">    Args:</span>
<span class="sd">        bitwidth (int): the quantizer bitwidth defining the number of</span>
<span class="sd">            quantized values.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bitwidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Initialize parent to store the bitwidth</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">bitwidth</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="MaxQuantizer.max_range_"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.MaxQuantizer.max_range_">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">max_range_</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the range on which the weights are quantized. This quantizer</span>
<span class="sd">        discretizes weights in the range:</span>

<span class="sd">         [-max(weights) ; max(weights)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w</span><span class="p">))</span></div>

<div class="viewcode-block" id="MaxQuantizer.scale_factor"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.MaxQuantizer.scale_factor">[docs]</a>    <span class="k">def</span> <span class="nf">scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">clip_scale_factor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kmax_</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_range_</span><span class="p">(</span><span class="n">w</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="MaxPerAxisQuantizer"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.MaxPerAxisQuantizer">[docs]</a><span class="k">class</span> <span class="nc">MaxPerAxisQuantizer</span><span class="p">(</span><span class="n">MaxQuantizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A quantizer that relies on maximum range per axis.</span>

<span class="sd">    Quantizes the specified weights into 2^bitwidth-1 values centered on zero.</span>
<span class="sd">    E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep</span>
<span class="sd">    with qstep being the quantization step. The quantization step is defined by:</span>

<span class="sd">     qstep = max_range / max_value</span>

<span class="sd">    with:</span>

<span class="sd">     - max_range = max(abs(W))</span>
<span class="sd">     - max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</span>

<span class="sd">    This is an evolution of the MaxQuantizer that defines the max_range per</span>
<span class="sd">    axis.</span>

<span class="sd">    The last dimension is used as axis, meaning that the scaling factor is a</span>
<span class="sd">    vector with as many values as &quot;filters&quot;, or &quot;neurons&quot;.</span>

<span class="sd">    Note: for a DepthwiseConv2D layer that has a single filter, this</span>
<span class="sd">    quantizer is strictly equivalent to the MaxQuantizer.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="MaxPerAxisQuantizer.max_range_"><a class="viewcode-back" href="../../api_reference/cnn2snn_apis.html#cnn2snn.quantization_ops.MaxPerAxisQuantizer.max_range_">[docs]</a>    <span class="k">def</span> <span class="nf">max_range_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="n">red_range</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">low_limit_range</span> <span class="o">=</span> <span class="mf">1e-10</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">red_range</span><span class="p">),</span>
                                <span class="n">low_limit_range</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="o">.</span><span class="n">max</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="n">identifier</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the weight quantizer corresponding to the identifier.</span>

<span class="sd">    The &#39;identifier&#39; input can take two types: either a weight quantizer</span>
<span class="sd">    instance, or a dictionary corresponding to the config serialization</span>
<span class="sd">    of a weight quantizer.</span>

<span class="sd">    Args:</span>
<span class="sd">        identifier (WeightQuantizer or dict): either a WeightQuantizer</span>
<span class="sd">            instance or a configuration dictionary to deserialize.</span>

<span class="sd">    Returns:</span>
<span class="sd">        :obj:`cnn2snn.WeightQuantizer`: a weight quantizer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">WeightQuantizer</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">identifier</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">deserialize_keras_object</span><span class="p">(</span>
            <span class="n">identifier</span><span class="p">,</span>
            <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span>
                <span class="s1">&#39;StdWeightQuantizer&#39;</span><span class="p">:</span> <span class="n">StdWeightQuantizer</span><span class="p">,</span>
                <span class="s1">&#39;StdPerAxisQuantizer&#39;</span><span class="p">:</span> <span class="n">StdPerAxisQuantizer</span><span class="p">,</span>
                <span class="s1">&#39;MaxQuantizer&#39;</span><span class="p">:</span> <span class="n">MaxQuantizer</span><span class="p">,</span>
                <span class="s1">&#39;MaxPerAxisQuantizer&#39;</span><span class="p">:</span> <span class="n">MaxPerAxisQuantizer</span>
            <span class="p">})</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not interpret identifier </span><span class="si">{</span><span class="n">identifier</span><span class="si">}</span><span class="s2"> &quot;</span>
                     <span class="s2">&quot;for a weight quantizer object&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">round_through</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Element-wise rounding to the closest integer with full gradient propagation.</span>
<span class="sd">    A trick from [Sergey Ioffe](http://stackoverflow.com/a/36480182).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rounded</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">rounded</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">ceil_through</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Element-wise ceiling operation (to the closest greater integer) with</span>
<span class="sd">    full gradient propagation.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ceiling_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">ceiling_value</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">clip_scale_factor</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Clips scale factor(s) to 1000, in order to avoid very large scale</span>
<span class="sd">    factors and thus very large Akida thresholds after conversion.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>