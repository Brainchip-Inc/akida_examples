<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>QuantizeML API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Akida models API" href="akida_models_apis.html" />
    <link rel="prev" title="CNN2SNN Toolkit API" href="cnn2snn_apis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#performance-measurement">Performance measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#keras-support">Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#onnx-support">ONNX support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-quantization-scenario">Typical quantization scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id3">Command-line interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-layers">Akida layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#sparsity">Sparsity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantized-layers">Quantized layers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#custom-patterns">Custom patterns</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-i-o">Model I/O</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#convert">3. Convert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html">Build Vision Transformers for Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-selection">1. Model selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-optimization-for-akida-hardware">2. Model optimization for Akida hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-training">3. Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#displaying-results-attention-maps">6. Displaying results Attention Maps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html">Advanced ONNX models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#get-model-and-data">1. Get model and data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#conversion">3. Conversion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#deprecated-cnn2snn-tutorials">[Deprecated] CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id11">Keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id12">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id14"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id15">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="api_reference.html">API reference</a></li>
      <li class="breadcrumb-item active">QuantizeML API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-quantizeml">
<span id="quantizeml-api"></span><h1>QuantizeML API<a class="headerlink" href="#module-quantizeml" title="Permalink to this headline"></a></h1>
<section id="layers">
<h2>Layers<a class="headerlink" href="#layers" title="Permalink to this headline"></a></h2>
<section id="reshaping">
<h3>Reshaping<a class="headerlink" href="#reshaping" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedFlatten">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedFlatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/flatten.html#QuantizedFlatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedFlatten" title="Permalink to this definition"></a></dt>
<dd><p>A Flatten layer that operates on quantized inputs</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedPermute">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedPermute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/permute.html#QuantizedPermute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedPermute" title="Permalink to this definition"></a></dt>
<dd><p>A Permute layer that operates on quantized inputs</p>
<p>Note: Keras Permute layer simply wraps the Tensorflow transpose op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dims</strong> (<em>tuple of ints</em>) – Permutation pattern does not include the
samples dimension. Indexing starts at 1.
For instance, <cite>(2, 1)</cite> permutes the first and second dimensions
of the input.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedReshape">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedReshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/reshape.html#QuantizedReshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedReshape" title="Permalink to this definition"></a></dt>
<dd><p>A Reshape layer that operates on quantized inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_shape</strong> (<em>tuple of ints</em>) – Target shape, does not include the samples
dimension (batch size).</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="activations">
<h3>Activations<a class="headerlink" href="#activations" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedReLU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/activations.html#QuantizedReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedReLU" title="Permalink to this definition"></a></dt>
<dd><p>Quantized version of the ReLU activation layer applicable on FixedPoint tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_value</strong> (<em>float</em><em>, </em><em>optional</em>) – ReLU maximum value. Defaults to 6.</p></li>
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="attention">
<h3>Attention<a class="headerlink" href="#attention" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Attention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#Attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Attention" title="Permalink to this definition"></a></dt>
<dd><p>Dot-product attention layer with configurable softmax.</p>
<p>Inputs are a tuple of tensors:</p>
<ul class="simple">
<li><p>a query tensor of shape [batch, tokens, hidden],</p></li>
<li><p>a key tensor of shape [batch, tokens, hidden],</p></li>
<li><p>a value tensor of shape [batch, tokens, hidden].</p></li>
</ul>
<p>The calculation follows the steps:</p>
<ol class="arabic">
<li><p>Split query, key, value per attention heads</p>
<blockquote>
<div><p>q, k, v : [batch, tokens, hidden] -&gt; [batch, token, num_heads, dim]</p>
</div></blockquote>
</li>
<li><p>Calculate cross-token scores as a query-key dot product:</p>
<blockquote>
<div><p>scores = tf.matmul(query, key, transpose_b=True)</p>
<p>scores : [batch, num_heads, token, token]</p>
</div></blockquote>
</li>
<li><p>Rescale score by dividing by the squared-root of dim.</p></li>
<li><p>Use scores to calculate a mask</p>
<blockquote>
<div><p>mask = softmax(scores)</p>
</div></blockquote>
</li>
<li><p>Combine mask with value</p>
<blockquote>
<div><p>output = tf.matmul(mask, value)</p>
<p>output: [batch, num_heads, token, dim]</p>
</div></blockquote>
</li>
<li><p>Merge heads to get back to 2D</p>
<blockquote>
<div><p>output: [batch, num_heads, token, dim] -&gt; [batch, token, hidden]</p>
</div></blockquote>
</li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> (<em>int</em>) – the number of attention heads</p></li>
<li><p><strong>softmax</strong> (<em>str</em><em>, </em><em>optional</em>) – ‘softmax’ or ‘shiftmax’. Defaults to ‘softmax’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAttention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#QuantizedAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAttention" title="Permalink to this definition"></a></dt>
<dd><p>An Attention layer that operates on quantized inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> (<em>int</em>) – the number of attention heads</p></li>
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p></li>
<li><p><strong>softmax</strong> (<em>str</em><em>, </em><em>optional</em>) – ‘softmax’ or ‘shiftmax’. Defaults to ‘shiftmax’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.string_to_softmax">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">string_to_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#string_to_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.string_to_softmax" title="Permalink to this definition"></a></dt>
<dd><p>Convert a string to a softmax function.
Available options are ‘softmax’ for standard softmax, ‘shiftmax’ for
shiftmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>s</strong> (<em>str</em>) – string to convert.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A softmax function.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="normalization">
<h3>Normalization<a class="headerlink" href="#normalization" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedBatchNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedBatchNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/batch_normalization.html#QuantizedBatchNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedBatchNormalization" title="Permalink to this definition"></a></dt>
<dd><p>Layer that normalizes its inputs, on the last axis.</p>
<p>The normalization is applied like this:</p>
<div class="math notranslate nohighlight">
\[\begin{split}y = \\frac{(x - \\mu) \\cdot \\gamma}{\\sigma} + \\beta \\
    = \\frac{x \\cdot \\gamma}{\\sigma} - \\
      \\frac{\\mu\\cdot \\gamma}{\\gamma} + \\beta\end{split}\]</div>
<p>if we consider:</p>
<div class="math notranslate nohighlight">
\[\begin{split}a = \\frac{\\gamma}{\\sigma}\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}b = -\\frac{\\mu\\cdot \\gamma}{\\sigma} + \\beta\end{split}\]</div>
<p>The normalization can be re-written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}y = a \\cdot x + b\end{split}\]</div>
<p>Note that this layer will hold variables with names gamma, beta, moving_mean (<span class="math notranslate nohighlight">\(\\mu\)</span>),
and moving_variance (<span class="math notranslate nohighlight">\(\\sigma = \\sqrt{moving\_variance + \\epsilon}\)</span>), so they can be
converted from a BatchNormalization layer. However, it’s a and b that are going to be quantized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>optional</em>) – The axis that was normalized on the
BatchNormalization layer. The only supported value is the
last dimension.</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Small value to avoid dividing by zero.
Defaults to 1e-3.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.LayerMadNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">LayerMadNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/normalization.html#LayerMadNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.LayerMadNormalization" title="Permalink to this definition"></a></dt>
<dd><p>Approximates the <cite>keras.layers.LayerNormalization</cite> (LN), replacing the computation of
the standard deviation by the mean average deviation (mad).</p>
<p>Taking into account the complexity of computing the standard deviation, the
LayerMadNormalization (LMN) is intended to replace the <span class="math notranslate nohighlight">\(std(x)\)</span> by <span class="math notranslate nohighlight">\(mad(x)\)</span> defined
as:</p>
<div class="math notranslate nohighlight">
\[mad(x) = \frac{sum(|x - mean(x)|)}{nb\_channels}\]</div>
<p>To simplify it even more and make it more hardware-friendly, <span class="math notranslate nohighlight">\(mean(x)\)</span> is zeroed:</p>
<div class="math notranslate nohighlight">
\[mad(x) = \frac{sum(|x|)}{nb\_channels}\]</div>
<p>Then, the equation of the layer is defined as:</p>
<div class="math notranslate nohighlight">
\[LMN(x) = \gamma\frac{x}{mad(x)} + \beta\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A tuning step in the switching procedure between the LN to LMN layer will be required
to find the <span class="math notranslate nohighlight">\((\gamma, \beta)\)</span> parameters that match the standard deviation changes.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedLayerNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedLayerNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/normalization.html#QuantizedLayerNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedLayerNormalization" title="Permalink to this definition"></a></dt>
<dd><p>A LayerNormalization layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="convolution">
<h3>Convolution<a class="headerlink" href="#convolution" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.PaddedConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">PaddedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#PaddedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.PaddedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A convolutional layer that can use custom padding values.</p>
<p>Note that when padding values are provided, padding ‘SAME’ will be applied with the provided
value (overriding ‘padding’ parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding_value</strong> (<em>float</em><em>, </em><em>list</em><em>, </em><em>tensor</em><em>, </em><em>optional</em>) – the value or the list of values used when
padding for the ‘same’ convolution type. Padding is per-tensor if one value is provided
or per-channel otherwise. If None, zero-padding is used. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#QuantizedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A convolutional layer that operates on quantized inputs and weights.</p>
<p>Note that when padding values are provided, padding ‘SAME’ will be applied with the provided
value (overriding ‘padding’ parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p></li>
<li><p><strong>padding_value</strong> (<em>float</em><em>, </em><em>list</em><em>, </em><em>tensor</em><em>, </em><em>optional</em>) – the value or the list of values used when
padding for the ‘same’ convolution type. Padding is per-tensor if one value is provided
or per-channel otherwise. If None, zero-padding is used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#QuantizedConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="depthwise-convolution">
<h3>Depthwise convolution<a class="headerlink" href="#depthwise-convolution" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDepthwiseConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDepthwiseConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/depthwise_convolution.html#QuantizedDepthwiseConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDepthwiseConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A depthwise convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.DepthwiseConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">DepthwiseConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/depthwise_convolution.html#DepthwiseConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.DepthwiseConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed depthwise convolutional layer.</p>
<p>It performs a transposed depthwise convolution on inputs.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDepthwiseConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDepthwiseConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/depthwise_convolution.html#QuantizedDepthwiseConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDepthwiseConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed depthwise convolutional layer that operates on quantized
inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization
configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="separable-convolution">
<h3>Separable convolution<a class="headerlink" href="#separable-convolution" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedSeparableConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedSeparableConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/separable_convolution.html#QuantizedSeparableConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedSeparableConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A separable convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="dense">
<h3>Dense<a class="headerlink" href="#dense" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDense">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/dense.html#QuantizedDense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDense" title="Permalink to this definition"></a></dt>
<dd><p>A Dense layer that operates on quantized inputs and weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="skip-connection">
<h3>Skip connection<a class="headerlink" href="#skip-connection" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Add">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/multi_inbounds.html#Add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Add" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>keras.layers.Add</cite> that allows to average inputs.</p>
<p>We only support a tuple of two inputs with the same shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>average</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>True</cite>, compute the average across all inputs.
Defaults to <cite>False</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAdd">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/multi_inbounds.html#QuantizedAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAdd" title="Permalink to this definition"></a></dt>
<dd><p>Sums two inputs and quantize the output.</p>
<p>The two inputs must be provided as a list or tuple of FixedPoint or Tensors.</p>
<p>The outputs are quantized according to the specified quantization configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedConcatenate">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConcatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/multi_inbounds.html#QuantizedConcatenate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedConcatenate" title="Permalink to this definition"></a></dt>
<dd><p>A Concatenate layer that operates on quantized inputs</p>
</dd></dl>

</section>
<section id="pooling">
<h3>Pooling<a class="headerlink" href="#pooling" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedMaxPool2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedMaxPool2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/pooling.html#QuantizedMaxPool2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedMaxPool2D" title="Permalink to this definition"></a></dt>
<dd><p>A max pooling layer that operates on quantized inputs.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedGlobalAveragePooling2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedGlobalAveragePooling2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/pooling.html#QuantizedGlobalAveragePooling2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedGlobalAveragePooling2D" title="Permalink to this definition"></a></dt>
<dd><p>A global average pooling layer that operates on quantized inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="shiftmax">
<h3>Shiftmax<a class="headerlink" href="#shiftmax" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Shiftmax">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Shiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#Shiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Shiftmax" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>shiftmax</cite> function, that calculates a softmax-like
activation.</p>
<p>Note that shiftmax operation is performed always along the last axis.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedShiftmax">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedShiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#QuantizedShiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedShiftmax" title="Permalink to this definition"></a></dt>
<dd><p>A quantized layer to do a quantized function similar to the softmax, but
using base 2 instead of e. So we replace</p>
<div class="math notranslate nohighlight">
\[softmax(x_i) = \frac{e^{x_i}}{sum(e^{x_k})}\]</div>
<p>With this:</p>
<div class="math notranslate nohighlight">
\[softmax2(x_i) = \frac{2^{x_i}}{sum(2^{x_k})}\]</div>
<p>This approximation is close enough to the original function. In order to
make it more hardware friendly, we also approximated the <span class="math notranslate nohighlight">\(sum(2^{x_k})\)</span>
to the closest power of two:</p>
<div class="math notranslate nohighlight">
\[shiftmax(x_i) = \frac{2^{x_i}}{2^{round(log2(sum(2^{x_k})))}}\]</div>
<p>So it can be implemented with a simple shift operation.</p>
<p>Implementation is inspired from this paper:</p>
<p>Cardarilli, G.C., Di Nunzio, L., Fazzolari, R. et al.
A pseudo-softmax function for hardware-based high speed image classification.
Sci Rep 11, 15307 (2021). <a class="reference external" href="https://doi.org/10.1038/s41598-021-94691-7">https://doi.org/10.1038/s41598-021-94691-7</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.shiftmax">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">shiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#shiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.shiftmax" title="Permalink to this definition"></a></dt>
<dd><p>Computes softmax-like activations, but using base 2 for the exponential.</p>
<p>Used as approximation of the softmax activation.</p>
<p>This function performs the equivalent of</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span> <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">exp</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">logits</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">sum_exp_shift</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">softmax</span> <span class="o">=</span> <span class="n">exp</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">sum_exp_shift</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">logits</span> <span class="o">-</span>  <span class="n">sum_exp_shift</span><span class="p">)</span>
</pre></div>
</div>
<p>When 2 ** <code class="xref py py-attr docutils literal notranslate"><span class="pre">sum_exp_shift</span></code> is an approximated of sum_exp as a Power-of-Two (PoT)</p>
<p>To avoid a high exponential (and a tf.inf representation by tensorflow), we adopt the
following equivalence:</p>
<p>Making the variable change <span class="math notranslate nohighlight">\(y=logits-x0\)</span>, we reach the same result as
<span class="math notranslate nohighlight">\(p=shiftmax(logits)\)</span>, because,</p>
<div class="math notranslate nohighlight">
\[p' = \frac{2^y}{sum(2^y)}
   = \frac{2^{logits-x0}}{sum(2^{logits-x0})}
   = \frac{2^{logits} * 2^{-x0}}{2^{-x0} * sum(2^{logits})}
   = \frac{2^{logits}}{sum(2^{logits})}
   = p\]</div>
<p>We take <span class="math notranslate nohighlight">\(x0 = max(logits)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<em>tf.Tensor</em>) – a non-empty <cite>Tensor</cite>.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>list</em><em>, </em><em>optional</em>) – the dimension shiftmax would be performed
on. The default is -1 which indicates the last dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>value of shiftmax function with the same type and shape as <cite>logits</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>InvalidArgumentError</strong> – if <cite>logits</cite> is empty or <cite>axis</cite> is beyond the last
    dimension of <cite>logits</cite>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We floor the <code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code> to approximate the results to those expected
when quantizing the operation.</p>
</div>
</dd></dl>

</section>
<section id="transformers">
<h3>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.ClassToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">ClassToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#ClassToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.ClassToken" title="Permalink to this definition"></a></dt>
<dd><p>Append a class token to an input layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initializer</strong> (<em>keras.initializers.Initializer</em>) – Initializer for the class
variable. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedClassToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedClassToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedClassToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedClassToken" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the <a class="reference internal" href="#quantizeml.layers.ClassToken" title="quantizeml.layers.ClassToken"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassToken</span></code></a> layer, allowing quantization of the output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.AddPositionEmbs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">AddPositionEmbs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#AddPositionEmbs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.AddPositionEmbs" title="Permalink to this definition"></a></dt>
<dd><p>Adds (optionally learned) positional embeddings to the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initializer</strong> (<em>keras.initializers.Initializer</em>) – Initializer for the class
variable. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAddPositionEmbs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAddPositionEmbs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedAddPositionEmbs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAddPositionEmbs" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the <a class="reference internal" href="#quantizeml.layers.AddPositionEmbs" title="quantizeml.layers.AddPositionEmbs"><code class="xref py py-class docutils literal notranslate"><span class="pre">AddPositionEmbs</span></code></a> layer, allowing operations in FixedPoint domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.ExtractToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">ExtractToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#ExtractToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.ExtractToken" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>tf.gather</cite> operation that allows to extract a Token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token</strong> (<em>int</em>) – the indice of the token to extract.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>optional</em>) – axis over which the user gather the token. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedExtractToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedExtractToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedExtractToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedExtractToken" title="Permalink to this definition"></a></dt>
<dd><p>Quantized version of the ExtractToken layer. Accepts only FixedPoint inputs.</p>
</dd></dl>

</section>
<section id="rescaling">
<h3>Rescaling<a class="headerlink" href="#rescaling" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedRescaling">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedRescaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/rescaling.html#QuantizedRescaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedRescaling" title="Permalink to this definition"></a></dt>
<dd><p>A layer that multiplies integer inputs by a scale</p>
<p>This is a simplified version of the keras Rescaling layer:</p>
<ul class="simple">
<li><p>it only supports a scalar scale,</p></li>
<li><p>it only supports zero offsets.</p></li>
</ul>
<p>This layer assumes the inputs are 8-bit integer: it simply wraps them into
an 8-bit per-tensor QFloat with the specified scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scale</strong> (<em>float</em>) – a scalar scale.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDropout">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/dropout.html#QuantizedDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDropout" title="Permalink to this definition"></a></dt>
<dd><p>A dropout layer that operates on quantized inputs and weights.</p>
<p>It is only implemented as a passthrough.</p>
</dd></dl>

</section>
<section id="quantizers">
<h3>Quantizers<a class="headerlink" href="#quantizers" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Quantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Quantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/quantizers.html#Quantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Quantizer" title="Permalink to this definition"></a></dt>
<dd><p>The base class for all quantizers.</p>
<p>The bitwidth defines the number of quantization levels on which the
values will be quantized.
For a quantizer that accepts unsigned values, the maximum quantization
level is <span class="math notranslate nohighlight">\(2 ^ {bitwidth} - 1\)</span>.
For a quantizer that accepts signed values, we lose one bit of precision to
store the sign.
When the quantizer is signed, the quantization interval is asymmetric around
zero (i.e range: <span class="math notranslate nohighlight">\([- 2 ^ {bitwidth - 1}, 2 ^ {bitwidth - 1} - 1]\)</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth.</p></li>
<li><p><strong>signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the quantizer expects signed values or unsigned.
Defaults to True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">WeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/weight_quantizer.html#WeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.layers.Quantizer" title="quantizeml.layers.quantizers.quantizers.Quantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.quantizers.quantizers.Quantizer</span></code></a></p>
<p>A uniform quantizer that converts a float Tensor to a QFloat representation.</p>
<p>In order, the WeightQuantizer:</p>
<blockquote>
<div><ul class="simple">
<li><p>evaluates the scales required to align the values on optimal ranges for FixedPoint
quantization,</p></li>
<li><p>quantizes the rescaled Tensor as a FixedPoint and returns a QFloat.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em><em>, </em><em>optional</em>) – the quantization bitwidth, defaults to 4.</p></li>
<li><p><strong>signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the quantizer expects signed values or unsigned.
Defaults to True.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>optional</em>) – the quantization range is a scalar (None) or a vector corresponding to
the given axis. Defaults to -1.</p></li>
<li><p><strong>fp_quantizer</strong> (<em>bool</em><em>, </em><em>optional</em>) – True to enable FixedPoint quantization, QFloat otherwise.
Defaults to False.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.WeightQuantizer.build" title="quantizeml.layers.WeightQuantizer.build"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build</span></code></a>(input_shape)</p></td>
<td><p>Build the layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.layers.WeightQuantizer.call" title="quantizeml.layers.WeightQuantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Quantize the float inputs</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.WeightQuantizer.get_config" title="quantizeml.layers.WeightQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Get the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/weight_quantizer.html#WeightQuantizer.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer.build" title="Permalink to this definition"></a></dt>
<dd><p>Build the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>list</em>) – the shape of input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/weight_quantizer.html#WeightQuantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the float inputs</p>
<p>The quantization is done in two steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the quantization ranges,</p></li>
<li><p>Quantize the inputs.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>tf.Tensor</em>) – the inputs tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/weight_quantizer.html#WeightQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get the config of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the config of the layer.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.AlignedWeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">AlignedWeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/aligned_weight_quantizer.html#AlignedWeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.AlignedWeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.layers.Quantizer" title="quantizeml.layers.quantizers.quantizers.Quantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.quantizers.quantizers.Quantizer</span></code></a></p>
<p>A uniform quantizer that converts a float Tensor to a QFloat representation.</p>
<p>Unlike its sibling the WeightQuantizer, it does not evaluate the fractional bits and scales of
the resulting QFloat, but instead aligns them on those of another QFloat input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em><em>, </em><em>optional</em>) – the quantization bitwidth. Defaults to 8.</p></li>
<li><p><strong>signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the quantizer expects signed values or unsigned.
Defaults to True.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.AlignedWeightQuantizer.call" title="quantizeml.layers.AlignedWeightQuantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs, other)</p></td>
<td><p>Quantize the float inputs, aligned on another QFloat</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.AlignedWeightQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/aligned_weight_quantizer.html#AlignedWeightQuantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.AlignedWeightQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the float inputs, aligned on another QFloat</p>
<p>The quantization is done in several steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute the quantization ranges,</p></li>
<li><p>Evaluate the maximum fractional bits,</p></li>
<li><p>Quantize the inputs as a QFloat,</p></li>
<li><p>Align the QFloat fractional bits on the other.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>tf.Tensor</em>) – the inputs tensor.</p></li>
<li><p><strong>other</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code>) – a tensor to align on.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a quantized tensor with the same scales and frac_bits as other.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">OutputQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/output_quantizer.html#OutputQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.layers.Quantizer" title="quantizeml.layers.quantizers.quantizers.Quantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.quantizers.quantizers.Quantizer</span></code></a></p>
<p>A uniform FixedPoint quantizer that selects the optimal number of fractional bits for the
range of its inputs and updates them accordingly.</p>
<p>The typical use case is to decrease the bitwidth of the result of a quantized layer operation to
avoid a saturation in downstream operations.</p>
<p>If the input is a QFloat, it is converted to a FixedPoint before updating its bitwidth.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em><em>, </em><em>optional</em>) – the quantization bitwidth. Defaults to 8.</p></li>
<li><p><strong>signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the quantizer expects signed values or unsigned.
Defaults to True.</p></li>
<li><p><strong>axis</strong> (<em>str</em><em>, </em><em>optional</em>) – the quantization range is a scalar (‘per-tensor’) or a vector
corresponding to the last axis (‘per-axis’). Defaults to ‘per-tensor’.</p></li>
<li><p><strong>scale_bits</strong> – (int, optional): the bitwidth to use when quantizing output scales.
Defaults to 8.</p></li>
<li><p><strong>buffer_bitwidth</strong> – (int, optional): buffer bitwidth value. Defaults to 32.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.OutputQuantizer.build" title="quantizeml.layers.OutputQuantizer.build"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build</span></code></a>(input_shape)</p></td>
<td><p>Build the layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.layers.OutputQuantizer.call" title="quantizeml.layers.OutputQuantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Quantize the QTensor inputs to a lower bitwidth.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.OutputQuantizer.get_config" title="quantizeml.layers.OutputQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Get the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/output_quantizer.html#OutputQuantizer.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer.build" title="Permalink to this definition"></a></dt>
<dd><p>Build the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>list</em>) – the shape of input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/output_quantizer.html#OutputQuantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the QTensor inputs to a lower bitwidth.</p>
<p>The quantization happens with the following steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Evaluate the nearest power(s) of two containing the quantization range(s)</p></li>
<li><p>Quantize the inputs.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code>) – the inputs tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/output_quantizer.html#OutputQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get the config of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the config of the layer.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Dequantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Dequantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/quantizers.html#Dequantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Dequantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Layer that allows to dequantize its inputs.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.Dequantizer.call" title="quantizeml.layers.Dequantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Convert QTensor inputs to float.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.Dequantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers/quantizers.html#Dequantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Dequantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Convert QTensor inputs to float.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (tf.Tensor or <code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code>) – the inputs tensor(s).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the dequantized tensor(s).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="calibration">
<h3>Calibration<a class="headerlink" href="#calibration" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.OutputObserver">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">OutputObserver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/output_observer.html#OutputObserver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputObserver" title="Permalink to this definition"></a></dt>
<dd><p>Calibration layer.</p>
<p>This layer is used to compute the future <cite>range_max</cite> of the equivalent OutputQuantizer in the
quantized model. It is placed where the OutputQuantizer will be inserted (end of blocks) and
accumulates the observed maximum values (with momentum) for input in the float model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>str</em>) – the quantization range is a scalar (‘per-tensor’) or a vector
corresponding to the last axis (‘per-axis’). Defaults to ‘per-tensor’.</p></li>
<li><p><strong>momentum</strong> (<em>float</em>) – the momentum for the moving average. Defaults to 0.9.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="recording">
<h3>Recording<a class="headerlink" href="#recording" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.recording">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">recording</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">enable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#recording"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.recording" title="Permalink to this definition"></a></dt>
<dd><p>Enable or disable recording.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>enable</strong> (<em>bool</em>) – True to enable recording, False to disable it</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.TensorRecorder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">TensorRecorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#TensorRecorder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.TensorRecorder" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class to store and retrieve a tf.Tensor extracted from a graph.</p>
<p>This is mainly used to recover FixedPoint alignment shift information.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.FixedPointRecorder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">FixedPointRecorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#FixedPointRecorder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.FixedPointRecorder" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class to store and retrieve a FixedPoint extracted from a graph.</p>
<p>This is mainly used to recover FixedPoint quantized weights.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QFloatRecorder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QFloatRecorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#QFloatRecorder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QFloatRecorder" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class to store and retrieve a QFloat extracted from a graph.</p>
<p>This is mainly used to recover QFloat quantized weights.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.NonTrackVariable">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">NonTrackVariable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#NonTrackVariable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.NonTrackVariable" title="Permalink to this definition"></a></dt>
<dd><p>A wrapper class for the temporary Tensor variables that should be tracked only during the
call and which does not require to be serialized within the layer.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.NonTrackFixedPointVariable">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">NonTrackFixedPointVariable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/recorders.html#NonTrackFixedPointVariable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.NonTrackFixedPointVariable" title="Permalink to this definition"></a></dt>
<dd><p>A wrapper class for the temporary FixedPoint variables that should be tracked only during
the call and which does not require to be serialized within the layer.</p>
</dd></dl>

</section>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline"></a></h2>
<section id="transforms">
<h3>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.align_rescaling">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">align_rescaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/align_rescaling.html#align_rescaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.align_rescaling" title="Permalink to this definition"></a></dt>
<dd><p>Aligns the Rescaling layer of the model to make it quantization ready.</p>
<p>This folds the offset into the bias of next layer.</p>
<p>The resulting Rescaling is therefore compatible with a quantization to a
QuantizedRescaling.</p>
<p>If the source model does not contain a Rescaling or if its Rescaling is already
aligned, then the original model is returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the source Keras model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the original model or a new model with Rescaling layer aligned</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.invert_batchnorm_pooling">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">invert_batchnorm_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/invert_batchnorm_pooling.html#invert_batchnorm_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.invert_batchnorm_pooling" title="Permalink to this definition"></a></dt>
<dd><p>Inverts pooling and BatchNormalization layers in a model to have BN layer before pooling.</p>
<p>Returns a new model where pooling and batch normalization layers are inverted. From a Keras
model where pooling layers precede batch normalization layers, this function places the BN
layers before pooling layers. This is the first step before folding BN layers into processing
layers.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Inversion of layers is equivalent only if the gammas of BN layers are positive. The
function raises an error if not.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the updated model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if a candidate BatchNormalization layer has gamma values that are not strictly
    positive.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.fold_batchnorms">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">fold_batchnorms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/fold_batchnorms.html#fold_batchnorms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.fold_batchnorms" title="Permalink to this definition"></a></dt>
<dd><p>Returns a new model where BatchNormalization layers are folded into previous layers.</p>
<p>From a Keras model where BN layers follow processing layers, this function removes the BN layers
and updates the preceding layers weights and bias accordingly. The new model is strictly
equivalent to the previous one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the original model or a model with BN folded</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.insert_layer">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">insert_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layer_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/insert_layer.html#insert_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.insert_layer" title="Permalink to this definition"></a></dt>
<dd><p>Inserts the given layer in the model after the layer with the name target_layer_name.</p>
<p>Note that new_layer type is restricted to (OutputQuantizer, Dequantizer).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p></li>
<li><p><strong>target_layer_name</strong> (<em>str</em>) – name of the layer after which to insert a layer</p></li>
<li><p><strong>new_layer</strong> (<em>keras.layers.Layer</em>) – layer to insert</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – when target_layer_name is not found in model or new_layer is not in
    (OutputQuantizer, Dequantizer)</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the new model</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.insert_rescaling">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">insert_rescaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/insert_layer.html#insert_rescaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.insert_rescaling" title="Permalink to this definition"></a></dt>
<dd><p>Inserts a Rescaling as first layer of the Model (after the Input)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p></li>
<li><p><strong>scale</strong> (<em>float</em>) – the Rescaling scale</p></li>
<li><p><strong>offset</strong> (<em>float</em>) – the Rescaling offset</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – when the Model does not have an Input layer.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the new model</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.invert_relu_maxpool">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">invert_relu_maxpool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/relu_maxpool.html#invert_relu_maxpool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.invert_relu_maxpool" title="Permalink to this definition"></a></dt>
<dd><p>Inverts ReLU and MaxPool2D layers in a model to have MaxPool2D before ReLU.</p>
<p>This transformation produces a strictly equivalent model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>keras.Model: the original model or the updated model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.remove_zeropadding2d">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">remove_zeropadding2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/remove_zeropadding2d.html#remove_zeropadding2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.remove_zeropadding2d" title="Permalink to this definition"></a></dt>
<dd><p>Removes ZeroPadding2D layers from a model.</p>
<p>ZeroPadding2D layers will not be supported by quantization so this transform adds support so
that when the ZeroPadding2D layers are immediately followed by a convolution layer with ‘valid’
padding, they are removed and the following convolution is updated with a ‘same’ padding
instead. This can however only happen when the padding specified in ZeroPadding2D actually
corresponds to a ‘same’ padding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the original model or a new model with ZeroPadding2D removed</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.replace_lambda">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">replace_lambda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/replace_lambda.html#replace_lambda"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.replace_lambda" title="Permalink to this definition"></a></dt>
<dd><p>Replaces lambda layers from a model with their equivalent Keras layer.</p>
<p>This transform handles the following replacements:</p>
<blockquote>
<div><ul class="simple">
<li><p>Lambda(relu) or Activation(‘relu’) → ReLU,</p></li>
<li><p>Lambda(transpose) → Permute,</p></li>
<li><p>Lambda(reshape) → Reshape,</p></li>
<li><p>Lambda(add) → Add.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the model of interest</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the original model or a new one with lambda replaced.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.sanitize">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">sanitize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/sanitize.html#sanitize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.sanitize" title="Permalink to this definition"></a></dt>
<dd><p>Sanitize a model preparing it for quantization.</p>
<p>This is a wrapping successive calls to several model transformations which aims at making the
model quantization ready.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the input model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the sanitized model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantization">
<h3>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.quantize">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qparams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">QuantizationParams(activation_bits=8,</span> <span class="pre">per_tensor_activations=False,</span> <span class="pre">weight_bits=8,</span> <span class="pre">output_bits=8,</span> <span class="pre">input_weight_bits=8,</span> <span class="pre">buffer_bits=32)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/quantize.html#quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Quantizes a Keras or ONNX model using the provided configuration or parameters.</p>
<p>Details on how this function behaves:</p>
<ul class="simple">
<li><p><cite>q_config</cite> has priority over <cite>qparams</cite>, meaning that when a match is found in <cite>q_config</cite> the
given configuration will be used instead of <cite>qparams</cite>. This is useful to handle specific cases
(e.g per-tensor output quantizer). This is only used when quantizing Keras models.</p></li>
<li><p>when no configuration is given, quantization parameters are deduced from <cite>qparams</cite> and
OutputQuantizers are automatically set on appropriate layers.</p></li>
<li><p><cite>qparams</cite> are only applied to ‘float’ Keras layers when they are first quantized. As a result,
when re-quantizing a model, one must provide a complete <cite>q_config</cite>. This is made easy with the
<cite>dump_config</cite> helper. Note the only configuration supported when quantizing ONNX models is
8-bit for weights and activations, but per_tensor_activations param will be taken into
account.</p></li>
</ul>
<p>If not already present, a final Dequantizer will be added at the end of the Model.</p>
<p>The model will also be calibrated using the provided (or randomly generated inputs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em><em> or </em><em>ModelProto</em>) – the model to quantize</p></li>
<li><p><strong>q_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – quantization configuration as a dictionary mapping layer names to
their quantization configuration. Defaults to None.</p></li>
<li><p><strong>qparams</strong> (<a class="reference internal" href="#quantizeml.models.QuantizationParams" title="quantizeml.models.QuantizationParams"><em>QuantizationParams</em></a><em>, </em><em>optional</em>) – global quantization parameters. Defaults to
QuantizationParams().</p></li>
<li><p><strong>samples</strong> (<em>tf.Dataset</em><em>, </em><em>np.array</em><em> or </em><em>generator</em><em>, </em><em>optional</em>) – calibration samples. When no samples
are provided, random samples are generated. Defaults to None.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em><em>, </em><em>optional</em>) – number of samples to use in the provided samples or number of
samples to generate. Defaults to 1024.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – the batch size. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of epochs. This parameter must be 1 for ONNX models.
Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model or ModelProto</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.dump_config">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">dump_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/quantize.html#dump_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.dump_config" title="Permalink to this definition"></a></dt>
<dd><p>Dump the quantization configuration of a quantized model, exporting the configuration for
each quantized layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a quantized model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the configuration of the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.check_quantization">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">check_quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/check_quantization.html#check_quantization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.check_quantization" title="Permalink to this definition"></a></dt>
<dd><p>Checks the specified model quantization.</p>
<p>It looks for errors that can be fixed in the quantization configuration:</p>
<ul class="simple">
<li><p>inaccurate weight scales quantization,</p></li>
<li><p>saturation in integer operations.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the model to check</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantization issues that were detected</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list(str)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.record_quantization_variables">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">record_quantization_variables</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/record.html#record_quantization_variables"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.record_quantization_variables" title="Permalink to this definition"></a></dt>
<dd><p>Helper method to record quantization objects in the graph.</p>
<p>Passing a dummy sample through the model in recording mode, this triggers the
recording of all dynamic quantization objects.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – model for which objects need to be recorded.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantization-parameters">
<h3>Quantization parameters<a class="headerlink" href="#quantization-parameters" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.models.QuantizationParams">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">QuantizationParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_tensor_activations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_weight_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantization_params.html#QuantizationParams"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.QuantizationParams" title="Permalink to this definition"></a></dt>
<dd><p>Class that holds quantization parameters.</p>
<p>This is a read-only data class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activation_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – activations quantization bitwidth. Defaults to 8.</p></li>
<li><p><strong>per_tensor_activations</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to quantize activation per-tensor or
per-axis. Defaults to False.</p></li>
<li><p><strong>weight_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – weights quantization bitwidth. Defaults to 8.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – outputs quantization bitwidth. Defaults to 8.</p></li>
<li><p><strong>input_weight_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – weights quantization bitwidth for the first layer.
Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – maximal buffer bitwidth allowed in operations.
Defaults to 32.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.get_quantization_params">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">get_quantization_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantization_params.html#get_quantization_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.get_quantization_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns global quantization parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the quantization parameters</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.models.QuantizationParams" title="quantizeml.models.QuantizationParams">QuantizationParams</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.quantization">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">quantization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">qparams</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantization_params.html#quantization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.quantization" title="Permalink to this definition"></a></dt>
<dd><p>Sets quantization parameters in a context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>qparams</strong> (<a class="reference internal" href="#quantizeml.models.QuantizationParams" title="quantizeml.models.QuantizationParams"><em>QuantizationParams</em></a>) – quantization parameters</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="id1">
<h3>Calibration<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.calibrate">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">calibrate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qmodel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/calibrate.html#calibrate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.calibrate" title="Permalink to this definition"></a></dt>
<dd><p>Calibrates the model using the provided samples.</p>
<p>With TENN models only np.array samples are supported for calibration. Those should have
a temporally coherent data, which means that their expected shape is
[batch_size*Seq, dim_0,, …, dim_n] for spatiotemporal TENNs where:</p>
<blockquote>
<div><ul class="simple">
<li><p>batch_size is the same batch_size provided to the calibration.</p></li>
<li><p>Seq is a dataset parameter that defines the temporally coherent data (eg number of frames
per video clips).</p></li>
</ul>
</div></blockquote>
<p>and [batch_size, (model.input_shape)] for recurrent TENNs.</p>
<p>When no samples are provided, random samples are generated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the original model</p></li>
<li><p><strong>qmodel</strong> (<em>keras.Model</em>) – the quantized model to calibrate</p></li>
<li><p><strong>samples</strong> (<em>tf.Dataset</em><em>, </em><em>np.array</em><em> or </em><em>generator</em><em>, </em><em>optional</em>) – calibration samples. When no samples
are provided, random samples are generated. Defaults to None.</p></li>
<li><p><strong>num_samples</strong> (<em>int</em><em>, </em><em>optional</em>) – number of samples to use in the provided samples or number of
samples to generate. Defaults to 1024.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – the batch size. Defaults to None.</p></li>
<li><p><strong>epochs</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of epochs. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.calibration_required">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">calibration_required</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/calibrate.html#calibration_required"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.calibration_required" title="Permalink to this definition"></a></dt>
<dd><p>Checks if a model requires calibration.</p>
<p>If one of the ‘OutputQuantizer’ layers in the model has its range_max variable set to 1, it
requires calibration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – the model to check</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if calibration is required, False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="utils">
<h3>Utils<a class="headerlink" href="#utils" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.load_model">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compile_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads a model with quantizeml custom layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> (<em>str</em>) – path of the model to load</p></li>
<li><p><strong>custom_layers</strong> (<em>dict</em><em>, </em><em>optional</em>) – custom layers to add to the model. Defaults to None.</p></li>
<li><p><strong>compile_model</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to compile the model. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the loaded model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.apply_weights_to_model">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">apply_weights_to_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#apply_weights_to_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.apply_weights_to_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads weights from a dictionary and apply it to a model.</p>
<p>Go through the dictionary of weights, find the corresponding variable in the
model and partially load its weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p></li>
<li><p><strong>weights</strong> (<em>dict</em>) – the dictionary of weights</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) – if True, throw warning messages if a dict item is not found in the
model. Defaults to True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline"></a></h2>
<section id="qtensor">
<h3>QTensor<a class="headerlink" href="#qtensor" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">QTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tensorflow.python.framework.tensor_shape.TensorShape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.framework.extension_type.ExtensionType</span></code></p>
<p>Abstract class to exchange quantized tensors between layers</p>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.Spec" title="quantizeml.tensors.QTensor.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.assert_per_tensor" title="quantizeml.tensors.QTensor.assert_per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assert_per_tensor</span></code></a>()</p></td>
<td><p>Asserts that a QTensor is quantized per-tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.clone" title="quantizeml.tensors.QTensor.clone"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clone</span></code></a>()</p></td>
<td><p>Returns a copy of the QTensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.to_float" title="quantizeml.tensors.QTensor.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QTensor</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.name" title="quantizeml.tensors.QTensor.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>Returns the QTensor name</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.per_tensor" title="quantizeml.tensors.QTensor.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.QTensor.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.assert_per_tensor">
<span class="sig-name descname"><span class="pre">assert_per_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.assert_per_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.assert_per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Asserts that a QTensor is quantized per-tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.clone" title="Permalink to this definition"></a></dt>
<dd><p>Returns a copy of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the copy.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.QTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#quantizeml.tensors.QTensor.name" title="Permalink to this definition"></a></dt>
<dd><p>Returns the QTensor name</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the QTensor name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.QTensor.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="fixedpoint">
<h3>FixedPoint<a class="headerlink" href="#fixedpoint" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">FixedPoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p>
<p>A Tensor of integer values representing fixed-point numbers</p>
<p>The value_bits parameter sets the maximum integer values that can be stored:</p>
<div class="math notranslate nohighlight">
\[int\_max = 2^{bits} - 1.\]</div>
<p>When a FixedPoint is created, its values are clipped to [-int_max-1, int_max].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>tf.Tensor</em>) – a tensor of integer values</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits.</p></li>
<li><p><strong>frac_bits</strong> (<em>tf.Tensor</em>) – an integer tensor of fractional bits.</p></li>
</ul>
</dd>
</dl>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.Spec" title="quantizeml.tensors.FixedPoint.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.abs" title="quantizeml.tensors.FixedPoint.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code></a>()</p></td>
<td><p>Returns the absolute value of the FixedPoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.align" title="quantizeml.tensors.FixedPoint.align"><code class="xref py py-obj docutils literal notranslate"><span class="pre">align</span></code></a>(other[, value_bits])</p></td>
<td><p>Align fractional bits</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.downscale" title="quantizeml.tensors.FixedPoint.downscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">downscale</span></code></a>(frac_bits)</p></td>
<td><p>Reduce the precision of a FixedPoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.expand" title="quantizeml.tensors.FixedPoint.expand"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand</span></code></a>(value_bits)</p></td>
<td><p>Expand the FixedPoint to the specified bitwidth</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.floor" title="quantizeml.tensors.FixedPoint.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code></a>()</p></td>
<td><p>Floors the FixedPoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.max_frac_bits" title="quantizeml.tensors.FixedPoint.max_frac_bits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_frac_bits</span></code></a>(value_bits, ranges[, clamp])</p></td>
<td><p>Evaluate the maximum fractional bit index for the quantization ranges.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.promote" title="quantizeml.tensors.FixedPoint.promote"><code class="xref py py-obj docutils literal notranslate"><span class="pre">promote</span></code></a>(bits)</p></td>
<td><p>Increase the number of value bits</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.quantize" title="quantizeml.tensors.FixedPoint.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(x, value_bits[, frac_bits])</p></td>
<td><p>Converts a float Tensor to a FixedPoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.rescale" title="quantizeml.tensors.FixedPoint.rescale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rescale</span></code></a>(frac_bits[, value_bits])</p></td>
<td><p>Rescale a FixedPoint to a specified precision and bitwidth</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.shift" title="quantizeml.tensors.FixedPoint.shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shift</span></code></a>(s)</p></td>
<td><p>Apply a tensor-wide left or right shift.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.to_float" title="quantizeml.tensors.FixedPoint.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QTensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.upscale" title="quantizeml.tensors.FixedPoint.upscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">upscale</span></code></a>(frac_bits[, value_bits])</p></td>
<td><p>Align a FixedPoint to a specified precision</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.name" title="quantizeml.tensors.FixedPoint.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>Returns the QTensor name</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.per_tensor" title="quantizeml.tensors.FixedPoint.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.sign" title="quantizeml.tensors.FixedPoint.sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code></a></p></td>
<td><p>Returns the sign of the FixedPoint</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.fixed_point.FixedPoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.abs">
<span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.abs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the absolute value of the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the absolute value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.align">
<span class="sig-name descname"><span class="pre">align</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.align"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.align" title="Permalink to this definition"></a></dt>
<dd><p>Align fractional bits</p>
<p>This returns an equivalent FixedPoint with a scalar fractional bit
corresponding to the maximum of the current and other FixedPoint on all
channels.</p>
<p>This is required before performing an operation that adds or subtracts
elements along the last dimension, to make sure all these elements are
in the same scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> (<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>) – a FixedPoint to align to</p></li>
<li><p><strong>value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the target value bits. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new FixedPoint with aligned
fractional bits and the shift that was applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.downscale">
<span class="sig-name descname"><span class="pre">downscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.downscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.downscale" title="Permalink to this definition"></a></dt>
<dd><p>Reduce the precision of a FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>frac_bits</strong> (<em>tf.Tensor</em>) – the target fractional bits</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the downscaled FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.expand">
<span class="sig-name descname"><span class="pre">expand</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.expand"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.expand" title="Permalink to this definition"></a></dt>
<dd><p>Expand the FixedPoint to the specified bitwidth</p>
<p>This returns an equivalent FixedPoint with a higher or equal number of
value bits and a scalar fractional bit corresponding to the maximum of
the initial fractional bits on all channels.</p>
<p>This is mostly used to recover a per-tensor FixedPoint that has been
compressed to a lower number of value bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value_bits</strong> (<em>int</em>) – the target value_bits</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new FixedPoint with expanded
fractional bits and the shift that was applied.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.floor">
<span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.floor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.floor" title="Permalink to this definition"></a></dt>
<dd><p>Floors the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a new FixedPoint without
fractional bits and the shift that was applied.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, tf.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.max_frac_bits">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">max_frac_bits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ranges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clamp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.max_frac_bits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.max_frac_bits" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the maximum fractional bit index for the quantization ranges.</p>
<p>This method evaluates the minimum number of integer bits required to cover the specified
quantization ranges (this can be a negative number if the ranges are strictly lower than
0.5).</p>
<p>From that it deduces the rightmost fractional bit indices.</p>
<p>The resulting frac_bits can be a negative number if the ranges are higher than the biggest
integer than can be represented with the specified value bits).</p>
<p>If specified, the maximum fractional bits are clamped to the available value_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits.</p></li>
<li><p><strong>(</strong><strong>tf</strong> (<em>ranges</em>) – Tensor): a tensor of float quantization ranges.</p></li>
<li><p><strong>clamp</strong> (<em>bool</em><em>, </em><em>optional</em>) – clamp the results to self.value_bits. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor: a tensor of fractional bits.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.name" title="Permalink to this definition"></a></dt>
<dd><p>Returns the QTensor name</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the QTensor name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.promote">
<span class="sig-name descname"><span class="pre">promote</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.promote"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.promote" title="Permalink to this definition"></a></dt>
<dd><p>Increase the number of value bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bits</strong> (<em>int</em>) – the new number of value bits</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a FixedPoint with increased value bits</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.quantize">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Converts a float Tensor to a FixedPoint</p>
<p>It converts the original float values into integer values so that:</p>
<div class="math notranslate nohighlight">
\[{x_{int}} = round(x * 2^{frac\_bits})\]</div>
<p>Note: <span class="math notranslate nohighlight">\(2^{-frac\_bits}\)</span> represents the FixedPoint precision.</p>
<p>Before returning, the resulting integer values are clipped to the
maximum integer values that can be stored for the specified value bits:</p>
<div class="math notranslate nohighlight">
\[[-2^{value\_bits}, 2^{value\_bits} - 1]\]</div>
<p>If frac_bits is not specified, the method starts by evaluating the number
of bits to dedicate to represent the integer part of the float tensor,
clipped to value_bits:</p>
<div class="math notranslate nohighlight">
\[int\_bits = ceil(log2(x))\]</div>
<p>Note: this number can be negative when x &lt; 0.5.</p>
<p>It then evaluates the offset of the least significant bit of the fractional
part of the float starting from zero. This represents the fractional bits:</p>
<div class="math notranslate nohighlight">
\[frac\_bits = value\_bits - int\_bits\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – a tensor of float values.</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits</p></li>
<li><p><strong>frac_bits</strong> (<em>tf.Tensor</em><em>, </em><em>optional</em>) – an integer tensor of fractional bits.
Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the FixedPoint tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.rescale">
<span class="sig-name descname"><span class="pre">rescale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.rescale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.rescale" title="Permalink to this definition"></a></dt>
<dd><p>Rescale a FixedPoint to a specified precision and bitwidth</p>
<p>This primarily rescales the FixedPoint values to match the precision
specified by the target fractional bits.</p>
<p>Optionally, this adjusts the value bits to the specified bitwidth.</p>
<p>The rescaling operation is:</p>
<ul class="simple">
<li><p>a left shift of the values when their precision increases,</p></li>
<li><p>a rounded right shift of the values when their precision decreases.</p></li>
</ul>
<p>This method can be used to:</p>
<ul class="simple">
<li><p>compress a FixedPoint to a lower bitwidth after having reduced its precision,</p></li>
<li><p>expand a FixedPoint to a larger bitwidth after having increased its precision.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>frac_bits</strong> (<em>tf.Tensor</em>) – the target fractional bits</p></li>
<li><p><strong>value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the target value bits</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the rescaled FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.shift">
<span class="sig-name descname"><span class="pre">shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.shift"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.shift" title="Permalink to this definition"></a></dt>
<dd><p>Apply a tensor-wide left or right shift.</p>
<p>This takes a tensor of shift values and apply them on each item of the
FixedPoint values.</p>
<p>The shift values should positive or negative integer:</p>
<ul class="simple">
<li><p>if the value is positive, it is a left-shift,</p></li>
<li><p>if the value is negative, it is a right-shift.</p></li>
</ul>
<p>The resulting FixedPoint has the same value bits and fractional bits as
the source FixedPoint, which means that clipping is applied on
left-shift and flooring is applied on right-shift.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>s</strong> (<em>tf.Tensor</em>) – the shift values for each pixel.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the result as a FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.sign">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">sign</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.sign" title="Permalink to this definition"></a></dt>
<dd><p>Returns the sign of the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the sign as a FixedPoint.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.upscale">
<span class="sig-name descname"><span class="pre">upscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.upscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.upscale" title="Permalink to this definition"></a></dt>
<dd><p>Align a FixedPoint to a specified precision</p>
<p>The target precision must be higher than the current one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>frac_bits</strong> (<em>tf.Tensor</em>) – the target fractional bits</p></li>
<li><p><strong>value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the target value bits</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the upscaled FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="qfloat">
<h3>QFloat<a class="headerlink" href="#qfloat" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">QFloat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p>
<p>A Tensor of FixedPoint values and scales representing float numbers</p>
<p>The QFloat is a dual representation of a float Tensor combining FixedPoint
values and float scales.</p>
<p>The QFloat is typically used to represent float tensors whose quantization
range is not ‘optimal’ for FixedPoint quantization: the original tensor is
first divided by the scales to be aligned on optimal ranges, then quantized
to FixedPoint values.</p>
<p>When converting back to float, values are dequantized and multiplied by the
scales to obtain the approximated float tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp</strong> (<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>) – a FixedPoint of values</p></li>
<li><p><strong>scales</strong> (<em>tf.Tensor</em>) – a Tensor of scales</p></li>
</ul>
</dd>
</dl>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.Spec" title="quantizeml.tensors.QFloat.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.max_frac_bits" title="quantizeml.tensors.QFloat.max_frac_bits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_frac_bits</span></code></a>(value_bits, ranges, scales[, ...])</p></td>
<td><p>Evaluate the maximum fractional bit index for the quantization ranges.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.optimal_scales" title="quantizeml.tensors.QFloat.optimal_scales"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimal_scales</span></code></a>(ranges, value_bits)</p></td>
<td><p>Evaluates the optimal QFloat scales for quantization ranges.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.promote" title="quantizeml.tensors.QFloat.promote"><code class="xref py py-obj docutils literal notranslate"><span class="pre">promote</span></code></a>(bits)</p></td>
<td><p>Increase the number of value bits</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.quantize" title="quantizeml.tensors.QFloat.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(x, value_bits, scales[, frac_bits])</p></td>
<td><p>Converts a float Tensor to a QFloat</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.quantize_scales" title="quantizeml.tensors.QFloat.quantize_scales"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize_scales</span></code></a>(scales, scale_bits)</p></td>
<td><p>Quantizes the QFloat scales with the specified bitwidth.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.to_fixed_point" title="quantizeml.tensors.QFloat.to_fixed_point"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_fixed_point</span></code></a>([scale_bits])</p></td>
<td><p>Returns a FixedPoint representation of the QFloat</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.to_float" title="quantizeml.tensors.QFloat.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QFloat</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.upscale" title="quantizeml.tensors.QFloat.upscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">upscale</span></code></a>(frac_bits[, value_bits])</p></td>
<td><p>Align a QFloat to a specified precision</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.name" title="quantizeml.tensors.QFloat.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>Returns the QTensor name</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.per_tensor" title="quantizeml.tensors.QFloat.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.QFloat.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.QFloat" title="quantizeml.tensors.qfloat.QFloat"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.max_frac_bits">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">max_frac_bits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ranges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clamp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.max_frac_bits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.max_frac_bits" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the maximum fractional bit index for the quantization ranges.</p>
<p>This method evaluates the minimum number of integer bits required to cover
the specified quantization ranges after having rescaled them with the specified
scales.
It simply calls the equivalent FixedPoint method on the rescaled ranges.
If specified, it clamps the results to the available value_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits.</p></li>
<li><p><strong>ranges</strong> (<em>tf.Tensor</em>) – a tensor of float quantization ranges.</p></li>
<li><p><strong>scales</strong> (<em>tf.Tensor</em>) – the scales to apply to the quantization ranges.</p></li>
<li><p><strong>clamp</strong> (<em>bool</em><em>, </em><em>optional</em>) – clamp the results to self.value_bits. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tensor of fractional bits.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#quantizeml.tensors.QFloat.name" title="Permalink to this definition"></a></dt>
<dd><p>Returns the QTensor name</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the QTensor name</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.optimal_scales">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">optimal_scales</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ranges</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.optimal_scales"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.optimal_scales" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the optimal QFloat scales for quantization ranges.</p>
<p>We choose the optimal quantization range for a given bitwidth as:</p>
<blockquote>
<div><p>[-int_max, int_max], with <span class="math notranslate nohighlight">\(int\_max = 2^{bits} - 1\)</span>.</p>
</div></blockquote>
<p>This methods evaluates the scales as the ratio to align the specified ranges
to the optimal ranges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ranges</strong> (<em>tf.Tensor</em>) – a tensor of quantization ranges.</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the optimal scales.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.QFloat.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.promote">
<span class="sig-name descname"><span class="pre">promote</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.promote"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.promote" title="Permalink to this definition"></a></dt>
<dd><p>Increase the number of value bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bits</strong> (<em>int</em>) – the new number of value bits</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a QFloat with increased value bits</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.QFloat" title="quantizeml.tensors.QFloat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.quantize">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Converts a float Tensor to a QFloat</p>
<p>It first evaluates and quantizes the scales required to align the quantization ranges
to the optimal range for the specified value bits.</p>
<p>It then quantizes the inputs with the quantized scales.</p>
<p>The resulting integer values are clipped to [-int_max-1, int_max].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>tf.Tensor</em>) – a tensor of float values.</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits.</p></li>
<li><p><strong>scales</strong> (<em>tf.Tensor</em>) – a tensor of alignment scales.</p></li>
<li><p><strong>frac_bits</strong> (<em>int</em>) – the inner FixedPoint fractional bits (defaults to 0).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the QFloat representation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.QFloat" title="quantizeml.tensors.QFloat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.quantize_scales">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">quantize_scales</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scales</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.quantize_scales"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.quantize_scales" title="Permalink to this definition"></a></dt>
<dd><p>Quantizes the QFloat scales with the specified bitwidth.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scales</strong> (<em>tf.Tensor</em>) – a tensor of float scales.</p></li>
<li><p><strong>scale_bits</strong> (<em>int</em>) – the number of scales bits.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the FixedPoint scales.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.to_fixed_point">
<span class="sig-name descname"><span class="pre">to_fixed_point</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.to_fixed_point"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.to_fixed_point" title="Permalink to this definition"></a></dt>
<dd><p>Returns a FixedPoint representation of the QFloat</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scale_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the scales quantization bitwidth. Defaults to 8.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the FixedPoint representation and scales.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, <a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QFloat</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.upscale">
<span class="sig-name descname"><span class="pre">upscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.upscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.upscale" title="Permalink to this definition"></a></dt>
<dd><p>Align a QFloat to a specified precision</p>
<p>The target precision must be higher than the current one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>frac_bits</strong> (<em>tf.Tensor</em>) – the target fractional bits</p></li>
<li><p><strong>value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the target value bits (defaults to current value bits)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the upscaled FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="onnx-support">
<h2>ONNX support<a class="headerlink" href="#onnx-support" title="Permalink to this headline"></a></h2>
<section id="id2">
<h3>Layers<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.OnnxLayer">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">OnnxLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opset_imports</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/base_layer.html#OnnxLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.OnnxLayer" title="Permalink to this definition"></a></dt>
<dd><p>Abstract class that represents an onnx subgraph in brainchip domain.</p>
<p>Child must define the attributes on __init__ and return the node list (subgraph) on
build_subgraph(). If these requirements are met, make_node() could be used to
define/register the custom node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_name</strong> (<em>str</em>) – the operation type base name.</p></li>
<li><p><strong>opset_imports</strong> (<em>list of OperatorSetIdProto</em><em>, </em><em>optional</em>) – the custom opset. Defaults to None.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – the custom attributes. Each attribute type will be
infered by <code class="docutils literal notranslate"><span class="pre">onnx.helper.make_attribute()</span></code>. Defaults to {}.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.QuantizedConv2D">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">2)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_pads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">0,</span> <span class="pre">0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/conv2d.html#QuantizedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.QuantizedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of QLinearConv() + MaxPool() + ReLU() as an exportable node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>strides</strong> (<em>list of int</em><em>, </em><em>optional</em>) – the convolutional strides. Defaults to [1, 1].</p></li>
<li><p><strong>pool_type</strong> (<em>str</em><em>, </em><em>optional</em>) – the pool type, one of {“none”, “max”, “gap”}. Defaults to “none”.</p></li>
<li><p><strong>pool_size</strong> (<em>list of int</em><em>, </em><em>optional</em>) – the kernel pool shape.
Ignore it when pool_type != “max”. Defaults to (2, 2).</p></li>
<li><p><strong>pool_stride</strong> (<em>list of int</em><em>, </em><em>optional</em>) – the kernel strides.
Ignore it when pool_type != “max”. Defaults to (2, 2).</p></li>
<li><p><strong>pool_pads</strong> (<em>list of int</em><em>, </em><em>optional</em>) – the size of each padding dimension.
Ignore it when pool_type != “max”. Defaults to [0, 0, 0, 0].</p></li>
<li><p><strong>input_conv</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether it is extended the set of operations of
the basic QuantizedConv2D, allowing to modify the padding value per input channel.
Defaults to False.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to apply relu operation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.QuantizedDepthwise2D">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDepthwise2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">1]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/depthwise2d.html#QuantizedDepthwise2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.QuantizedDepthwise2D" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of Conv() + MaxPool() + ReLU() as an exportable node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>strides</strong> (<em>list of int</em><em>, </em><em>optional</em>) – the convolutional strides. Defaults to [1, 1].</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to apply relu operation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.QuantizedDense1D">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDense1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">flatten</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/dense.html#QuantizedDense1D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.QuantizedDense1D" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of Flatten() + QGemm() + ReLU() as an exportable node.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>flatten</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to flatten the inputs. Defaults to False.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to apply relu operation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.QuantizedAdd">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/multi_inbounds.html#QuantizedAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.QuantizedAdd" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of Add() as an exportable node.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.InputQuantizer">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">InputQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_signed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/quantizers.html#InputQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.InputQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of QuantizeLinear(), use to quantize the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tp</strong> (<em>TensorProto</em>) – the input of the ONNX model.</p></li>
<li><p><strong>input_signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the input is signed. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.layers.Dequantizer">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.layers.</span></span><span class="sig-name descname"><span class="pre">Dequantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/layers/quantizers.html#Dequantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.layers.Dequantizer" title="Permalink to this definition"></a></dt>
<dd><p>Intermediate representation of DequantizeLinear(), use to dequantize the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the node name. Defaults to ‘’.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="custom-patterns">
<h3>Custom patterns<a class="headerlink" href="#custom-patterns" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.onnx_support.quantization.custom_pattern_scope">
<span class="sig-prename descclassname"><span class="pre">quantizeml.onnx_support.quantization.</span></span><span class="sig-name descname"><span class="pre">custom_pattern_scope</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patterns</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/onnx_support/quantization/register_patterns.html#custom_pattern_scope"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.onnx_support.quantization.custom_pattern_scope" title="Permalink to this definition"></a></dt>
<dd><p>Register a custom pattern in the context to be used at quantization time.</p>
<p>A pattern is understood as a sequence of continuous operations in the graph,
whose representation can converge in an <code class="docutils literal notranslate"><span class="pre">OnnxLayer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>patterns</strong> (<em>dict</em>) – a list of sequence of nodes (keys) and their mapper function (values).</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cnn2snn_apis.html" class="btn btn-neutral float-left" title="CNN2SNN Toolkit API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="akida_models_apis.html" class="btn btn-neutral float-right" title="Akida models API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>