<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>QuantizeML API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Akida models API" href="akida_models_apis.html" />
    <link rel="prev" title="CNN2SNN Toolkit API" href="cnn2snn_apis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #78b3ff" >
            <a href="../index.html">
            <img src="../_static/akida.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                MetaTF 2.2.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#performances-measurement">Performances measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#yolo-training">YOLO training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/compatibility.html">Akida versions compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compatibility.html#upgrading-models-with-legacy-quantizers">Upgrading models with legacy quantizers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#dense2d">Dense2D</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#add">Add</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#sparsity">Sparsity</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#tool-functions">Tool functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize-layer">quantize_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#load-quantized-model">load_quantized_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#calibration">Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#stdperaxisquantizer">StdPerAxisQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cnn">CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="#add">Add</a></li>
<li class="toctree-l4"><a class="reference internal" href="#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reciprocal">Reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transformers">Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#qfloat">QFloat</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">Reciprocal</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#dense-block">dense_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mlp-block">mlp_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#multi-head-attention">multi_head_attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformer-block">transformer_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#conv-transpose-block">conv_transpose_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#sepconv-transpose-block">sepconv_transpose_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#tools">tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#batchnormalization-gamma-constraint">BatchNormalization gamma constraint</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#convtiny">ConvTiny</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/index.html">General examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html">Regression tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/index.html">CNN2SNN tutorials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/index.html">Edge examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#time-icon-ref-time-domain"> Time domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#fault-detection">Fault detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id2">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #78b3ff" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="api_reference.html">API reference</a> &raquo;</li>
      <li>QuantizeML API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-quantizeml">
<span id="quantizeml-api"></span><h1>QuantizeML API<a class="headerlink" href="#module-quantizeml" title="Permalink to this headline"></a></h1>
<section id="layers">
<h2>Layers<a class="headerlink" href="#layers" title="Permalink to this headline"></a></h2>
<section id="reshaping">
<h3>Reshaping<a class="headerlink" href="#reshaping" title="Permalink to this headline"></a></h3>
<section id="quantizedflatten">
<h4>QuantizedFlatten<a class="headerlink" href="#quantizedflatten" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedFlatten">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedFlatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/flatten.html#QuantizedFlatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedFlatten" title="Permalink to this definition"></a></dt>
<dd><p>A Flatten layer that operates on quantized inputs</p>
</dd></dl>

</section>
<section id="quantizedpermute">
<h4>QuantizedPermute<a class="headerlink" href="#quantizedpermute" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedPermute">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedPermute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/permute.html#QuantizedPermute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedPermute" title="Permalink to this definition"></a></dt>
<dd><p>A Permute layer that operates on quantized inputs</p>
<p>Note: Keras Permute layer simply wraps the Tensorflow transpose op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dims</strong> (<em>tuple of ints</em>) – Permutation pattern does not include the
samples dimension. Indexing starts at 1.
For instance, <cite>(2, 1)</cite> permutes the first and second dimensions
of the input.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedreshape">
<h4>QuantizedReshape<a class="headerlink" href="#quantizedreshape" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedReshape">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedReshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reshaping/reshape.html#QuantizedReshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedReshape" title="Permalink to this definition"></a></dt>
<dd><p>A Reshape layer that operates on quantized inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_shape</strong> (<em>tuple of ints</em>) – Target shape, does not include the samples
dimension (batch size).</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="activations">
<h3>Activations<a class="headerlink" href="#activations" title="Permalink to this headline"></a></h3>
<section id="quantizedgelu">
<h4>QuantizedGELU<a class="headerlink" href="#quantizedgelu" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedGELU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedGELU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/activations.html#QuantizedGELU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedGELU" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the <a class="reference external" href="https://arxiv.org/abs/1606.08415">Gaussian Error Linear Units (GELU)</a>
activation, following the implementation on <a class="reference external" href="https://arxiv.org/abs/2101.01321">i-BERT</a>.</p>
<p>To quantize non-linear activation functions, three ways are commonly used:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Dequantize the input, make the activation function in float and then quantize the output.</p></li>
<li><p>Store the quantized input in a lookup table, and use it to quantize.</p></li>
<li><p>Approximate the activation function with a linear function.</p></li>
</ol>
</div></blockquote>
<p>Follow the explanation given on <a class="reference external" href="https://arxiv.org/abs/2101.01321">i-BERT</a>, in order
to reduce on-chip memory cost and increase efficient hardware performance, the third way
is used here.</p>
<p>The GELU activation function is defined as:</p>
<div class="math notranslate nohighlight">
\[GELU(x) = 0.5*x*[1 + erf(\frac{x}{sqrt(2)})]\]</div>
<p>Where erf(<span class="math notranslate nohighlight">\(x\)</span>) is the error function. <a class="reference external" href="https://arxiv.org/abs/2101.01321">i-BERT</a> shows
that a degree two polynomial approximation to the erf function would be given by</p>
<div class="math notranslate nohighlight">
\[L(x) = sgn(x)[a(clip(|x|, max = -b) + b)^2 + 1]\]</div>
<p>With <span class="math notranslate nohighlight">\(a = -0.2888\)</span>, <span class="math notranslate nohighlight">\(b = -1.769\)</span>, and average error / maximum error of
<span class="math notranslate nohighlight">\(8.2\times10^{-3} / 1.8\times10^{-2}\)</span> (respectively), within the range <span class="math notranslate nohighlight">\(|x| &lt; 1\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em>) – quantization configuration of input/output quantizers.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedrelu">
<h4>QuantizedReLU<a class="headerlink" href="#quantizedrelu" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedReLU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/activations.html#QuantizedReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedReLU" title="Permalink to this definition"></a></dt>
<dd><p>Quantized version of the ReLU activation layer applicable on FixedPoint tensor.</p>
</dd></dl>

</section>
</section>
<section id="attention">
<h3>Attention<a class="headerlink" href="#attention" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Attention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#Attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Attention" title="Permalink to this definition"></a></dt>
<dd><p>Dot-product attention layer with configurable softmax.</p>
<p>Inputs are a tuple of tensors:
- a query tensor of shape [batch, tokens, hidden],
- a key tensor of shape [batch, tokens, hidden],
- a value tensor of shape [batch, tokens, hidden].</p>
<p>The calculation follows the steps:</p>
<ol class="arabic">
<li><p>Split query, key, value per attention heads</p>
<blockquote>
<div><p>q, k, v : [batch, tokens, hidden] -&gt; [batch, token, num_heads, dim]</p>
</div></blockquote>
</li>
<li><p>Calculate cross-token scores as a query-key dot product:</p>
<blockquote>
<div><p>scores = tf.matmul(query, key, transpose_b=True)</p>
<p>scores : [batch, num_heads, token, token]</p>
</div></blockquote>
</li>
<li><p>Rescale score by dividing by the squared-root of dim.</p></li>
<li><p>Use scores to calculate a mask</p>
<blockquote>
<div><p>mask = softmax(scores)</p>
</div></blockquote>
</li>
<li><p>Combine mask with value</p>
<blockquote>
<div><p>output = tf.matmul(mask, value)</p>
<p>output: [batch, num_heads, token, dim]</p>
</div></blockquote>
</li>
<li><p>Merge heads to get back to 2D</p>
<blockquote>
<div><p>output: [batch, num_heads, token, dim] -&gt; [batch, token, hidden]</p>
</div></blockquote>
</li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> (<em>int</em>) – the number of attention heads</p></li>
<li><p><strong>softmax</strong> (<em>str</em><em>, </em><em>optional</em>) – ‘softmax’ or ‘shiftmax’. Defaults to ‘softmax’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<section id="quantizedattention">
<h4>QuantizedAttention<a class="headerlink" href="#quantizedattention" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAttention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAttention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#QuantizedAttention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAttention" title="Permalink to this definition"></a></dt>
<dd><p>An Attention layer that operates on quantized inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> (<em>int</em>) – the number of attention heads</p></li>
<li><p><strong>softmax</strong> (<em>str</em><em>, </em><em>optional</em>) – ‘softmax’ or ‘shiftmax’. Defaults to ‘shiftmax’</p></li>
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="string-to-softmax">
<h4>string_to_softmax<a class="headerlink" href="#string-to-softmax" title="Permalink to this headline"></a></h4>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.string_to_softmax">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">string_to_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/attention.html#string_to_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.string_to_softmax" title="Permalink to this definition"></a></dt>
<dd><p>Convert a string to a softmax function.
Available options are ‘softmax’ for standard softmax, ‘shiftmax’ for
shiftmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>s</strong> (<em>str</em>) – string to convert.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A softmax function.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="cnn">
<h3>CNN<a class="headerlink" href="#cnn" title="Permalink to this headline"></a></h3>
<section id="paddedconv2d">
<h4>PaddedConv2D<a class="headerlink" href="#paddedconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.PaddedConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">PaddedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#PaddedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.PaddedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A convolutional layer that can use a custom padding value.</p>
<p>Note that when a padding value is provided, padding ‘SAME’ will be applied with the provided
value (overriding ‘padding’ parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding_value</strong> (<em>float</em><em>, </em><em>optional</em>) – the value used when padding for the ‘same’ convolution
type. If None, zero-padding is used. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedconv2d">
<h4>QuantizedConv2D<a class="headerlink" href="#quantizedconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#QuantizedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A convolutional layer that operates on quantized inputs and weights.</p>
<p>Note that when a padding value is provided, padding ‘SAME’ will be applied with the provided
value (overriding ‘padding’ parameter).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p></li>
<li><p><strong>padding_value</strong> (<em>float</em><em>, </em><em>optional</em>) – the value used when padding for the ‘same’ convolution
type. If None, zero-padding is used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedconv2dtranspose">
<h4>QuantizedConv2DTranspose<a class="headerlink" href="#quantizedconv2dtranspose" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/convolution.html#QuantizedConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizeddepthwiseconv2d">
<h4>QuantizedDepthwiseConv2D<a class="headerlink" href="#quantizeddepthwiseconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDepthwiseConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDepthwiseConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/depthwise_convolution.html#QuantizedDepthwiseConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDepthwiseConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A depthwise convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedseparableconv2d">
<h4>QuantizedSeparableConv2D<a class="headerlink" href="#quantizedseparableconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedSeparableConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedSeparableConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/separable_convolution.html#QuantizedSeparableConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedSeparableConv2D" title="Permalink to this definition"></a></dt>
<dd><p>A separable convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="separableconv2dtranspose">
<h4>SeparableConv2DTranspose<a class="headerlink" href="#separableconv2dtranspose" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.SeparableConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">SeparableConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/separable_convolution.html#SeparableConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.SeparableConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed separable convolutional layer.</p>
<p>It performs a transposed depthwise convolution on inputs followed by a standard pointwise
operation.</p>
</dd></dl>

</section>
<section id="quantizedseparableconv2dtranspose">
<h4>QuantizedSeparableConv2DTranspose<a class="headerlink" href="#quantizedseparableconv2dtranspose" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedSeparableConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedSeparableConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/separable_convolution.html#QuantizedSeparableConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedSeparableConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>A transposed separable convolutional layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizeddense">
<h4>QuantizedDense<a class="headerlink" href="#quantizeddense" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedDense">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedDense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/dense.html#QuantizedDense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedDense" title="Permalink to this definition"></a></dt>
<dd><p>A Dense layer that operates on quantized inputs and weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="dropout">
<h3>Dropout<a class="headerlink" href="#dropout" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QDropout">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/dropout.html#QDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QDropout" title="Permalink to this definition"></a></dt>
<dd><p>A dropout layer that operates on quantized inputs and weights.</p>
<p>It is only implemented as a passthrough.</p>
</dd></dl>

</section>
<section id="add">
<h3>Add<a class="headerlink" href="#add" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Add">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/layers.html#Add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Add" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>keras.layers.Add</cite> that allows to average inputs.
We only support a tuple of two inputs with same shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>average</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>True</cite>, compute the average across all inputs.
Defaults to <cite>False</cite>.</p>
</dd>
</dl>
</dd></dl>

<section id="quantizedadd">
<h4>QuantizedAdd<a class="headerlink" href="#quantizedadd" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAdd">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAdd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/layers.html#QuantizedAdd"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAdd" title="Permalink to this definition"></a></dt>
<dd><p>Sums two inputs and quantize the output.</p>
<p>The two inputs must be provided as a list or tuple of FixedPoint or Tensors.</p>
<p>The outputs are quantized according to the specified quantization configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.deserialize_quant_object">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">deserialize_quant_object</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quant_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">object_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_quantizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mandatory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/layers.html#deserialize_quant_object"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.deserialize_quant_object" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper function of tf.keras.utils.deserialize_keras_object.
It allows to select the right config from the config file dict,
and raises an error if no config found or set to None.
If one is found, it returns the corresponding deserialized Keras
object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>quant_config</strong> (<em>dict</em>) – quantization config dictionnary.</p></li>
<li><p><strong>object_name</strong> (<em>str</em>) – keras object name to deserialize.</p></li>
<li><p><strong>weight_quantizer</strong> (<em>bool</em>) – if true set a WeightQuantizer otherwise
set an OutputQuantizer.</p></li>
<li><p><strong>mandatory</strong> (<em>bool</em><em>, </em><em>optional</em>) – flag to specify if the object to
deserialize is mandatory. If yes raises an Error otherwise
returns None. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the targeted deserialized keras
object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.keras.class</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="normalization">
<h3>Normalization<a class="headerlink" href="#normalization" title="Permalink to this headline"></a></h3>
<section id="layermadnormalization">
<h4>LayerMadNormalization<a class="headerlink" href="#layermadnormalization" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.LayerMadNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">LayerMadNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/normalization.html#LayerMadNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.LayerMadNormalization" title="Permalink to this definition"></a></dt>
<dd><p>Approximates the <code class="xref py py-obj docutils literal notranslate"><span class="pre">keras.layers.LayerNormalization</span></code> (LN), replacing the computation of
the standard deviation by the mean average deviation (mad).</p>
<p>Taking into account the complexity of the calculate required in the standard deviation,
the LayerMadNormalization (LMN) is intended to replace the <span class="math notranslate nohighlight">\(std(x)\)</span> by <span class="math notranslate nohighlight">\(mad(x)\)</span>,
defined as:</p>
<div class="math notranslate nohighlight">
\[mad(x) = |x - mean(x)| * 2^\text{-nb_channels}\]</div>
<p>Then, the equation of the layer is defined as:</p>
<div class="math notranslate nohighlight">
\[LMN(x) = \gamma\frac{x - mean(x)}{mad(x)} + \beta\]</div>
<p>Also, to develop a hardware compatible quantization, we make the approximation of mean
on a Power Of Two (PoT):</p>
<div class="math notranslate nohighlight">
\[mean(x) = sum(x) * 2^\text{-nb_channels}\]</div>
<p>Where nb_channels = <span class="math notranslate nohighlight">\(round(log2(inputs.shape[axis]))\)</span></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A tuning step in the switching procedure between the LN to LMN layer will be required
to find the <span class="math notranslate nohighlight">\((\gamma, \beta)\)</span> parameters that match the standard deviation changes.</p>
</div>
</dd></dl>

</section>
<section id="quantizedlayernormalization">
<h4>QuantizedLayerNormalization<a class="headerlink" href="#quantizedlayernormalization" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedLayerNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedLayerNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/normalization.html#QuantizedLayerNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedLayerNormalization" title="Permalink to this definition"></a></dt>
<dd><p>A LayerNormalization layer that operates on quantized inputs and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="pooling">
<h3>Pooling<a class="headerlink" href="#pooling" title="Permalink to this headline"></a></h3>
<section id="quantizedmaxpool2d">
<h4>QuantizedMaxPool2D<a class="headerlink" href="#quantizedmaxpool2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedMaxPool2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedMaxPool2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/pooling.html#QuantizedMaxPool2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedMaxPool2D" title="Permalink to this definition"></a></dt>
<dd><p>A max pooling layer that operates on quantized inputs.</p>
</dd></dl>

</section>
<section id="quantizedglobalaveragepooling2d">
<h4>QuantizedGlobalAveragePooling2D<a class="headerlink" href="#quantizedglobalaveragepooling2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedGlobalAveragePooling2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedGlobalAveragePooling2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/pooling.html#QuantizedGlobalAveragePooling2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedGlobalAveragePooling2D" title="Permalink to this definition"></a></dt>
<dd><p>A global average pooling layer that operates on quantized inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="quantizers">
<h3>Quantizers<a class="headerlink" href="#quantizers" title="Permalink to this headline"></a></h3>
<section id="quantizer">
<h4>Quantizer<a class="headerlink" href="#quantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Quantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Quantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#Quantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Quantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>The base class for all quantizers.</p>
<p>The bitwidth defines the number of quantization levels on which the
values will be quantized.
For a quantizer that accepts unsigned values, the maximum quantization
level is 2 ^ bitwidth - 1.
For a quantizer that accepts signed values, we lose one bit of precision to
store the sign.
When the quantizer is signed, the quantization interval is asymmetric around
zero (i.e range: [- 2 ^ (bitwidth - 1), 2 ^ (bitwidth - 1) - 1]).
The quantization is actually performed on absolute values, between 0 and
max_value, where:</p>
<ul class="simple">
<li><p>max_value is either a scalar (per-tensor quantization), or a vector
(per-axis quantization),</p></li>
<li><p>max_value is a static value on inference, and an adaptative value on training.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth.</p></li>
<li><p><strong>signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the quantizer expects signed values or unsigned.
Defaults to True.</p></li>
<li><p><strong>axis</strong> (<em>str</em><em>, </em><em>optional</em>) – reduce across all tensor values (‘per-tensor’) or keep the
last axis (‘per-axis’). Defaults to ‘per-tensor’.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To get more information about the moving average implementation, see the
<a class="reference external" href="https://bit.ly/3KcEaUh">BatchNormalizationLayer</a> class.</p>
</div>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.Quantizer.build" title="quantizeml.layers.Quantizer.build"><code class="xref py py-obj docutils literal notranslate"><span class="pre">build</span></code></a>(input_shape)</p></td>
<td><p>Build the layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.layers.Quantizer.get_config" title="quantizeml.layers.Quantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Get the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.Quantizer.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#Quantizer.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Quantizer.build" title="Permalink to this definition"></a></dt>
<dd><p>Build the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>list</em>) – the shape of input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.Quantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#Quantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Quantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get the config of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the config of the layer.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="weightquantizer">
<h4>WeightQuantizer<a class="headerlink" href="#weightquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">WeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#WeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.layers.Quantizer" title="quantizeml.layers.quantizers.Quantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.quantizers.Quantizer</span></code></a></p>
<p>A trivial uniform quantizer that has only one scale for everything.</p>
<p>Scale is dynamic (depends on inputs), and it can be read via the scale property.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth.</p></li>
<li><p><strong>scale_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of bits for the scaling. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.WeightQuantizer.call" title="quantizeml.layers.WeightQuantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs[, training])</p></td>
<td><p>Update the max_value from the new inputs, and quantize them in three steps:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.layers.WeightQuantizer.get_config" title="quantizeml.layers.WeightQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Get the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#WeightQuantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Update the max_value from the new inputs, and quantize them in three steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Check if the inputs are float values,</p></li>
<li><p>Compute and update the max_value, only during training or if max_value
has never been updated and</p></li>
<li><p>Quantize the inputs.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code>) – the inputs tensor.</p></li>
<li><p><strong>training</strong> (<em>bool</em><em>, </em><em>optional</em>) – the training mode. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.WeightQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#WeightQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.WeightQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get the config of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the config of the layer.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="outputquantizer">
<h4>OutputQuantizer<a class="headerlink" href="#outputquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">OutputQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#OutputQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.layers.Calibrable</span></code>, <a class="reference internal" href="#quantizeml.layers.Quantizer" title="quantizeml.layers.quantizers.Quantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.layers.quantizers.Quantizer</span></code></a></p>
<p>A uniform quantizer that aligns its quantization range to a Power-of-two.
Its max_value is updated during the calibration by the moving average algorithm,
inspired by the BatchNormalizationLayer moving average algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth.</p></li>
<li><p><strong>signed</strong> (<em>bool</em>) – whether the quantizer expects signed values or unsigned.</p></li>
<li><p><strong>momentum</strong> (<em>float</em><em>, </em><em>optional</em>) – the momentum for the moving average. Defaults to 0.9.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To get more information about the moving average implementation, see the
<a class="reference external" href="https://bit.ly/3KcEaUh">BatchNormalizationLayer</a> class:</p>
</div>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.OutputQuantizer.call" title="quantizeml.layers.OutputQuantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs[, training])</p></td>
<td><p>Update the max_value from moving average, and quantize the inputs in three steps:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.layers.OutputQuantizer.get_config" title="quantizeml.layers.OutputQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Get the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#OutputQuantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Update the max_value from moving average, and quantize the inputs in three steps:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Check that the inputs Tensor is a FixedPoint,</p></li>
<li><p>Update the max_value from moving average, only if calibration is enabled and</p></li>
<li><p>Quantize the inputs.</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code>) – the inputs tensor.</p></li>
<li><p><strong>training</strong> (<em>bool</em><em>, </em><em>optional</em>) – the training mode. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.OutputQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#OutputQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.OutputQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Get the config of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the config of the layer.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dequantizer">
<h4>Dequantizer<a class="headerlink" href="#dequantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Dequantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Dequantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#Dequantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Dequantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Layer that allows to dequantize its inputs.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.layers.Dequantizer.call" title="quantizeml.layers.Dequantizer.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs[, training])</p></td>
<td><p>Convert QTensor inputs to float.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.layers.Dequantizer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/quantizers.html#Dequantizer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Dequantizer.call" title="Permalink to this definition"></a></dt>
<dd><p>Convert QTensor inputs to float.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code>) – the inputs tensor(s).</p></li>
<li><p><strong>training</strong> (<em>bool</em><em>, </em><em>optional</em>) – the training mode. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the dequantized tensor(s).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="reciprocal">
<h3>Reciprocal<a class="headerlink" href="#reciprocal" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Reciprocal">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Reciprocal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reciprocal.html#Reciprocal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Reciprocal" title="Permalink to this definition"></a></dt>
<dd><p>Layer that computes the reciprocal of the input.</p>
</dd></dl>

<section id="quantizedreciprocal">
<h4>QuantizedReciprocal<a class="headerlink" href="#quantizedreciprocal" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedReciprocal">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedReciprocal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/reciprocal.html#QuantizedReciprocal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedReciprocal" title="Permalink to this definition"></a></dt>
<dd><p>Piece-wise approximation of y = 1/x.</p>
<p>The approximation works on values in the range [1, 2).
To go into that range, we shift the input to put the leftmost bit (MSB) to
1 and change the frac_bits so that there is only one int bit.
Once that is done the approximation is as follows:</p>
<p>y’ = 1.59375 - 0.625 * x if x &lt; 1.5
y’ = 1.125 - 0.3125 * x  if x &gt;= 1.5</p>
<p>Note that this can be performed in hardware this way:</p>
<p>y’ = 51 * 2^-5 - x * (2^-1 + 2^-3) if x &lt; 1.5
y’ = 36 * 2^-5 - x * (2^-2 + 2^-4) if x &gt;= 1.5</p>
<p>Implementation inspired by:</p>
<p>Cardarilli, G.C., Di Nunzio, L., Fazzolari, R. et al.
A pseudo-softmax function for hardware-based high speed image classification.
Sci Rep 11, 15307 (2021). <a class="reference external" href="https://doi.org/10.1038/s41598-021-94691-7">https://doi.org/10.1038/s41598-021-94691-7</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the quantization configuration. Defaults to {}.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="shiftmax">
<h3>Shiftmax<a class="headerlink" href="#shiftmax" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.Shiftmax">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">Shiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#Shiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.Shiftmax" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>shiftmax</cite> function, that calculates a softmax-like
activation.</p>
<p>Note that shiftmax operation is performed always along the last axis.</p>
</dd></dl>

<section id="quantizedshiftmax">
<h4>QuantizedShiftmax<a class="headerlink" href="#quantizedshiftmax" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedShiftmax">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedShiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#QuantizedShiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedShiftmax" title="Permalink to this definition"></a></dt>
<dd><p>A quantized layer to do a quantized function similar to the softmax, but
using base 2 instead of e. So we replace</p>
<div class="math notranslate nohighlight">
\[softmax(x_i) = \frac{e^{x_i}}{sum(e^{x_k})}\]</div>
<p>With this:</p>
<div class="math notranslate nohighlight">
\[softmax2(x_i) = \frac{2^{x_i}}{sum(2^{x_k})}\]</div>
<p>This approximation is close enough to the original function. In order to
make it more hardware friendly, we also approximated the <span class="math notranslate nohighlight">\(sum(2^{x_k})\)</span>
to the closest power of two:</p>
<div class="math notranslate nohighlight">
\[shiftmax(x_i) = \frac{2^{x_i}}{2^{round(log2(sum(2^{x_k})))}}\]</div>
<p>So it can be implemented with a simple shift operation.</p>
<p>Implementation is inspired from this paper:</p>
<p>Cardarilli, G.C., Di Nunzio, L., Fazzolari, R. et al.
A pseudo-softmax function for hardware-based high speed image classification.
Sci Rep 11, 15307 (2021). <a class="reference external" href="https://doi.org/10.1038/s41598-021-94691-7">https://doi.org/10.1038/s41598-021-94691-7</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.layers.shiftmax">
<span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">shiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/shiftmax.html#shiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.shiftmax" title="Permalink to this definition"></a></dt>
<dd><p>Computes softmax-like activations, but using base 2 for the exponential.</p>
<p>Used as approximation of the softmax activation.</p>
<p>This function performs the equivalent of</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span> <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">exp</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">logits</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">sum_exp_shift</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">softmax</span> <span class="o">=</span> <span class="n">exp</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">sum_exp_shift</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">logits</span> <span class="o">-</span>  <span class="n">sum_exp_shift</span><span class="p">)</span>
</pre></div>
</div>
<p>When 2 ** <code class="xref py py-attr docutils literal notranslate"><span class="pre">sum_exp_shift</span></code> is an approximated of sum_exp as a Power-of-Two (PoT)</p>
<p>To avoid a high exponential (and a tf.inf representation by tensorflow), we adopt the
following equivalence:</p>
<p>Making the variable change <span class="math notranslate nohighlight">\(y=logits-x0\)</span>, we reach the same result as
<span class="math notranslate nohighlight">\(p=shiftmax(logits)\)</span>, because,</p>
<div class="math notranslate nohighlight">
\[p' = \frac{2^y}{sum(2^y)}
   = \frac{2^{logits-x0}}{sum(2^{logits-x0})}
   = \frac{2^{logits} * 2^{-x0}}{2^{-x0} * sum(2^{logits})}
   = \frac{2^{logits}}{sum(2^{logits})}
   = p\]</div>
<p>We take <span class="math notranslate nohighlight">\(x0 = max(logits)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>) – a non-empty <cite>Tensor</cite>.</p></li>
<li><p><strong>axis</strong> (<em>int</em><em>, </em><em>list</em><em>, </em><em>optional</em>) – the dimension shiftmax would be performed
on. The default is -1 which indicates the last dimension.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>value of shiftmax function with the same type and shape as <cite>logits</cite>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>InvalidArgumentError</strong> – if <cite>logits</cite> is empty or <cite>axis</cite> is beyond the last
    dimension of <cite>logits</cite>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We floor the <code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code> to approximate the results to those expected
when quantizing the operation.</p>
</div>
</dd></dl>

</section>
</section>
<section id="transformers">
<h3>Transformers<a class="headerlink" href="#transformers" title="Permalink to this headline"></a></h3>
<section id="classtoken">
<h4>ClassToken<a class="headerlink" href="#classtoken" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.ClassToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">ClassToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#ClassToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.ClassToken" title="Permalink to this definition"></a></dt>
<dd><p>Append a class token to an input layer.</p>
</dd></dl>

</section>
<section id="quantizedclasstoken">
<h4>QuantizedClassToken<a class="headerlink" href="#quantizedclasstoken" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedClassToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedClassToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedClassToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedClassToken" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the <a class="reference internal" href="#quantizeml.layers.ClassToken" title="quantizeml.layers.ClassToken"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassToken</span></code></a> layer, allowing quantization of the output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="addpositionembs">
<h4>AddPositionEmbs<a class="headerlink" href="#addpositionembs" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.AddPositionEmbs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">AddPositionEmbs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#AddPositionEmbs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.AddPositionEmbs" title="Permalink to this definition"></a></dt>
<dd><p>Adds (optionally learned) positional embeddings to the inputs.</p>
</dd></dl>

</section>
<section id="quantizedaddpositionembs">
<h4>QuantizedAddPositionEmbs<a class="headerlink" href="#quantizedaddpositionembs" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedAddPositionEmbs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedAddPositionEmbs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedAddPositionEmbs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedAddPositionEmbs" title="Permalink to this definition"></a></dt>
<dd><p>Quantize the <a class="reference internal" href="#quantizeml.layers.AddPositionEmbs" title="quantizeml.layers.AddPositionEmbs"><code class="xref py py-class docutils literal notranslate"><span class="pre">AddPositionEmbs</span></code></a> layer, allowing operations in FixedPoint domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>quant_config</strong> (<em>dict</em><em>, </em><em>optional</em>) – the serialized quantization configuration.
Defaults to empty configuration.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="extracttoken">
<h4>ExtractToken<a class="headerlink" href="#extracttoken" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.ExtractToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">ExtractToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#ExtractToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.ExtractToken" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper class of <cite>tf.gather</cite> operation that allows to extract a Token.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>token</strong> (<em>int</em>) – the indice of the token to extract.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizedextracttoken">
<h4>QuantizedExtractToken<a class="headerlink" href="#quantizedextracttoken" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.layers.QuantizedExtractToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.layers.</span></span><span class="sig-name descname"><span class="pre">QuantizedExtractToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/layers/vit.html#QuantizedExtractToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.layers.QuantizedExtractToken" title="Permalink to this definition"></a></dt>
<dd><p>Quantized version of the ExtractToken layer. Accepts only FixedPoint inputs.</p>
</dd></dl>

</section>
</section>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline"></a></h2>
<section id="transforms">
<h3>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.invert_batchnorm_pooling">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">invert_batchnorm_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/batch_normalization.html#invert_batchnorm_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.invert_batchnorm_pooling" title="Permalink to this definition"></a></dt>
<dd><p>Inverts pooling and BatchNormalization layers in a model to have BN layer before pooling.</p>
<p>Returns a new model where pooling and batch normalization layers are inverted. From a Keras
model where pooling layers precede batch normalization layers, this function places the BN
layers before pooling layers. This is the first step before folding BN layers into processing
layers.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Inversion of layers is equivalent only if the gammas of BN layers are positive. The
function raises an error if not.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the updated model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if a candidate BatchNormalization layer has gamma values that are not strictly
    positive.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.fold_batchnorms">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">fold_batchnorms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/batch_normalization.html#fold_batchnorms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.fold_batchnorms" title="Permalink to this definition"></a></dt>
<dd><p>Returns a new model where BatchNormalization layers are folded into previous layers.</p>
<p>From a Keras model where BN layers follow processing layers, this function removes the BN layers
and updates the preceding layers weights and bias accordingly. The new model is strictly
equivalent to the previous one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the model with BN folded</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.transforms.fold_rescaling">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.transforms.</span></span><span class="sig-name descname"><span class="pre">fold_rescaling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/transforms/rescaling.html#fold_rescaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.transforms.fold_rescaling" title="Permalink to this definition"></a></dt>
<dd><p>Folds the Rescaling layer of the model into the next layer weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>keras.Model</em>) – a Keras model to fold</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the model with Rescaling layer folded</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantization">
<h3>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.quantize">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dequantizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/quantize.html#quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Quantizes the model using the provided configuration.</p>
<p>Applying the quantization configuration is done in two steps, giving priority to the first:</p>
<ol class="arabic">
<li><p>Match the quantization configuration from the layer name, as long as the final part of its
name matches with the configuration key.
Example: To quantize all “Transformer/EncoderBlock_x/MlpBlock/activation” layers, a
configuration with the key “activation” or “MlpBlock/activation” will be enough. This allows
the possibility to have a specific configuration for the activation function of block 5 using
the “Transformer/EncoderBlock_5/MlpBlock/activation” key.</p>
<p>Notes:</p>
<blockquote>
<div><ul class="simple">
<li><p>If configuration for all blocks are not defined, a global configuration is required.</p></li>
<li><p>To avoid ambiguity, the key with the most details in terms of hierarchy should be
selected, e.g. “activation” key in the quantization configuration will be enough to
quantize all “activation” layers. However, if it is required to define a different
configuration in all MLP blocks activations, configuration key should be
“MlpBlock/activation” instead.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Match the quantization configuration from the layer name, as long as the format
‘…/ParentLayer&lt;_i&gt;/SubParentLayer&lt;_j&gt;/…/Layer&lt;_k&gt;’ matches with layer.name, where {i, j,
k} are optional integers. Example: “EncoderBlock/add” key will quantize all layers ending
with the format “EncoderBlock_i/add_j” (“EncoderBlock_0/add_0”, “EncoderBlock_0/add_1”,
“EncoderBlock_1/add_0”, “EncoderBlock_1/add_1”, …).</p>
<blockquote>
<div><p>Note:</p>
<blockquote>
<div><p>The configuration priority in this case is defined by the number of hierarchical terms
and the detail in subindices from the end to the beginning of the key name. That is
“EncoderBlock/add_0” will have priority over “EncoderBlock/add” and
“EncoderBlock_0/add”. The “EncoderBlock_0/add_0” case is covered by the previous point.</p>
</div></blockquote>
</div></blockquote>
</li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to quantize</p></li>
<li><p><strong>q_config</strong> (<em>dict</em>) – quantization configuration</p></li>
<li><p><strong>add_dequantizer</strong> (<em>bool</em><em>, </em><em>optional</em>) – allows to convert output to float. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the quantized model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.dump_config">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">dump_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_default</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/quantize.html#dump_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.dump_config" title="Permalink to this definition"></a></dt>
<dd><p>Dump the quantization configuration of a quantized model, exporting the configuration for
each quantized layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – a quantized model.</p></li>
<li><p><strong>skip_default</strong> (<em>bool</em><em>, </em><em>optional</em>) – remove default values on each quantizer. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the configuration of the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="utils">
<h3>Utils<a class="headerlink" href="#utils" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.load_model">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compile_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.load_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads a model with Vision Transformer custom layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_path</strong> (<em>str</em>) – path of the model to load</p></li>
<li><p><strong>custom_layers</strong> (<em>dict</em><em>, </em><em>optional</em>) – custom layers to add to the model. Defaults to {}.</p></li>
<li><p><strong>compile_model</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether to compile the model. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the loaded model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">keras.models.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.deep_clone_model">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">deep_clone_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#deep_clone_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.deep_clone_model" title="Permalink to this definition"></a></dt>
<dd><p>Clone a model, assign variable to variable. Useful when a clone function is used,
and new layers have not the same number of parameters as the original layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">keras.models.Model</span></code>) – model to be cloned</p></li>
<li><p><strong>args</strong> (<em>optional</em>) – arguments pass to <code class="xref py py-func docutils literal notranslate"><span class="pre">keras.models.clone_model()</span></code> function</p></li>
<li><p><strong>kwargs</strong> (<em>optional</em>) – arguments pass to <code class="xref py py-func docutils literal notranslate"><span class="pre">keras.models.clone_model()</span></code> function</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the cloned model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">keras.models.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.set_calibrate">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">set_calibrate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#set_calibrate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.set_calibrate" title="Permalink to this definition"></a></dt>
<dd><p>Enable or disable calibration for all layers in a model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">keras.models.Model</span></code>) – model to be calibrated</p></li>
<li><p><strong>value</strong> (<em>bool</em>) – True to enable calibration, False to disable it</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.insert_layer">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">insert_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layer_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#insert_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.insert_layer" title="Permalink to this definition"></a></dt>
<dd><p>Inserts the given layer in the model before or after the layer with the name
target_layer_name depending on the type of new_layer.</p>
<p>Note that new_layer type is restricted to (Quantizer, Dequantizer) and a Quantizer will be added
before new_layer while a Dequantizer will be added after</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p></li>
<li><p><strong>target_layer_name</strong> (<em>str</em>) – name of the layer after which to insert a layer</p></li>
<li><p><strong>new_layer</strong> (<em>keras.Layer</em>) – layer to insert</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – when target_layer_name is not found in model or new_layer is not in (Quantizer,
    Dequantizer)</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the new model</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.load_weights">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">load_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#load_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.load_weights" title="Permalink to this definition"></a></dt>
<dd><p>Loads weights from a npz file and apply it to a model.</p>
<p>Go through the dictionary of weights of the npz file, find the corresponding variable in the
model and partially load its weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to update</p></li>
<li><p><strong>weights_path</strong> (<em>str</em>) – the path of the npz file to load</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.models.save_weights">
<span class="sig-prename descclassname"><span class="pre">quantizeml.models.</span></span><span class="sig-name descname"><span class="pre">save_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/models/utils.html#save_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.models.save_weights" title="Permalink to this definition"></a></dt>
<dd><p>Save model weights on an npz file.</p>
<p>Takes a model and save the weights of all its layers into an npz file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>keras.Model</em>) – the model to save its weights</p></li>
<li><p><strong>weights_path</strong> (<em>str</em>) – the path of the npz file to save</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline"></a></h2>
<section id="qtensor">
<h3>QTensor<a class="headerlink" href="#qtensor" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">QTensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tensorflow.python.framework.ops.Tensor</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">7</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tensorflow.python.framework.tensor_shape.TensorShape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.framework.extension_type.ExtensionType</span></code></p>
<p>Abstract class to exchange quantized tensors between layers</p>
<p>The QTensor values are actually stored as integer, but it provides a
conversion method to project these values into a float representation.</p>
<p>The value_bits parameter sets the maximum integer values that can be stored:</p>
<blockquote>
<div><p>int_max = 2^bits - 1.</p>
</div></blockquote>
<p>When a QTensor is created, its values are clipped to [-int_max-1, int_max].</p>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.Spec" title="quantizeml.tensors.QTensor.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.assert_per_tensor" title="quantizeml.tensors.QTensor.assert_per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assert_per_tensor</span></code></a>()</p></td>
<td><p>Asserts that a QTensor is quantized per-tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.clone" title="quantizeml.tensors.QTensor.clone"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clone</span></code></a>()</p></td>
<td><p>Returns a copy of the QTensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.to_float" title="quantizeml.tensors.QTensor.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QTensor</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QTensor.per_tensor" title="quantizeml.tensors.QTensor.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.QTensor.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.assert_per_tensor">
<span class="sig-name descname"><span class="pre">assert_per_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.assert_per_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.assert_per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Asserts that a QTensor is quantized per-tensor</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.clone">
<span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.clone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.clone" title="Permalink to this definition"></a></dt>
<dd><p>Returns a copy of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the copy.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.QTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QTensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.QTensor.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QTensor.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qtensor.html#QTensor.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QTensor.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="fixedpoint">
<h3>FixedPoint<a class="headerlink" href="#fixedpoint" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">FixedPoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p>
<p>A Tensor of integer values representing fixed-point numbers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a tensor of integer values</p></li>
<li><p><strong>frac_bits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>, optional) – an integer tensor of
fractional bits. Defaults to 0.</p></li>
<li><p><strong>value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of value bits. Defaults to 32.</p></li>
</ul>
</dd>
</dl>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.Spec" title="quantizeml.tensors.FixedPoint.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.abs" title="quantizeml.tensors.FixedPoint.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code></a>()</p></td>
<td><p>Returns the absolute value of the FixedPoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.align" title="quantizeml.tensors.FixedPoint.align"><code class="xref py py-obj docutils literal notranslate"><span class="pre">align</span></code></a>([other])</p></td>
<td><p>Align fractional bits</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.downscale" title="quantizeml.tensors.FixedPoint.downscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">downscale</span></code></a>(frac_bits, value_bits)</p></td>
<td><p>Encode a FixedPoint with a lower bitwidth</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.floor" title="quantizeml.tensors.FixedPoint.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code></a>()</p></td>
<td><p>Floors the FixedPoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.promote" title="quantizeml.tensors.FixedPoint.promote"><code class="xref py py-obj docutils literal notranslate"><span class="pre">promote</span></code></a>(bits)</p></td>
<td><p>Increase the number of value bits</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.quantize" title="quantizeml.tensors.FixedPoint.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(x, frac_bits, value_bits)</p></td>
<td><p>Converts a float Tensor to a FixedPoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.shift" title="quantizeml.tensors.FixedPoint.shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shift</span></code></a>(s)</p></td>
<td><p>Apply a tensor-wide left or right shift.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.to_float" title="quantizeml.tensors.FixedPoint.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QTensor</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.per_tensor" title="quantizeml.tensors.FixedPoint.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint.sign" title="quantizeml.tensors.FixedPoint.sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code></a></p></td>
<td><p>Returns the sign of the FixedPoint</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.fixed_point.FixedPoint"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.abs">
<span class="sig-name descname"><span class="pre">abs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.abs" title="Permalink to this definition"></a></dt>
<dd><p>Returns the absolute value of the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the absolute value.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.align">
<span class="sig-name descname"><span class="pre">align</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.align"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.align" title="Permalink to this definition"></a></dt>
<dd><p>Align fractional bits</p>
<p>This returns an equivalent FixedPoint with a scalar fractional bit
corresponding to the maximum of:</p>
<blockquote>
<div><ul class="simple">
<li><p>the initial fractional bits on all channels,</p></li>
<li><p>when specified, the other FixedPoint fractional bits on all channels.</p></li>
</ul>
</div></blockquote>
<p>This is required before performing an operation that adds or subtracts
elements along the last dimension, to make sure all these elements are
in the same scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>) – a FixedPoint to align to</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>a new FixedPoint with aligned</dt><dd><p>fractional bits and the shift that was applied.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.downscale">
<span class="sig-name descname"><span class="pre">downscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.downscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.downscale" title="Permalink to this definition"></a></dt>
<dd><p>Encode a FixedPoint with a lower bitwidth</p>
<p>It applies a left/right shift to the source FixedPoint values to align
them on the target maximum fractional bits.</p>
<p>It then clips them to the boundaries specified by the target value bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>frac_bits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the target fractional bits</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the target value bits</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a <a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.floor">
<span class="sig-name descname"><span class="pre">floor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.floor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.floor" title="Permalink to this definition"></a></dt>
<dd><p>Floors the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>a new FixedPoint without</dt><dd><p>fractional bits and the shift that was applied.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple(<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.promote">
<span class="sig-name descname"><span class="pre">promote</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.promote"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.promote" title="Permalink to this definition"></a></dt>
<dd><p>Increase the number of value bits</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bits</strong> (<em>int</em>) – the new number of value bits</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a FixedPoint with increased value bits</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.quantize">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Converts a float Tensor to a FixedPoint</p>
<p>It converts the original float values into integer values so that:</p>
<div class="math notranslate nohighlight">
\[{x_{int}} = round(x * 2^{frac\_bits})\]</div>
<p>It then evaluates the maximum integer values that can be stored for
the specified value bits: int_max = 2^bits - 1.</p>
<p>The resulting integer values are clipped to [-int_max, int_max].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a tensor of float values.</p></li>
<li><p><strong>frac_bits</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – an integer tensor of fractional bits</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a <a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.shift">
<span class="sig-name descname"><span class="pre">shift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.shift"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.shift" title="Permalink to this definition"></a></dt>
<dd><p>Apply a tensor-wide left or right shift.</p>
<p>This takes a tensor of shift values and apply them on each item of the
FixedPoint values.</p>
<p>The shift values should positive or negative integer:</p>
<ul class="simple">
<li><p>if the value is positive, it is a left-shift,</p></li>
<li><p>if the value is negative, it is a right-shift.</p></li>
</ul>
<p>The resulting FixedPoint has the same value bits and fractional bits as
the source FixedPoint, which means that clipping is applied on
left-shift and flooring is applied on right-shift.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>s</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the shift values for each pixel.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the result as a FixedPoint</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.sign">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">sign</span></span><a class="headerlink" href="#quantizeml.tensors.FixedPoint.sign" title="Permalink to this definition"></a></dt>
<dd><p>Returns the sign of the FixedPoint</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the sign as a FixedPoint.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.FixedPoint.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/fixed_point.html#FixedPoint.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.FixedPoint.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QTensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="qfloat">
<h3>QFloat<a class="headerlink" href="#qfloat" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">QFloat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#quantizeml.tensors.QTensor" title="quantizeml.tensors.qtensor.QTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qtensor.QTensor</span></code></a></p>
<p>A Tensor of integer values representing quantized float numbers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a tensor of integer values</p></li>
<li><p><strong>scales</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a FixedPoint of scales</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits</p></li>
</ul>
</dd>
</dl>
<p><strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.Spec" title="quantizeml.tensors.QFloat.Spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Spec</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat.Spec</span></code></p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.per_tensor" title="quantizeml.tensors.QFloat.per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">per_tensor</span></code></a></p></td>
<td><p>Returns if QTensor is quantized per-tensor</p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.quantize" title="quantizeml.tensors.QFloat.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(x, float_max, value_bits, scales_bits)</p></td>
<td><p>Converts a float Tensor to a QFloat</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#quantizeml.tensors.QFloat.to_float" title="quantizeml.tensors.QFloat.to_float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_float</span></code></a>()</p></td>
<td><p>Returns a float representation of the QFloat</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.Spec">
<span class="sig-name descname"><span class="pre">Spec</span></span><a class="headerlink" href="#quantizeml.tensors.QFloat.Spec" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat.Spec</span></code>
<strong>Classes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">value_type</span></code></p></td>
<td><p>alias of <a class="reference internal" href="#quantizeml.tensors.QFloat" title="quantizeml.tensors.qfloat.QFloat"><code class="xref py py-class docutils literal notranslate"><span class="pre">quantizeml.tensors.qfloat.QFloat</span></code></a></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.per_tensor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">per_tensor</span></span><a class="headerlink" href="#quantizeml.tensors.QFloat.per_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Returns if QTensor is quantized per-tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if QTensor is quantized per-tensor or False on per-axis case.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.quantize">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">float_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_bits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales_bits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Converts a float Tensor to a QFloat</p>
<p>It first evaluates the maximum integer values that can be stored for
the specified value bits: int_max = 2^bits - 1.</p>
<p>It then converts the original float values into integer values so that:</p>
<div class="math notranslate nohighlight">
\[\begin{split}{x_{int}} = round(x * \\frac{int\_max}{float\_max})\end{split}\]</div>
<p>The resulting integer values are clipped to [-int_max-1, int_max].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a tensor of float values.</p></li>
<li><p><strong>float_max</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – a tensor of maximum values</p></li>
<li><p><strong>value_bits</strong> (<em>int</em>) – the number of value bits</p></li>
<li><p><strong>scales_bits</strong> (<em>int</em>) – the number of scales bits</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the QFloat representation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.QFloat" title="quantizeml.tensors.QFloat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QFloat</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quantizeml.tensors.QFloat.to_float">
<span class="sig-name descname"><span class="pre">to_float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/qfloat.html#QFloat.to_float"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.QFloat.to_float" title="Permalink to this definition"></a></dt>
<dd><p>Returns a float representation of the QFloat</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the float representation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="id4">
<h3>Reciprocal<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="quantizeml.tensors.reciprocal_lut">
<span class="sig-prename descclassname"><span class="pre">quantizeml.tensors.</span></span><span class="sig-name descname"><span class="pre">reciprocal_lut</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.fixed_point.FixedPoint"><span class="pre">quantizeml.tensors.fixed_point.FixedPoint</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">tensorflow.python.framework.ops.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frac_bits</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_value_bits</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/quantizeml/tensors/reciprocal.html#reciprocal_lut"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quantizeml.tensors.reciprocal_lut" title="Permalink to this definition"></a></dt>
<dd><p>Compute the reciprocal of a FixedPoint value, using a lookup table.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code>) – the value to compute its reciprocal.</p></li>
<li><p><strong>frac_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the resolution of fractional bits. Defaults to None.</p></li>
<li><p><strong>out_value_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of bits of the output. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – the name of the operation. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the reciprocal of x.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#quantizeml.tensors.FixedPoint" title="quantizeml.tensors.FixedPoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FixedPoint</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cnn2snn_apis.html" class="btn btn-neutral float-left" title="CNN2SNN Toolkit API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="akida_models_apis.html" class="btn btn-neutral float-right" title="Akida models API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>