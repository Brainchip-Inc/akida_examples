<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>CNN2SNN Toolkit API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/design-tabs.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="QuantizeML API" href="quantizeml_apis.html" />
    <link rel="prev" title="Akida runtime API" href="akida_apis.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#performance-measurement">Performance measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#keras-support">Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#onnx-support">ONNX support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-quantization-scenario">Typical quantization scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id3">Command-line interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-layers">Akida layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_apis.html#sparsity">Sparsity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#constraint">Constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantized-layers">Quantized layers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#id2">Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#custom-patterns">Custom patterns</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-i-o">Model I/O</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#convert">3. Convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#gxnor-mnist">4. GXNOR/MNIST</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html">Build Vision Transformers for Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-selection">1. Model selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-optimization-for-akida-hardware">2. Model optimization for Akida hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-training">3. Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#displaying-results-attention-maps">6. Displaying results Attention Maps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html">Advanced ONNX models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#get-model-and-data">1. Get model and data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#conversion">3. Conversion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#deprecated-cnn2snn-tutorials">[Deprecated] CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id11">Keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id12">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id14"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id15">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="api_reference.html">API reference</a></li>
      <li class="breadcrumb-item active">CNN2SNN Toolkit API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-cnn2snn">
<span id="cnn2snn-toolkit-api"></span><h1>CNN2SNN Toolkit API<a class="headerlink" href="#module-cnn2snn" title="Permalink to this headline"></a></h1>
<section id="akida-version">
<h2>Akida version<a class="headerlink" href="#akida-version" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.AkidaVersion">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">AkidaVersion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/akida_versions.html#AkidaVersion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.AkidaVersion" title="Permalink to this definition"></a></dt>
<dd><p>An enumeration.</p>
<dl class="py data">
<dt class="sig sig-object py" id="cnn2snn.AkidaVersion.AkidaVersion.v1">
<span class="sig-name descname"><span class="pre">v1</span></span><em class="property"> <span class="pre">=Akida</span> <span class="pre">1.0</span> <span class="pre">SOC</span> <span class="pre">and</span> <span class="pre">IP</span></em><a class="headerlink" href="#cnn2snn.AkidaVersion.AkidaVersion.v1" title="Permalink to this definition"></a></dt>
<dd><p>An enumeration.</p>
</dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="cnn2snn.AkidaVersion.AkidaVersion.v2">
<span class="sig-name descname"><span class="pre">v2</span></span><em class="property"> <span class="pre">=Akida</span> <span class="pre">2.0</span> <span class="pre">IP</span></em><a class="headerlink" href="#cnn2snn.AkidaVersion.AkidaVersion.v2" title="Permalink to this definition"></a></dt>
<dd><p>An enumeration.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.get_akida_version">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">get_akida_version</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/akida_versions.html#get_akida_version"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.get_akida_version" title="Permalink to this definition"></a></dt>
<dd><p>Get the target akida version for model conversion.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the target akida version, by default <code class="docutils literal notranslate"><span class="pre">AkidaVersion.v2</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#cnn2snn.AkidaVersion" title="cnn2snn.AkidaVersion">AkidaVersion</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.set_akida_version">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">set_akida_version</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">version</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/akida_versions.html#set_akida_version"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.set_akida_version" title="Permalink to this definition"></a></dt>
<dd><p>Select the target akida version for model conversion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>version</strong> (<a class="reference internal" href="#cnn2snn.AkidaVersion" title="cnn2snn.AkidaVersion"><em>AkidaVersion</em></a>) – the target Akida version.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="conversion">
<h2>Conversion<a class="headerlink" href="#conversion" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.convert">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">convert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/converter.html#convert"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.convert" title="Permalink to this definition"></a></dt>
<dd><p>Converts a Keras or ONNX quantized model to an Akida one.</p>
<p>This method is compatible with model quantized with <a class="reference internal" href="#cnn2snn.quantize" title="cnn2snn.quantize"><code class="xref py py-func docutils literal notranslate"><span class="pre">cnn2snn.quantize()</span></code></a>
and <code class="xref py py-func docutils literal notranslate"><span class="pre">quantizeml.quantize()</span></code>. To check the difference between the two
conversion processes check the methods _convert_cnn2snn and _convert_quantizeml
below.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">onnx.ModelProto</span></code>) – a model to convert.</p></li>
<li><p><strong>file_path</strong> (<em>str</em><em>, </em><em>optional</em>) – destination for the akida model.
(Default value = None)</p></li>
<li><p><strong>input_scaling</strong> (<em>2 elements tuple</em><em>, </em><em>optional</em>) – value of the input scaling.
(Default value = None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an Akida model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="akida_apis.html#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">akida.Model</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.check_model_compatibility">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">check_model_compatibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/converter.html#check_model_compatibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.check_model_compatibility" title="Permalink to this definition"></a></dt>
<dd><p>Checks that a float Keras or ONNX model is Akida compatible.</p>
<p>The process stops on the first incompatibility encountered with an exception. The
problematic step (quantization or conversion or mapping) is indicated in the exception message.
Then if errors occurs, issues must be fixed iteratively in order to obtain an Akida
compatible model.
Note that the version context is used to determine compatibility.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">onnx.ModelProto</span></code>) – the model to check.</p></li>
<li><p><strong>device</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">akida.HwDevice</span></code>, optional) – the device to map on. If a device is provided,
there will be a check that the model can fully run on such device. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – if model type is incompatbile with Akida version context.</p></li>
<li><p><strong>ValueError</strong> – if device is incompatibile with Akida version context.</p></li>
<li><p><strong>Exception</strong> – if an incompatibility is encountered on quantization/conversion/mapping steps.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="legacy-quantization-api">
<h2>Legacy quantization API<a class="headerlink" href="#legacy-quantization-api" title="Permalink to this headline"></a></h2>
<p>While it is possible to quantize Akida 1.0 models using cnn2snn legacy quantization blocks, such
usage is deprecated. You should rather use
<a class="reference external" href="../user_guide/quantizeml.html#">QuantizeML</a> tool to quantize a model whenever possible.</p>
<section id="utils">
<h3>Utils<a class="headerlink" href="#utils" title="Permalink to this headline"></a></h3>
<p>A detailed description of the input_scaling parameter is given in the
<a class="reference external" href="../user_guide/cnn2snn.html#input-scaling">user guide</a>.</p>
<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.compatibility_checks.check_model_compatibility">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.compatibility_checks.</span></span><span class="sig-name descname"><span class="pre">check_model_compatibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/compatibility_checks.html#check_model_compatibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.compatibility_checks.check_model_compatibility" title="Permalink to this definition"></a></dt>
<dd><p>Checks if a Keras model is compatible for cnn2snn conversion.</p>
<p>This function doesn’t convert the Keras model to an Akida model
but only checks if the model design is compatible.</p>
<p>Note that this function doesn’t check if the model is compatible with
Akida hardware.
To check compatibility with a specific hardware device, convert the model
and call <cite>model.map</cite> with this device as argument.</p>
<p><strong>1. How to build a compatible Keras quantized model?</strong></p>
<p>The following lines give details and constraints on how to build a Keras
model compatible for the conversion to an Akida model.</p>
<p><strong>2. General information about layers</strong></p>
<p>An Akida layer must be seen as a block of Keras layers starting with a
processing layer (Conv2D, SeparableConv2D,
Dense). All blocks of Keras layers except the last block must have
exactly one activation layer (ReLU or ActivationDiscreteRelu). Other
optional layers can be present in a block such as a pooling layer or a
batch normalization layer.
Here are all the supported Keras layers for an Akida-compatible model:</p>
<ul class="simple">
<li><p>Processing layers:</p>
<ul>
<li><p>tf.keras Conv2D/SeparableConv2D/Dense</p></li>
<li><p>cnn2snn QuantizedConv2D/QuantizedSeparableConv2D/QuantizedDense</p></li>
</ul>
</li>
<li><p>Activation layers:</p>
<ul>
<li><p>tf.keras ReLU</p></li>
<li><p>cnn2snn ActivationDiscreteRelu</p></li>
<li><p>any increasing activation function (only for the last block of layers)
such as softmax, sigmoid set as last layer. This layer must derive from
tf.keras.layers.Activation, and it will be removed during conversion to
an Akida model.</p></li>
</ul>
</li>
<li><p>Pooling layers:</p>
<ul>
<li><p>MaxPool2D</p></li>
<li><p>GlobalAvgPool2D</p></li>
</ul>
</li>
<li><p>BatchNormalization</p></li>
<li><p>Dropout</p></li>
<li><p>Flatten</p></li>
<li><p>Input</p></li>
<li><p>Reshape</p></li>
</ul>
<p>Example of a block of Keras layers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="o">----------</span>
       <span class="o">|</span> <span class="n">Conv2D</span> <span class="o">|</span>
       <span class="o">----------</span>
           <span class="o">||</span>
           \<span class="o">/</span>
 <span class="o">----------------------</span>
 <span class="o">|</span> <span class="n">BatchNormalization</span> <span class="o">|</span>
 <span class="o">----------------------</span>
           <span class="o">||</span>
           \<span class="o">/</span>
      <span class="o">-------------</span>
      <span class="o">|</span> <span class="n">MaxPool2D</span> <span class="o">|</span>
      <span class="o">-------------</span>
           <span class="o">||</span>
           \<span class="o">/</span>
<span class="o">--------------------------</span>
<span class="o">|</span> <span class="n">ActivationDiscreteRelu</span> <span class="o">|</span>
<span class="o">--------------------------</span>
</pre></div>
</div>
<p><strong>3. Constraints about inputs</strong></p>
<p>An Akida model can accept two types of inputs: sparse events or 8-bit
images. Whatever the input type, the Keras inputs must respect the
following relation:</p>
<blockquote>
<div><p>input_akida = scale * input_keras + shift</p>
</div></blockquote>
<p>where the Akida inputs must be positive integers, the input scale must be
a float value and the input shift must be an integer. In other words,
scale * input_keras must be integers.</p>
<p>Depending on the input type:</p>
<ul class="simple">
<li><p>if the inputs are events (sparse), the first layer of the Keras model can
be any processing layer. The input shift must be zero.</p></li>
<li><p>if the inputs are images, the first layer must be a Conv2D
layer.</p></li>
</ul>
<p><strong>4. Constraints about layers’ parameters</strong></p>
<p>To be Akida-compatible, the Keras layers must observe the following rules:</p>
<ul class="simple">
<li><p>all layers with the ‘data_format’ parameter must be ‘channels_last’</p></li>
<li><p>all processing quantized layers and ActivationDiscreteRelu must have a
valid quantization bitwidth</p></li>
<li><p>a Dense layer must have an input shape of (N,) or (1, 1, N)</p></li>
<li><p>a BatchNormalization layer must have ‘axis’ set to -1 (default)</p></li>
<li><p>a BatchNormalization layer cannot have negative gammas</p></li>
<li><p>Reshape layers can only be used to transform a tensor of shape (N,) to a
tensor of shape (1, 1, N), and vice-versa</p></li>
<li><p>only one pooling layer can be used in each block</p></li>
<li><p>a MaxPool2D layer must have the same ‘padding’ as the corresponding
processing quantized layer</p></li>
</ul>
<p><strong>5. Constraints about the order of layers</strong></p>
<p>To be Akida-compatible, the order of Keras layers must observe the following
rules:</p>
<ul class="simple">
<li><p>a block of Keras layers must start with a processing quantized layer</p></li>
<li><p>where present, a BatchNormalization/GlobalAvgPool2D layer must be placed
before the activation</p></li>
<li><p>a Flatten layer can only be used before a Dense layer</p></li>
<li><p>an Activation layer other than ReLU can only be used in the last layer</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – the model to check.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.load_quantized_model">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">load_quantized_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compile_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/utils.html#load_quantized_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.load_quantized_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads a quantized model saved in TF or HDF5 format.</p>
<p>If the model was compiled and trained before saving, its training state
will be loaded as well.
This function is a wrapper of <cite>tf.keras.models.load_model</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> (<em>string</em>) – path to the saved model.</p></li>
<li><p><strong>custom_objects</strong> (<em>dict</em>) – optional dictionary mapping names (strings) to
custom classes or functions to be considered during deserialization.</p></li>
<li><p><strong>compile_model</strong> (<em>bool</em>) – whether to compile the model after loading.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Keras model instance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="calibration">
<h3>Calibration<a class="headerlink" href="#calibration" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.calibration.QuantizationSampler">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.calibration.</span></span><span class="sig-name descname"><span class="pre">QuantizationSampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/calibration/calibration.html#QuantizationSampler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.calibration.QuantizationSampler" title="Permalink to this definition"></a></dt>
<dd><p>A tool to inspect the layer outputs of a quantized model</p>
<p>The sampler is initialized with a quantized model and a set of samples used
for the evaluation of the layer outputs. An optional batch size can be
specified to avoid out-of-memory errors when using a GPU.</p>
<p>To evaluate the outputs of a specific layer, it must first be selected
using the <cite>select_layer</cite> member.</p>
<p>Once done, three methods are available to inspect the layer outputs:</p>
<ul class="simple">
<li><p><cite>quantized_outputs</cite> returns the actual outputs of the layer,</p></li>
<li><p><cite>float_outputs</cite> returns the outputs of the layer if its weights were not
quantized,</p></li>
<li><p><cite>quantization_error</cite> applies the <cite>keras.metrics.Metric</cite> passed as
arguments to the difference between the float and quantized outputs.</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Evaluate the quantization MSE of a quantized layer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_quantized</span> <span class="o">=</span> <span class="n">cnn2snn</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
<span class="gp">... </span>                                   <span class="n">weight_quantization</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>                                   <span class="n">activ_quantization</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Instantiate a QuantizationSampler with a few dataset samples</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">QuantizationSampler</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Select the quantized layer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span><span class="o">.</span><span class="n">select_layer</span><span class="p">(</span><span class="n">model_quantized</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Evaluate the Mean Squared Error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mse</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">quantization_error</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">keras.Model</span></code>) – a quantized Keras model</p></li>
<li><p><strong>samples</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – a set of calibration samples</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – the batch size used for evaluation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.calibration.bias_correction">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.calibration.</span></span><span class="sig-name descname"><span class="pre">bias_correction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/calibration/bias_correction.html#bias_correction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.calibration.bias_correction" title="Permalink to this definition"></a></dt>
<dd><p>Apply a corrective bias to quantized layers.</p>
<p>This implements the Bias Correction algorithm described in:
Data-Free Quantization Through Weight Equalization and Bias Correction
Markus Nagel, Mart van Baalen, Tijmen Blankevoort, Max Welling
<a class="reference external" href="https://arxiv.org/abs/1906.04721">https://arxiv.org/abs/1906.04721</a></p>
<p>It is empirically demonstrated in the original paper that the weight
quantization can introduce a biased error in the activations that is quite
significant for low bitwidth weights (i.e. lower than 8-bit).
This algorithm simply estimates the quantization bias on a set of samples,
and subtracts it from the layer bias variable.</p>
<p>If the accuracy of the quantized model suffers a huge drop as compared to
the original model, this simple correction can recover the largest part of
the drop, but not all of it.</p>
<p>When optimizing a model, nothing is required but a set of samples for
calibration (typically from the training dataset).
Depending on the model and dataset, your mileage may vary, but it has been
observed empirically that there is no significant difference between the
models fixed with a very few samples (16) and those fixed with a higher
number of samples (1024).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">keras.Model</span></code>) – a quantized Keras Model</p></li>
<li><p><strong>samples</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – a set of samples used for calibration</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – the batch size used when evaluating samples</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a quantized Keras model whose biases have been
corrected</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.calibration.adaround">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.calibration.</span></span><span class="sig-name descname"><span class="pre">adaround</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">model</span></em>, <em class="sig-param"><span class="pre">samples</span></em>, <em class="sig-param"><span class="pre">optimizer</span></em>, <em class="sig-param"><span class="pre">epochs</span></em>, <em class="sig-param"><span class="pre">loss=&lt;keras.losses.MeanSquaredError</span> <span class="pre">object&gt;</span></em>, <em class="sig-param"><span class="pre">batch_size=None</span></em>, <em class="sig-param"><span class="pre">include_activation=False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/calibration/adaround.html#adaround"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.calibration.adaround" title="Permalink to this definition"></a></dt>
<dd><p>Optimize the rounding of quantized weights.</p>
<p>This implements the Adaround algorithm described in:
Up or Down? Adaptive Rounding for Post-Training Quantization
Markus Nagel, Rana Ali Amjad, Mart van Baalen, Christos Louizos, Tijmen
Blankevoort
<a class="reference external" href="https://arxiv.org/abs/2004.10568">https://arxiv.org/abs/2004.10568</a></p>
<p>Instead of rounding weights to the nearest, Adaround introduces a tensor of
continuous variables representing the decimals of the float weights, and
thus formulates the minimization of the quantization error as a  Quadratic
Unconstrained Binary Optimization problem, iteratively pushing the decimal
variables to a distribution of 0 and 1 minimizing the error.</p>
<p>After the optimization, the quantization scales are preserved, but each
weight is closer or equal to a quantized value.</p>
<p>When optimizing a model, the following must be provided:</p>
<ul class="simple">
<li><p>a set of samples (typically from the training dataset),</p></li>
<li><p>an optimizer,</p></li>
<li><p>the maximum number of epochs (the optimization of a layer stops when all
weights have been rounded).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">keras.Model</span></code>) – a quantized Keras Model</p></li>
<li><p><strong>samples</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">np.ndarray</span></code>) – a set of samples used for calibration</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.keras.optimizers.Optimizer</span></code>) – an optimizer</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the maximum number of epochs</p></li>
<li><p><strong>loss</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.keras.losses.Loss</span></code>) – the error loss function</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – the batch size used when evaluating samples</p></li>
<li><p><strong>include_activation</strong> (<em>bool</em>) – quantization error is evaluated after
activation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a quantized Keras model whose weights have been
optimized</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.Model</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="transforms">
<h3>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.sequentialize">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">sequentialize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/sequential.html#sequentialize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.sequentialize" title="Permalink to this definition"></a></dt>
<dd><p>Transform a Model into Sequential sub-models and Concatenate layers.</p>
<p>This function returns an equivalent model where all linear branches are
replaced by a Sequential sub-model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Keras model</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Keras model with Sequential sub-models</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.syncretize">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">syncretize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/sequential.html#syncretize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.syncretize" title="Permalink to this definition"></a></dt>
<dd><p>Align all linear branches of a Model with akida layer sequences.</p>
<p>The input model must be composed of Sequential submodels and Concatenate
layers. This function will apply transformations on every Sequential
submodel and returns an equivalent functional model with akida compatible
sequences of layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Keras model with Sequential submodels.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Keras model with akida-compatible Sequential
submodels.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.invert_batchnorm_pooling">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">invert_batchnorm_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/batch_normalization.html#invert_batchnorm_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.invert_batchnorm_pooling" title="Permalink to this definition"></a></dt>
<dd><p>Inverts pooling and BatchNormalization layers in a Sequential model to
have BN layer before pooling.</p>
<p>Having pool-&gt;BN or BN-&gt;pool is equivalent only if BN layer has no negative
gammas.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Sequential Keras model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Sequential Keras model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.fold_batchnorm">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">fold_batchnorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/batch_normalization.html#fold_batchnorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.fold_batchnorm" title="Permalink to this definition"></a></dt>
<dd><p>Folds BatchNormalization layers into the preceding neural layers of
a Sequential model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Sequential Keras model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Sequential Keras model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.weights_homogeneity">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">weights_homogeneity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/equalization.html#weights_homogeneity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.weights_homogeneity" title="Permalink to this definition"></a></dt>
<dd><p>Give an estimation of the homogeneity of layer weights</p>
<p>For each Conv or Dense layer in the model, this compares the ranges of
the weights for each filter with the range of the tensor.
The score for each filter is expressed as an homogeneity rate (1 is the
maximum), and the layer homogeneity rate is the mean of all filter rates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Keras model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>rates indexed by layer names.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.normalize_separable_layer">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">normalize_separable_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/equalization.html#normalize_separable_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.normalize_separable_layer" title="Permalink to this definition"></a></dt>
<dd><p>This normalizes the depthwise weights of a SeparableConv2D.</p>
<blockquote>
<div><p>In order to limit the quantization error when using a per-tensor
quantization of depthwise weights, this rescales all depthwise weights
to fit within the [-1, 1] range.
To preserve the output of the layer, each depthwise kernel is rescaled
independently to the [-1, 1] interval by dividing all weights by the
absolute maximum value, and inversely, all pointwise filters ‘looking’
at these kernels are multiplied by the same value.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>layer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.layers.SeparableConv2D</span></code>) – a Keras SeparableConv2D
layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.normalize_separable_model">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">normalize_separable_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/equalization.html#normalize_separable_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.normalize_separable_model" title="Permalink to this definition"></a></dt>
<dd><p>This normalizes the depthwise weights of all SeparableConv2D in a Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – a Keras model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new Keras model with normalized depthwise
weights in SeparableConv2D layers.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.transforms.reshape">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.transforms.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_keras</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/transforms/reshape.html#reshape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.transforms.reshape" title="Permalink to this definition"></a></dt>
<dd><p>Rescales the model by changing its input size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_keras</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) – Keras model to rescale</p></li>
<li><p><strong>input_x</strong> (<em>int</em>) – desired model input first dimension</p></li>
<li><p><strong>input_y</strong> (<em>int</em>) – desired model input second dimension</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the rescaled model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.Model</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="constraint">
<h3>Constraint<a class="headerlink" href="#constraint" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.min_value_constraint.MinValueConstraint">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.min_value_constraint.</span></span><span class="sig-name descname"><span class="pre">MinValueConstraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">min_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/min_value_constraint.html#MinValueConstraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.min_value_constraint.MinValueConstraint" title="Permalink to this definition"></a></dt>
<dd><p>Constraint that ensures that weights values are not below a minimum
value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>min_value</strong> – the minimum desired value for the weights</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantization">
<h3>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.quantize">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_quantization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activ_quantization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_weight_quantization</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fold_BN</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantizer_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization.html#quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Converts a standard sequential Keras model to a CNN2SNN Keras quantized
model, compatible for Akida conversion.</p>
<p>This function returns a Keras model where the standard neural layers
(Conv2D, SeparableConv2D, Dense) and the ReLU activations are replaced with
CNN2SNN quantized layers (QuantizedConv2D, QuantizedSeparableConv2D,
QuantizedDense, QuantizedRelu).</p>
<p>Several transformations are applied to the model:
- the order of MaxPool and BatchNormalization layers are inverted so that
BatchNormalization always happens first,
- the batch normalization layers are folded into the previous layers.</p>
<p>This new model can be either directly converted to akida, or first
retrained for a few epochs to recover any accuracy loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – a standard Keras model</p></li>
<li><p><strong>weight_quantization</strong> (<em>int</em>) – <p>sets all weights in the model to have
a particular quantization bitwidth except for the weights in the
first layer.</p>
<ul>
<li><p>’0’ implements floating point 32-bit weights.</p></li>
<li><p>’2’ through ‘8’ implements n-bit weights where n is from 2-8 bits.</p></li>
</ul>
</p></li>
<li><p><strong>activ_quantization</strong> (<em>int</em>) – <p>sets all activations in the model to have a
particular activation quantization bitwidth.</p>
<ul>
<li><p>’0’ implements floating point 32-bit activations.</p></li>
<li><p>’1’ through ‘8’ implements n-bit weights where n is from 1-8 bits.</p></li>
</ul>
</p></li>
<li><p><strong>input_weight_quantization</strong> (<em>int</em>) – <p>sets weight quantization in the first
layer. Defaults to weight_quantization value.</p>
<ul>
<li><p>’None’ implements the same bitwidth as the other weights.</p></li>
<li><p>’0’ implements floating point 32-bit weights.</p></li>
<li><p>’2’ through ‘8’ implements n-bit weights where n is from 2-8 bits.</p></li>
</ul>
</p></li>
<li><p><strong>fold_BN</strong> (<em>bool</em>) – enable folding batch normalization layers with their
corresponding neural layer.</p></li>
<li><p><strong>quantizer_function</strong> (<em>function</em>) – callable that takes as argument the layer
instance to be quantized and the corresponding default quantizer and
returns the quantizer to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a quantized Keras model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="cnn2snn.quantize_layer">
<span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">quantize_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bitwidth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantizer_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization.html#quantize_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantize_layer" title="Permalink to this definition"></a></dt>
<dd><p>Quantizes a specific layer with the given bitwidth.</p>
<p>This function returns a Keras model where the target layer is quantized.
All other layers are preserved.
If the target layer is a native Keras layer (Conv2D, SeparableConv2D, Dense,
ReLU), it is replaced by a CNN2SNN quantized layer (QuantizedConv2D,
QuantizedSeparableConv2D, QuantizedDense, ActivationDiscreteRelu). If
the target layer is an already quantized layer, only the bitwidth is
modified.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Quantize a layer of a native Keras model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)),</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_quantized</span> <span class="o">=</span> <span class="n">cnn2snn</span><span class="o">.</span><span class="n">quantize_layer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
<span class="gp">... </span>                                         <span class="n">target_layer</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                                         <span class="n">bitwidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_quantized</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cnn2snn</span><span class="o">.</span><span class="n">QuantizedDense</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">model_quantized</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">bitwidth</span><span class="p">)</span>
<span class="go">4</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Quantize a layer of an an already quantized layer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_quantized</span> <span class="o">=</span> <span class="n">cnn2snn</span><span class="o">.</span><span class="n">quantize_layer</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span>
<span class="gp">... </span>                                         <span class="n">target_layer</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bitwidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">model_quantized</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">bitwidth</span><span class="p">)</span>
<span class="go">2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – a standard Keras model</p></li>
<li><p><strong>target_layer</strong> – a standard or quantized Keras layer to be
converted, or the index or name of the target layer.</p></li>
<li><p><strong>bitwidth</strong> (<em>int</em>) – the desired quantization bitwidth. If zero, no
quantization will be applied.</p></li>
<li><p><strong>quantizer_function</strong> (<em>function</em>) – callable that takes as argument the layer
instance to be quantized and the corresponding default quantizer and
returns the quantizer to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a quantized Keras model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.keras.Model</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – In case of invalid target layer</p></li>
<li><p><strong>ValueError</strong> – If bitwidth is not greater than zero</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="quantizers">
<h3>Quantizers<a class="headerlink" href="#quantizers" title="Permalink to this headline"></a></h3>
<section id="weightquantizer">
<h4>WeightQuantizer<a class="headerlink" href="#weightquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.WeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.quantization_ops.</span></span><span class="sig-name descname"><span class="pre">WeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#WeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.WeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>The base class for all weight quantizers.</p>
<p>This base class must be overloaded as well as the two functions <cite>quantize</cite>
and <cite>scale_factor</cite>.</p>
<p>Quantizers derived from this class must be symmetric uniform mid-tread
quantizers, in order to be compatible with the conversion into an Akida
model. Quantization is usually done in two steps:</p>
<ol class="arabic simple">
<li><p>The weights must be first quantized on integer values in the
range imposed by the bitwidth, e.g. from -7 to 7 for a 4-bit
quantization.</p></li>
<li><p>These integer weights are then reconstructed to float discretized
values, in the range of the original weights. For example, 4-bit integer
weights are reconstructed on a grid from -7*qstep to 7*qstep, where
qstep is the quantization step size between two levels of the uniform
grid.</p></li>
</ol>
<p>For a full explanation about mid-tread uniform quantization, one can take a
look at <a class="reference external" href="https://en.wikipedia.org/wiki/Quantization_(signal_processing)#Example">the Wikipedia page</a>.</p>
<p>The <cite>quantize</cite> function takes as inputs the original weights and must
return the reconstructed float values after quantization. The
<cite>scale_factor</cite> function must return the factor used to transform the float
reconstructed weights into the integer values obtained after step 1. In other
words, given a set of float weights “w”:</p>
<blockquote>
<div><p>quantize(w) * scale_factor(w) is a set of integer weights.</p>
</div></blockquote>
<p>The bitwidth defines the number of quantization levels on which the
weights will be quantized. For instance, a 4-bit quantization gives
integer values between -7 and 7. More generally, for a n-bit
quantization, values are ranged from -kmax to kmax where kmax is
(2^(n-1) - 1).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth.</p>
</dd>
</dl>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.WeightQuantizer.bitwidth" title="cnn2snn.quantization_ops.WeightQuantizer.bitwidth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwidth</span></code></a></p></td>
<td><p>Returns the bitwidth of the quantizer</p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.WeightQuantizer.get_config" title="cnn2snn.quantization_ops.WeightQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.WeightQuantizer.quantize" title="cnn2snn.quantization_ops.WeightQuantizer.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(w)</p></td>
<td><p>Quantizes the specified weights Tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.WeightQuantizer.scale_factor" title="cnn2snn.quantization_ops.WeightQuantizer.scale_factor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_factor</span></code></a>(w)</p></td>
<td><p>Evaluates the scale factor for the specified weights tf.Tensor.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.WeightQuantizer.bitwidth">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">bitwidth</span></span><a class="headerlink" href="#cnn2snn.quantization_ops.WeightQuantizer.bitwidth" title="Permalink to this definition"></a></dt>
<dd><p>Returns the bitwidth of the quantizer</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.WeightQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#WeightQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.WeightQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.WeightQuantizer.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#WeightQuantizer.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.WeightQuantizer.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Quantizes the specified weights Tensor.</p>
<p>This function must return a tf.Tensor containing float weights
discretized on a uniform grid based on the scale factor “sf”.
In other words, the discretized weights must be values among:
-kmax/sf, …, -2/sf, -1/sf, 0, 1/sf, 2/sf, …, kmax/sf</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>w</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the weights Tensor to quantize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of quantized weights.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.WeightQuantizer.scale_factor">
<span class="sig-name descname"><span class="pre">scale_factor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#WeightQuantizer.scale_factor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.WeightQuantizer.scale_factor" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the scale factor for the specified weights tf.Tensor.</p>
<p>This function returns the scale factor to get the quantized integer
weights from the reconstructed float weights. It is equal to the
inverse of the quantization step size.</p>
<p>The scale factor can be a scalar that is applied on the whole tensor
of weights. It can also be a vector of length the number of filters,
where each value applies to the weights of the corresponding output
filter. This is called a per-axis quantization, as opposed to a
per-tensor quantization. The number of filters is usually the last
dimension of the weights tensor. More details are given
<a class="reference external" href="https://www.tensorflow.org/lite/performance/quantization_spec?hl=sv#per-axis_vs_per-tensor">here</a></p>
<p>Note that the <cite>quantizer_dw</cite> of a depthwise convolution in a
QuantizedSeparableConv2D layer must imperatively return a scalar scale
factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>w</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the weights Tensor to quantize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor containing a list of scalar values
(1 or more).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="linearweightquantizer">
<h4>LinearWeightQuantizer<a class="headerlink" href="#linearweightquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.LinearWeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.quantization_ops.</span></span><span class="sig-name descname"><span class="pre">LinearWeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#LinearWeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.LinearWeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.quantization_ops.WeightQuantizer" title="cnn2snn.quantization_ops.WeightQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_ops.WeightQuantizer</span></code></a></p>
<p>An abstract linear weight quantizer</p>
<p>This abstract class proposes a linear symmetric and uniform quantization
function. The “linear” term here means that there is no non-linear
transformation of the weights before the uniform quantization.</p>
<p>The <cite>scale_factor</cite> function must be overloaded.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.LinearWeightQuantizer.quantize" title="cnn2snn.quantization_ops.LinearWeightQuantizer.quantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize</span></code></a>(w)</p></td>
<td><p>Linearly quantizes the input weights on a symmetric uniform grid based on the scale factor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.quantization_ops.LinearWeightQuantizer.scale_factor" title="cnn2snn.quantization_ops.LinearWeightQuantizer.scale_factor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_factor</span></code></a>(w)</p></td>
<td><p>Evaluates the scale factor for the specified weights tf.Tensor.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.LinearWeightQuantizer.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#LinearWeightQuantizer.quantize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.LinearWeightQuantizer.quantize" title="Permalink to this definition"></a></dt>
<dd><p>Linearly quantizes the input weights on a symmetric uniform grid
based on the scale factor.</p>
<p>The input weights are directly rounded to the closest discretized
value, without any transformation on the input weights.</p>
<p>The gradient is estimated using the Straight-Through Estimator (STE),
i.e. the gradient is computed as if there were no quantization.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.quantization_ops.LinearWeightQuantizer.scale_factor">
<span class="sig-name descname"><span class="pre">scale_factor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#LinearWeightQuantizer.scale_factor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.quantization_ops.LinearWeightQuantizer.scale_factor" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the scale factor for the specified weights tf.Tensor.</p>
<p>This function returns the scale factor to get the quantized integer
weights from the reconstructed float weights. It is equal to the
inverse of the quantization step size.</p>
<p>The scale factor can be a scalar that is applied on the whole tensor
of weights. It can also be a vector of length the number of filters,
where each value applies to the weights of the corresponding output
filter. This is called a per-axis quantization, as opposed to a
per-tensor quantization. The number of filters is usually the last
dimension of the weights tensor. More details are given
<a class="reference external" href="https://www.tensorflow.org/lite/performance/quantization_spec?hl=sv#per-axis_vs_per-tensor">here</a></p>
<p>Note that the <cite>quantizer_dw</cite> of a depthwise convolution in a
QuantizedSeparableConv2D layer must imperatively return a scalar scale
factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>w</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the weights Tensor to quantize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor containing a list of scalar values
(1 or more).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="stdweightquantizer">
<h4>StdWeightQuantizer<a class="headerlink" href="#stdweightquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.StdWeightQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">StdWeightQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdWeightQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdWeightQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.quantization_ops.LinearWeightQuantizer" title="cnn2snn.quantization_ops.LinearWeightQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_ops.LinearWeightQuantizer</span></code></a></p>
<p>A uniform quantizer based on weights standard deviation.</p>
<p>Quantizes the specified weights into 2^bitwidth-1 values centered on zero.
E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep
with qstep being the quantization step. The quantization step is defined by:</p>
<blockquote>
<div><p>qstep = threshold * std(W) / max_value</p>
</div></blockquote>
<p>with max_value being 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</p>
<p>All values below or above threshold * std(W) are automatically assigned to
the min (resp max) value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> (<em>int</em>) – the standard deviation multiplier used to exclude
outliers.</p></li>
<li><p><strong>bitwidth</strong> (<em>int</em>) – the quantizer bitwidth defining the number of
quantized values.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.StdWeightQuantizer.get_config" title="cnn2snn.StdWeightQuantizer.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.StdWeightQuantizer.scale_factor" title="cnn2snn.StdWeightQuantizer.scale_factor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_factor</span></code></a>(w)</p></td>
<td><p>Evaluates the scale factor for the specified weights tf.Tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.StdWeightQuantizer.sigma_" title="cnn2snn.StdWeightQuantizer.sigma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sigma_</span></code></a>(w)</p></td>
<td><p>Returns the standard deviation(s) of a set of weights</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.StdWeightQuantizer.threshold" title="cnn2snn.StdWeightQuantizer.threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold</span></code></a></p></td>
<td><p>Returns the threshold of the std quantizer</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.StdWeightQuantizer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdWeightQuantizer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdWeightQuantizer.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.StdWeightQuantizer.scale_factor">
<span class="sig-name descname"><span class="pre">scale_factor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdWeightQuantizer.scale_factor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdWeightQuantizer.scale_factor" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the scale factor for the specified weights tf.Tensor.</p>
<p>This function returns the scale factor to get the quantized integer
weights from the reconstructed float weights. It is equal to the
inverse of the quantization step size.</p>
<p>The scale factor can be a scalar that is applied on the whole tensor
of weights. It can also be a vector of length the number of filters,
where each value applies to the weights of the corresponding output
filter. This is called a per-axis quantization, as opposed to a
per-tensor quantization. The number of filters is usually the last
dimension of the weights tensor. More details are given
<a class="reference external" href="https://www.tensorflow.org/lite/performance/quantization_spec?hl=sv#per-axis_vs_per-tensor">here</a></p>
<p>Note that the <cite>quantizer_dw</cite> of a depthwise convolution in a
QuantizedSeparableConv2D layer must imperatively return a scalar scale
factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>w</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the weights Tensor to quantize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor containing a list of scalar values
(1 or more).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.StdWeightQuantizer.sigma_">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">sigma_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdWeightQuantizer.sigma_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdWeightQuantizer.sigma_" title="Permalink to this definition"></a></dt>
<dd><p>Returns the standard deviation(s) of a set of weights</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.StdWeightQuantizer.threshold">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">threshold</span></span><a class="headerlink" href="#cnn2snn.StdWeightQuantizer.threshold" title="Permalink to this definition"></a></dt>
<dd><p>Returns the threshold of the std quantizer</p>
</dd></dl>

</dd></dl>

</section>
<section id="stdperaxisquantizer">
<h4>StdPerAxisQuantizer<a class="headerlink" href="#stdperaxisquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.StdPerAxisQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">StdPerAxisQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdPerAxisQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdPerAxisQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.StdWeightQuantizer" title="cnn2snn.quantization_ops.StdWeightQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_ops.StdWeightQuantizer</span></code></a></p>
<p>A quantizer that relies on weights standard deviation per axis.</p>
<p>Quantizes the specified weights into 2^bitwidth-1 values centered on zero.
E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep
with qstep being the quantization step. The quantization step is defined by:</p>
<blockquote>
<div><p>qstep = max_range / max_value</p>
</div></blockquote>
<p>with:</p>
<blockquote>
<div><ul class="simple">
<li><p>max_range = max(abs(W))</p></li>
<li><p>max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</p></li>
</ul>
</div></blockquote>
<p>This is an evolution of the StdWeightQuantizer that defines the weights
range per axis.</p>
<p>The last dimension is used as axis, meaning that the scaling factor is a
vector with as many values as “filters”, or “neurons”.</p>
<p>Note: for a DepthwiseConv2D layer that has a single filter, this
quantizer is strictly equivalent to the StdWeightQuantizer.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.StdPerAxisQuantizer.sigma_" title="cnn2snn.StdPerAxisQuantizer.sigma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sigma_</span></code></a>(w)</p></td>
<td><p>Returns the standard deviation(s) of a set of weights</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.StdPerAxisQuantizer.sigma_">
<span class="sig-name descname"><span class="pre">sigma_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#StdPerAxisQuantizer.sigma_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.StdPerAxisQuantizer.sigma_" title="Permalink to this definition"></a></dt>
<dd><p>Returns the standard deviation(s) of a set of weights</p>
</dd></dl>

</dd></dl>

</section>
<section id="maxquantizer">
<h4>MaxQuantizer<a class="headerlink" href="#maxquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.MaxQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">MaxQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#MaxQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.MaxQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.quantization_ops.LinearWeightQuantizer" title="cnn2snn.quantization_ops.LinearWeightQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_ops.LinearWeightQuantizer</span></code></a></p>
<p>A quantizer that relies on maximum range.</p>
<p>Quantizes the specified weights into 2^bitwidth-1 values centered on zero.
E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep
with qstep being the quantization step. The quantization step is defined by:</p>
<blockquote>
<div><p>qstep = max_range / max_value</p>
</div></blockquote>
<p>with:</p>
<blockquote>
<div><ul class="simple">
<li><p>max_range = max(abs(W))</p></li>
<li><p>max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bitwidth</strong> (<em>int</em>) – the quantizer bitwidth defining the number of
quantized values.</p>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.MaxQuantizer.max_range_" title="cnn2snn.MaxQuantizer.max_range_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_range_</span></code></a>(w)</p></td>
<td><p>Get the range on which the weights are quantized.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.MaxQuantizer.scale_factor" title="cnn2snn.MaxQuantizer.scale_factor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale_factor</span></code></a>(w)</p></td>
<td><p>Evaluates the scale factor for the specified weights tf.Tensor.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.MaxQuantizer.max_range_">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">max_range_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#MaxQuantizer.max_range_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.MaxQuantizer.max_range_" title="Permalink to this definition"></a></dt>
<dd><p>Get the range on which the weights are quantized. This quantizer
discretizes weights in the range:</p>
<blockquote>
<div><p>[-max(weights) ; max(weights)]</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.MaxQuantizer.scale_factor">
<span class="sig-name descname"><span class="pre">scale_factor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#MaxQuantizer.scale_factor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.MaxQuantizer.scale_factor" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the scale factor for the specified weights tf.Tensor.</p>
<p>This function returns the scale factor to get the quantized integer
weights from the reconstructed float weights. It is equal to the
inverse of the quantization step size.</p>
<p>The scale factor can be a scalar that is applied on the whole tensor
of weights. It can also be a vector of length the number of filters,
where each value applies to the weights of the corresponding output
filter. This is called a per-axis quantization, as opposed to a
per-tensor quantization. The number of filters is usually the last
dimension of the weights tensor. More details are given
<a class="reference external" href="https://www.tensorflow.org/lite/performance/quantization_spec?hl=sv#per-axis_vs_per-tensor">here</a></p>
<p>Note that the <cite>quantizer_dw</cite> of a depthwise convolution in a
QuantizedSeparableConv2D layer must imperatively return a scalar scale
factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>w</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the weights Tensor to quantize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor containing a list of scalar values
(1 or more).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="maxperaxisquantizer">
<h4>MaxPerAxisQuantizer<a class="headerlink" href="#maxperaxisquantizer" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.MaxPerAxisQuantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">MaxPerAxisQuantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#MaxPerAxisQuantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.MaxPerAxisQuantizer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.MaxQuantizer" title="cnn2snn.quantization_ops.MaxQuantizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_ops.MaxQuantizer</span></code></a></p>
<p>A quantizer that relies on maximum range per axis.</p>
<p>Quantizes the specified weights into 2^bitwidth-1 values centered on zero.
E.g. with bitwidth = 4, 15 quantization levels: from -7 * qstep to 7 * qstep
with qstep being the quantization step. The quantization step is defined by:</p>
<blockquote>
<div><p>qstep = max_range / max_value</p>
</div></blockquote>
<p>with:</p>
<blockquote>
<div><ul class="simple">
<li><p>max_range = max(abs(W))</p></li>
<li><p>max_value = 2^(bitwidth-1) - 1. E.g with bitwidth = 4, max_value = 7.</p></li>
</ul>
</div></blockquote>
<p>This is an evolution of the MaxQuantizer that defines the max_range per
axis.</p>
<p>The last dimension is used as axis, meaning that the scaling factor is a
vector with as many values as “filters”, or “neurons”.</p>
<p>Note: for a DepthwiseConv2D layer that has a single filter, this
quantizer is strictly equivalent to the MaxQuantizer.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.MaxPerAxisQuantizer.max_range_" title="cnn2snn.MaxPerAxisQuantizer.max_range_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_range_</span></code></a>(w)</p></td>
<td><p>Get the range on which the weights are quantized.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.MaxPerAxisQuantizer.max_range_">
<span class="sig-name descname"><span class="pre">max_range_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_ops.html#MaxPerAxisQuantizer.max_range_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.MaxPerAxisQuantizer.max_range_" title="Permalink to this definition"></a></dt>
<dd><p>Get the range on which the weights are quantized. This quantizer
discretizes weights in the range:</p>
<blockquote>
<div><p>[-max(weights) ; max(weights)]</p>
</div></blockquote>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="quantized-layers">
<h3>Quantized layers<a class="headerlink" href="#quantized-layers" title="Permalink to this headline"></a></h3>
<section id="quantizedconv2d">
<h4>QuantizedConv2D<a class="headerlink" href="#quantizedconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.QuantizedConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">QuantizedConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedConv2D" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.layers.convolutional.conv2d.Conv2D</span></code></p>
<p>A quantization-aware Keras convolutional layer.</p>
<p>Inherits from Keras Conv2D layer, applying a quantization on weights during
the forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filters</strong> (<em>int</em>) – the number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>tuple of integer</em>) – the kernel spatial dimensions.</p></li>
<li><p><strong>quantizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">cnn2snn.WeightQuantizer</span></code>) – the quantizer
to apply during the forward pass.</p></li>
<li><p><strong>strides</strong> (<em>integer</em><em>, or </em><em>tuple of integers</em><em>, </em><em>optional</em>) – strides of the
convolution along spatial dimensions.</p></li>
<li><p><strong>padding</strong> (<em>str</em><em>, </em><em>optional</em>) – one of ‘valid’ or ‘same’.</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em>) – whether the layer uses a bias vector.</p></li>
<li><p><strong>kernel_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the weights.</p></li>
<li><p><strong>bias_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the bias.</p></li>
<li><p><strong>activity_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the output of the layer.</p></li>
<li><p><strong>kernel_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the weights.</p></li>
<li><p><strong>bias_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the bias.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedConv2D.call" title="cnn2snn.QuantizedConv2D.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Evaluates input Tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.QuantizedConv2D.get_config" title="cnn2snn.QuantizedConv2D.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedConv2D.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedConv2D.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedConv2D.call" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates input Tensor.</p>
<p>This applies the quantization on weights, then evaluates the input
Tensor and produces the output Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – input Tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedConv2D.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedConv2D.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedConv2D.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="quantizeddense">
<h4>QuantizedDense<a class="headerlink" href="#quantizeddense" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.QuantizedDense">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">QuantizedDense</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedDense"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedDense" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.layers.core.dense.Dense</span></code></p>
<p>A quantization-aware Keras dense layer.</p>
<p>Inherits from Keras Dense layer, applying a quantization on weights during
the forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – the number of neurons.</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em>) – whether the layer uses a bias vector.</p></li>
<li><p><strong>quantizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">cnn2snn.WeightQuantizer</span></code>) – the quantizer
to apply during the forward pass.</p></li>
<li><p><strong>kernel_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the weights.</p></li>
<li><p><strong>bias_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the bias.</p></li>
<li><p><strong>activity_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the output of the layer.</p></li>
<li><p><strong>kernel_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the weights.</p></li>
<li><p><strong>bias_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the bias.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedDense.call" title="cnn2snn.QuantizedDense.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Evaluates input Tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.QuantizedDense.get_config" title="cnn2snn.QuantizedDense.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedDense.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedDense.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedDense.call" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates input Tensor.</p>
<p>This applies the quantization on weights, then evaluates the input
Tensor and produces the output Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – input Tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>output Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedDense.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedDense.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedDense.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="quantizedseparableconv2d">
<h4>QuantizedSeparableConv2D<a class="headerlink" href="#quantizedseparableconv2d" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.QuantizedSeparableConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">QuantizedSeparableConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedSeparableConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedSeparableConv2D" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.layers.convolutional.separable_conv2d.SeparableConv2D</span></code></p>
<p>A quantization-aware Keras separable convolutional layer.</p>
<p>Inherits from Keras SeparableConv2D layer, applying a quantization on
weights during the forward pass.</p>
<p>Creates a quantization-aware separable convolutional layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filters</strong> (<em>int</em>) – the number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>tuple of integer</em>) – the kernel spatial dimensions.</p></li>
<li><p><strong>quantizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">cnn2snn.WeightQuantizer</span></code>) – the quantizer to apply
during the forward pass.</p></li>
<li><p><strong>quantizer_dw</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">cnn2snn.WeightQuantizer</span></code>, optional) – the
depthwise quantizer to apply during the forward pass.</p></li>
<li><p><strong>strides</strong> (<em>integer</em><em>, or </em><em>tuple of integers</em><em>, </em><em>optional</em>) – strides of the
convolution along spatial dimensions.</p></li>
<li><p><strong>padding</strong> (<em>str</em><em>, </em><em>optional</em>) – One of ‘valid’ or ‘same’.</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether the layer uses a bias vector.</p></li>
<li><p><strong>depthwise_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the depthwise kernel.</p></li>
<li><p><strong>pointwise_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the pointwise kernel.</p></li>
<li><p><strong>bias_initializer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.initializer</span></code>, optional) – initializer for the bias vector.</p></li>
<li><p><strong>depthwise_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the depthwise kernel.</p></li>
<li><p><strong>pointwise_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the pointwise kernel.</p></li>
<li><p><strong>bias_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the bias.</p></li>
<li><p><strong>activity_regularizer</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.regularizer</span></code>, optional) – regularization applied to the output of the layer.</p></li>
<li><p><strong>depthwise_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the depthwise kernel.</p></li>
<li><p><strong>pointwise_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the pointwise kernel.</p></li>
<li><p><strong>bias_constraint</strong> (str, or a <code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.keras.constraint</span></code>, optional) – constraint applied to the bias.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedSeparableConv2D.call" title="cnn2snn.QuantizedSeparableConv2D.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs)</p></td>
<td><p>Evaluates input Tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.QuantizedSeparableConv2D.get_config" title="cnn2snn.QuantizedSeparableConv2D.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedSeparableConv2D.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedSeparableConv2D.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedSeparableConv2D.call" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates input Tensor.</p>
<p>This applies the quantization on weights, then evaluates the input
Tensor and produces the output Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – input Tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedSeparableConv2D.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedSeparableConv2D.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedSeparableConv2D.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="quantizedactivation">
<h4>QuantizedActivation<a class="headerlink" href="#quantizedactivation" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">QuantizedActivation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedActivation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedActivation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">keras.engine.base_layer.Layer</span></code></p>
<p>Base class for quantized activation layers.</p>
<p>This base class must be overloaded as well as the <cite>step</cite> &#64;property function.</p>
<p>This &#64;property function must return a TensorFlow object (e.g. tf.Tensor
or tf.Variable) of scalar values. The <cite>.numpy()</cite> method must be callable on
them. They can be fixed at initialization or can be trainable variables.</p>
<p>The CNN2SNN toolkit only support linear quantized activation as defined in
the <cite>quantized_activation</cite> function.</p>
<p>The bitwidth defines the number of quantization levels on which the
activation will be quantized. For instance, a 4-bit quantization gives
15 activation levels. More generally, a n-bit quantization gives 2^n-1
levels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bitwidth</strong> (<em>int</em>) – the quantization bitwidth</p>
</dd>
</dl>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.bitwidth" title="cnn2snn.QuantizedActivation.bitwidth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwidth</span></code></a></p></td>
<td><p>Returns the bitwidth of the quantized activation</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.step" title="cnn2snn.QuantizedActivation.step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">step</span></code></a></p></td>
<td><p>Returns the interval between two quantized activation values</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.threshold" title="cnn2snn.QuantizedActivation.threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold</span></code></a></p></td>
<td><p>The quantization threshold is equal to half the quantization step to better approximate the ReLU.</p></td>
</tr>
</tbody>
</table>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.call" title="cnn2snn.QuantizedActivation.call"><code class="xref py py-obj docutils literal notranslate"><span class="pre">call</span></code></a>(inputs, *args, **kwargs)</p></td>
<td><p>Evaluates the quantized activations for the specified input Tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.get_config" title="cnn2snn.QuantizedActivation.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedActivation.quantized_activation" title="cnn2snn.QuantizedActivation.quantized_activation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantized_activation</span></code></a>(x)</p></td>
<td><p>Evaluates the quantized activations for the specified input Tensor.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.bitwidth">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">bitwidth</span></span><a class="headerlink" href="#cnn2snn.QuantizedActivation.bitwidth" title="Permalink to this definition"></a></dt>
<dd><p>Returns the bitwidth of the quantized activation</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedActivation.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedActivation.call" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the quantized activations for the specified input Tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedActivation.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedActivation.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.quantized_activation">
<span class="sig-name descname"><span class="pre">quantized_activation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedActivation.quantized_activation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedActivation.quantized_activation" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the quantized activations for the specified input Tensor.</p>
<p>Activations will be clipped to a quantization range, and quantized to a
number of values defined by the bitwidth: N = (2^bitwidth - 1) values
plus zero.</p>
<p>The quantization is defined by a single step parameter, that defines
the interval between two quantized values.</p>
<p>A quantization threshold set to half the quantization step is used to
evaluate the quantization intervals, to make sure that each quantized
value is exactly in the middle of its quantization interval, thus
minimizing the quantization error.</p>
<p>For any potential x, the activation output is as follows:</p>
<ul class="simple">
<li><p>if x &lt;= threshold, activation is zero</p></li>
<li><p>if threshold + (n - 1) * step &lt; x &lt;= threshold + n * step,
activation is n * step</p></li>
<li><p>if x &gt; threshold + levels * step, activation is levels * step</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">tensorflow.Tensor</span></code>) – the input values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.step">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">step</span></span><a class="headerlink" href="#cnn2snn.QuantizedActivation.step" title="Permalink to this definition"></a></dt>
<dd><p>Returns the interval between two quantized activation values</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.QuantizedActivation.threshold">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">threshold</span></span><a class="headerlink" href="#cnn2snn.QuantizedActivation.threshold" title="Permalink to this definition"></a></dt>
<dd><p>The quantization threshold is equal to half the quantization step to
better approximate the ReLU.</p>
</dd></dl>

</dd></dl>

</section>
<section id="activationdiscreterelu">
<h4>ActivationDiscreteRelu<a class="headerlink" href="#activationdiscreterelu" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.ActivationDiscreteRelu">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">ActivationDiscreteRelu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#ActivationDiscreteRelu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.ActivationDiscreteRelu" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.QuantizedActivation" title="cnn2snn.quantization_layers.QuantizedActivation"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_layers.QuantizedActivation</span></code></a></p>
<p>A discrete ReLU Keras Activation.</p>
<p>For bitwidth 1 or 2:</p>
<blockquote>
<div><ul class="simple">
<li><p>threshold is 0.5 and step is 1</p></li>
</ul>
</div></blockquote>
<p>For bithwidth &gt; 2, with N = 2^bitwidth - 1:</p>
<blockquote>
<div><ul class="simple">
<li><p>threshold is 3 / N and step is 6 / N</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>bitwidth</strong> (<em>int</em>) – the activation bitwidth.</p>
</dd>
</dl>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.ActivationDiscreteRelu.step" title="cnn2snn.ActivationDiscreteRelu.step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">step</span></code></a></p></td>
<td><p>Returns the interval between two quantized activation values</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.ActivationDiscreteRelu.step">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">step</span></span><a class="headerlink" href="#cnn2snn.ActivationDiscreteRelu.step" title="Permalink to this definition"></a></dt>
<dd><p>Returns the interval between two quantized activation values</p>
</dd></dl>

</dd></dl>

</section>
<section id="quantizedrelu">
<h4>QuantizedReLU<a class="headerlink" href="#quantizedrelu" title="Permalink to this headline"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="cnn2snn.QuantizedReLU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">cnn2snn.</span></span><span class="sig-name descname"><span class="pre">QuantizedReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedReLU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#cnn2snn.QuantizedActivation" title="cnn2snn.quantization_layers.QuantizedActivation"><code class="xref py py-class docutils literal notranslate"><span class="pre">cnn2snn.quantization_layers.QuantizedActivation</span></code></a></p>
<p>A configurable Quantized ReLU Keras Activation.</p>
<p>In addition to the quantization bitwidth, this class can be initialized
with a max_value parameter corresponding to the ReLU maximum value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bitwidth</strong> (<em>int</em>) – the activation bitwidth.</p></li>
<li><p><strong>max_value</strong> (<em>float</em>) – the initial max_value</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedReLU.get_config" title="cnn2snn.QuantizedReLU.get_config"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_config</span></code></a>()</p></td>
<td><p>Returns the config of the layer.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#cnn2snn.QuantizedReLU.step" title="cnn2snn.QuantizedReLU.step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">step</span></code></a></p></td>
<td><p>Returns the interval between two quantized activation values</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="cnn2snn.QuantizedReLU.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/cnn2snn/quantization_layers.html#QuantizedReLU.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#cnn2snn.QuantizedReLU.get_config" title="Permalink to this definition"></a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="cnn2snn.QuantizedReLU.step">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">step</span></span><a class="headerlink" href="#cnn2snn.QuantizedReLU.step" title="Permalink to this definition"></a></dt>
<dd><p>Returns the interval between two quantized activation values</p>
</dd></dl>

</dd></dl>

</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="akida_apis.html" class="btn btn-neutral float-left" title="Akida runtime API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="quantizeml_apis.html" class="btn btn-neutral float-right" title="QuantizeML API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>