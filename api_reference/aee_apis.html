<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Akida Execution Engine API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN2SNN Toolkit API" href="cnn2snn_apis.html" />
    <link rel="prev" title="API reference" href="api_reference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #78b3ff" >
            <a href="../index.html">
            <img src="../_static/akida.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                MetaTF 2.0.5
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/aee.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#cifar10-training-and-tuning">CIFAR10 training and tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#yolo-training">YOLO training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#akida-nsoc-pre-production">Akida NSoC (Pre-production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#akida-nsoc-production">Akida NSoC (Production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#id1">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#id2">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#id3">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#id4">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/compatibility.html">Akida versions compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compatibility.html#upgrading-models-with-legacy-quantizers">Upgrading models with legacy quantizers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Akida Execution Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparsity">Sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concat">Concat</a></li>
<li class="toctree-l3"><a class="reference internal" href="#backendtype">BackendType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#padding">Padding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pooltype">PoolType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learningtype">LearningType</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hwversion">HwVersion</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compatibility">Compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="#device">Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hwdevice">HWDevice</a></li>
<li class="toctree-l3"><a class="reference internal" href="#socdriver">SocDriver</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequence">Sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#soc">soc</a></li>
<li class="toctree-l3"><a class="reference internal" href="#powermeter">PowerMeter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#tool-functions">Tool functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize-layer">quantize_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#load-quantized-model">load_quantized_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#load-partial-weights">load_partial_weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#trainablestdweightquantizer">TrainableStdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizeddepthwiseconv2d">QuantizedDepthwiseConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#dense-block">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#batchnormalization-gamma-constraint">BatchNormalization gamma constraint</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#convtiny">ConvTiny</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#create-a-keras-gxnor-model">2. Create a Keras GXNOR model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#conversion-to-akida">3. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html">DS-CNN CIFAR10 inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html#create-a-keras-ds-cnn-model">2. Create a Keras DS-CNN model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_ds_cnn_cifar10.html#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html">MobileNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html#create-a-keras-mobilenet-model">2. Create a Keras MobileNet model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_mobilenet_imagenet.html#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_regression.html">Regression tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_regression.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_regression.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html">Transfer learning with MobileNet for cats vs. dogs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#load-and-preprocess-data">1. Load and preprocess data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#modify-a-pre-trained-base-keras-model">2. Modify a pre-trained base Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#train-the-transferred-model-for-the-new-task">3. Train the transferred model for the new task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#quantize-the-top-layer">4 Quantize the top layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#convert-to-akida">5. Convert to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_transfer_learning.html#plot-confusion-matrix">6. Plot confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#load-and-reshape-mnist-dataset">1. Load and reshape MNIST dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-definition">2. Model definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-training">3. Model training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-fine-tuning-quantization-aware-training">5. Model fine tuning (quantization-aware training)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-conversion">6. Model conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#quantized-activation-layer-details">3. Quantized Activation Layer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#time-icon-ref-time-domain"> Time domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#fault-detection">Fault detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id2">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #78b3ff" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="api_reference.html">API reference</a> &raquo;</li>
      <li>Akida Execution Engine API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-akida">
<span id="akida-execution-engine-api"></span><h1>Akida Execution Engine API<a class="headerlink" href="#module-akida" title="Permalink to this headline"></a></h1>
<dl class="py attribute">
<dt class="sig sig-object py" id="akida.__version__">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">__version__</span></span><a class="headerlink" href="#akida.__version__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current version of the akida module.</p>
</dd></dl>

<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Model">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model" title="Permalink to this definition"></a></dt>
<dd><p>An Akida neural <code class="docutils literal notranslate"><span class="pre">Model</span></code>, represented as a hierarchy of layers.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> class is the main interface to Akida and allows:</p>
<ul class="simple">
<li><p>to create an empty <code class="docutils literal notranslate"><span class="pre">Model</span></code> to which you can add layers programmatically
using the sequential API,</p></li>
<li><p>to reload a full <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a serialized file or a memory buffer,</p></li>
<li><p>to create a new <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a list of layers taken from an existing
<code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p></li>
</ul>
<p>It provides methods to instantiate, train, test and save models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em>, </em><em>optional</em>) – path to the serialized Model.
If None, an empty sequential model will be created, or filled
with the layers in the layers parameter.</p></li>
<li><p><strong>serialized_buffer</strong> (<em>bytes</em><em>, </em><em>optional</em>) – binary buffer containing a
serialized Model.</p></li>
<li><p><strong>layers</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>, optional) – list of layers that will be copied
to the new model. If the list does not start with an input layer,
it will be added automatically.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.add" title="akida.Model.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(self, layer, inbound_layers)</p></td>
<td><p>Add a layer to the current model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.add_classes" title="akida.Model.add_classes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_classes</span></code></a>(num_add_classes)</p></td>
<td><p>Adds classes to the last layer of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.compile" title="akida.Model.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(self, num_weights[, num_classes, ...])</p></td>
<td><p>Prepare the internal parameters of the last layer of the model for training</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.evaluate" title="akida.Model.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(inputs)</p></td>
<td><p>Evaluates a set of images or events through the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.fit" title="akida.Model.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(inputs[, input_labels])</p></td>
<td><p>Trains a set of images or events through the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.forward" title="akida.Model.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs)</p></td>
<td><p>Forwards a set of images or events through the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.get_layer" title="akida.Model.get_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.get_layer_count" title="akida.Model.get_layer_count"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer_count</span></code></a>(self)</p></td>
<td><p>The number of layers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.map" title="akida.Model.map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">map</span></code></a>(self, device, hw_only)</p></td>
<td><p>Map the model to a Device using a target backend.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.pop_layer" title="akida.Model.pop_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop_layer</span></code></a>(self)</p></td>
<td><p>Remove the last layer of the current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.predict" title="akida.Model.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(inputs[, num_classes])</p></td>
<td><p>Returns the model class predictions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.save" title="akida.Model.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(self, arg0)</p></td>
<td><p>Saves all the model configuration (all layers and weights) to a file on disk.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.summary" title="akida.Model.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>()</p></td>
<td><p>Prints a string summary of the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.to_buffer" title="akida.Model.to_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_buffer</span></code></a>(self)</p></td>
<td><p>Serializes all the model configuration (all layers and weights) to a bytes buffer.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.device" title="akida.Model.device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">device</span></code></a></p></td>
<td><p>The device the Model is mapped to (or None)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.hw_device" title="akida.Model.hw_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hw_device</span></code></a></p></td>
<td><p>Internal method to get the hardware device the Model is mapped to (or None)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.input_shape" title="akida.Model.input_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_shape</span></code></a></p></td>
<td><p>The model input dimensions (width, height, features).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.layers" title="akida.Model.layers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layers</span></code></a></p></td>
<td><p>Get a list of layers in current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.metrics" title="akida.Model.metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></a></p></td>
<td><p>The model metrics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.output_shape" title="akida.Model.output_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_shape</span></code></a></p></td>
<td><p>The model output dimensions (width, height, features).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.sequences" title="akida.Model.sequences"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sequences</span></code></a></p></td>
<td><p>The list of layer sequences in the Model</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.statistics" title="akida.Model.statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">statistics</span></code></a></p></td>
<td><p>Get statistics by sequence for this model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.ModelBase</span></em>, <em class="sig-param"><span class="pre">layer:</span> <span class="pre">akida::Layer</span></em>, <em class="sig-param"><span class="pre">inbound_layers:</span> <span class="pre">List[akida::Layer]</span> <span class="pre">=</span> <span class="pre">[]</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.add" title="Permalink to this definition"></a></dt>
<dd><p>Add a layer to the current model.</p>
<p>A list of inbound layers can optionally be specified.
These layers must already be included in the model.
if no inbound layer is specified, and the layer is not the first layer
in the model, the last included layer will be used as inbound layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer</strong> (<em>one of the available layers</em>) – layer instance to be added to the model</p></li>
<li><p><strong>inbound_layers</strong> (a list of <cite>Layer</cite>) – an optional list of inbound layers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add_classes">
<span class="sig-name descname"><span class="pre">add_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_add_classes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.add_classes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.add_classes" title="Permalink to this definition"></a></dt>
<dd><p>Adds classes to the last layer of the model.</p>
<p>A model with a compiled last layer is ready to learn using the Akida
built-in learning algorithm. This function allows to add new classes
(i.e. new neurons) to the last layer, keeping the previously learned
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_add_classes</strong> (<em>int</em>) – number of classes to add to the last layer</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if the last layer is not compiled</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">akida.core.ModelBase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_weights</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_competition</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.10000000149011612</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plasticity_decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.compile" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the internal parameters of the last layer of the model for training</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_weights</strong> (<em>int</em>) – number of connections for each neuron.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of classes when running in a
‘labeled mode’.</p></li>
<li><p><strong>initial_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines how easily the weights
will change when learning occurs.</p></li>
<li><p><strong>learning_competition</strong> (<em>float</em><em>, </em><em>optional</em>) – controls competition between
neurons.</p></li>
<li><p><strong>min_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the minimum level to which
plasticity will decay.</p></li>
<li><p><strong>plasticity_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the decay of plasticity
with each learning step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.device">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#akida.Model.device" title="Permalink to this definition"></a></dt>
<dd><p>The device the Model is mapped to (or None)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates a set of images or events through the model.</p>
<p>Forwards an input tensor through the model and returns a float array.</p>
<p>It applies ONLY to models without an activation on the last layer.
The output values are obtained from the model discrete potentials by
applying a shift and a scale.</p>
<p>The expected input tensor dimensions are:</p>
<ul class="simple">
<li><p>n, representing the number of frames or samples,</p></li>
<li><p>w, representing the width,</p></li>
<li><p>h, representing the height,</p></li>
<li><p>c, representing the channel, or more generally the feature.</p></li>
</ul>
<p>If the inputs are events, the input shape must be (n, w, h, c), but if
the inputs are images (numpy array), their shape must be (n, h, w, c).</p>
<p>Note: only grayscale (c=1) or RGB (c=3) images (arrays) are supported.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, w, h, c) numpy.ndarray</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a float array of shape (n, w, h, c).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>RuntimeError</strong> – if the model last layer has an activation.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, or if the model only has an InputData layer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.fit" title="Permalink to this definition"></a></dt>
<dd><p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<p>The expected input tensor dimensions are:</p>
<ul class="simple">
<li><p>n, representing the number of frames or samples,</p></li>
<li><p>w, representing the width,</p></li>
<li><p>h, representing the height,</p></li>
<li><p>c, representing the channel, or more generally the feature.</p></li>
</ul>
<p>If the inputs are events, the input shape must be (n, w, h, c), but if
the inputs are images, their shape must be (n, h, w, c).</p>
<p>Note: only grayscale (c=1) or RGB (c=3) images (arrays) are supported.</p>
<p>If activations are enabled for the last layer, the output is an uint8
tensor.</p>
<p>If activations are disabled for the last layer, the output is an int32
tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p></li>
<li><p><strong>input_labels</strong> (<em>list</em><em>(</em><em>int</em><em>)</em><em>, </em><em>optional</em>) – input labels.
Must have one label per input, or a single label for all inputs.
If a label exceeds the defined number of classes, the input will
be discarded. (Default value = None).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape (n, out_w, out_h, out_c).</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forwards a set of images or events through the model.</p>
<p>Forwards an input tensor through the model and returns an output tensor.</p>
<p>The expected input tensor dimensions are:</p>
<ul class="simple">
<li><p>n, representing the number of frames or samples,</p></li>
<li><p>w, representing the width,</p></li>
<li><p>h, representing the height,</p></li>
<li><p>c, representing the channel, or more generally the feature.</p></li>
</ul>
<p>If the inputs are events, the input shape must be (n, w, h, c), but if
the inputs are images, their shape must be (n, h, w, c).</p>
<p>Note: only grayscale (c=1) or RGB (c=3) images (arrays) are supported.</p>
<p>If activations are enabled for the last layer, the output is an uint8
tensor.</p>
<p>If activations are disabled for the last layer, the output is an int32
tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a numpy array of shape (n, out_w, out_h, out_c).</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the inputs doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer">
<span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.get_layer" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic">
<li><p>get_layer(self: akida.core.ModelBase, layer_name: str) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_name</dt>
<dd class="field-odd"><p>name of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_name</dt>
<dd class="field-even"><p>str</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>get_layer(self: akida.core.ModelBase, layer_index: int) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_index</dt>
<dd class="field-odd"><p>index of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_index</dt>
<dd class="field-even"><p>int</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer_count">
<span class="sig-name descname"><span class="pre">get_layer_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">akida.core.ModelBase</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#akida.Model.get_layer_count" title="Permalink to this definition"></a></dt>
<dd><p>The number of layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.hw_device">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">hw_device</span></span><a class="headerlink" href="#akida.Model.hw_device" title="Permalink to this definition"></a></dt>
<dd><p>Internal method to get the hardware device the Model is mapped to (or None)</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.input_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_shape</span></span><a class="headerlink" href="#akida.Model.input_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model input dimensions (width, height, features).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.layers">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#akida.Model.layers" title="Permalink to this definition"></a></dt>
<dd><p>Get a list of layers in current model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.map">
<span class="sig-name descname"><span class="pre">map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.ModelBase</span></em>, <em class="sig-param"><span class="pre">device:</span> <span class="pre">akida::Device</span></em>, <em class="sig-param"><span class="pre">hw_only:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.map" title="Permalink to this definition"></a></dt>
<dd><p>Map the model to a Device using a target backend.</p>
<p>This method tries to map a Model to the specified Device, implicitly
identifying one or more layer sequences that are mapped individually on
the Device Mesh.</p>
<p>An optional hw_only parameter can be specified to force the mapping
strategy to use only one hardware sequence, thus reducing software
intervention on the inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<cite>Device</cite>) – the target Device or None</p></li>
<li><p><strong>hw_only</strong> (<em>bool</em>) – when true, the model should be mapped in one sequence</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.metrics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#akida.Model.metrics" title="Permalink to this definition"></a></dt>
<dd><p>The model metrics.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.output_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_shape</span></span><a class="headerlink" href="#akida.Model.output_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model output dimensions (width, height, features).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.pop_layer">
<span class="sig-name descname"><span class="pre">pop_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">akida.core.ModelBase</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.pop_layer" title="Permalink to this definition"></a></dt>
<dd><p>Remove the last layer of the current model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.predict" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model class predictions.</p>
<p>Forwards an input tensor (images or events) through the model
and compute predictions based on the neuron id.
If the number of output neurons is greater than the number of classes,
the neurons are automatically assigned to a class by dividing their id
by the number of classes.</p>
<p>The expected input tensor dimensions are:</p>
<ul class="simple">
<li><p>n, representing the number of frames or samples,</p></li>
<li><p>w, representing the width,</p></li>
<li><p>h, representing the height,</p></li>
<li><p>c, representing the channel, or more generally the feature.</p></li>
</ul>
<p>If the inputs are events, the input shape must be (n, w, h, c), but if
the inputs are images their shape must be (n, h, w, c).</p>
<p>Note: only grayscale (c=1) or RGB (c=3) images (arrays) are supported.</p>
<p>Note that the predictions are based on the activation values of the last
layer: for most use cases, you may want to disable activations for that
layer (ie setting <code class="docutils literal notranslate"><span class="pre">activation=False</span></code>) to get a better
accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – optional parameter (defaults to the
number of neurons in the last layer).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array of shape (n).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">akida.core.ModelBase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.save" title="Permalink to this definition"></a></dt>
<dd><p>Saves all the model configuration (all layers and weights) to a
file on disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_file</strong> (<em>str</em>) – full path of the serialized model (.fbz file).</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.sequences">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">sequences</span></span><a class="headerlink" href="#akida.Model.sequences" title="Permalink to this definition"></a></dt>
<dd><p>The list of layer sequences in the Model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.statistics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">statistics</span></span><a class="headerlink" href="#akida.Model.statistics" title="Permalink to this definition"></a></dt>
<dd><p>Get statistics by sequence for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><cite>SequenceStatistics</cite> indexed by name.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>a dictionary of obj</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/model.html#Model.summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Model.summary" title="Permalink to this definition"></a></dt>
<dd><p>Prints a string summary of the model.</p>
<p>This method prints a summary of the model with details for every layer,
grouped by sequences:</p>
<ul class="simple">
<li><p>name and type in the first column</p></li>
<li><p>output shape</p></li>
<li><p>kernel shape</p></li>
</ul>
<p>If there is any layer with unsupervised learning enabled, it will list
them, with these details:</p>
<ul class="simple">
<li><p>name of layer</p></li>
<li><p>number of incoming connections</p></li>
<li><p>number of weights per neuron</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.to_buffer">
<span class="sig-name descname"><span class="pre">to_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">akida.core.ModelBase</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bytes</span></span></span><a class="headerlink" href="#akida.Model.to_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Serializes all the model configuration (all layers and weights) to a
bytes buffer.</p>
</dd></dl>

</dd></dl>

</section>
<section id="layer">
<h2>Layer<a class="headerlink" href="#layer" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Layer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Layer</span></span><a class="headerlink" href="#akida.Layer" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_learning_histogram" title="akida.Layer.get_learning_histogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_learning_histogram</span></code></a>()</p></td>
<td><p>Returns an histogram of learning percentages.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.get_variable" title="akida.Layer.get_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable</span></code></a>(name)</p></td>
<td><p>Get the value of a layer variable.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_variable_names" title="akida.Layer.get_variable_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable_names</span></code></a>()</p></td>
<td><p>Get the list of variable names for this layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.set_variable" title="akida.Layer.set_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_variable</span></code></a>(name, values)</p></td>
<td><p>Set the value of a layer variable.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.inbounds" title="akida.Layer.inbounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inbounds</span></code></a></p></td>
<td><p>The layer inbound layers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.input_bits" title="akida.Layer.input_bits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_bits</span></code></a></p></td>
<td><p>The layer input bits.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.input_dims" title="akida.Layer.input_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_dims</span></code></a></p></td>
<td><p>The layer input dimensions (width, height, channels).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.learning" title="akida.Layer.learning"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learning</span></code></a></p></td>
<td><p>The layer learning parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.mapping" title="akida.Layer.mapping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mapping</span></code></a></p></td>
<td><p>The layer hardware mapping.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.name" title="akida.Layer.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The layer name.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.output_dims" title="akida.Layer.output_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_dims</span></code></a></p></td>
<td><p>The layer output dimensions (width, height, features).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.parameters" title="akida.Layer.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a></p></td>
<td><p>The layer parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.variables" title="akida.Layer.variables"><code class="xref py py-obj docutils literal notranslate"><span class="pre">variables</span></code></a></p></td>
<td><p>The layer trainable variables.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_learning_histogram">
<span class="sig-name descname"><span class="pre">get_learning_histogram</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_learning_histogram" title="Permalink to this definition"></a></dt>
<dd><p>Returns an histogram of learning percentages.</p>
<p>Returns a list of learning percentages and the associated number of
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a (n,2) numpy.ndarray containing the learning
percentages and the number of neurons.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable">
<span class="sig-name descname"><span class="pre">get_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul class="simple">
<li><p>Weights variables are typically integer arrays of shape:
(width, height, features/channels, num_neurons) row-major (‘C’).</p></li>
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – the variable name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array containing the variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable_names">
<span class="sig-name descname"><span class="pre">get_variable_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable_names" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of variable names for this layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of variable names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.inbounds">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">inbounds</span></span><a class="headerlink" href="#akida.Layer.inbounds" title="Permalink to this definition"></a></dt>
<dd><p>The layer inbound layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_bits">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_bits</span></span><a class="headerlink" href="#akida.Layer.input_bits" title="Permalink to this definition"></a></dt>
<dd><p>The layer input bits.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_dims</span></span><a class="headerlink" href="#akida.Layer.input_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer input dimensions (width, height, channels).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.learning">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learning</span></span><a class="headerlink" href="#akida.Layer.learning" title="Permalink to this definition"></a></dt>
<dd><p>The layer learning parameters set.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.mapping">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mapping</span></span><a class="headerlink" href="#akida.Layer.mapping" title="Permalink to this definition"></a></dt>
<dd><p>The layer hardware mapping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Layer.name" title="Permalink to this definition"></a></dt>
<dd><p>The layer name.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.output_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_dims</span></span><a class="headerlink" href="#akida.Layer.output_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer output dimensions (width, height, features).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.parameters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">parameters</span></span><a class="headerlink" href="#akida.Layer.parameters" title="Permalink to this definition"></a></dt>
<dd><p>The layer parameters set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.set_variable">
<span class="sig-name descname"><span class="pre">set_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.set_variable" title="Permalink to this definition"></a></dt>
<dd><p>Set the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul>
<li><p>Weights variables are typically integer arrays of shape:</p>
<p>(num_neurons, features/channels, height, width) col-major ordered (‘F’)</p>
</li>
</ul>
<p>or equivalently:</p>
<blockquote>
<div><p>(width, height, features/channels, num_neurons) row-major (‘C’).</p>
</div></blockquote>
<ul class="simple">
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – the variable name.</p></li>
<li><p><strong>values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray containing the variable values.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.variables">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">variables</span></span><a class="headerlink" href="#akida.Layer.variables" title="Permalink to this definition"></a></dt>
<dd><p>The layer trainable variables.</p>
</dd></dl>

</dd></dl>

</section>
<section id="sparsity">
<h2>Sparsity<a class="headerlink" href="#sparsity" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="akida.evaluate_sparsity">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">evaluate_sparsity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/sparsity.html#evaluate_sparsity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.evaluate_sparsity" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the sparsity of a Model on a set of inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></a>) – the model to evaluate</p></li>
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary of float sparsity values indexed by layers</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="inputdata">
<h2>InputData<a class="headerlink" href="#inputdata" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputData">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputData</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/input_data.html#InputData"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputData" title="Permalink to this definition"></a></dt>
<dd><p>This is the general purpose input layer. It takes events in a simple
address-event data format; that is, each event is characterized by a trio
of values giving x, y and channel values.</p>
<p>Regarding the input dimension values, note that AEE expects inputs with
zero-based indexing, i.e., if input_width is defined as 12, then the model
expects all input events to have x-values in the range 0–11.</p>
<p>Where possible:</p>
<ul class="simple">
<li><p>The x and y dimensions should be used for discretely-sampled continuous
domains such as space (e.g., images) or time-series (e.g., an audio
signal).</p></li>
<li><p>The c dimension should be used for ‘category indices’, where there is no
particular relationship between neighboring values.</p></li>
</ul>
<p>The input dimension values are used for:</p>
<ul class="simple">
<li><p>Error checking – input events are checked and if any fall outside the
defined input range, then the whole set of events sent on that
processing call is rejected. An error will also be generated if the
defined values are larger than the true input dimensions.</p></li>
<li><p>Configuring the input and output dimensions of subsequent layers in the
model.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>input_bits</strong> (<em>int</em>) – input bitwidth.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="inputconvolutional">
<h2>InputConvolutional<a class="headerlink" href="#inputconvolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_shape</span></em>, <em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em>, <em class="sig-param"><span class="pre">padding_value=0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/input_convolutional.html#InputConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>The <code class="docutils literal notranslate"><span class="pre">InputConvolutional</span></code> layer is an image-specific input layer.</p>
<p>It is used if images are sent directly to AEE without using the
event-generating method. If the User applies their own event-generating
method, the resulting events should be sent to an InputData type layer
instead.</p>
<p>The InputConvolutional layer accepts images in 8-bit pixels, either
grayscale or RGB. Images are converted to events using a combination of
convolution kernels, activation thresholds and winner-take-all (WTA)
policies. Note that since the layer input is dense, expect approximately one
event per pixel – fewer if there are large contrast-free regions in the
image, such as with the MNIST dataset.</p>
<p>Note that this format is not appropriate for neuromorphic camera type input
which data is natively event-based and should be sent to an InputData type
input layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of
convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>tuple</em><em>, </em><em>optional</em>) – tuple of integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
<li><p><strong>padding_value</strong> (<em>int</em><em>, </em><em>optional</em>) – value used when padding.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="fullyconnected">
<h2>FullyConnected<a class="headerlink" href="#fullyconnected" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.FullyConnected">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">FullyConnected</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/fully_connected.html#FullyConnected"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.FullyConnected" title="Permalink to this definition"></a></dt>
<dd><p>This is used for most processing purposes, since any neuron in the layer
can be connected to any input channel.</p>
<p>Outputs are returned from FullyConnected layers as a list of events, that
is, as a triplet of x, y and feature values. However, FullyConnected
models by definition have no intrinsic spatial organization. Thus, all
output events have x and y values of zero with only the f value being
meaningful – corresponding to the index of the event-generating neuron.
Note that each neuron can only generate a single event for each packet of
inputs processed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – number of units.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to
quantize the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="convolutional">
<h2>Convolutional<a class="headerlink" href="#convolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Convolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Convolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/convolutional.html#Convolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Convolutional" title="Permalink to this definition"></a></dt>
<dd><p>Convolutional or “weight-sharing” layers are commonly used in visual
processing. However, the convolution operation is extremely useful in any
domain where translational invariance is required – that is, where localized
patterns may be of interest regardless of absolute position within the
input. The convolution implemented here is typical of that used in visual
processing, i.e., it is a 2D convolution (across the x- and y-dimensions),
but a 3D input with a 3D filter. No convolution occurs across the third
dimension; events from input feature 1 only interact with connections to
input feature 1 – likewise for input feature 2 and so on. Typically,
the input feature is the identity of the event-emitting neuron in the
previous layer.</p>
<p>Outputs are returned from convolutional layers as a list of events, that is,
as a triplet of x, y and feature (neuron index) values. Note that for a
single packet processed, each neuron can only generate a single event at a
given location, but can generate events at multiple different locations and
that multiple neurons may all generate events at a single location.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="separableconvolutional">
<h2>SeparableConvolutional<a class="headerlink" href="#separableconvolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.SeparableConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">SeparableConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=2</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/separable_convolutional.html#SeparableConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.SeparableConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>Separable convolutions consist in first performing a depthwise spatial
convolution (which acts on each input channel separately) followed by a
pointwise convolution which mixes together the resulting output channels.
Intuitively, separable convolutions can be understood as a way to factorize
a convolution kernel into two smaller kernels, thus decreasing the number of
computations required to evaluate the output potentials. The
<code class="docutils literal notranslate"><span class="pre">SeparableConvolutional</span></code> layer can also integrate a final pooling
operation to reduce its spatial output dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of pointwise filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="concat">
<h2>Concat<a class="headerlink" href="#concat" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Concat">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/concat.html#Concat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Concat" title="Permalink to this definition"></a></dt>
<dd><p>Concatenates its inputs along the last dimension</p>
<p>It takes as input a list of tensors, all of the same shape except for the
last dimension, and returns a single tensor that is the concatenation
of all inputs.</p>
<p>It accepts as inputs either potentials or activations.</p>
<p>It can perform an activation on the concatenated output with its own set of
activation parameters and variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to
quantize the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="backendtype">
<h2>BackendType<a class="headerlink" href="#backendtype" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.BackendType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">BackendType</span></span><a class="headerlink" href="#akida.BackendType" title="Permalink to this definition"></a></dt>
<dd><p>Members:</p>
<p>Software</p>
<p>Hardware</p>
<p>Hybrid</p>
</dd></dl>

</section>
<section id="padding">
<h2>Padding<a class="headerlink" href="#padding" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Padding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Padding</span></span><a class="headerlink" href="#akida.Padding" title="Permalink to this definition"></a></dt>
<dd><p>Sets the effective padding of the input for convolution, thereby determining the output dimensions. Naming conventions are the same as Keras/Tensorflow.</p>
<p>Members:</p>
<blockquote>
<div><p>Valid : No padding</p>
<p>Same : Padded so that output size is input size divided by the stride</p>
</div></blockquote>
</dd></dl>

</section>
<section id="pooltype">
<h2>PoolType<a class="headerlink" href="#pooltype" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PoolType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PoolType</span></span><a class="headerlink" href="#akida.PoolType" title="Permalink to this definition"></a></dt>
<dd><p>The pooling type</p>
<p>Members:</p>
<blockquote>
<div><p>NoPooling : No pooling applied</p>
<p>Max : Maximum pixel value is selected</p>
<p>Average : Average pixel value is selected</p>
</div></blockquote>
</dd></dl>

</section>
<section id="learningtype">
<h2>LearningType<a class="headerlink" href="#learningtype" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.LearningType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">LearningType</span></span><a class="headerlink" href="#akida.LearningType" title="Permalink to this definition"></a></dt>
<dd><p>The learning type</p>
<p>Members:</p>
<blockquote>
<div><p>NoLearning : Learning is disabled, inference-only mode</p>
<p>AkidaUnsupervised : Built-in unsupervised learning rules</p>
</div></blockquote>
</dd></dl>

</section>
<section id="hwversion">
<h2>HwVersion<a class="headerlink" href="#hwversion" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HwVersion">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HwVersion</span></span><a class="headerlink" href="#akida.HwVersion" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.major_rev" title="akida.HwVersion.major_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">major_rev</span></code></a></p></td>
<td><p>The hardware major revision</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.minor_rev" title="akida.HwVersion.minor_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minor_rev</span></code></a></p></td>
<td><p>The hardware minor revision</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.product_id" title="akida.HwVersion.product_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">product_id</span></code></a></p></td>
<td><p>The hardware product identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.vendor_id" title="akida.HwVersion.vendor_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vendor_id</span></code></a></p></td>
<td><p>The hardware vendor identifier</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.major_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">major_rev</span></span><a class="headerlink" href="#akida.HwVersion.major_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware major revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.minor_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">minor_rev</span></span><a class="headerlink" href="#akida.HwVersion.minor_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware minor revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.product_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">product_id</span></span><a class="headerlink" href="#akida.HwVersion.product_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware product identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.vendor_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">vendor_id</span></span><a class="headerlink" href="#akida.HwVersion.vendor_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware vendor identifier</p>
</dd></dl>

</dd></dl>

</section>
<section id="compatibility">
<h2>Compatibility<a class="headerlink" href="#compatibility" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="akida.compatibility.create_from_model">
<span class="sig-prename descclassname"><span class="pre">akida.compatibility.</span></span><span class="sig-name descname"><span class="pre">create_from_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hw_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/compatibility/conversion.html#create_from_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.compatibility.create_from_model" title="Permalink to this definition"></a></dt>
<dd><p>Tries to create a HW compatible model from an incompatible one</p>
<p>Tries to create a HW compatible model from an incompatible one, using SW
workarounds for known limitations. It returns a converted model that is not
guaranteed to be HW compatible, depending if workaround have been found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code>) – a Model object to convert</p></li>
<li><p><strong>hw_version</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">HwVersion</span></code>, optional) – version of the Hardware</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new Model with no guarantee that it is HW compatible.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="device">
<h2>Device<a class="headerlink" href="#device" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Device">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Device</span></span><a class="headerlink" href="#akida.Device" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.desc" title="akida.Device.desc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">desc</span></code></a></p></td>
<td><p>Returns the Device description</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Device.mesh" title="akida.Device.mesh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mesh</span></code></a></p></td>
<td><p>The device Mesh layout</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.version" title="akida.Device.version"><code class="xref py py-obj docutils literal notranslate"><span class="pre">version</span></code></a></p></td>
<td><p>The device hardware version.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.desc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">desc</span></span><a class="headerlink" href="#akida.Device.desc" title="Permalink to this definition"></a></dt>
<dd><p>Returns the Device description</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a string describing the Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.mesh">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mesh</span></span><a class="headerlink" href="#akida.Device.mesh" title="Permalink to this definition"></a></dt>
<dd><p>The device Mesh layout</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.version">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">version</span></span><a class="headerlink" href="#akida.Device.version" title="Permalink to this definition"></a></dt>
<dd><p>The device hardware version.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.devices">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">devices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.devices" title="Permalink to this definition"></a></dt>
<dd><p>Returns the full list of available hardware devices</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.AKD1000">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">AKD1000</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">hw_version=BC.00.000.002</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#AKD1000"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.AKD1000" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for an AKD1000 NSoC.</p>
<p>This function returns a virtual device for the Brainchip’s AKD1000
NSoC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hw_version</strong> (<a class="reference internal" href="#akida.HwVersion" title="akida.HwVersion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HwVersion</span></code></a>, optional) – optional parameter (defaults</p></li>
<li><p><strong>revision</strong><strong>)</strong><strong></strong> (<em>to the NSoC_v2 hardware</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a virtual device.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.TwoNodesIP">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">TwoNodesIP</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#TwoNodesIP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.TwoNodesIP" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for a two nodes Akida IP.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a virtual device.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="hwdevice">
<h2>HWDevice<a class="headerlink" href="#hwdevice" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HardwareDevice">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HardwareDevice</span></span><a class="headerlink" href="#akida.HardwareDevice" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.evaluate" title="akida.HardwareDevice.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device, returns a float array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.forward" title="akida.HardwareDevice.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.read_clock_counter" title="akida.HardwareDevice.read_clock_counter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read_clock_counter</span></code></a>(self)</p></td>
<td><p>Reads the DMA clock counter value</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.toggle_clock_counter" title="akida.HardwareDevice.toggle_clock_counter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toggle_clock_counter</span></code></a>(self, arg0)</p></td>
<td><p>Turn the DMA clock counter on or off</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.unprogram" title="akida.HardwareDevice.unprogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unprogram</span></code></a>(self)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.learn_enabled" title="akida.HardwareDevice.learn_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learn_enabled</span></code></a></p></td>
<td><p>Property that enables/disables learning on current program (if possible).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.memory" title="akida.HardwareDevice.memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memory</span></code></a></p></td>
<td><p>The device memory usage and top usage (in bytes)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.pipeline" title="akida.HardwareDevice.pipeline"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pipeline</span></code></a></p></td>
<td><p>Property to enable/disable input pipeline.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.program" title="akida.HardwareDevice.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Property that retrieves current program or programs a device using a serialized program bytes object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.soc" title="akida.HardwareDevice.soc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">soc</span></code></a></p></td>
<td><p>The SocDriver interface used by the device, or None if the device is not a SoC</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device, returns a float array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with float outputs from the device</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.forward" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with outputs from the device</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.learn_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learn_enabled</span></span><a class="headerlink" href="#akida.HardwareDevice.learn_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Property that enables/disables learning on current program (if
possible).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.memory">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">memory</span></span><a class="headerlink" href="#akida.HardwareDevice.memory" title="Permalink to this definition"></a></dt>
<dd><p>The device memory usage and top usage (in bytes)</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.pipeline">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">pipeline</span></span><a class="headerlink" href="#akida.HardwareDevice.pipeline" title="Permalink to this definition"></a></dt>
<dd><p>Property to enable/disable input pipeline.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.HardwareDevice.program" title="Permalink to this definition"></a></dt>
<dd><p>Property that retrieves current program or programs a device using a
serialized program bytes object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.read_clock_counter">
<span class="sig-name descname"><span class="pre">read_clock_counter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#akida.HardwareDevice.read_clock_counter" title="Permalink to this definition"></a></dt>
<dd><p>Reads the DMA clock counter value</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.soc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">soc</span></span><a class="headerlink" href="#akida.HardwareDevice.soc" title="Permalink to this definition"></a></dt>
<dd><p>The SocDriver interface used by the device, or None if the device
is not a SoC</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.toggle_clock_counter">
<span class="sig-name descname"><span class="pre">toggle_clock_counter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.toggle_clock_counter" title="Permalink to this definition"></a></dt>
<dd><p>Turn the DMA clock counter on or off</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.unprogram">
<span class="sig-name descname"><span class="pre">unprogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.unprogram" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="socdriver">
<h2>SocDriver<a class="headerlink" href="#socdriver" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.SocDriver">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.</span></span><span class="sig-name descname"><span class="pre">SocDriver</span></span><a class="headerlink" href="#akida.core.SocDriver" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_measurement_enabled" title="akida.core.SocDriver.power_measurement_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_measurement_enabled</span></code></a></p></td>
<td><p>Power measurement is off by default.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_meter" title="akida.core.SocDriver.power_meter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_meter</span></code></a></p></td>
<td><p>Power meter associated to the SoC.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_measurement_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_measurement_enabled</span></span><a class="headerlink" href="#akida.core.SocDriver.power_measurement_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Power measurement is off by default. Toggle it on to get power information in the statistics or when calling PowerMeter.events().</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_meter">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_meter</span></span><a class="headerlink" href="#akida.core.SocDriver.power_meter" title="Permalink to this definition"></a></dt>
<dd><p>Power meter associated to the SoC.</p>
</dd></dl>

</dd></dl>

</section>
<section id="sequence">
<h2>Sequence<a class="headerlink" href="#sequence" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Sequence">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Sequence</span></span><a class="headerlink" href="#akida.Sequence" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.backend" title="akida.Sequence.backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backend</span></code></a></p></td>
<td><p>The backend type for this Sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.name" title="akida.Sequence.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The name of the sequence</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.passes" title="akida.Sequence.passes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">passes</span></code></a></p></td>
<td><p>Get the list of passes in this sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.program" title="akida.Sequence.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Get the hardware program for this sequence.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.backend">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">backend</span></span><a class="headerlink" href="#akida.Sequence.backend" title="Permalink to this definition"></a></dt>
<dd><p>The backend type for this Sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Sequence.name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the sequence</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.passes">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">passes</span></span><a class="headerlink" href="#akida.Sequence.passes" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of passes in this sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.Sequence.program" title="Permalink to this definition"></a></dt>
<dd><p>Get the hardware program for this sequence.</p>
<p>Returns None if the Sequence is not compatible with the selected
Device.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a bytes buffer or None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="np">
<h2>NP<a class="headerlink" href="#np" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Mesh">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Mesh</span></span><a class="headerlink" href="#akida.NP.Mesh" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_conf" title="akida.NP.Mesh.dma_conf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_conf</span></code></a></p></td>
<td><p>DMA configuration endpoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_event" title="akida.NP.Mesh.dma_event"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_event</span></code></a></p></td>
<td><p>DMA event endpoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.nps" title="akida.NP.Mesh.nps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nps</span></code></a></p></td>
<td><p>Neural processors</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_conf">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_conf</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_conf" title="Permalink to this definition"></a></dt>
<dd><p>DMA configuration endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_event">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_event</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_event" title="Permalink to this definition"></a></dt>
<dd><p>DMA event endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.nps">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">nps</span></span><a class="headerlink" href="#akida.NP.Mesh.nps" title="Permalink to this definition"></a></dt>
<dd><p>Neural processors</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Info">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Info</span></span><a class="headerlink" href="#akida.NP.Info" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Info.ident" title="akida.NP.Info.ident"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ident</span></code></a></p></td>
<td><p>NP identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Info.types" title="akida.NP.Info.types"><code class="xref py py-obj docutils literal notranslate"><span class="pre">types</span></code></a></p></td>
<td><p>NP supported types</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.ident">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ident</span></span><a class="headerlink" href="#akida.NP.Info.ident" title="Permalink to this definition"></a></dt>
<dd><p>NP identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.types">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">types</span></span><a class="headerlink" href="#akida.NP.Info.types" title="Permalink to this definition"></a></dt>
<dd><p>NP supported types</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Ident">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Ident</span></span><a class="headerlink" href="#akida.NP.Ident" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.col" title="akida.NP.Ident.col"><code class="xref py py-obj docutils literal notranslate"><span class="pre">col</span></code></a></p></td>
<td><p>NP column number</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Ident.id" title="akida.NP.Ident.id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">id</span></code></a></p></td>
<td><p>NP id</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.row" title="akida.NP.Ident.row"><code class="xref py py-obj docutils literal notranslate"><span class="pre">row</span></code></a></p></td>
<td><p>NP row number</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.col">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">col</span></span><a class="headerlink" href="#akida.NP.Ident.col" title="Permalink to this definition"></a></dt>
<dd><p>NP column number</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#akida.NP.Ident.id" title="Permalink to this definition"></a></dt>
<dd><p>NP id</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.row">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">row</span></span><a class="headerlink" href="#akida.NP.Ident.row" title="Permalink to this definition"></a></dt>
<dd><p>NP row number</p>
</dd></dl>

</dd></dl>

</section>
<section id="soc">
<h2>soc<a class="headerlink" href="#soc" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.soc.ClockMode">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.soc.</span></span><span class="sig-name descname"><span class="pre">ClockMode</span></span><a class="headerlink" href="#akida.core.soc.ClockMode" title="Permalink to this definition"></a></dt>
<dd><p>Clock mode configuration</p>
<p>Members:</p>
<blockquote>
<div><p>Performance</p>
<p>Economy</p>
<p>LowPower</p>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.core.soc.get_clock_mode">
<span class="sig-prename descclassname"><span class="pre">akida.core.soc.</span></span><span class="sig-name descname"><span class="pre">get_clock_mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#akida.core.soc.ClockMode" title="akida.core.soc.ClockMode"><span class="pre">akida.core.soc.ClockMode</span></a></span></span><a class="headerlink" href="#akida.core.soc.get_clock_mode" title="Permalink to this definition"></a></dt>
<dd><p>Return clock mode of SoC currently connected</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.core.soc.set_clock_mode">
<span class="sig-prename descclassname"><span class="pre">akida.core.soc.</span></span><span class="sig-name descname"><span class="pre">set_clock_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.core.soc.ClockMode" title="akida.core.soc.ClockMode"><span class="pre">akida.core.soc.ClockMode</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.core.soc.set_clock_mode" title="Permalink to this definition"></a></dt>
<dd><p>Set clock mode of SoC currently connected</p>
</dd></dl>

</section>
<section id="powermeter">
<h2>PowerMeter<a class="headerlink" href="#powermeter" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerMeter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerMeter</span></span><a class="headerlink" href="#akida.PowerMeter" title="Permalink to this definition"></a></dt>
<dd><p>Gives access to power measurements.</p>
<p>When power measurements are enabled for a specific device, this object
stores them as a list of <code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code> objects.
The events list cannot exceed a predefined size: when it is full, older
events are replaced by newer events.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerMeter.events" title="akida.PowerMeter.events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events</span></code></a>(self)</p></td>
<td><p>Retrieve all pending events</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerMeter.latest_measure" title="akida.PowerMeter.latest_measure"><code class="xref py py-obj docutils literal notranslate"><span class="pre">latest_measure</span></code></a>(self)</p></td>
<td><p>Get the latest power measure</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.PowerMeter.events">
<span class="sig-name descname"><span class="pre">events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.PowerMeter" title="akida.core.PowerMeter"><span class="pre">akida.core.PowerMeter</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.PowerEvent" title="akida.core.PowerEvent"><span class="pre">akida.core.PowerEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.PowerMeter.events" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve all pending events</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.PowerMeter.latest_measure">
<span class="sig-name descname"><span class="pre">latest_measure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.PowerMeter" title="akida.core.PowerMeter"><span class="pre">akida.core.PowerMeter</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">object</span></span></span><a class="headerlink" href="#akida.PowerMeter.latest_measure" title="Permalink to this definition"></a></dt>
<dd><p>Get the latest power measure</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerEvent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerEvent</span></span><a class="headerlink" href="#akida.PowerEvent" title="Permalink to this definition"></a></dt>
<dd><p>A timestamped power measurement.</p>
<p>Each PowerEvent contains a voltage value in µV and a current value in mA.
The power in mW can be obtained as: voltage * current / 10^6.</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.current" title="akida.PowerEvent.current"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current</span></code></a></p></td>
<td><p>Current value in mA</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerEvent.ts" title="akida.PowerEvent.ts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ts</span></code></a></p></td>
<td><p>Timestamp of the event</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.voltage" title="akida.PowerEvent.voltage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">voltage</span></code></a></p></td>
<td><p>Voltage value in µV</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.current">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">current</span></span><a class="headerlink" href="#akida.PowerEvent.current" title="Permalink to this definition"></a></dt>
<dd><p>Current value in mA</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.ts">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ts</span></span><a class="headerlink" href="#akida.PowerEvent.ts" title="Permalink to this definition"></a></dt>
<dd><p>Timestamp of the event</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.voltage">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">voltage</span></span><a class="headerlink" href="#akida.PowerEvent.voltage" title="Permalink to this definition"></a></dt>
<dd><p>Voltage value in µV</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api_reference.html" class="btn btn-neutral float-left" title="API reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnn2snn_apis.html" class="btn btn-neutral float-right" title="CNN2SNN Toolkit API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>