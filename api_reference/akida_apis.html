<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Akida runtime API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN2SNN Toolkit API" href="cnn2snn_apis.html" />
    <link rel="prev" title="API reference" href="api_reference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../index.html">
            
              <img src="../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#performance-measurement">Performance measurement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#keras-support">Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/quantizeml.html#onnx-support">ONNX support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-quantization-scenario">Typical quantization scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id3">Command-line interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#akida-layers">Akida layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sparsity">Sparsity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantized-layers">Quantized layers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="quantizeml_apis.html#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#id2">Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="quantizeml_apis.html#custom-patterns">Custom patterns</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-i-o">Model I/O</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_global_workflow.html#convert">3. Convert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html">Build Vision Transformers for Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-selection">1. Model selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-optimization-for-akida-hardware">2. Model optimization for Akida hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-training">3. Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_7_vision_transformer.html#displaying-results-attention-maps">6. Displaying results Attention Maps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_8_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html">Advanced ONNX models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#get-model-and-data">1. Get model and data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/quantization/plot_3_custom_patterns.html#conversion">3. Conversion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#deprecated-cnn2snn-tutorials">[Deprecated] CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id11">Keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id12">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo_performance.html#id14"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../model_zoo_performance.html#id15">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="api_reference.html">API reference</a></li>
      <li class="breadcrumb-item active">Akida runtime API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-akida">
<span id="akida-runtime-api"></span><h1>Akida runtime API<a class="headerlink" href="#module-akida" title="Permalink to this headline"></a></h1>
<dl class="py attribute">
<dt class="sig sig-object py" id="akida.__version__">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">__version__</span></span><a class="headerlink" href="#akida.__version__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current version of the akida module.</p>
</dd></dl>

<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Model">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><a class="headerlink" href="#akida.Model" title="Permalink to this definition"></a></dt>
<dd><p>An Akida neural <code class="docutils literal notranslate"><span class="pre">Model</span></code>, represented as a hierarchy of layers.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> class is the main interface to Akida and allows:</p>
<ul class="simple">
<li><p>to create an empty <code class="docutils literal notranslate"><span class="pre">Model</span></code> to which you can add layers programmatically
using the sequential API,</p></li>
<li><p>to reload a full <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a serialized file or a memory buffer,</p></li>
<li><p>to create a new <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a list of layers taken from an existing
<code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p></li>
</ul>
<p>It provides methods to instantiate, train, test and save models.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> input and output shapes have 4 dimensions, the first one being
the number of samples.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> accepts only uint8 tensors as inputs, whose values are
encoded using either 1, 2, 4 or 8-bit precision (i.e. whose max value is
1, 3, 15 or 255 respectively).</p>
<p>If the inputs are 8-bit, then the first layer of the <code class="docutils literal notranslate"><span class="pre">Model</span></code> must be a
convolutional layer with either 1 or 3 input channels.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> output is an int8 our uint8 numpy array if activations
are enabled for the last layer, otherwise it is an int32 numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em>, </em><em>optional</em>) – path to the serialized Model.
If None, an empty sequential model will be created, or filled
with the layers in the layers parameter.</p></li>
<li><p><strong>layers</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>, optional) – list of layers that will be copied
to the new model. If the list does not start with an input layer,
it will be added automatically.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.add" title="akida.Model.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(self, layer, inbound_layers)</p></td>
<td><p>Add a layer to the current model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.add_classes" title="akida.Model.add_classes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_classes</span></code></a>(self, num_add_classes)</p></td>
<td><p>Adds classes to the last layer of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.compile" title="akida.Model.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(self, optimizer)</p></td>
<td><p>Select and prepare the optimizer for learning of the last layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.evaluate" title="akida.Model.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(self, inputs, labels[, ...])</p></td>
<td><p>Returns the model class accuracy.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.fit" title="akida.Model.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.forward" title="akida.Model.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(self, inputs[, batch_size])</p></td>
<td><p>Forwards a set of inputs through the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.from_dict" title="akida.Model.from_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_dict</span></code></a>(model_dict)</p></td>
<td><p>Instantiate a Model from a dict representation</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.from_json" title="akida.Model.from_json"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_json</span></code></a>(model_str)</p></td>
<td><p>Instantiate a Model from a JSON representation</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.get_layer" title="akida.Model.get_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.get_layer_count" title="akida.Model.get_layer_count"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer_count</span></code></a>(self)</p></td>
<td><p>The number of layers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.map" title="akida.Model.map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">map</span></code></a>(self, device, hw_only)</p></td>
<td><p>Map the model to a Device using a target backend.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.pop_layer" title="akida.Model.pop_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop_layer</span></code></a>(self)</p></td>
<td><p>Remove the last layer of the current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.predict" title="akida.Model.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, inputs[, batch_size])</p></td>
<td><p>Predicts a set of inputs through the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.predict_classes" title="akida.Model.predict_classes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_classes</span></code></a>(inputs[, num_classes, ...])</p></td>
<td><p>Predicts the class labels for the specified inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.save" title="akida.Model.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(self, arg0)</p></td>
<td><p>Saves all the model configuration (all layers and weights) to a file on disk.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.summary" title="akida.Model.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>()</p></td>
<td><p>Prints a string summary of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.to_buffer" title="akida.Model.to_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_buffer</span></code></a>(self)</p></td>
<td><p>Serializes all the model configuration (all layers and weights) to a bytes buffer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.to_dict" title="akida.Model.to_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dict</span></code></a>()</p></td>
<td><p>Provide a dict representation of the Model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.to_json" title="akida.Model.to_json"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_json</span></code></a>()</p></td>
<td><p>Provide a JSON representation of the Model</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.input_shape" title="akida.Model.input_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_shape</span></code></a></p></td>
<td><p>The model input dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.ip_version" title="akida.Model.ip_version"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ip_version</span></code></a></p></td>
<td><p>The IP version this model is compatible with.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.layers" title="akida.Model.layers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layers</span></code></a></p></td>
<td><p>Get a list of layers in current model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.learning" title="akida.Model.learning"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learning</span></code></a></p></td>
<td><p>The learning parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.metrics" title="akida.Model.metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></a></p></td>
<td><p>The model metrics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.output_shape" title="akida.Model.output_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_shape</span></code></a></p></td>
<td><p>The model output dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.power_events" title="akida.Model.power_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_events</span></code></a></p></td>
<td><p>Copy of power events logged after inference</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.sequences" title="akida.Model.sequences"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sequences</span></code></a></p></td>
<td><p>The list of layer sequences in the Model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.statistics" title="akida.Model.statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">statistics</span></code></a></p></td>
<td><p>Get statistics by sequence for this model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.Model</span></em>, <em class="sig-param"><span class="pre">layer:</span> <span class="pre">akida::Layer</span></em>, <em class="sig-param"><span class="pre">inbound_layers:</span> <span class="pre">List[akida::Layer]</span> <span class="pre">=</span> <span class="pre">[]</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.add" title="Permalink to this definition"></a></dt>
<dd><p>Add a layer to the current model.</p>
<p>A list of inbound layers can optionally be specified.
These layers must already be included in the model.
if no inbound layer is specified, and the layer is not the first layer
in the model, the last included layer will be used as inbound layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer</strong> (<em>one of the available layers</em>) – layer instance to be added to the model</p></li>
<li><p><strong>inbound_layers</strong> (a list of <cite>Layer</cite>) – an optional list of inbound layers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add_classes">
<span class="sig-name descname"><span class="pre">add_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_add_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.add_classes" title="Permalink to this definition"></a></dt>
<dd><p>Adds classes to the last layer of the model.</p>
<p>A model with a compiled last layer is ready to learn using the Akida
built-in learning algorithm. This function allows to add new classes
(i.e. new neurons) to the last layer, keeping the previously learned
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_add_classes</strong> (<em>int</em>) – number of classes to add to the last layer</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if the last layer is not compiled</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.Model</span></em>, <em class="sig-param"><span class="pre">optimizer:</span> <span class="pre">akida::LearningParams</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.compile" title="Permalink to this definition"></a></dt>
<dd><p>Select and prepare the optimizer for learning of the last layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">akida.LearningParams</span></code>) – the optimizer used for learning</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.int32</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#akida.Model.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model class accuracy.</p>
<p>Forwards an input tensor through the model and compute accuracy
based on labels.
If the number of output neurons is greater than the number of classes,
the neurons are automatically assigned to a class by dividing their id
by the number of classes.</p>
<p>Note that the evaluation is based on the activation values of the last
layer: for most use cases, you may want to disable activations for that
layer (ie setting <code class="docutils literal notranslate"><span class="pre">activation=False</span></code>) to get a better
accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n) tensor of labels for the inputs</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – optional parameter (defaults to the
number of neurons in the last layer).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the accuracy of the model to predict the labels based on the
inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.fit" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: float, batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<em>float</em><em>, </em><em>optional</em>) – input label</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) int8 or uint8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: numpy.ndarray, batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, optional) – input labels.
Must have one label per input, or a single label for all inputs.
If a label exceeds the defined number of classes, the input will
be discarded. (Default value = None).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) int8 or int8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: list = [], batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<em>list</em><em>(</em><em>int</em><em>)</em><em>, </em><em>optional</em>) – input labels.
Must have one label per input, or a single label for all inputs.
If a label exceeds the defined number of classes, the input will
be discarded. (Default value = None).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) int8 or int8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.Model.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forwards a set of inputs through the model.</p>
<p>Forwards an input tensor through the model and returns an output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) uint8, int8 or
int32 tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the inputs doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.from_dict">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">from_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.from_dict" title="Permalink to this definition"></a></dt>
<dd><p>Instantiate a Model from a dict representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_dict</strong> (<em>dict</em>) – a Model dictionary.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.from_json">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">from_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.from_json" title="Permalink to this definition"></a></dt>
<dd><p>Instantiate a Model from a JSON representation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_str</strong> (<em>str</em>) – a JSON-formatted string corresponding to a Model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer">
<span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.get_layer" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic">
<li><p>get_layer(self: akida.core.Model, layer_name: str) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_name</dt>
<dd class="field-odd"><p>name of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_name</dt>
<dd class="field-even"><p>str</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>get_layer(self: akida.core.Model, layer_index: int) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_index</dt>
<dd class="field-odd"><p>index of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_index</dt>
<dd class="field-even"><p>int</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer_count">
<span class="sig-name descname"><span class="pre">get_layer_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#akida.Model.get_layer_count" title="Permalink to this definition"></a></dt>
<dd><p>The number of layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.input_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_shape</span></span><a class="headerlink" href="#akida.Model.input_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model input dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.ip_version">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ip_version</span></span><a class="headerlink" href="#akida.Model.ip_version" title="Permalink to this definition"></a></dt>
<dd><p>The IP version this model is compatible with.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.layers">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#akida.Model.layers" title="Permalink to this definition"></a></dt>
<dd><p>Get a list of layers in current model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.learning">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learning</span></span><a class="headerlink" href="#akida.Model.learning" title="Permalink to this definition"></a></dt>
<dd><p>The learning parameters set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.map">
<span class="sig-name descname"><span class="pre">map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.Model</span></em>, <em class="sig-param"><span class="pre">device:</span> <span class="pre">akida::Device</span></em>, <em class="sig-param"><span class="pre">hw_only:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.map" title="Permalink to this definition"></a></dt>
<dd><p>Map the model to a Device using a target backend.</p>
<p>This method tries to map a Model to the specified Device, implicitly
identifying one or more layer sequences that are mapped individually on
the Device Mesh.</p>
<p>An optional hw_only parameter can be specified to force the mapping
strategy to use only one hardware sequence, thus reducing software
intervention on the inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<cite>Device</cite>) – the target Device or None</p></li>
<li><p><strong>hw_only</strong> (<em>bool</em>) – when true, the model should be mapped in one sequence</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.metrics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#akida.Model.metrics" title="Permalink to this definition"></a></dt>
<dd><p>The model metrics.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.output_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_shape</span></span><a class="headerlink" href="#akida.Model.output_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model output dimensions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.pop_layer">
<span class="sig-name descname"><span class="pre">pop_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.pop_layer" title="Permalink to this definition"></a></dt>
<dd><p>Remove the last layer of the current model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.power_events">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_events</span></span><a class="headerlink" href="#akida.Model.power_events" title="Permalink to this definition"></a></dt>
<dd><p>Copy of power events logged after inference</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.Model.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predicts a set of inputs through the model.</p>
<p>Forwards an input tensor through the model and returns a float array.</p>
<p>It applies ONLY to models without an activation on the last layer.
The output values are obtained from the model discrete potentials by
applying a shift and a scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, w, h, c) float tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>RuntimeError</strong> – if the model last layer has an activation.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, or if the model only has an InputData layer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.predict_classes">
<span class="sig-name descname"><span class="pre">predict_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.predict_classes" title="Permalink to this definition"></a></dt>
<dd><p>Predicts the class labels for the specified inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of output classes</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array of class labels</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.save" title="Permalink to this definition"></a></dt>
<dd><p>Saves all the model configuration (all layers and weights) to a
file on disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_file</strong> (<em>str</em>) – full path of the serialized model (.fbz file).</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.sequences">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">sequences</span></span><a class="headerlink" href="#akida.Model.sequences" title="Permalink to this definition"></a></dt>
<dd><p>The list of layer sequences in the Model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.statistics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">statistics</span></span><a class="headerlink" href="#akida.Model.statistics" title="Permalink to this definition"></a></dt>
<dd><p>Get statistics by sequence for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary of <code class="xref py py-obj docutils literal notranslate"><span class="pre">SequenceStatistics</span></code> indexed by name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.summary" title="Permalink to this definition"></a></dt>
<dd><p>Prints a string summary of the model.</p>
<p>This method prints a summary of the model with details for every layer,
grouped by sequences:</p>
<ul class="simple">
<li><p>name and type in the first column</p></li>
<li><p>output shape</p></li>
<li><p>kernel shape</p></li>
</ul>
<p>If there is any layer with unsupervised learning enabled, it will list
them, with these details:</p>
<ul class="simple">
<li><p>name of layer</p></li>
<li><p>number of incoming connections</p></li>
<li><p>number of weights per neuron</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.to_buffer">
<span class="sig-name descname"><span class="pre">to_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bytes</span></span></span><a class="headerlink" href="#akida.Model.to_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Serializes all the model configuration (all layers and weights) to a
bytes buffer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.to_dict" title="Permalink to this definition"></a></dt>
<dd><p>Provide a dict representation of the Model</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a Model dictionary.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.to_json">
<span class="sig-name descname"><span class="pre">to_json</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.to_json" title="Permalink to this definition"></a></dt>
<dd><p>Provide a JSON representation of the Model</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a JSON-formatted string corresponding to a Model.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="layer">
<h2>Layer<a class="headerlink" href="#layer" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Layer<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Layer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Layer</span></span><a class="headerlink" href="#akida.Layer" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_learning_histogram" title="akida.Layer.get_learning_histogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_learning_histogram</span></code></a>()</p></td>
<td><p>Returns an histogram of learning percentages.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.get_variable" title="akida.Layer.get_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable</span></code></a>(name)</p></td>
<td><p>Get the value of a layer variable.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_variable_names" title="akida.Layer.get_variable_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable_names</span></code></a>()</p></td>
<td><p>Get the list of variable names for this layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.set_variable" title="akida.Layer.set_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_variable</span></code></a>(name, values)</p></td>
<td><p>Set the value of a layer variable.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.to_dict" title="akida.Layer.to_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dict</span></code></a>()</p></td>
<td><p>Provide a dict representation of the Layer</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.inbounds" title="akida.Layer.inbounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inbounds</span></code></a></p></td>
<td><p>The layer inbound layers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.input_bits" title="akida.Layer.input_bits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_bits</span></code></a></p></td>
<td><p>The layer input bits.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.input_dims" title="akida.Layer.input_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_dims</span></code></a></p></td>
<td><p>The layer input dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.mapping" title="akida.Layer.mapping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mapping</span></code></a></p></td>
<td><p>The layer hardware mapping.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.name" title="akida.Layer.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The layer name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.output_dims" title="akida.Layer.output_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_dims</span></code></a></p></td>
<td><p>The layer output dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.output_signed" title="akida.Layer.output_signed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_signed</span></code></a></p></td>
<td><p>Whether output is signed or not.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.parameters" title="akida.Layer.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a></p></td>
<td><p>The layer parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.variables" title="akida.Layer.variables"><code class="xref py py-obj docutils literal notranslate"><span class="pre">variables</span></code></a></p></td>
<td><p>The layer trainable variables.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_learning_histogram">
<span class="sig-name descname"><span class="pre">get_learning_histogram</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_learning_histogram" title="Permalink to this definition"></a></dt>
<dd><p>Returns an histogram of learning percentages.</p>
<p>Returns a list of learning percentages and the associated number of
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a (n,2) numpy.ndarray containing the learning
percentages and the number of neurons.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable">
<span class="sig-name descname"><span class="pre">get_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul class="simple">
<li><p>Weights variables are typically integer arrays of shape:
(x, y, features/channels, num_neurons) row-major (‘C’).</p></li>
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – the variable name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array containing the variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable_names">
<span class="sig-name descname"><span class="pre">get_variable_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable_names" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of variable names for this layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of variable names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.inbounds">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">inbounds</span></span><a class="headerlink" href="#akida.Layer.inbounds" title="Permalink to this definition"></a></dt>
<dd><p>The layer inbound layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_bits">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_bits</span></span><a class="headerlink" href="#akida.Layer.input_bits" title="Permalink to this definition"></a></dt>
<dd><p>The layer input bits.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_dims</span></span><a class="headerlink" href="#akida.Layer.input_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer input dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.mapping">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mapping</span></span><a class="headerlink" href="#akida.Layer.mapping" title="Permalink to this definition"></a></dt>
<dd><p>The layer hardware mapping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Layer.name" title="Permalink to this definition"></a></dt>
<dd><p>The layer name.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.output_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_dims</span></span><a class="headerlink" href="#akida.Layer.output_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer output dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.output_signed">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_signed</span></span><a class="headerlink" href="#akida.Layer.output_signed" title="Permalink to this definition"></a></dt>
<dd><p>Whether output is signed or not.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.parameters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">parameters</span></span><a class="headerlink" href="#akida.Layer.parameters" title="Permalink to this definition"></a></dt>
<dd><p>The layer parameters set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.set_variable">
<span class="sig-name descname"><span class="pre">set_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.set_variable" title="Permalink to this definition"></a></dt>
<dd><p>Set the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul>
<li><p>Weights variables are typically integer arrays of shape:</p>
<p>(num_neurons, features/channels, y, x) col-major ordered (‘F’)</p>
</li>
</ul>
<p>or equivalently:</p>
<blockquote>
<div><p>(x, y, features/channels, num_neurons) row-major (‘C’).</p>
</div></blockquote>
<ul class="simple">
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – the variable name.</p></li>
<li><p><strong>values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray containing the variable values.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.to_dict" title="Permalink to this definition"></a></dt>
<dd><p>Provide a dict representation of the Layer</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a Layer dictionary.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.variables">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">variables</span></span><a class="headerlink" href="#akida.Layer.variables" title="Permalink to this definition"></a></dt>
<dd><p>The layer trainable variables.</p>
</dd></dl>

</dd></dl>

</section>
<section id="mapping">
<h3>Mapping<a class="headerlink" href="#mapping" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Layer.Mapping">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.Layer.</span></span><span class="sig-name descname"><span class="pre">Mapping</span></span><a class="headerlink" href="#akida.Layer.Mapping" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.Mapping.nps" title="akida.Layer.Mapping.nps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nps</span></code></a></p></td>
<td><p>a list of <code class="docutils literal notranslate"><span class="pre">NP.Mapping</span></code> objects.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.Mapping.nps">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">nps</span></span><a class="headerlink" href="#akida.Layer.Mapping.nps" title="Permalink to this definition"></a></dt>
<dd><p>a list of <code class="docutils literal notranslate"><span class="pre">NP.Mapping</span></code> objects.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="akida-layers">
<h2>Akida layers<a class="headerlink" href="#akida-layers" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputData">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputData</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_signed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/input_data.html#InputData"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputData" title="Permalink to this definition"></a></dt>
<dd><p>This layer is used to specify the Model input dimensions and bitwidth.</p>
<p>It specifically targets Models accepting signed or low bitwidth inputs, or if
the channel number is neither 1 nor 3.
For images input, model must start instead with an image-specific input layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>input_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – input bitwidth. Defaults to 4.</p></li>
<li><p><strong>input_signed</strong> (<em>bool</em><em>, </em><em>optional</em>) – whether the input is signed or not.
Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="akida-v1-layers">
<h2>Akida V1 layers<a class="headerlink" href="#akida-v1-layers" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_shape</span></em>, <em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em>, <em class="sig-param"><span class="pre">padding_value=0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/input_convolutional.html#InputConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>This represents an image-specific input convolutional layer.</p>
<p>The initial convolutional layer in a network, which receives image inputs
in either RGB or grayscale format is converted into an InputConvolutional
Layer on Akida.
This layer optionally executes Pooling and ReLU operation to the outputs of
Convolution.</p>
<p>It is the only Akida V1 layer with 8-bit weights.
It applies a ‘convolution’ (actually a cross-correlation) optionally
followed by a pooling operation to the input images.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
representing the 8-bit images as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integers representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution. Defaults to
Padding.Same.</p></li>
<li><p><strong>kernel_stride</strong> (<em>tuple</em><em>, </em><em>optional</em>) – tuple of integer representing the
convolution stride (X, Y). Defaults to (1, 1).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.
Defaults to 1.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter). Defaults to (-1, -1).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(NoPooling, Max or Average). Defaults to PoolType.NoPooling.</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions. Defaults to (-1, -1)</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function. Defaults to True.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response. Defaults to 1.</p></li>
<li><p><strong>padding_value</strong> (<em>int</em><em>, </em><em>optional</em>) – value used when padding. Defaults to 0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.FullyConnected">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">FullyConnected</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/fully_connected.html#FullyConnected"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.FullyConnected" title="Permalink to this definition"></a></dt>
<dd><p>This represents a Dense or Linear neural layer.</p>
<p>A standard Dense Layer in a network is converted to FullyConnected Layer
on Akida.
This layer optionally executes ReLU operation to the outputs of the Dense
Layer.</p>
<p>The FullyConnected layer accepts 1-bit, 2-bit or 4-bit input tensors.
The FullyConnected can be configured with 1-bit, 2-bit or 4-bit weights.
It multiplies the inputs by its internal unit weights, returning a 4D
tensor of values whose first dimension is the number of samples and the
last dimension represents the number of units.
It can optionally apply a step-wise ReLU activation to its outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – number of units.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.
Defaults to 1.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function. Defaults to True.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize the neuron
response. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Convolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Convolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/convolutional.html#Convolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Convolutional" title="Permalink to this definition"></a></dt>
<dd><p>This represents a standard Convolutional layer.</p>
<p>A standard Convolution Layer in a network having an input with arbitrary
number of channels is converted to Convolutional Layer on Akida.
This layer optionally executes Pooling and ReLU operation to the outputs of
Convolution.</p>
<p>The Convolutional layer accepts 1-bit, 2-bit or 4-bit 3D input tensors with
an arbitrary number of channels.
The Convolutional layer can be configured with 1-bit, 2-bit or 4-bit weights.
It applies a convolution (not a cross-correlation) optionally followed by a
pooling operation to the input tensors.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integers representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution. Defaults to
Padding.Same.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing the
convolution stride (X, Y). Defaults to (1, 1).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.
Defaults to 1.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter). Defaults to (-1, -1).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(NoPooling, Max or Average). Defaults to Pooling.NoPooling.</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions. Defaults to (-1, -1).</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function. Defaults to True.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.SeparableConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">SeparableConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=2</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/separable_convolutional.html#SeparableConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.SeparableConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>This represents a separable convolution layer.</p>
<p>A standard Separable Convolution Layer in a network having an input with
arbitrary number of channels is converted to SeparableConvolutional Layer
on Akida.
This layer optionally executes Pooling and ReLU operation to the outputs of
Separable Convolution.</p>
<p>This layer accepts 1-bit, 2-bit or 4-bit 3D input tensors.
It can be configured with 1-bit, 2-bit or 4-bit weights.
Separable convolutions consist in first performing a depthwise spatial
convolution (which acts on each input channel separately) followed by a
pointwise convolution which mixes together the resulting output channels.
Note: this layer applies a real convolution, and not a cross-correlation.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integers representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of pointwise filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution. Defaults to
Padding.Same.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing the
convolution stride (X, Y). Defaults to (1, 1).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.
Defaults to 2.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter). Defaults to (-1, -1).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type (NoPooling, Max or
Average). Defaults to PoolType.NoPooling.</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions. Defaults to (-1, -1).</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function. Defaults to True.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="akida-v2-layers">
<h2>Akida V2 layers<a class="headerlink" href="#akida-v2-layers" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_shape</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=1</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_size=-1</span></em>, <em class="sig-param"><span class="pre">pool_stride=-1</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">output_bits=8</span></em>, <em class="sig-param"><span class="pre">buffer_bits=32</span></em>, <em class="sig-param"><span class="pre">post_op_buffer_bits=32</span></em>, <em class="sig-param"><span class="pre">name=''</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/input_conv2d.html#InputConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputConv2D" title="Permalink to this definition"></a></dt>
<dd><p>This represents the Akida V2 InputConv2D layer.</p>
<p>This layer is an image-specific input layer. It only accepts images in 8-bit pixels, either
grayscale or RGB.
Its kernel weights should be 8-bit.
It applies a convolution (actually a cross-correlation) optionally followed by a bias
addition, a pooling operation and a ReLU activation.
Inputs shape must be in the form (X, Y, C). Being the result of a quantized operation, it is
possible to apply some shifts to adjust the output scales to the equivalent operation performed
on floats, while maintaining a limited usage of bits and performing the operations on integer
values.
The order of the input spatial dimensions is preserved, but their values may change according
to the convolution and pooling parameters.</p>
<p>The InputConv2D operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Note that output values will be saturated on the range that can be represented with
output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – integer value specifying the height and width of the 2D convolution
window.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution rather Padding.Same or
Padding.Valid.
Defaults to Padding.Same.</p></li>
<li><p><strong>kernel_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – integer representing the convolution stride across both
spatial dimensions.
Defaults to 1.</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type (NoPooling, Max).
Defaults to PoolType.NoPooling.</p></li>
<li><p><strong>pool_size</strong> (<em>int</em><em>, </em><em>optional</em>) – integer value specifying the height and width of the window
over which to take the maximum or the average (depending on pool_type parameter).
Defaults to -1.</p></li>
<li><p><strong>pool_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – integer representing the stride across both dimensions.
Defaults to -1.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation function.
Defaults to True.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Stem">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Stem</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">192</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_non_patch_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/stem.html#Stem"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Stem" title="Permalink to this definition"></a></dt>
<dd><p>Stem layer corresponding to the Stem block of Transformer models.</p>
<p>It’s composed of the following layers:</p>
<blockquote>
<div><ul class="simple">
<li><p>The Embedding layer</p></li>
<li><p>The Reshape layer</p></li>
<li><p>The ClassToken (+ DistToken for distilled model) layer(s)</p></li>
<li><p>The AddPosEmbedding layer</p></li>
</ul>
</div></blockquote>
<p>This layer covers all the above layers operations.</p>
<p>Note that final output values will be saturated on the range that can
be represented with output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the spatially square 3D input shape.</p></li>
<li><p><strong>filters</strong> (<em>int</em><em>, </em><em>optional</em>) – Positive integer, dimensionality of the output space.
Defaults to 192.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em><em>, </em><em>optional</em>) – kernel size. Defaults to 16.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>num_non_patch_tokens</strong> (<em>int</em><em>, </em><em>optional</em>) – number of non patch tokens to concatenate
with the input along it last axis. Defaults to 0.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Conv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Conv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">kernel_stride=1</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_size=-1</span></em>, <em class="sig-param"><span class="pre">pool_stride=-1</span></em>, <em class="sig-param"><span class="pre">output_bits=8</span></em>, <em class="sig-param"><span class="pre">buffer_bits=28</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">post_op_buffer_bits=32</span></em>, <em class="sig-param"><span class="pre">name=''</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/conv2d.html#Conv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Conv2D" title="Permalink to this definition"></a></dt>
<dd><p>This represents the Akida V2 Conv2D layer.</p>
<p>It applies a convolution optionally followed by a bias addition, a
pooling operation and a ReLU activation.
Inputs shape must be in the form (X, Y, C). Being the result of a quantized
operation, it is possible to apply some shifts to adjust the inputs/outputs
scales to the equivalent operation performed on floats, while maintaining
a limited usage of bits and performing the operations on integer values.
The order of the input spatial dimensions is preserved, but their values may
change according to the convolution and pooling parameters.</p>
<p>The Conv2D operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">&lt;&lt;</span> <span class="n">input_shift</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span> <span class="p">(</span><span class="n">optional</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="p">(</span><span class="n">optional</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="p">(</span><span class="n">optional</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Note that output values will be saturated on the range that can be represented with
output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – integer value specifying the height and width of the 2D convolution
window.</p></li>
<li><p><strong>kernel_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – integer representing the convolution stride across both
spatial dimensions.
Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution rather Padding.Same or
Padding.Valid.
Defaults to Padding.Same.</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type (NoPooling, Max or Average).
Defaults to PoolType.NoPooling.</p></li>
<li><p><strong>pool_size</strong> (<em>int</em><em>, </em><em>optional</em>) – integer value specifying the height and width of the window
over which to take the maximum or the average (depending on pool_type parameter).
Defaults to -1.</p></li>
<li><p><strong>pool_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – integer representing the stride across both dimensions.
Defaults to -1.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 28.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation function.
Defaults to True.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Conv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Conv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/conv2d_transpose.html#Conv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Conv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>This represents the Akida V2 Conv2DTranspose layer.</p>
<p>It applies a transposed convolution (also called deconvolution) optionally followed by a bias
addition and a ReLU activation.
Inputs shape must be in the form (X, Y, C). Being the result of a quantized operation, it is
possible to apply some shifts to adjust the inputs/outputs scales to the equivalent operation
performed on floats, while maintaining a limited usage of bits and performing the operations on
integer values.
The order of the input spatial dimensions is preserved, but their values may change according
to the layer parameters.
Note that the layer performs only transpose convolution with a “Same” padding and a kernel
stride equal to 2.</p>
<p>The Conv2DTranspose operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">&lt;&lt;</span> <span class="n">input_shift</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">conv2d_transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Note that output values will be saturated on the range that can be represented with
output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>kernel_size</strong> (<em>int</em>) – integer value specifying the height and width of the 2D convolution
window.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation function.
Defaults to True.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 28.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Dense1D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Dense1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/dense1d.html#Dense1D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Dense1D" title="Permalink to this definition"></a></dt>
<dd><p>Dense layer capable of working on 1D inputs.</p>
<p>This is a simple dotproduct between an input of shape (1, 1, X) and a kernel
of shape (X, F) to output a tensor of shape (1, 1, F). Being the result of a
quantized operation, it is possible to apply some shifts to adjust the
inputs/outputs scales to the equivalent operation performed on floats, while
maintaining a limited usage of bits and performing the operations on integer
values.</p>
<p>The 1D Dense operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">&lt;&lt;</span> <span class="n">input_shift</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Inputs shape must be (1, 1, X), if not it’s reshaped automatically at the
beginning. Note that output values will be saturated on the range that can be
represented with output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – Positive integer, dimensionality of the output space.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 28.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – apply a ReLU activation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Dense2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Dense2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/dense2d.html#Dense2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Dense2D" title="Permalink to this definition"></a></dt>
<dd><p>Dense layer capable of working on 2D inputs.</p>
<p>The 2D Dense operation is simply the repetition of a 1D
FullyConnected/Dense operation over each input row.
Inputs shape mush be in the form (1, X, Y). Being the result of a quantized
operation, it is possible to apply some shifts to adjust the inputs/outputs
scales to the equivalent operation performed on floats, while maintaining
a limited usage of bits and performing the operations on integer values.</p>
<p>The 2D Dense operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">&lt;&lt;</span> <span class="n">input_shift</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Inputs shape must be (1, X, Y). Note that output values will be saturated
on the range that can be represented with output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – Positive integer, dimensionality of the output space.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – apply a ReLU activation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.DepthwiseConv2D">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">DepthwiseConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">kernel_stride=1</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_size=-1</span></em>, <em class="sig-param"><span class="pre">pool_stride=-1</span></em>, <em class="sig-param"><span class="pre">output_bits=8</span></em>, <em class="sig-param"><span class="pre">buffer_bits=28</span></em>, <em class="sig-param"><span class="pre">post_op_buffer_bits=32</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">name=''</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/depthwise_conv2d.html#DepthwiseConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.DepthwiseConv2D" title="Permalink to this definition"></a></dt>
<dd><p>This represents a depthwise convolutional layer.</p>
<p>This is like a standard convolution, except it acts on each input channel separately.
There is a single filter per input channel, so weights shape is (X, Y, F).
Being the result of a quantized operation, it is possible to apply some shifts to adjust the
inputs/outputs scales to the equivalent operation performed on floats, while maintaining a
limited usage of bits and performing the operations on integer values.</p>
<p>Note: this layer applies a real convolution, and not a cross-correlation. It can optionally
apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index as input.</p>
<p>It returns a 4D tensor whose first dimension is the sample index and the last dimension is the
number of convolution filters, so the same as input channels.
The order of the input spatial dimensions is preserved, but their value may change according to
the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Integer representing the spatial dimensions of the depthwise kernel.</p></li>
<li><p><strong>kernel_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – Integer representing the spatial convolution stride.
Defaults to 1.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution. Defaults to Padding.Same.</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type (NoPooling, or Max). Defaults to
PoolType.NoPooling.</p></li>
<li><p><strong>pool_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Integer representing the window size over which to take the
maximum. Defaults to -1.</p></li>
<li><p><strong>pool_stride</strong> (<em>int</em><em>, </em><em>optional</em>) – Integer representing the pooling stride dimensions. A value of
-1 means same as pool_size. Defaults to -1.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 28.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable ReLU activation function. Defaults to True.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.DepthwiseConv2DTranspose">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">DepthwiseConv2DTranspose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/depthwise_conv2d_transpose.html#DepthwiseConv2DTranspose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.DepthwiseConv2DTranspose" title="Permalink to this definition"></a></dt>
<dd><p>This represents the Akida V2 DepthwiseConv2DTranspose layer.</p>
<p>It applies a transposed depthwise convolution (also called deconvolution) optionally followed
by a bias addition and a ReLU activation.
This is like a standard transposed convolution, except it acts on each input channel
separately.
Inputs shape must be in the form (X, Y, C). Being the result of a quantized operation, it is
possible to apply some shifts to adjust the inputs/outputs scales to the equivalent operation
performed on floats, while maintaining a limited usage of bits and performing the operations on
integer values.
The order of the input spatial dimensions is preserved, but their values may change according
to the layer parameters.
Note that the layer performs only transpose depthwise convolution with a “Same” padding and a
kernel stride equal to 2.</p>
<p>The DepthwiseConv2DTranspose operation can be described as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">&lt;&lt;</span> <span class="n">input_shift</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prod</span> <span class="o">=</span> <span class="n">depthwise_conv2d_transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">prod</span> <span class="o">+</span> <span class="p">(</span><span class="n">bias</span> <span class="o">&lt;&lt;</span> <span class="n">bias_shift</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1">#optional</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">*</span> <span class="n">output_scale</span> <span class="o">&gt;&gt;</span> <span class="n">output_shift</span>
</pre></div>
</div>
<p>Note that output values will be saturated on the range that can be represented with
output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>int</em>) – Integer representing the spatial dimensions of the depthwise kernel.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation function.
Defaults to True.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 28.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Attention">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_heads</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shiftmax_output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/attention.html#Attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Attention" title="Permalink to this definition"></a></dt>
<dd><p>Multi-head attention layer.</p>
<p>From A. Vaswani et al., “Attention is All You Need” (arXiv:1706.03762):
“Self-attention, sometimes called intra-attention is an attention mechanism
relating different positions of a single sequence in order to compute a
representation of the sequence.”</p>
<p>This layer will take three inputs, Query, Key and Value, and perform these
actions on each head:</p>
<ul class="simple">
<li><p>Multiply Query and Key to obtain a vector of attention scores expressing
how tokens/patches relate to one another.</p></li>
<li><p>Divide by a scale factor.</p></li>
<li><p>Convert the score to a probability mask using a Softmax function
(replaced by a Shiftmax in our implementation).</p></li>
<li><p>Multiply the mask by the Values.</p></li>
</ul>
<p>Note that outputs and masks will be saturated on the range that can be
represented with output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> (<em>int</em>) – number of heads.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth. Defaults to 32</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>shiftmax_output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth for shiftmax,
must be no more than 1/2 of buffer_bits. Defaults to 10</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.VitEncoderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">VitEncoderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">192</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">768</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokens_to_extract</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/vit_encoder_block.html#VitEncoderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.VitEncoderBlock" title="Permalink to this definition"></a></dt>
<dd><p>Layer corresponding to a ViT encoder block.</p>
<blockquote>
<div><p>It’s composed of the following layers:</p>
<blockquote>
<div><ul class="simple">
<li><p>a pre-attention MadNorm layer</p></li>
<li><p>Query, Key and Value Dense layers</p></li>
<li><p>an Attention layer and it Dense projection layer</p></li>
<li><p>a skip connection (Add) between the input and the output of attention projection</p></li>
<li><p>a pre-ML MadNorm layer</p></li>
<li><p>a MLP composed of two Dense layers</p></li>
<li><p>a skip connection (Add) between the MLP output and the previous Add layer</p></li>
<li><p>optionally when tokens_to_extract is set to a non zero value, a BatchNormalization
layer and the given ExtractToken number (1 or 2)</p></li>
<li><p>optionally when num_classes is set a classification head with one or 2 Dense layers
depending on the number of tokens</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<p>This layer covers all the above layers operations.</p>
<p>Note that final output values will be saturated on the range that can be represented with
output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em><em>, </em><em>optional</em>) – internal shape of the block. Defaults to 192.</p></li>
<li><p><strong>mlp_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – dimension of the first dense layer of the MLP. Defaults to 768.</p></li>
<li><p><strong>num_heads</strong> (<em>int</em><em>, </em><em>optional</em>) – number of heads in the multi-head attention. Defaults to 3.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of classes to set in the classification head, if zero
no classification head is added. ‘tokens_to_extract’ must be different from 0. Defaults
to 0.</p></li>
<li><p><strong>tokens_to_extract</strong> (<em>int</em><em>, </em><em>optional</em>) – number of non patch tokens to extract. Defaults to 0.</p></li>
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>head_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – similar to ‘output_bits’ but for the optional head(s). Defaults
to 28.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Add">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/add.html#Add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Add" title="Permalink to this definition"></a></dt>
<dd><p>Layer that adds two inputs from incoming layers.</p>
<p>It takes as input the output tensors from the input layers, all of the same
shape, and returns a single tensor (also of the same shape).
Add layers require Incoming input layers to produce output tensors of the
same type.
The Add layer will create three variables, <cite>a_shift</cite>, <cite>b_shift</cite> and
<cite>output_shift</cite>.
The operation it will perform on each couple of integer values on input
tensors (a, b) is equivalent to:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span> <span class="n">a1</span> <span class="o">=</span> <span class="n">a</span> <span class="o">&lt;&lt;</span> <span class="n">a_shift</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">b1</span> <span class="o">=</span> <span class="n">b</span> <span class="o">&lt;&lt;</span> <span class="n">b_shift</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">intermediate_output</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">+</span> <span class="n">b1</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">shift</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_shift</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>     <span class="k">if</span> <span class="n">shift</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">intermediate_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="o">|</span><span class="n">shift</span><span class="o">|</span>
<span class="gp">&gt;&gt;&gt; </span>     <span class="k">else</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">intermediate_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="o">|</span><span class="n">shift</span><span class="o">|</span>
</pre></div>
</div>
<p>Note that output values will be saturated on the range that can be
represented with output_bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – apply a ReLU activation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Concatenate">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Concatenate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/concatenate.html#Concatenate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Concatenate" title="Permalink to this definition"></a></dt>
<dd><p>Layer that concatenates two or more inputs from incoming layers, along
the last dimensions.</p>
<p>The operation is equivalent to this numpy operation</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span> <span class="c1"># Inputs are a and b</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>All inbound layers should have the same output dimensions on the first two
axis. All inbound layers should have the same output bitwidth and output
sign.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.ExtractToken">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">ExtractToken</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">begin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/extract_token.html#ExtractToken"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.ExtractToken" title="Permalink to this definition"></a></dt>
<dd><p>A layer capable of extracting a range from input tensor.</p>
<p>This is similar to numpy.take_along_axis, where the indices are in the
range [begin:end]. Note that reduction axis will be the first axis that
is not 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>begin</strong> (<em>int</em><em>, </em><em>optional</em>) – beginning of the range to take into account.
Defaults to 0.</p></li>
<li><p><strong>end</strong> (<em>int</em><em>, </em><em>optional</em>) – end of the range to take into account.
Defaults to None.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.BatchNormalization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">BatchNormalization</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/batch_normalization.html#BatchNormalization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.BatchNormalization" title="Permalink to this definition"></a></dt>
<dd><p>Batch Normalization applied on the last axis.</p>
<p>The normalization is applied as:</p>
<p>outputs = a * x + b</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – add a ReLU activation. Defaults to False.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.MadNorm">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">MadNorm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/madnorm.html#MadNorm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.MadNorm" title="Permalink to this definition"></a></dt>
<dd><p>A function similar to the MAD normalization layer presented
in quantizeml. (Note that the normalization is only available over
the last dimension)</p>
<p>Instead of using the standard deviation (std) during the normalization
division, the sum of absolute values is used.
The normalization is performed in this way:</p>
<blockquote>
<div><p>MadNorm(x) = x * gamma / sum(abs(x)) + beta</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – buffer bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Shiftmax">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Shiftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_op_buffer_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/shiftmax.html#Shiftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Shiftmax" title="Permalink to this definition"></a></dt>
<dd><p>A function similar to the softmax.</p>
<p>Instead of using e as base, it uses 2 and a shift. So we replace</p>
<div class="math notranslate nohighlight">
\[softmax(x_i) = \frac{e^{x_i}}{sum(e^{x_k})}\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[shiftmax(x_i) = \frac{2^{x_i}}{round(log2(sum(2^{x_k})))}\]</div>
<p>This is evaluated with a shift.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – output bitwidth. Defaults to 8.</p></li>
<li><p><strong>buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth. Defaults to 32.</p></li>
<li><p><strong>post_op_buffer_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – internal bitwidth for post operations. Defaults to 32.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.Dequantizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Dequantizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/layers/dequantizer.html#Dequantizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Dequantizer" title="Permalink to this definition"></a></dt>
<dd><p>Layer capable of dequantizing an input tensor.</p>
<p>This resolve the scales of an input tensor, following the equantion:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="nb">input</span> <span class="n">x</span> <span class="n">scales</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer. Defaults to empty string.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="layer-parameters">
<h2>Layer parameters<a class="headerlink" href="#layer-parameters" title="Permalink to this headline"></a></h2>
<section id="layertype">
<h3>LayerType<a class="headerlink" href="#layertype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.LayerType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">LayerType</span></span><a class="headerlink" href="#akida.LayerType" title="Permalink to this definition"></a></dt>
<dd><p>The layer type</p>
<p>Members:</p>
<blockquote>
<div><p>Unknown</p>
<p>InputData</p>
<p>InputConvolutional</p>
<p>FullyConnected</p>
<p>Convolutional</p>
<p>SeparableConvolutional</p>
<p>Add</p>
<p>Dense2D</p>
<p>Shiftmax</p>
<p>Attention</p>
<p>Stem</p>
<p>MadNorm</p>
<p>Concatenate</p>
<p>BatchNormalization</p>
<p>Conv2D</p>
<p>InputConv2D</p>
<p>DepthwiseConv2D</p>
<p>Conv2DTranspose</p>
<p>ExtractToken</p>
<p>Dequantizer</p>
<p>DepthwiseConv2DTranspose</p>
<p>BufferTempConv</p>
<p>DepthwiseBufferTempConv</p>
<p>StatefulRecurrent</p>
<p>VitEncoderBlock</p>
</div></blockquote>
</dd></dl>

</section>
<section id="padding">
<h3>Padding<a class="headerlink" href="#padding" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Padding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Padding</span></span><a class="headerlink" href="#akida.Padding" title="Permalink to this definition"></a></dt>
<dd><p>Sets the effective padding of the input for convolution, thereby determining the output dimensions. Naming conventions are the same as Keras/Tensorflow.</p>
<p>Members:</p>
<blockquote>
<div><p>Valid : No padding</p>
<p>Same : Padded so that output size is input size divided by the stride</p>
</div></blockquote>
</dd></dl>

</section>
<section id="pooltype">
<h3>PoolType<a class="headerlink" href="#pooltype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PoolType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PoolType</span></span><a class="headerlink" href="#akida.PoolType" title="Permalink to this definition"></a></dt>
<dd><p>The pooling type</p>
<p>Members:</p>
<blockquote>
<div><p>NoPooling : No pooling applied</p>
<p>Max : Maximum pixel value is selected</p>
<p>Average : Average pixel value is selected</p>
</div></blockquote>
</dd></dl>

</section>
</section>
<section id="optimizers">
<h2>Optimizers<a class="headerlink" href="#optimizers" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.Optimizer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.</span></span><span class="sig-name descname"><span class="pre">Optimizer</span></span><a class="headerlink" href="#akida.core.Optimizer" title="Permalink to this definition"></a></dt>
<dd><p>Optimizer generic parameters</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.Optimizer.get" title="akida.core.Optimizer.get"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get</span></code></a>(self, key)</p></td>
<td><p>Retrieve a value from the LearningParams object.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.core.Optimizer.get">
<span class="sig-name descname"><span class="pre">get</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.core.Optimizer" title="akida.core.Optimizer"><span class="pre">akida.core.Optimizer</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#akida.core.Optimizer.get" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve a value from the LearningParams object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> (<em>str</em>) – key of the value.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>value associated to the key.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – if the value is not present in the LearningParams object.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.AkidaUnsupervised">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">AkidaUnsupervised</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_weights</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_competition</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.10000000149011612</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plasticity_decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#akida.core.Optimizer" title="akida.core.Optimizer"><span class="pre">akida.core.Optimizer</span></a></span></span><a class="headerlink" href="#akida.AkidaUnsupervised" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the Akida Unsupervised optimizer for learning of the last layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_weights</strong> (<em>int</em>) – number of connections for each neuron.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of classes when running in a
‘labeled mode’.</p></li>
<li><p><strong>initial_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines how easily the weights
will change when learning occurs.</p></li>
<li><p><strong>learning_competition</strong> (<em>float</em><em>, </em><em>optional</em>) – controls competition between
neurons.</p></li>
<li><p><strong>min_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the minimum level to which
plasticity will decay.</p></li>
<li><p><strong>plasticity_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the decay of plasticity
with each learning step.</p></li>
<li><p><strong>optimizer</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">akida.LearningParams</span></code>) – the optimizer used for
learning</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="sequence">
<h2>Sequence<a class="headerlink" href="#sequence" title="Permalink to this headline"></a></h2>
<section id="id2">
<h3>Sequence<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Sequence">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Sequence</span></span><a class="headerlink" href="#akida.Sequence" title="Permalink to this definition"></a></dt>
<dd><p>Represents a sequence of layers.</p>
<p>Sequences can be mapped in Software or on a Device.</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.backend" title="akida.Sequence.backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backend</span></code></a></p></td>
<td><p>The backend type for this Sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.name" title="akida.Sequence.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The name of the sequence</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.passes" title="akida.Sequence.passes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">passes</span></code></a></p></td>
<td><p>Get the list of passes in this sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.program" title="akida.Sequence.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Get the hardware program for this sequence.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.program_parts" title="akida.Sequence.program_parts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program_parts</span></code></a></p></td>
<td><p>Get the program, splitted in different parts</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.backend">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">backend</span></span><a class="headerlink" href="#akida.Sequence.backend" title="Permalink to this definition"></a></dt>
<dd><p>The backend type for this Sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Sequence.name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the sequence</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.passes">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">passes</span></span><a class="headerlink" href="#akida.Sequence.passes" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of passes in this sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.Sequence.program" title="Permalink to this definition"></a></dt>
<dd><p>Get the hardware program for this sequence.</p>
<p>Returns None if the Sequence is not compatible with the selected
Device.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a bytes buffer or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.program_parts">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program_parts</span></span><a class="headerlink" href="#akida.Sequence.program_parts" title="Permalink to this definition"></a></dt>
<dd><p>Get the program, splitted in different parts</p>
</dd></dl>

</dd></dl>

</section>
<section id="backendtype">
<h3>BackendType<a class="headerlink" href="#backendtype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.BackendType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">BackendType</span></span><a class="headerlink" href="#akida.BackendType" title="Permalink to this definition"></a></dt>
<dd><p>Members:</p>
<p>Software</p>
<p>Hardware</p>
<p>Hybrid</p>
</dd></dl>

</section>
<section id="pass">
<h3>Pass<a class="headerlink" href="#pass" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Pass">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Pass</span></span><a class="headerlink" href="#akida.Pass" title="Permalink to this definition"></a></dt>
<dd><p>Represents a subset of the Sequence.</p>
<p>Hardware Sequences can typically be split into multiple passes on devices
that support hardware partial reconfiguration feature, reducing the
intervention of the software during inference.</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Pass.layers" title="akida.Pass.layers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layers</span></code></a></p></td>
<td><p>Get the list of layers in this pass.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Pass.layers">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#akida.Pass.layers" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of layers in this pass.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="device">
<h2>Device<a class="headerlink" href="#device" title="Permalink to this headline"></a></h2>
<section id="id3">
<h3>Device<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Device">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Device</span></span><a class="headerlink" href="#akida.Device" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.desc" title="akida.Device.desc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">desc</span></code></a></p></td>
<td><p>Returns the Device description</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Device.mesh" title="akida.Device.mesh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mesh</span></code></a></p></td>
<td><p>The device Mesh layout</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.version" title="akida.Device.version"><code class="xref py py-obj docutils literal notranslate"><span class="pre">version</span></code></a></p></td>
<td><p>The device hardware version.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.desc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">desc</span></span><a class="headerlink" href="#akida.Device.desc" title="Permalink to this definition"></a></dt>
<dd><p>Returns the Device description</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a string describing the Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.mesh">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mesh</span></span><a class="headerlink" href="#akida.Device.mesh" title="Permalink to this definition"></a></dt>
<dd><p>The device Mesh layout</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.version">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">version</span></span><a class="headerlink" href="#akida.Device.version" title="Permalink to this definition"></a></dt>
<dd><p>The device hardware version.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.devices">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">devices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.devices" title="Permalink to this definition"></a></dt>
<dd><p>Returns the full list of available hardware devices</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.AKD1000">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">AKD1000</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#AKD1000"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.AKD1000" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for an AKD1000 NSoC.</p>
<p>This function returns a virtual device for the Brainchip’s AKD1000
NSoC.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a virtual device.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.TwoNodesIP">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">TwoNodesIP</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#TwoNodesIP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.TwoNodesIP" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for a two nodes Akida IP.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a virtual device.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="hwversion">
<h3>HwVersion<a class="headerlink" href="#hwversion" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HwVersion">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HwVersion</span></span><a class="headerlink" href="#akida.HwVersion" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.major_rev" title="akida.HwVersion.major_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">major_rev</span></code></a></p></td>
<td><p>The hardware major revision</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.minor_rev" title="akida.HwVersion.minor_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minor_rev</span></code></a></p></td>
<td><p>The hardware minor revision</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.product_id" title="akida.HwVersion.product_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">product_id</span></code></a></p></td>
<td><p>The hardware product identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.vendor_id" title="akida.HwVersion.vendor_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vendor_id</span></code></a></p></td>
<td><p>The hardware vendor identifier</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.major_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">major_rev</span></span><a class="headerlink" href="#akida.HwVersion.major_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware major revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.minor_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">minor_rev</span></span><a class="headerlink" href="#akida.HwVersion.minor_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware minor revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.product_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">product_id</span></span><a class="headerlink" href="#akida.HwVersion.product_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware product identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.vendor_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">vendor_id</span></span><a class="headerlink" href="#akida.HwVersion.vendor_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware vendor identifier</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="hwdevice">
<h2>HWDevice<a class="headerlink" href="#hwdevice" title="Permalink to this headline"></a></h2>
<section id="id4">
<h3>HWDevice<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HardwareDevice">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HardwareDevice</span></span><a class="headerlink" href="#akida.HardwareDevice" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.fit" title="akida.HardwareDevice.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.forward" title="akida.HardwareDevice.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.predict" title="akida.HardwareDevice.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device, returns a float array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.program_external" title="akida.HardwareDevice.program_external"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program_external</span></code></a>(self, arg0, arg1)</p></td>
<td><p>Program a device using a serialized program info bytes object, and the address, as it is seen from akida on the device, of corresponding program data that must have been written beforehand.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.reset_top_memory" title="akida.HardwareDevice.reset_top_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_top_memory</span></code></a>(self)</p></td>
<td><p>Reset the device memory informations</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.unprogram" title="akida.HardwareDevice.unprogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unprogram</span></code></a>(self)</p></td>
<td><p>Clear current program from hardware device, restoring its initial state</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.inference_power_events" title="akida.HardwareDevice.inference_power_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_power_events</span></code></a></p></td>
<td><p>Copy of power events logged after inference</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.learn_enabled" title="akida.HardwareDevice.learn_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learn_enabled</span></code></a></p></td>
<td><p>Property that enables/disables learning on current program (if possible).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.learn_mem" title="akida.HardwareDevice.learn_mem"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learn_mem</span></code></a></p></td>
<td><p>Property that retrieves learning layer's memory or updates a device using a serialized learning layer memory buffer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.memory" title="akida.HardwareDevice.memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memory</span></code></a></p></td>
<td><p>The device memory usage and top usage (in bytes)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.metrics" title="akida.HardwareDevice.metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></a></p></td>
<td><p>The metrics from this device</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.program" title="akida.HardwareDevice.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Property that retrieves current program or programs a device using a serialized program bytes object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.soc" title="akida.HardwareDevice.soc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">soc</span></code></a></p></td>
<td><p>The SocDriver interface used by the device, or None if the device is not a SoC</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.HardwareDevice.fit" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: float) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
<ol class="arabic simple" start="2">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: numpy.ndarray) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
<ol class="arabic simple" start="3">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: list = []) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.forward" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with outputs from the device</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.inference_power_events">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">inference_power_events</span></span><a class="headerlink" href="#akida.HardwareDevice.inference_power_events" title="Permalink to this definition"></a></dt>
<dd><p>Copy of power events logged after inference</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.learn_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learn_enabled</span></span><a class="headerlink" href="#akida.HardwareDevice.learn_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Property that enables/disables learning on current program (if
possible).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.learn_mem">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learn_mem</span></span><a class="headerlink" href="#akida.HardwareDevice.learn_mem" title="Permalink to this definition"></a></dt>
<dd><p>Property that retrieves learning layer’s memory or updates a device
using a serialized learning layer memory buffer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.memory">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">memory</span></span><a class="headerlink" href="#akida.HardwareDevice.memory" title="Permalink to this definition"></a></dt>
<dd><p>The device memory usage and top usage (in bytes)</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.metrics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#akida.HardwareDevice.metrics" title="Permalink to this definition"></a></dt>
<dd><p>The metrics from this device</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.predict" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device, returns a float array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with float outputs from the device</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.HardwareDevice.program" title="Permalink to this definition"></a></dt>
<dd><p>Property that retrieves current program or programs a device using a
serialized program bytes object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.program_external">
<span class="sig-name descname"><span class="pre">program_external</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bytes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.program_external" title="Permalink to this definition"></a></dt>
<dd><p>Program a device using a serialized program info bytes object,
and the address, as it is seen from akida on the device,
of corresponding program data that must have been written beforehand.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.reset_top_memory">
<span class="sig-name descname"><span class="pre">reset_top_memory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.reset_top_memory" title="Permalink to this definition"></a></dt>
<dd><p>Reset the device memory informations</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.soc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">soc</span></span><a class="headerlink" href="#akida.HardwareDevice.soc" title="Permalink to this definition"></a></dt>
<dd><p>The SocDriver interface used by the device, or None if the device
is not a SoC</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.unprogram">
<span class="sig-name descname"><span class="pre">unprogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.unprogram" title="Permalink to this definition"></a></dt>
<dd><p>Clear current program from hardware device, restoring its initial
state</p>
</dd></dl>

</dd></dl>

</section>
<section id="socdriver">
<h3>SocDriver<a class="headerlink" href="#socdriver" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.SocDriver">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.</span></span><span class="sig-name descname"><span class="pre">SocDriver</span></span><a class="headerlink" href="#akida.core.SocDriver" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.SocDriver.clock_mode" title="akida.core.SocDriver.clock_mode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clock_mode</span></code></a></p></td>
<td><p>Clock mode of the NSoC.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_measurement_enabled" title="akida.core.SocDriver.power_measurement_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_measurement_enabled</span></code></a></p></td>
<td><p>Power measurement is off by default.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_meter" title="akida.core.SocDriver.power_meter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_meter</span></code></a></p></td>
<td><p>Power meter associated to the SoC.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.clock_mode">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">clock_mode</span></span><a class="headerlink" href="#akida.core.SocDriver.clock_mode" title="Permalink to this definition"></a></dt>
<dd><p>Clock mode of the NSoC.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_measurement_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_measurement_enabled</span></span><a class="headerlink" href="#akida.core.SocDriver.power_measurement_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Power measurement is off by default. Toggle it on to get power information in the statistics or when calling PowerMeter.events().</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_meter">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_meter</span></span><a class="headerlink" href="#akida.core.SocDriver.power_meter" title="Permalink to this definition"></a></dt>
<dd><p>Power meter associated to the SoC.</p>
</dd></dl>

</dd></dl>

</section>
<section id="clockmode">
<h3>ClockMode<a class="headerlink" href="#clockmode" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.soc.ClockMode">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.soc.</span></span><span class="sig-name descname"><span class="pre">ClockMode</span></span><a class="headerlink" href="#akida.core.soc.ClockMode" title="Permalink to this definition"></a></dt>
<dd><p>Clock mode configuration</p>
<p>Members:</p>
<blockquote>
<div><p>Performance</p>
<p>Economy</p>
<p>LowPower</p>
</div></blockquote>
</dd></dl>

</section>
</section>
<section id="powermeter">
<h2>PowerMeter<a class="headerlink" href="#powermeter" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerMeter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerMeter</span></span><a class="headerlink" href="#akida.PowerMeter" title="Permalink to this definition"></a></dt>
<dd><p>Gives access to power measurements.</p>
<p>When power measurements are enabled for a specific device, this object
stores them as a list of <code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code> objects.
The events list cannot exceed a predefined size: when it is full, older
events are replaced by newer events.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerMeter.events" title="akida.PowerMeter.events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events</span></code></a>(self)</p></td>
<td><p>Retrieve all pending events</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerMeter.floor" title="akida.PowerMeter.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code></a></p></td>
<td><p>Get the floor power</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.PowerMeter.events">
<span class="sig-name descname"><span class="pre">events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.PowerMeter" title="akida.core.PowerMeter"><span class="pre">akida.core.PowerMeter</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.PowerEvent" title="akida.core.PowerEvent"><span class="pre">akida.core.PowerEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.PowerMeter.events" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve all pending events</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerMeter.floor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">floor</span></span><a class="headerlink" href="#akida.PowerMeter.floor" title="Permalink to this definition"></a></dt>
<dd><p>Get the floor power</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerEvent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerEvent</span></span><a class="headerlink" href="#akida.PowerEvent" title="Permalink to this definition"></a></dt>
<dd><p>A timestamped power measurement.</p>
<p>Each PowerEvent contains:
- a voltage value in µV (microvolt),
- a current value in mA (milliampere),
- the corresponding power value in mW (milliwatt).</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.current" title="akida.PowerEvent.current"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current</span></code></a></p></td>
<td><p>Current value in mA</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerEvent.power" title="akida.PowerEvent.power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power</span></code></a></p></td>
<td><p>Power value in mW</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.ts" title="akida.PowerEvent.ts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ts</span></code></a></p></td>
<td><p>Timestamp of the event</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerEvent.voltage" title="akida.PowerEvent.voltage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">voltage</span></code></a></p></td>
<td><p>Voltage value in µV</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.current">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">current</span></span><a class="headerlink" href="#akida.PowerEvent.current" title="Permalink to this definition"></a></dt>
<dd><p>Current value in mA</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.power">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power</span></span><a class="headerlink" href="#akida.PowerEvent.power" title="Permalink to this definition"></a></dt>
<dd><p>Power value in mW</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.ts">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ts</span></span><a class="headerlink" href="#akida.PowerEvent.ts" title="Permalink to this definition"></a></dt>
<dd><p>Timestamp of the event</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.voltage">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">voltage</span></span><a class="headerlink" href="#akida.PowerEvent.voltage" title="Permalink to this definition"></a></dt>
<dd><p>Voltage value in µV</p>
</dd></dl>

</dd></dl>

</section>
<section id="np">
<h2>NP<a class="headerlink" href="#np" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Mesh">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Mesh</span></span><a class="headerlink" href="#akida.NP.Mesh" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_conf" title="akida.NP.Mesh.dma_conf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_conf</span></code></a></p></td>
<td><p>DMA configuration endpoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_event" title="akida.NP.Mesh.dma_event"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_event</span></code></a></p></td>
<td><p>DMA event endpoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.nps" title="akida.NP.Mesh.nps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nps</span></code></a></p></td>
<td><p>Neural processors</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_conf">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_conf</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_conf" title="Permalink to this definition"></a></dt>
<dd><p>DMA configuration endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_event">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_event</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_event" title="Permalink to this definition"></a></dt>
<dd><p>DMA event endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.nps">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">nps</span></span><a class="headerlink" href="#akida.NP.Mesh.nps" title="Permalink to this definition"></a></dt>
<dd><p>Neural processors</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Info">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Info</span></span><a class="headerlink" href="#akida.NP.Info" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Info.ident" title="akida.NP.Info.ident"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ident</span></code></a></p></td>
<td><p>NP identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Info.types" title="akida.NP.Info.types"><code class="xref py py-obj docutils literal notranslate"><span class="pre">types</span></code></a></p></td>
<td><p>NP supported types</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.ident">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ident</span></span><a class="headerlink" href="#akida.NP.Info.ident" title="Permalink to this definition"></a></dt>
<dd><p>NP identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.types">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">types</span></span><a class="headerlink" href="#akida.NP.Info.types" title="Permalink to this definition"></a></dt>
<dd><p>NP supported types</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Ident">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Ident</span></span><a class="headerlink" href="#akida.NP.Ident" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.col" title="akida.NP.Ident.col"><code class="xref py py-obj docutils literal notranslate"><span class="pre">col</span></code></a></p></td>
<td><p>NP column number</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Ident.id" title="akida.NP.Ident.id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">id</span></code></a></p></td>
<td><p>NP id</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.row" title="akida.NP.Ident.row"><code class="xref py py-obj docutils literal notranslate"><span class="pre">row</span></code></a></p></td>
<td><p>NP row number</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.col">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">col</span></span><a class="headerlink" href="#akida.NP.Ident.col" title="Permalink to this definition"></a></dt>
<dd><p>NP column number</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#akida.NP.Ident.id" title="Permalink to this definition"></a></dt>
<dd><p>NP id</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.row">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">row</span></span><a class="headerlink" href="#akida.NP.Ident.row" title="Permalink to this definition"></a></dt>
<dd><p>NP row number</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Type">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Type</span></span><a class="headerlink" href="#akida.NP.Type" title="Permalink to this definition"></a></dt>
<dd><p>Members:</p>
<p>HRC : High Resolution Convolution</p>
<p>CNP1 : Convolutional Neural Processor Type 1</p>
<p>CNP2 : Convolutional Neural Processor Type 2</p>
<p>FNP2 : FullyConnected Neural Processor (external memory)</p>
<p>FNP3 : FullyConnected Neural Processor (internal memory)</p>
<p>VIT_NODE : FullyConnected Neural Processor (internal memory)</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Mapping">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Mapping</span></span><a class="headerlink" href="#akida.NP.Mapping" title="Permalink to this definition"></a></dt>
<dd><p>The mapping of a subset of a Layer on a Neural Processor”</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mapping.filters" title="akida.NP.Mapping.filters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filters</span></code></a></p></td>
<td><p>Number of filters processed by the Neural Processor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mapping.ident" title="akida.NP.Mapping.ident"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ident</span></code></a></p></td>
<td><p>Neural Processor identifier</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mapping.single_buffer" title="akida.NP.Mapping.single_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">single_buffer</span></code></a></p></td>
<td><p>Neural Processor uses a single or dual input buffer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mapping.type" title="akida.NP.Mapping.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a></p></td>
<td><p>Neural Processor type</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.filters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">filters</span></span><a class="headerlink" href="#akida.NP.Mapping.filters" title="Permalink to this definition"></a></dt>
<dd><p>Number of filters processed by the Neural Processor</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.ident">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ident</span></span><a class="headerlink" href="#akida.NP.Mapping.ident" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.single_buffer">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">single_buffer</span></span><a class="headerlink" href="#akida.NP.Mapping.single_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor uses a single or dual input buffer</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.type">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">type</span></span><a class="headerlink" href="#akida.NP.Mapping.type" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor type</p>
</dd></dl>

</dd></dl>

</section>
<section id="tools">
<h2>Tools<a class="headerlink" href="#tools" title="Permalink to this headline"></a></h2>
<section id="sparsity">
<h3>Sparsity<a class="headerlink" href="#sparsity" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="akida.evaluate_sparsity">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">evaluate_sparsity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/sparsity.html#evaluate_sparsity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.evaluate_sparsity" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the sparsity of a Model on a set of inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></a>) – the model to evaluate</p></li>
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary of float sparsity values indexed by layers</p>
</dd>
</dl>
</dd></dl>

<p><strong>Miscellaneous:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.statistics" title="akida.statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">statistics</span></code></a></p></td>
<td><p>Get statistics by sequence for this model.</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="akida.statistics">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">statistics</span></span><a class="headerlink" href="#akida.statistics" title="Permalink to this definition"></a></dt>
<dd><p>Get statistics by sequence for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary of <code class="xref py py-obj docutils literal notranslate"><span class="pre">SequenceStatistics</span></code> indexed by name.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api_reference.html" class="btn btn-neutral float-left" title="API reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnn2snn_apis.html" class="btn btn-neutral float-right" title="CNN2SNN Toolkit API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>