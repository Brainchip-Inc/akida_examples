<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Akida runtime API &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CNN2SNN Toolkit API" href="cnn2snn_apis.html" />
    <link rel="prev" title="API reference" href="api_reference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #78b3ff" >
            <a href="../index.html">
            <img src="../_static/akida.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                MetaTF 2.2.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#performances-measurement">Performances measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#yolo-training">YOLO training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/compatibility.html">Akida versions compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/compatibility.html#upgrading-models-with-legacy-quantizers">Upgrading models with legacy quantizers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="api_reference.html">API reference</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pooltype">PoolType</a></li>
<li class="toctree-l4"><a class="reference internal" href="#learningtype">LearningType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sparsity">Sparsity</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compatibility">Compatibility</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#tool-functions">Tool functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantize-layer">quantize_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#load-quantized-model">load_quantized_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#calibration">Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#stdperaxisquantizer">StdPerAxisQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#dense-block">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#batchnormalization-gamma-constraint">BatchNormalization gamma constraint</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#convtiny">ConvTiny</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="akida_models_apis.html#gxnor">GXNOR</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#create-a-keras-gxnor-model">2. Create a Keras GXNOR model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_0_gxnor_mnist.html#conversion-to-akida">3. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#create-a-keras-akidanet-model">2. Create a Keras AkidaNet model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">6. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_3_regression.html">Regression tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#add-a-float-classification-head-to-the-model">3. Add a float classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#freeze-the-base-model">4. Freeze the base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#train-for-a-few-epochs">5. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#quantize-the-classification-head">6. Quantize the classification head</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_4_transfer_learning.html#compute-accuracy">7. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/general/plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#load-and-reshape-mnist-dataset">1. Load and reshape MNIST dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-definition">2. Model definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-training">3. Model training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-fine-tuning-quantization-aware-training">5. Model fine tuning (quantization-aware training)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_0_cnn_flow.html#model-conversion">6. Model conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#time-icon-ref-time-domain"> Time domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#fault-detection">Fault detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../zoo_performances.html#id2">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #78b3ff" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="api_reference.html">API reference</a> &raquo;</li>
      <li>Akida runtime API</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-akida">
<span id="akida-runtime-api"></span><h1>Akida runtime API<a class="headerlink" href="#module-akida" title="Permalink to this headline"></a></h1>
<dl class="py attribute">
<dt class="sig sig-object py" id="akida.__version__">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">__version__</span></span><a class="headerlink" href="#akida.__version__" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current version of the akida module.</p>
</dd></dl>

<section id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Model">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><a class="headerlink" href="#akida.Model" title="Permalink to this definition"></a></dt>
<dd><p>An Akida neural <code class="docutils literal notranslate"><span class="pre">Model</span></code>, represented as a hierarchy of layers.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> class is the main interface to Akida and allows:</p>
<ul class="simple">
<li><p>to create an empty <code class="docutils literal notranslate"><span class="pre">Model</span></code> to which you can add layers programmatically
using the sequential API,</p></li>
<li><p>to reload a full <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a serialized file or a memory buffer,</p></li>
<li><p>to create a new <code class="docutils literal notranslate"><span class="pre">Model</span></code> from a list of layers taken from an existing
<code class="docutils literal notranslate"><span class="pre">Model</span></code>.</p></li>
</ul>
<p>It provides methods to instantiate, train, test and save models.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> input and output shapes have 4 dimensions, the first one being
the number of samples.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> accepts only uint8 tensors as inputs, whose values are
encoded using either 1, 2, 4 or 8-bit precision (i.e. whose max value is
1, 3, 15 or 255 respectively).</p>
<p>If the inputs are 8-bit, then the first layer of the <code class="docutils literal notranslate"><span class="pre">Model</span></code> must be a
convolutional layer with either 1 or 3 input channels.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Model</span></code> output is an uint8 tensor If activations are enabled for the
last layer, otherwise it is an int32 tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em><em>, </em><em>optional</em>) – path to the serialized Model.
If None, an empty sequential model will be created, or filled
with the layers in the layers parameter.</p></li>
<li><p><strong>layers</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code>, optional) – list of layers that will be copied
to the new model. If the list does not start with an input layer,
it will be added automatically.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.add" title="akida.Model.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(self, layer, inbound_layers)</p></td>
<td><p>Add a layer to the current model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.add_classes" title="akida.Model.add_classes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_classes</span></code></a>(self, num_add_classes)</p></td>
<td><p>Adds classes to the last layer of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.compile" title="akida.Model.compile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compile</span></code></a>(self, num_weights[, num_classes, ...])</p></td>
<td><p>Prepare the internal parameters of the last layer of the model for training</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.evaluate" title="akida.Model.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(self, inputs, labels[, ...])</p></td>
<td><p>Returns the model class accuracy.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.fit" title="akida.Model.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.forward" title="akida.Model.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(self, inputs[, batch_size])</p></td>
<td><p>Forwards a set of inputs through the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.get_layer" title="akida.Model.get_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.get_layer_count" title="akida.Model.get_layer_count"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_layer_count</span></code></a>(self)</p></td>
<td><p>The number of layers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.map" title="akida.Model.map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">map</span></code></a>(self, device, hw_only)</p></td>
<td><p>Map the model to a Device using a target backend.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.pop_layer" title="akida.Model.pop_layer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop_layer</span></code></a>(self)</p></td>
<td><p>Remove the last layer of the current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.predict" title="akida.Model.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, inputs[, batch_size])</p></td>
<td><p>Predicts a set of inputs through the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.predict_classes" title="akida.Model.predict_classes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_classes</span></code></a>(inputs[, num_classes, ...])</p></td>
<td><p>Predicts the class labels for the specified inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.readback_from_device" title="akida.Model.readback_from_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">readback_from_device</span></code></a>(self)</p></td>
<td><p>Readback variables and registers discrepancies from mapped hardware device.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.save" title="akida.Model.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(self, arg0)</p></td>
<td><p>Saves all the model configuration (all layers and weights) to a file on disk.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.summary" title="akida.Model.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>()</p></td>
<td><p>Prints a string summary of the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.to_buffer" title="akida.Model.to_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_buffer</span></code></a>(self)</p></td>
<td><p>Serializes all the model configuration (all layers and weights) to a bytes buffer.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.input_shape" title="akida.Model.input_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_shape</span></code></a></p></td>
<td><p>The model input dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.layers" title="akida.Model.layers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layers</span></code></a></p></td>
<td><p>Get a list of layers in current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.metrics" title="akida.Model.metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></a></p></td>
<td><p>The model metrics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.output_shape" title="akida.Model.output_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_shape</span></code></a></p></td>
<td><p>The model output dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.power_events" title="akida.Model.power_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_events</span></code></a></p></td>
<td><p>Copy of power events logged after inference</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Model.sequences" title="akida.Model.sequences"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sequences</span></code></a></p></td>
<td><p>The list of layer sequences in the Model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Model.statistics" title="akida.Model.statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">statistics</span></code></a></p></td>
<td><p>Get statistics by sequence for this model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.Model</span></em>, <em class="sig-param"><span class="pre">layer:</span> <span class="pre">akida::Layer</span></em>, <em class="sig-param"><span class="pre">inbound_layers:</span> <span class="pre">List[akida::Layer]</span> <span class="pre">=</span> <span class="pre">[]</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.add" title="Permalink to this definition"></a></dt>
<dd><p>Add a layer to the current model.</p>
<p>A list of inbound layers can optionally be specified.
These layers must already be included in the model.
if no inbound layer is specified, and the layer is not the first layer
in the model, the last included layer will be used as inbound layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer</strong> (<em>one of the available layers</em>) – layer instance to be added to the model</p></li>
<li><p><strong>inbound_layers</strong> (a list of <cite>Layer</cite>) – an optional list of inbound layers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.add_classes">
<span class="sig-name descname"><span class="pre">add_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_add_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.add_classes" title="Permalink to this definition"></a></dt>
<dd><p>Adds classes to the last layer of the model.</p>
<p>A model with a compiled last layer is ready to learn using the Akida
built-in learning algorithm. This function allows to add new classes
(i.e. new neurons) to the last layer, keeping the previously learned
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_add_classes</strong> (<em>int</em>) – number of classes to add to the last layer</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if the last layer is not compiled</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_weights</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_competition</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_plasticity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.10000000149011612</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plasticity_decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.compile" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the internal parameters of the last layer of the model for training</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_weights</strong> (<em>int</em>) – number of connections for each neuron.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – number of classes when running in a
‘labeled mode’.</p></li>
<li><p><strong>initial_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines how easily the weights
will change when learning occurs.</p></li>
<li><p><strong>learning_competition</strong> (<em>float</em><em>, </em><em>optional</em>) – controls competition between
neurons.</p></li>
<li><p><strong>min_plasticity</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the minimum level to which
plasticity will decay.</p></li>
<li><p><strong>plasticity_decay</strong> (<em>float</em><em>, </em><em>optional</em>) – defines the decay of plasticity
with each learning step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.int32</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#akida.Model.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Returns the model class accuracy.</p>
<p>Forwards an input tensor through the model and compute accuracy
based on labels.
If the number of output neurons is greater than the number of classes,
the neurons are automatically assigned to a class by dividing their id
by the number of classes.</p>
<p>Note that the evaluation is based on the activation values of the last
layer: for most use cases, you may want to disable activations for that
layer (ie setting <code class="docutils literal notranslate"><span class="pre">activation=False</span></code>) to get a better
accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n) tensor of labels for the inputs</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – optional parameter (defaults to the
number of neurons in the last layer).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the accuracy of the model to predict the labels based on the
inputs.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.fit" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: float, batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<em>float</em><em>, </em><em>optional</em>) – input label</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) uint8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="2">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: numpy.ndarray, batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>, optional) – input labels.
Must have one label per input, or a single label for all inputs.
If a label exceeds the defined number of classes, the input will
be discarded. (Default value = None).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) uint8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
<ol class="arabic simple" start="3">
<li><p>fit(self: akida.core.Model, inputs: numpy.ndarray, input_labels: list = [], batch_size: int = 0) -&gt; numpy.ndarray</p></li>
</ol>
<p>Trains a set of images or events through the model.</p>
<p>Trains the model with the specified input tensor (numpy array).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>input_labels</strong> (<em>list</em><em>(</em><em>int</em><em>)</em><em>, </em><em>optional</em>) – input labels.
Must have one label per input, or a single label for all inputs.
If a label exceeds the defined number of classes, the input will
be discarded. (Default value = None).</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) uint8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.Model.forward" title="Permalink to this definition"></a></dt>
<dd><p>Forwards a set of inputs through the model.</p>
<p>Forwards an input tensor through the model and returns an output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, out_x, out_y, out_c) uint8 or int32
tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>ValueError</strong> – if the inputs doesn’t match the required shape,
    format, etc.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer">
<span class="sig-name descname"><span class="pre">get_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.get_layer" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic">
<li><p>get_layer(self: akida.core.Model, layer_name: str) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_name</dt>
<dd class="field-odd"><p>name of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_name</dt>
<dd class="field-even"><p>str</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>get_layer(self: akida.core.Model, layer_index: int) -&gt; akida::Layer</p>
<blockquote>
<div><p>Get a reference to a specific layer.</p>
<p>This method allows a deeper introspection of the model by providing
access to the underlying layers.</p>
<dl class="field-list simple">
<dt class="field-odd">param layer_index</dt>
<dd class="field-odd"><p>index of the layer to retrieve</p>
</dd>
<dt class="field-even">type layer_index</dt>
<dd class="field-even"><p>int</p>
</dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a <code class="docutils literal notranslate"><span class="pre">Layer</span></code></p>
</dd>
</dl>
</div></blockquote>
</li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.get_layer_count">
<span class="sig-name descname"><span class="pre">get_layer_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#akida.Model.get_layer_count" title="Permalink to this definition"></a></dt>
<dd><p>The number of layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.input_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_shape</span></span><a class="headerlink" href="#akida.Model.input_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model input dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.layers">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#akida.Model.layers" title="Permalink to this definition"></a></dt>
<dd><p>Get a list of layers in current model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.map">
<span class="sig-name descname"><span class="pre">map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">self:</span> <span class="pre">akida.core.Model</span></em>, <em class="sig-param"><span class="pre">device:</span> <span class="pre">akida::Device</span></em>, <em class="sig-param"><span class="pre">hw_only:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.map" title="Permalink to this definition"></a></dt>
<dd><p>Map the model to a Device using a target backend.</p>
<p>This method tries to map a Model to the specified Device, implicitly
identifying one or more layer sequences that are mapped individually on
the Device Mesh.</p>
<p>An optional hw_only parameter can be specified to force the mapping
strategy to use only one hardware sequence, thus reducing software
intervention on the inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<cite>Device</cite>) – the target Device or None</p></li>
<li><p><strong>hw_only</strong> (<em>bool</em>) – when true, the model should be mapped in one sequence</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.metrics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#akida.Model.metrics" title="Permalink to this definition"></a></dt>
<dd><p>The model metrics.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.output_shape">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_shape</span></span><a class="headerlink" href="#akida.Model.output_shape" title="Permalink to this definition"></a></dt>
<dd><p>The model output dimensions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.pop_layer">
<span class="sig-name descname"><span class="pre">pop_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.pop_layer" title="Permalink to this definition"></a></dt>
<dd><p>Remove the last layer of the current model.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.power_events">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_events</span></span><a class="headerlink" href="#akida.Model.power_events" title="Permalink to this definition"></a></dt>
<dd><p>Copy of power events logged after inference</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.Model.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predicts a set of inputs through the model.</p>
<p>Forwards an input tensor through the model and returns a float array.</p>
<p>It applies ONLY to models without an activation on the last layer.
The output values are obtained from the model discrete potentials by
applying a shift and a scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a (n, w, h, c) float tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>TypeError</strong> – if the input is not a numpy.ndarray.</p></li>
<li><p><strong>RuntimeError</strong> – if the model last layer has an activation.</p></li>
<li><p><strong>ValueError</strong> – if the input doesn’t match the required shape,
    format, or if the model only has an InputData layer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.predict_classes">
<span class="sig-name descname"><span class="pre">predict_classes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.predict_classes" title="Permalink to this definition"></a></dt>
<dd><p>Predicts the class labels for the specified inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a (n, x, y, c) uint8 tensor</p></li>
<li><p><strong>num_classes</strong> (<em>int</em><em>, </em><em>optional</em>) – the number of output classes</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – maximum number of inputs that should be
processed at a time</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array of class labels</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.readback_from_device">
<span class="sig-name descname"><span class="pre">readback_from_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict[str,</span> <span class="pre">akida::HwLayerReadback]</span></span></span><a class="headerlink" href="#akida.Model.readback_from_device" title="Permalink to this definition"></a></dt>
<dd><p>Readback variables and registers discrepancies from mapped hardware
device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.Model.save" title="Permalink to this definition"></a></dt>
<dd><p>Saves all the model configuration (all layers and weights) to a
file on disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model_file</strong> (<em>str</em>) – full path of the serialized model (.fbz file).</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.sequences">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">sequences</span></span><a class="headerlink" href="#akida.Model.sequences" title="Permalink to this definition"></a></dt>
<dd><p>The list of layer sequences in the Model</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Model.statistics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">statistics</span></span><a class="headerlink" href="#akida.Model.statistics" title="Permalink to this definition"></a></dt>
<dd><p>Get statistics by sequence for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary of <code class="xref py py-obj docutils literal notranslate"><span class="pre">SequenceStatistics</span></code> indexed by name.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Model.summary" title="Permalink to this definition"></a></dt>
<dd><p>Prints a string summary of the model.</p>
<p>This method prints a summary of the model with details for every layer,
grouped by sequences:</p>
<ul class="simple">
<li><p>name and type in the first column</p></li>
<li><p>output shape</p></li>
<li><p>kernel shape</p></li>
</ul>
<p>If there is any layer with unsupervised learning enabled, it will list
them, with these details:</p>
<ul class="simple">
<li><p>name of layer</p></li>
<li><p>number of incoming connections</p></li>
<li><p>number of weights per neuron</p></li>
</ul>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Model.to_buffer">
<span class="sig-name descname"><span class="pre">to_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.Model" title="akida.core.Model"><span class="pre">akida.core.Model</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bytes</span></span></span><a class="headerlink" href="#akida.Model.to_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Serializes all the model configuration (all layers and weights) to a
bytes buffer.</p>
</dd></dl>

</dd></dl>

</section>
<section id="layer">
<h2>Layer<a class="headerlink" href="#layer" title="Permalink to this headline"></a></h2>
<section id="id1">
<h3>Layer<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Layer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Layer</span></span><a class="headerlink" href="#akida.Layer" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_learning_histogram" title="akida.Layer.get_learning_histogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_learning_histogram</span></code></a>()</p></td>
<td><p>Returns an histogram of learning percentages.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.get_variable" title="akida.Layer.get_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable</span></code></a>(name)</p></td>
<td><p>Get the value of a layer variable.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.get_variable_names" title="akida.Layer.get_variable_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_variable_names</span></code></a>()</p></td>
<td><p>Get the list of variable names for this layer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.set_variable" title="akida.Layer.set_variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_variable</span></code></a>(name, values)</p></td>
<td><p>Set the value of a layer variable.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.inbounds" title="akida.Layer.inbounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inbounds</span></code></a></p></td>
<td><p>The layer inbound layers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.input_bits" title="akida.Layer.input_bits"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_bits</span></code></a></p></td>
<td><p>The layer input bits.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.input_dims" title="akida.Layer.input_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">input_dims</span></code></a></p></td>
<td><p>The layer input dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.learning" title="akida.Layer.learning"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learning</span></code></a></p></td>
<td><p>The layer learning parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.mapping" title="akida.Layer.mapping"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mapping</span></code></a></p></td>
<td><p>The layer hardware mapping.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.name" title="akida.Layer.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The layer name.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.output_dims" title="akida.Layer.output_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">output_dims</span></code></a></p></td>
<td><p>The layer output dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Layer.parameters" title="akida.Layer.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a></p></td>
<td><p>The layer parameters set.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.variables" title="akida.Layer.variables"><code class="xref py py-obj docutils literal notranslate"><span class="pre">variables</span></code></a></p></td>
<td><p>The layer trainable variables.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_learning_histogram">
<span class="sig-name descname"><span class="pre">get_learning_histogram</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_learning_histogram" title="Permalink to this definition"></a></dt>
<dd><p>Returns an histogram of learning percentages.</p>
<p>Returns a list of learning percentages and the associated number of
neurons.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a (n,2) numpy.ndarray containing the learning
percentages and the number of neurons.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable">
<span class="sig-name descname"><span class="pre">get_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable" title="Permalink to this definition"></a></dt>
<dd><p>Get the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul class="simple">
<li><p>Weights variables are typically integer arrays of shape:
(x, y, features/channels, num_neurons) row-major (‘C’).</p></li>
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em>) – the variable name.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an array containing the variable.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.get_variable_names">
<span class="sig-name descname"><span class="pre">get_variable_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.get_variable_names" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of variable names for this layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a list of variable names.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.inbounds">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">inbounds</span></span><a class="headerlink" href="#akida.Layer.inbounds" title="Permalink to this definition"></a></dt>
<dd><p>The layer inbound layers.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_bits">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_bits</span></span><a class="headerlink" href="#akida.Layer.input_bits" title="Permalink to this definition"></a></dt>
<dd><p>The layer input bits.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.input_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_dims</span></span><a class="headerlink" href="#akida.Layer.input_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer input dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.learning">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learning</span></span><a class="headerlink" href="#akida.Layer.learning" title="Permalink to this definition"></a></dt>
<dd><p>The layer learning parameters set.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.mapping">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mapping</span></span><a class="headerlink" href="#akida.Layer.mapping" title="Permalink to this definition"></a></dt>
<dd><p>The layer hardware mapping.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Layer.name" title="Permalink to this definition"></a></dt>
<dd><p>The layer name.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.output_dims">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_dims</span></span><a class="headerlink" href="#akida.Layer.output_dims" title="Permalink to this definition"></a></dt>
<dd><p>The layer output dimensions.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.parameters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">parameters</span></span><a class="headerlink" href="#akida.Layer.parameters" title="Permalink to this definition"></a></dt>
<dd><p>The layer parameters set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.Layer.set_variable">
<span class="sig-name descname"><span class="pre">set_variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.Layer.set_variable" title="Permalink to this definition"></a></dt>
<dd><p>Set the value of a layer variable.</p>
<p>Layer variables are named entities representing the weights or
thresholds used during inference:</p>
<ul>
<li><p>Weights variables are typically integer arrays of shape:</p>
<p>(num_neurons, features/channels, y, x) col-major ordered (‘F’)</p>
</li>
</ul>
<p>or equivalently:</p>
<blockquote>
<div><p>(x, y, features/channels, num_neurons) row-major (‘C’).</p>
</div></blockquote>
<ul class="simple">
<li><p>Threshold variables are typically integer or float arrays of shape:
(num_neurons).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – the variable name.</p></li>
<li><p><strong>values</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray containing the variable values.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.variables">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">variables</span></span><a class="headerlink" href="#akida.Layer.variables" title="Permalink to this definition"></a></dt>
<dd><p>The layer trainable variables.</p>
</dd></dl>

</dd></dl>

</section>
<section id="mapping">
<h3>Mapping<a class="headerlink" href="#mapping" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Layer.Mapping">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.Layer.</span></span><span class="sig-name descname"><span class="pre">Mapping</span></span><a class="headerlink" href="#akida.Layer.Mapping" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Layer.Mapping.nps" title="akida.Layer.Mapping.nps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nps</span></code></a></p></td>
<td><p>a list of <code class="docutils literal notranslate"><span class="pre">NP.Mapping</span></code> objects.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Layer.Mapping.nps">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">nps</span></span><a class="headerlink" href="#akida.Layer.Mapping.nps" title="Permalink to this definition"></a></dt>
<dd><p>a list of <code class="docutils literal notranslate"><span class="pre">NP.Mapping</span></code> objects.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="inputdata">
<h2>InputData<a class="headerlink" href="#inputdata" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputData">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputData</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/input_data.html#InputData"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputData" title="Permalink to this definition"></a></dt>
<dd><p>This layer is used to specify the input dimensions of a low bitwidth Model.</p>
<p>Models accepting 8-bit images must start with an InputConvolutional layer,
but layers accepting integer inputs with a lower bitwidth (i.e. not images)
must start instead with an InputData layer.
This layer does not modify its inputs: it just allows to define the Model
input dimensions and bitwidth.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>input_bits</strong> (<em>int</em>) – input bitwidth.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="inputconvolutional">
<h2>InputConvolutional<a class="headerlink" href="#inputconvolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.InputConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">InputConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_shape</span></em>, <em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em>, <em class="sig-param"><span class="pre">padding_value=0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/input_convolutional.html#InputConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.InputConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>The <code class="docutils literal notranslate"><span class="pre">InputConvolutional</span></code> layer is an image-specific input layer.</p>
<p>The InputConvolutional layer accepts images in 8-bit pixels, either
grayscale or RGB.
It is the only akida layer with 8-bit weights.
It applies a ‘convolution’ (actually a cross-correlation) optionally
followed by a pooling operation to the input images.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
representing the 8-bit images as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple</em>) – the 3D input shape.</p></li>
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of
convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>tuple</em><em>, </em><em>optional</em>) – tuple of integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
<li><p><strong>padding_value</strong> (<em>int</em><em>, </em><em>optional</em>) – value used when padding.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="fullyconnected">
<h2>FullyConnected<a class="headerlink" href="#fullyconnected" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.FullyConnected">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">FullyConnected</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">act_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/fully_connected.html#FullyConnected"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.FullyConnected" title="Permalink to this definition"></a></dt>
<dd><p>This represents a Dense or Linear neural layer.</p>
<p>The FullyConnected layer accepts 1-bit, 2-bit or 4-bit input tensors.
The FullyConnected can be configured with 1-bit, 2-bit or 4-bit weights.
It multiplies the inputs by its internal unit weights, returning a 4D
tensor of values whose first dimension is the number of samples and the
last dimension represents the number of units.
It can optionally apply a step-wise ReLU activation to its outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>int</em>) – number of units.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to
quantize the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="convolutional">
<h2>Convolutional<a class="headerlink" href="#convolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Convolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Convolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=1</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/convolutional.html#Convolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.Convolutional" title="Permalink to this definition"></a></dt>
<dd><p>This represents a standard Convolutional layer.</p>
<p>The Convolutional layer accepts 1-bit, 2-bit or 4-bit 3D input tensors with
an arbitrary number of channels.
The Convolutional layer can be configured with 1-bit, 2-bit or 4-bit weights.
It applies a convolution (not a cross-correlation) optionally followed by a
pooling operation to the input tensors.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="separableconvolutional">
<h2>SeparableConvolutional<a class="headerlink" href="#separableconvolutional" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.SeparableConvolutional">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">SeparableConvolutional</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">kernel_size</span></em>, <em class="sig-param"><span class="pre">filters</span></em>, <em class="sig-param"><span class="pre">name=''</span></em>, <em class="sig-param"><span class="pre">padding=&lt;Padding.Same:</span> <span class="pre">1&gt;</span></em>, <em class="sig-param"><span class="pre">kernel_stride=(1</span></em>, <em class="sig-param"><span class="pre">1)</span></em>, <em class="sig-param"><span class="pre">weights_bits=2</span></em>, <em class="sig-param"><span class="pre">pool_size=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">pool_type=&lt;PoolType.NoPooling:</span> <span class="pre">0&gt;</span></em>, <em class="sig-param"><span class="pre">pool_stride=(-1</span></em>, <em class="sig-param"><span class="pre">-1)</span></em>, <em class="sig-param"><span class="pre">activation=True</span></em>, <em class="sig-param"><span class="pre">threshold=0</span></em>, <em class="sig-param"><span class="pre">act_step=1</span></em>, <em class="sig-param"><span class="pre">act_bits=1</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/separable_convolutional.html#SeparableConvolutional"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.SeparableConvolutional" title="Permalink to this definition"></a></dt>
<dd><p>This represents a separable convolution layer.</p>
<p>This layer accepts 1-bit, 2-bit or 4-bit 3D input tensors with an arbitrary
number of channels.
It can be configured with 1-bit, 2-bit or 4-bit weights.
Separable convolutions consist in first performing a depthwise spatial
convolution (which acts on each input channel separately) followed by a
pointwise convolution which mixes together the resulting output channels.
Note: this layer applies a real convolution, and not a cross-correlation.
It can optionally apply a step-wise ReLU activation to its outputs.
The layer expects a 4D tensor whose first dimension is the sample index
as input.
It returns a 4D tensor whose first dimension is the sample index and the
last dimension is the number of convolution filters.
The order of the input spatial dimensions is preserved, but their value may
change according to the convolution and pooling parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<em>list</em>) – list of 2 integer representing the spatial
dimensions of the convolutional kernel.</p></li>
<li><p><strong>filters</strong> (<em>int</em>) – number of pointwise filters.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – name of the layer.</p></li>
<li><p><strong>padding</strong> (<a class="reference internal" href="#akida.Padding" title="akida.Padding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Padding</span></code></a>, optional) – type of convolution.</p></li>
<li><p><strong>kernel_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integer representing the
convolution stride (X, Y).</p></li>
<li><p><strong>weights_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize weights.</p></li>
<li><p><strong>pool_size</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers, representing the window
size over which to take the maximum or the average (depending on
pool_type parameter).</p></li>
<li><p><strong>pool_type</strong> (<a class="reference internal" href="#akida.PoolType" title="akida.PoolType"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PoolType</span></code></a>, optional) – pooling type
(None, Max or Average).</p></li>
<li><p><strong>pool_stride</strong> (<em>list</em><em>, </em><em>optional</em>) – list of 2 integers representing
the stride dimensions.</p></li>
<li><p><strong>activation</strong> (<em>bool</em><em>, </em><em>optional</em>) – enable or disable activation
function.</p></li>
<li><p><strong>threshold</strong> (<em>int</em><em>, </em><em>optional</em>) – threshold for neurons to fire or
generate an event.</p></li>
<li><p><strong>act_step</strong> (<em>float</em><em>, </em><em>optional</em>) – length of the potential
quantization intervals.</p></li>
<li><p><strong>act_bits</strong> (<em>int</em><em>, </em><em>optional</em>) – number of bits used to quantize
the neuron response.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="layer-parameters">
<h2>Layer parameters<a class="headerlink" href="#layer-parameters" title="Permalink to this headline"></a></h2>
<section id="layertype">
<h3>LayerType<a class="headerlink" href="#layertype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.LayerType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">LayerType</span></span><a class="headerlink" href="#akida.LayerType" title="Permalink to this definition"></a></dt>
<dd><p>The layer type</p>
<p>Members:</p>
<blockquote>
<div><p>Unknown</p>
<p>InputData</p>
<p>InputConvolutional</p>
<p>FullyConnected</p>
<p>Convolutional</p>
<p>SeparableConvolutional</p>
</div></blockquote>
</dd></dl>

</section>
<section id="padding">
<h3>Padding<a class="headerlink" href="#padding" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Padding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Padding</span></span><a class="headerlink" href="#akida.Padding" title="Permalink to this definition"></a></dt>
<dd><p>Sets the effective padding of the input for convolution, thereby determining the output dimensions. Naming conventions are the same as Keras/Tensorflow.</p>
<p>Members:</p>
<blockquote>
<div><p>Valid : No padding</p>
<p>Same : Padded so that output size is input size divided by the stride</p>
</div></blockquote>
</dd></dl>

</section>
<section id="pooltype">
<h3>PoolType<a class="headerlink" href="#pooltype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PoolType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PoolType</span></span><a class="headerlink" href="#akida.PoolType" title="Permalink to this definition"></a></dt>
<dd><p>The pooling type</p>
<p>Members:</p>
<blockquote>
<div><p>NoPooling : No pooling applied</p>
<p>Max : Maximum pixel value is selected</p>
<p>Average : Average pixel value is selected</p>
</div></blockquote>
</dd></dl>

</section>
<section id="learningtype">
<h3>LearningType<a class="headerlink" href="#learningtype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.LearningType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">LearningType</span></span><a class="headerlink" href="#akida.LearningType" title="Permalink to this definition"></a></dt>
<dd><p>The learning type</p>
<p>Members:</p>
<blockquote>
<div><p>NoLearning : Learning is disabled, inference-only mode</p>
<p>AkidaUnsupervised : Built-in unsupervised learning rules</p>
</div></blockquote>
</dd></dl>

</section>
</section>
<section id="sequence">
<h2>Sequence<a class="headerlink" href="#sequence" title="Permalink to this headline"></a></h2>
<section id="id2">
<h3>Sequence<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Sequence">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Sequence</span></span><a class="headerlink" href="#akida.Sequence" title="Permalink to this definition"></a></dt>
<dd><p>Represents a sequence of layers.</p>
<p>Sequences can be mapped in Software or on a Device.</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.backend" title="akida.Sequence.backend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backend</span></code></a></p></td>
<td><p>The backend type for this Sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.name" title="akida.Sequence.name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name</span></code></a></p></td>
<td><p>The name of the sequence</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Sequence.passes" title="akida.Sequence.passes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">passes</span></code></a></p></td>
<td><p>Get the list of passes in this sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Sequence.program" title="akida.Sequence.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Get the hardware program for this sequence.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.backend">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">backend</span></span><a class="headerlink" href="#akida.Sequence.backend" title="Permalink to this definition"></a></dt>
<dd><p>The backend type for this Sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.name">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#akida.Sequence.name" title="Permalink to this definition"></a></dt>
<dd><p>The name of the sequence</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.passes">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">passes</span></span><a class="headerlink" href="#akida.Sequence.passes" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of passes in this sequence.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Sequence.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.Sequence.program" title="Permalink to this definition"></a></dt>
<dd><p>Get the hardware program for this sequence.</p>
<p>Returns None if the Sequence is not compatible with the selected
Device.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a bytes buffer or None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="backendtype">
<h3>BackendType<a class="headerlink" href="#backendtype" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.BackendType">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">BackendType</span></span><a class="headerlink" href="#akida.BackendType" title="Permalink to this definition"></a></dt>
<dd><p>Members:</p>
<p>Software</p>
<p>Hardware</p>
<p>Hybrid</p>
</dd></dl>

</section>
<section id="pass">
<h3>Pass<a class="headerlink" href="#pass" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Pass">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Pass</span></span><a class="headerlink" href="#akida.Pass" title="Permalink to this definition"></a></dt>
<dd><p>Represents a subset of the Sequence.</p>
<p>Hardware Sequences can typically be split into multiple passes on devices
that support hardware partial reconfiguration feature, reducing the
intervention of the software during inference.</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Pass.layers" title="akida.Pass.layers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layers</span></code></a></p></td>
<td><p>Get the list of layers in this pass.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Pass.layers">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">layers</span></span><a class="headerlink" href="#akida.Pass.layers" title="Permalink to this definition"></a></dt>
<dd><p>Get the list of layers in this pass.</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="device">
<h2>Device<a class="headerlink" href="#device" title="Permalink to this headline"></a></h2>
<section id="id3">
<h3>Device<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.Device">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">Device</span></span><a class="headerlink" href="#akida.Device" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.desc" title="akida.Device.desc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">desc</span></code></a></p></td>
<td><p>Returns the Device description</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.Device.mesh" title="akida.Device.mesh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mesh</span></code></a></p></td>
<td><p>The device Mesh layout</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.Device.version" title="akida.Device.version"><code class="xref py py-obj docutils literal notranslate"><span class="pre">version</span></code></a></p></td>
<td><p>The device hardware version.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.desc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">desc</span></span><a class="headerlink" href="#akida.Device.desc" title="Permalink to this definition"></a></dt>
<dd><p>Returns the Device description</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a string describing the Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.mesh">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">mesh</span></span><a class="headerlink" href="#akida.Device.mesh" title="Permalink to this definition"></a></dt>
<dd><p>The device Mesh layout</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.Device.version">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">version</span></span><a class="headerlink" href="#akida.Device.version" title="Permalink to this definition"></a></dt>
<dd><p>The device hardware version.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.devices">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">devices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.devices" title="Permalink to this definition"></a></dt>
<dd><p>Returns the full list of available hardware devices</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of Device</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.AKD1000">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">AKD1000</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#AKD1000"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.AKD1000" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for an AKD1000 NSoC.</p>
<p>This function returns a virtual device for the Brainchip’s AKD1000
NSoC.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a virtual device.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.TwoNodesIP">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">TwoNodesIP</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/virtual_devices.html#TwoNodesIP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.TwoNodesIP" title="Permalink to this definition"></a></dt>
<dd><p>Returns a virtual device for a two nodes Akida IP.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a virtual device.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#akida.Device" title="akida.Device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Device</span></code></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="hwversion">
<h3>HwVersion<a class="headerlink" href="#hwversion" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HwVersion">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HwVersion</span></span><a class="headerlink" href="#akida.HwVersion" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.major_rev" title="akida.HwVersion.major_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">major_rev</span></code></a></p></td>
<td><p>The hardware major revision</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.minor_rev" title="akida.HwVersion.minor_rev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minor_rev</span></code></a></p></td>
<td><p>The hardware minor revision</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HwVersion.product_id" title="akida.HwVersion.product_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">product_id</span></code></a></p></td>
<td><p>The hardware product identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HwVersion.vendor_id" title="akida.HwVersion.vendor_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vendor_id</span></code></a></p></td>
<td><p>The hardware vendor identifier</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.major_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">major_rev</span></span><a class="headerlink" href="#akida.HwVersion.major_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware major revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.minor_rev">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">minor_rev</span></span><a class="headerlink" href="#akida.HwVersion.minor_rev" title="Permalink to this definition"></a></dt>
<dd><p>The hardware minor revision</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.product_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">product_id</span></span><a class="headerlink" href="#akida.HwVersion.product_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware product identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HwVersion.vendor_id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">vendor_id</span></span><a class="headerlink" href="#akida.HwVersion.vendor_id" title="Permalink to this definition"></a></dt>
<dd><p>The hardware vendor identifier</p>
</dd></dl>

</dd></dl>

</section>
</section>
<section id="hwdevice">
<h2>HWDevice<a class="headerlink" href="#hwdevice" title="Permalink to this headline"></a></h2>
<section id="id4">
<h3>HWDevice<a class="headerlink" href="#id4" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.HardwareDevice">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">HardwareDevice</span></span><a class="headerlink" href="#akida.HardwareDevice" title="Permalink to this definition"></a></dt>
<dd><p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.fit" title="akida.HardwareDevice.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(*args, **kwargs)</p></td>
<td><p>Overloaded function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.forward" title="akida.HardwareDevice.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.predict" title="akida.HardwareDevice.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self, arg0)</p></td>
<td><p>Processes inputs on a programmed device, returns a float array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.unprogram" title="akida.HardwareDevice.unprogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unprogram</span></code></a>(self)</p></td>
<td><p>Clear current program from hardware device, restoring its initial state</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.inference_power_events" title="akida.HardwareDevice.inference_power_events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inference_power_events</span></code></a></p></td>
<td><p>Copy of power events logged after inference</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.learn_enabled" title="akida.HardwareDevice.learn_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learn_enabled</span></code></a></p></td>
<td><p>Property that enables/disables learning on current program (if possible).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.learn_mem" title="akida.HardwareDevice.learn_mem"><code class="xref py py-obj docutils literal notranslate"><span class="pre">learn_mem</span></code></a></p></td>
<td><p>Property that retrieves learning layer's memory or updates a device using a serialized learning layer memory buffer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.memory" title="akida.HardwareDevice.memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memory</span></code></a></p></td>
<td><p>The device memory usage and top usage (in bytes)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.metrics" title="akida.HardwareDevice.metrics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">metrics</span></code></a></p></td>
<td><p>The metrics from this device</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.HardwareDevice.program" title="akida.HardwareDevice.program"><code class="xref py py-obj docutils literal notranslate"><span class="pre">program</span></code></a></p></td>
<td><p>Property that retrieves current program or programs a device using a serialized program bytes object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.HardwareDevice.soc" title="akida.HardwareDevice.soc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">soc</span></code></a></p></td>
<td><p>The SocDriver interface used by the device, or None if the device is not a SoC</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#akida.HardwareDevice.fit" title="Permalink to this definition"></a></dt>
<dd><p>Overloaded function.</p>
<ol class="arabic simple">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: float) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
<ol class="arabic simple" start="2">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: numpy.ndarray) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
<ol class="arabic simple" start="3">
<li><p>fit(self: akida.core.HardwareDevice, inputs: numpy.ndarray[numpy.uint8], input_labels: list = []) -&gt; numpy.ndarray</p></li>
</ol>
<p>Learn from inputs on a programmed device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.forward" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with outputs from the device</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.inference_power_events">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">inference_power_events</span></span><a class="headerlink" href="#akida.HardwareDevice.inference_power_events" title="Permalink to this definition"></a></dt>
<dd><p>Copy of power events logged after inference</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.learn_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learn_enabled</span></span><a class="headerlink" href="#akida.HardwareDevice.learn_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Property that enables/disables learning on current program (if
possible).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.learn_mem">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">learn_mem</span></span><a class="headerlink" href="#akida.HardwareDevice.learn_mem" title="Permalink to this definition"></a></dt>
<dd><p>Property that retrieves learning layer’s memory or updates a device
using a serialized learning layer memory buffer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.memory">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">memory</span></span><a class="headerlink" href="#akida.HardwareDevice.memory" title="Permalink to this definition"></a></dt>
<dd><p>The device memory usage and top usage (in bytes)</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.metrics">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#akida.HardwareDevice.metrics" title="Permalink to this definition"></a></dt>
<dd><p>The metrics from this device</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">arg0</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.uint8</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">numpy.ndarray</span></span></span><a class="headerlink" href="#akida.HardwareDevice.predict" title="Permalink to this definition"></a></dt>
<dd><p>Processes inputs on a programmed device, returns a float array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> – <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with shape matching current program</p>
</dd>
</dl>
<p>:return <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> with float outputs from the device</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.program">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">program</span></span><a class="headerlink" href="#akida.HardwareDevice.program" title="Permalink to this definition"></a></dt>
<dd><p>Property that retrieves current program or programs a device using a
serialized program bytes object.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.HardwareDevice.soc">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">soc</span></span><a class="headerlink" href="#akida.HardwareDevice.soc" title="Permalink to this definition"></a></dt>
<dd><p>The SocDriver interface used by the device, or None if the device
is not a SoC</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="akida.HardwareDevice.unprogram">
<span class="sig-name descname"><span class="pre">unprogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.HardwareDevice" title="akida.core.HardwareDevice"><span class="pre">akida.core.HardwareDevice</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#akida.HardwareDevice.unprogram" title="Permalink to this definition"></a></dt>
<dd><p>Clear current program from hardware device, restoring its initial
state</p>
</dd></dl>

</dd></dl>

</section>
<section id="socdriver">
<h3>SocDriver<a class="headerlink" href="#socdriver" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.SocDriver">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.</span></span><span class="sig-name descname"><span class="pre">SocDriver</span></span><a class="headerlink" href="#akida.core.SocDriver" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.SocDriver.clock_mode" title="akida.core.SocDriver.clock_mode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clock_mode</span></code></a></p></td>
<td><p>Clock mode of the NSoC.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_measurement_enabled" title="akida.core.SocDriver.power_measurement_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_measurement_enabled</span></code></a></p></td>
<td><p>Power measurement is off by default.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.core.SocDriver.power_meter" title="akida.core.SocDriver.power_meter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power_meter</span></code></a></p></td>
<td><p>Power meter associated to the SoC.</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.clock_mode">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">clock_mode</span></span><a class="headerlink" href="#akida.core.SocDriver.clock_mode" title="Permalink to this definition"></a></dt>
<dd><p>Clock mode of the NSoC.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_measurement_enabled">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_measurement_enabled</span></span><a class="headerlink" href="#akida.core.SocDriver.power_measurement_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Power measurement is off by default. Toggle it on to get power information in the statistics or when calling PowerMeter.events().</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.core.SocDriver.power_meter">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power_meter</span></span><a class="headerlink" href="#akida.core.SocDriver.power_meter" title="Permalink to this definition"></a></dt>
<dd><p>Power meter associated to the SoC.</p>
</dd></dl>

</dd></dl>

</section>
<section id="clockmode">
<h3>ClockMode<a class="headerlink" href="#clockmode" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="akida.core.soc.ClockMode">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.core.soc.</span></span><span class="sig-name descname"><span class="pre">ClockMode</span></span><a class="headerlink" href="#akida.core.soc.ClockMode" title="Permalink to this definition"></a></dt>
<dd><p>Clock mode configuration</p>
<p>Members:</p>
<blockquote>
<div><p>Performance</p>
<p>Economy</p>
<p>LowPower</p>
</div></blockquote>
</dd></dl>

</section>
</section>
<section id="powermeter">
<h2>PowerMeter<a class="headerlink" href="#powermeter" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerMeter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerMeter</span></span><a class="headerlink" href="#akida.PowerMeter" title="Permalink to this definition"></a></dt>
<dd><p>Gives access to power measurements.</p>
<p>When power measurements are enabled for a specific device, this object
stores them as a list of <code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code> objects.
The events list cannot exceed a predefined size: when it is full, older
events are replaced by newer events.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerMeter.events" title="akida.PowerMeter.events"><code class="xref py py-obj docutils literal notranslate"><span class="pre">events</span></code></a>(self)</p></td>
<td><p>Retrieve all pending events</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerMeter.floor" title="akida.PowerMeter.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code></a></p></td>
<td><p>Get the floor power</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="akida.PowerMeter.events">
<span class="sig-name descname"><span class="pre">events</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#akida.PowerMeter" title="akida.core.PowerMeter"><span class="pre">akida.core.PowerMeter</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#akida.PowerEvent" title="akida.core.PowerEvent"><span class="pre">akida.core.PowerEvent</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#akida.PowerMeter.events" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve all pending events</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerMeter.floor">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">floor</span></span><a class="headerlink" href="#akida.PowerMeter.floor" title="Permalink to this definition"></a></dt>
<dd><p>Get the floor power</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.PowerEvent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">PowerEvent</span></span><a class="headerlink" href="#akida.PowerEvent" title="Permalink to this definition"></a></dt>
<dd><p>A timestamped power measurement.</p>
<p>Each PowerEvent contains:
- a voltage value in µV (microvolt),
- a current value in mA (milliampere),
- the corresponding power value in mW (milliwatt).</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.current" title="akida.PowerEvent.current"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current</span></code></a></p></td>
<td><p>Current value in mA</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerEvent.power" title="akida.PowerEvent.power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">power</span></code></a></p></td>
<td><p>Power value in mW</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.PowerEvent.ts" title="akida.PowerEvent.ts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ts</span></code></a></p></td>
<td><p>Timestamp of the event</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.PowerEvent.voltage" title="akida.PowerEvent.voltage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">voltage</span></code></a></p></td>
<td><p>Voltage value in µV</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.current">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">current</span></span><a class="headerlink" href="#akida.PowerEvent.current" title="Permalink to this definition"></a></dt>
<dd><p>Current value in mA</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.power">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">power</span></span><a class="headerlink" href="#akida.PowerEvent.power" title="Permalink to this definition"></a></dt>
<dd><p>Power value in mW</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.ts">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ts</span></span><a class="headerlink" href="#akida.PowerEvent.ts" title="Permalink to this definition"></a></dt>
<dd><p>Timestamp of the event</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.PowerEvent.voltage">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">voltage</span></span><a class="headerlink" href="#akida.PowerEvent.voltage" title="Permalink to this definition"></a></dt>
<dd><p>Voltage value in µV</p>
</dd></dl>

</dd></dl>

</section>
<section id="np">
<h2>NP<a class="headerlink" href="#np" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Mesh">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Mesh</span></span><a class="headerlink" href="#akida.NP.Mesh" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_conf" title="akida.NP.Mesh.dma_conf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_conf</span></code></a></p></td>
<td><p>DMA configuration endpoint</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mesh.dma_event" title="akida.NP.Mesh.dma_event"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dma_event</span></code></a></p></td>
<td><p>DMA event endpoint</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mesh.nps" title="akida.NP.Mesh.nps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nps</span></code></a></p></td>
<td><p>Neural processors</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_conf">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_conf</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_conf" title="Permalink to this definition"></a></dt>
<dd><p>DMA configuration endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.dma_event">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">dma_event</span></span><a class="headerlink" href="#akida.NP.Mesh.dma_event" title="Permalink to this definition"></a></dt>
<dd><p>DMA event endpoint</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mesh.nps">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">nps</span></span><a class="headerlink" href="#akida.NP.Mesh.nps" title="Permalink to this definition"></a></dt>
<dd><p>Neural processors</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Info">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Info</span></span><a class="headerlink" href="#akida.NP.Info" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Info.ident" title="akida.NP.Info.ident"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ident</span></code></a></p></td>
<td><p>NP identifier</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Info.types" title="akida.NP.Info.types"><code class="xref py py-obj docutils literal notranslate"><span class="pre">types</span></code></a></p></td>
<td><p>NP supported types</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.ident">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ident</span></span><a class="headerlink" href="#akida.NP.Info.ident" title="Permalink to this definition"></a></dt>
<dd><p>NP identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Info.types">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">types</span></span><a class="headerlink" href="#akida.NP.Info.types" title="Permalink to this definition"></a></dt>
<dd><p>NP supported types</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Ident">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Ident</span></span><a class="headerlink" href="#akida.NP.Ident" title="Permalink to this definition"></a></dt>
<dd><p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.col" title="akida.NP.Ident.col"><code class="xref py py-obj docutils literal notranslate"><span class="pre">col</span></code></a></p></td>
<td><p>NP column number</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Ident.id" title="akida.NP.Ident.id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">id</span></code></a></p></td>
<td><p>NP id</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Ident.row" title="akida.NP.Ident.row"><code class="xref py py-obj docutils literal notranslate"><span class="pre">row</span></code></a></p></td>
<td><p>NP row number</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.col">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">col</span></span><a class="headerlink" href="#akida.NP.Ident.col" title="Permalink to this definition"></a></dt>
<dd><p>NP column number</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.id">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#akida.NP.Ident.id" title="Permalink to this definition"></a></dt>
<dd><p>NP id</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Ident.row">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">row</span></span><a class="headerlink" href="#akida.NP.Ident.row" title="Permalink to this definition"></a></dt>
<dd><p>NP row number</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Type">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Type</span></span><a class="headerlink" href="#akida.NP.Type" title="Permalink to this definition"></a></dt>
<dd><p>Members:</p>
<p>HRC : High Resolution Convolution</p>
<p>CNP1 : Convolutional Neural Processor Type 1</p>
<p>CNP2 : Convolutional Neural Processor Type 2</p>
<p>FNP2 : FullyConnected Neural Processor (external memory)</p>
<p>FNP3 : FullyConnected Neural Processor (internal memory)</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="akida.NP.Mapping">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">akida.NP.</span></span><span class="sig-name descname"><span class="pre">Mapping</span></span><a class="headerlink" href="#akida.NP.Mapping" title="Permalink to this definition"></a></dt>
<dd><p>The mapping of a subset of a Layer on a Neural Processor”</p>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mapping.filters" title="akida.NP.Mapping.filters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filters</span></code></a></p></td>
<td><p>Number of filters processed by the Neural Processor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mapping.ident" title="akida.NP.Mapping.ident"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ident</span></code></a></p></td>
<td><p>Neural Processor identifier</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.NP.Mapping.single_buffer" title="akida.NP.Mapping.single_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">single_buffer</span></code></a></p></td>
<td><p>Neural Processor uses a single or dual input buffer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#akida.NP.Mapping.type" title="akida.NP.Mapping.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a></p></td>
<td><p>Neural Processor type</p></td>
</tr>
</tbody>
</table>
<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.filters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">filters</span></span><a class="headerlink" href="#akida.NP.Mapping.filters" title="Permalink to this definition"></a></dt>
<dd><p>Number of filters processed by the Neural Processor</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.ident">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">ident</span></span><a class="headerlink" href="#akida.NP.Mapping.ident" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor identifier</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.single_buffer">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">single_buffer</span></span><a class="headerlink" href="#akida.NP.Mapping.single_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor uses a single or dual input buffer</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="akida.NP.Mapping.type">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">type</span></span><a class="headerlink" href="#akida.NP.Mapping.type" title="Permalink to this definition"></a></dt>
<dd><p>Neural Processor type</p>
</dd></dl>

</dd></dl>

</section>
<section id="tools">
<h2>Tools<a class="headerlink" href="#tools" title="Permalink to this headline"></a></h2>
<section id="sparsity">
<h3>Sparsity<a class="headerlink" href="#sparsity" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="akida.evaluate_sparsity">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">evaluate_sparsity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/sparsity.html#evaluate_sparsity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.evaluate_sparsity" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate the sparsity of a Model on a set of inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="#akida.Model" title="akida.Model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></a>) – the model to evaluate</p></li>
<li><p><strong>inputs</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) – a numpy.ndarray</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dictionary of float sparsity values indexed by layers</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="compatibility">
<h3>Compatibility<a class="headerlink" href="#compatibility" title="Permalink to this headline"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="akida.compatibility.create_from_model">
<span class="sig-prename descclassname"><span class="pre">akida.compatibility.</span></span><span class="sig-name descname"><span class="pre">create_from_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/compatibility/conversion.html#create_from_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.compatibility.create_from_model" title="Permalink to this definition"></a></dt>
<dd><p>Tries to create a HW compatible model from an incompatible one</p>
<p>Tries to create a HW compatible model from an incompatible one, using SW
workarounds for known limitations. It returns a converted model that is not
guaranteed to be HW compatible, depending if workaround have been found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code>) – a Model object to convert</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new Model with no guarantee that it is HW compatible.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="akida.compatibility.transpose">
<span class="sig-prename descclassname"><span class="pre">akida.compatibility.</span></span><span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/akida/compatibility/conversion.html#transpose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#akida.compatibility.transpose" title="Permalink to this definition"></a></dt>
<dd><p>Transpose the weights of a legacy (pre-2.1.4) model</p>
<p>This only applies to:</p>
<ul class="simple">
<li><p>models converted using cnn2snn,</p></li>
<li><p>models instantiated using the Sequential API starting with an
InputConvolutional.</p></li>
</ul>
<p>Models instantiated using the Sequential API starting with an InputData
don’t need to have their weights transposed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code>) – a Model object whose weights need transposing</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new Model with transposed weights</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Model</span></code></p>
</dd>
</dl>
</dd></dl>

<p><strong>Miscellaneous:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#akida.statistics" title="akida.statistics"><code class="xref py py-obj docutils literal notranslate"><span class="pre">statistics</span></code></a></p></td>
<td><p>Get statistics by sequence for this model.</p></td>
</tr>
</tbody>
</table>
<dl class="py attribute">
<dt class="sig sig-object py" id="akida.statistics">
<span class="sig-prename descclassname"><span class="pre">akida.</span></span><span class="sig-name descname"><span class="pre">statistics</span></span><a class="headerlink" href="#akida.statistics" title="Permalink to this definition"></a></dt>
<dd><p>Get statistics by sequence for this model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary of <code class="xref py py-obj docutils literal notranslate"><span class="pre">SequenceStatistics</span></code> indexed by name.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api_reference.html" class="btn btn-neutral float-left" title="API reference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="cnn2snn_apis.html" class="btn btn-neutral float-right" title="CNN2SNN Toolkit API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>