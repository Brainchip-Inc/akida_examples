

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DS-CNN CIFAR10 inference &mdash; Akida Examples  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Transfer learning with MobileNet for cats vs. dogs" href="plot_transfer_learning.html" />
    <link rel="prev" title="DS-CNN/KWS inference" href="plot_ds_cnn_kws.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #3f51b5" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/akida.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                Akida 1.8.8
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/aee.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#the-akida-execution-engine">The Akida Execution Engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#id1">1. The Spiking Neural Network model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#id2">2. Input data format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#id3">3. Determine training mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#id4">4. Interpreting outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#neural-network-model">Neural Network model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#specifying-the-neural-network-model">Specifying the Neural Network model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/aee.html#id5">Using Akida Unsupervised Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#compiling-a-layer">Compiling a layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/aee.html#id6">Learning parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#cifar10-training-and-tuning">CIFAR10 training and tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#kws-training">KWS training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#input-layer">Input layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../user_guide/hw_constraints.html#data-processing-layers">Data-Processing layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#convolutional-layer">Convolutional layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../user_guide/hw_constraints.html#fully-connected-layer">Fully connected layer</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/aee_apis.html">Akida Execution Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#layerstatistics">LayerStatistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#observer">Observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#dense">Dense</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#sparse">Sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#coords-to-sparse">coords_to_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#dense-to-sparse">dense_to_sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#packetize">packetize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#backend">Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#convolutionmode">ConvolutionMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#poolingtype">PoolingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#learningtype">LearningType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/aee_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#trainableweightquantizer">TrainableWeightQuantizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#weightfloat">WeightFloat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizeddepthwiseconv2d">QuantizedDepthwiseConv2D</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#quantization-blocks">Quantization blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#dense-block">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#id1">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#id2">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#id3">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_gxnor_mnist.html">GXNOR/MNIST inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_gxnor_mnist.html#loading-the-mnist-dataset">1. Loading the MNIST dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gxnor_mnist.html#look-at-some-images-from-the-test-dataset">2. Look at some images from the test dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gxnor_mnist.html#load-the-pre-trained-akida-model">3. Load the pre-trained Akida model</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gxnor_mnist.html#classify-a-single-image">4. Classify a single image</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gxnor_mnist.html#check-performance-across-a-number-of-samples">5. Check performance across a number of samples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_regression.html">Regression tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#load-dependencies">1. Load dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#load-the-dataset">2. Load the dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#create-a-keras-model-satisfying-akida-nsoc-requirements">3. Create a Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#check-performance">4. Check performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#conversion-to-akida">5. Conversion to Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_regression.html#convert-the-trained-keras-model-to-akida">5.1 Convert the trained Keras model to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_regression.html#check-akida-model-accuracy">5.2 Check Akida model accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_regression.html#estimate-age-on-a-single-image">6. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_cnn_flow.html">CNN conversion flow tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_cnn_flow.html#load-and-reshape-mnist-dataset">1. Load and reshape MNIST dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_cnn_flow.html#model-definition">2. Model definition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_cnn_flow.html#model-training">3. Model training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_cnn_flow.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_cnn_flow.html#model-fine-tuning-quantization-aware-training">5. Model fine tuning (quantization-aware training)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_cnn_flow.html#model-conversion">6. Model conversion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_ds_cnn_kws.html#load-cnn2snn-tool-dependencies">1. Load CNN2SNN tool dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ds_cnn_kws.html#load-the-preprocessed-dataset">2. Load the preprocessed dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ds_cnn_kws.html#create-a-keras-model-satisfying-akida-nsoc-requirements">3. Create a Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ds_cnn_kws.html#check-performance">4. Check performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ds_cnn_kws.html#conversion-to-akida">5. Conversion to Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_ds_cnn_kws.html#convert-the-trained-keras-model-to-akida">5.1 Convert the trained Keras model to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_ds_cnn_kws.html#check-prediction-accuracy">5.2 Check prediction accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_ds_cnn_kws.html#confusion-matrix">5.3 Confusion matrix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">DS-CNN CIFAR10 inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-a-keras-ds-cnn-model">2. Create a Keras DS-CNN model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantized-model">3. Quantized model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#conversion-to-akida">5. Conversion to Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#convert-to-akida-model">5.1 Convert to Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#check-hardware-compliancy">5.2 Check hardware compliancy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#check-performance">5.3 Check performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#show-predictions-for-a-random-image">5.4 Show predictions for a random image</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_transfer_learning.html">Transfer learning with MobileNet for cats vs. dogs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_transfer_learning.html#transfer-learning-process">1. Transfer learning process</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_transfer_learning.html#load-and-preprocess-data">2. Load and preprocess data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#a-load-and-split-data">2.A - Load and split data</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#b-preprocess-the-test-set">2.B - Preprocess the test set</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#c-get-labels">2.C - Get labels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_transfer_learning.html#convert-a-quantized-keras-model-to-akida">3. Convert a quantized Keras model to Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#a-instantiate-a-keras-base-model">3.A - Instantiate a Keras base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#b-modify-the-network-and-load-pre-trained-weights">3.B - Modify the network and load pre-trained weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#c-convert-to-akida">3.C - Convert to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_transfer_learning.html#classify-test-images">4. Classify test images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#a-classify-test-images">4.A Classify test images</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_transfer_learning.html#b-compare-results">4.B Compare results</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_mobilenet_imagenet.html">MobileNet/ImageNet inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plot_mobilenet_imagenet.html#load-cnn2snn-tool-dependencies">1. Load CNN2SNN tool dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_mobilenet_imagenet.html#load-test-images-from-imagenet">2. Load test images from ImageNet</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#load-test-images-and-preprocess-test-images">2.1 Load test images and preprocess test images</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#load-labels">2.2 Load labels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_mobilenet_imagenet.html#create-a-quantized-keras-model">3. Create a quantized Keras model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#instantiate-keras-model">3.1 Instantiate Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#check-performance-of-the-keras-model">3.2 Check performance of the Keras model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_mobilenet_imagenet.html#convert-keras-model-for-akida-nsoc">4. Convert Keras model for Akida NSoC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#convert-keras-model-to-an-akida-compatible-model">4.1 Convert Keras model to an Akida compatible model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#test-performance-of-the-akida-model">4.2 Test performance of the Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_mobilenet_imagenet.html#show-predictions-for-a-random-test-image">4.3 Show predictions for a random test image</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Akida Examples</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Akida examples</a> &raquo;</li>
        
      <li>DS-CNN CIFAR10 inference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-examples-plot-ds-cnn-cifar10-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="ds-cnn-cifar10-inference">
<span id="sphx-glr-examples-plot-ds-cnn-cifar10-py"></span><h1>DS-CNN CIFAR10 inference<a class="headerlink" href="#ds-cnn-cifar10-inference" title="Permalink to this headline">¶</a></h1>
<p>This tutorial uses the CIFAR-10 dataset (60k training images distributed in 10
object classes) for a classic object classification task with a network built
around the Depthwise Separable Convolutional Neural Network (DS-CNN) which is
originated from <a class="reference external" href="https://arxiv.org/pdf/1711.07128.pdf">Zhang et al (2018)</a>.</p>
<p>The goal of the tutorial is to provide users with an example of a complex model
that can be converted to an Akida model and that can be run on Akida NSoC
with an accuracy similar to a standard Keras floating point model.</p>
<div class="section" id="dataset-preparation">
<h2>1. Dataset preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">cifar10</span>

<span class="c1"># Load CIFAR10 dataset</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Reshape x-data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Set aside raw test data for use with Akida Execution Engine later</span>
<span class="n">raw_x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>

<span class="c1"># Rescale x-data</span>
<span class="n">a</span> <span class="o">=</span> <span class="mi">255</span>
<span class="n">b</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_train</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">a</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_test</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="n">a</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

     8192/170498071 [..............................] - ETA: 35:00
    40960/170498071 [..............................] - ETA: 14:05
    90112/170498071 [..............................] - ETA: 9:31 
   122880/170498071 [..............................] - ETA: 9:32
   286720/170498071 [..............................] - ETA: 5:00
   385024/170498071 [..............................] - ETA: 4:27
   483328/170498071 [..............................] - ETA: 3:53
   516096/170498071 [..............................] - ETA: 3:56
   598016/170498071 [..............................] - ETA: 3:48
   712704/170498071 [..............................] - ETA: 3:36
   827392/170498071 [..............................] - ETA: 3:26
   942080/170498071 [..............................] - ETA: 3:19
  1056768/170498071 [..............................] - ETA: 3:06
  1089536/170498071 [..............................] - ETA: 3:09
  1187840/170498071 [..............................] - ETA: 3:06
  1302528/170498071 [..............................] - ETA: 3:02
  1417216/170498071 [..............................] - ETA: 2:54
  1449984/170498071 [..............................] - ETA: 2:56
  1548288/170498071 [..............................] - ETA: 2:51
  1581056/170498071 [..............................] - ETA: 2:53
  1679360/170498071 [..............................] - ETA: 2:51
  1810432/170498071 [..............................] - ETA: 2:48
  1941504/170498071 [..............................] - ETA: 2:45
  2072576/170498071 [..............................] - ETA: 2:43
  2203648/170498071 [..............................] - ETA: 2:40
  2334720/170498071 [..............................] - ETA: 2:36
  2383872/170498071 [..............................] - ETA: 2:36
  2482176/170498071 [..............................] - ETA: 2:36
  2613248/170498071 [..............................] - ETA: 2:34
  2744320/170498071 [..............................] - ETA: 2:30
  2793472/170498071 [..............................] - ETA: 2:31
  2891776/170498071 [..............................] - ETA: 2:30
  3022848/170498071 [..............................] - ETA: 2:27
  3072000/170498071 [..............................] - ETA: 2:28
  3170304/170498071 [..............................] - ETA: 2:27
  3317760/170498071 [..............................] - ETA: 2:26
  3448832/170498071 [..............................] - ETA: 2:23
  3497984/170498071 [..............................] - ETA: 2:23
  3596288/170498071 [..............................] - ETA: 2:23
  3743744/170498071 [..............................] - ETA: 2:22
  3874816/170498071 [..............................] - ETA: 2:20
  3923968/170498071 [..............................] - ETA: 2:20
  4022272/170498071 [..............................] - ETA: 2:20
  4169728/170498071 [..............................] - ETA: 2:19
  4317184/170498071 [..............................] - ETA: 2:18
  4448256/170498071 [..............................] - ETA: 2:16
  4497408/170498071 [..............................] - ETA: 2:16
  4595712/170498071 [..............................] - ETA: 2:15
  4661248/170498071 [..............................] - ETA: 2:15
  4759552/170498071 [..............................] - ETA: 2:15
  4890624/170498071 [..............................] - ETA: 2:15
  5038080/170498071 [..............................] - ETA: 2:14
  5185536/170498071 [..............................] - ETA: 2:13
  5316608/170498071 [..............................] - ETA: 2:12
  5365760/170498071 [..............................] - ETA: 2:12
  5464064/170498071 [..............................] - ETA: 2:11
  5513216/170498071 [..............................] - ETA: 2:11
  5611520/170498071 [..............................] - ETA: 2:11
  5758976/170498071 [&gt;.............................] - ETA: 2:11
  5906432/170498071 [&gt;.............................] - ETA: 2:10
  6037504/170498071 [&gt;.............................] - ETA: 2:09
  6086656/170498071 [&gt;.............................] - ETA: 2:09
  6201344/170498071 [&gt;.............................] - ETA: 2:09
  6332416/170498071 [&gt;.............................] - ETA: 2:08
  6365184/170498071 [&gt;.............................] - ETA: 2:08
  6479872/170498071 [&gt;.............................] - ETA: 2:08
  6610944/170498071 [&gt;.............................] - ETA: 2:07
  6660096/170498071 [&gt;.............................] - ETA: 2:07
  6774784/170498071 [&gt;.............................] - ETA: 2:07
  6905856/170498071 [&gt;.............................] - ETA: 2:06
  6938624/170498071 [&gt;.............................] - ETA: 2:07
  7069696/170498071 [&gt;.............................] - ETA: 2:06
  7200768/170498071 [&gt;.............................] - ETA: 2:06
  7348224/170498071 [&gt;.............................] - ETA: 2:06
  7479296/170498071 [&gt;.............................] - ETA: 2:04
  7528448/170498071 [&gt;.............................] - ETA: 2:05
  7643136/170498071 [&gt;.............................] - ETA: 2:05
  7774208/170498071 [&gt;.............................] - ETA: 2:04
  7806976/170498071 [&gt;.............................] - ETA: 2:04
  7938048/170498071 [&gt;.............................] - ETA: 2:04
  8069120/170498071 [&gt;.............................] - ETA: 2:04
  8200192/170498071 [&gt;.............................] - ETA: 2:03
  8249344/170498071 [&gt;.............................] - ETA: 2:03
  8364032/170498071 [&gt;.............................] - ETA: 2:03
  8495104/170498071 [&gt;.............................] - ETA: 2:02
  8544256/170498071 [&gt;.............................] - ETA: 2:02
  8658944/170498071 [&gt;.............................] - ETA: 2:02
  8790016/170498071 [&gt;.............................] - ETA: 2:01
  8839168/170498071 [&gt;.............................] - ETA: 2:02
  8953856/170498071 [&gt;.............................] - ETA: 2:02
  9084928/170498071 [&gt;.............................] - ETA: 2:01
  9134080/170498071 [&gt;.............................] - ETA: 2:01
  9248768/170498071 [&gt;.............................] - ETA: 2:01
  9379840/170498071 [&gt;.............................] - ETA: 2:00
  9428992/170498071 [&gt;.............................] - ETA: 2:00
  9543680/170498071 [&gt;.............................] - ETA: 2:00
  9691136/170498071 [&gt;.............................] - ETA: 2:00
  9838592/170498071 [&gt;.............................] - ETA: 1:59
  9887744/170498071 [&gt;.............................] - ETA: 1:59
 10002432/170498071 [&gt;.............................] - ETA: 1:59
 10149888/170498071 [&gt;.............................] - ETA: 1:58
 10199040/170498071 [&gt;.............................] - ETA: 1:58
 10313728/170498071 [&gt;.............................] - ETA: 1:58
 10461184/170498071 [&gt;.............................] - ETA: 1:58
 10510336/170498071 [&gt;.............................] - ETA: 1:58
 10625024/170498071 [&gt;.............................] - ETA: 1:58
 10788864/170498071 [&gt;.............................] - ETA: 1:57
 10952704/170498071 [&gt;.............................] - ETA: 1:57
 11116544/170498071 [&gt;.............................] - ETA: 1:56
 11280384/170498071 [&gt;.............................] - ETA: 1:56
 11444224/170498071 [=&gt;............................] - ETA: 1:56
 11608064/170498071 [=&gt;............................] - ETA: 1:55
 11788288/170498071 [=&gt;............................] - ETA: 1:55
 11952128/170498071 [=&gt;............................] - ETA: 1:54
 12132352/170498071 [=&gt;............................] - ETA: 1:54
 12312576/170498071 [=&gt;............................] - ETA: 1:53
 12492800/170498071 [=&gt;............................] - ETA: 1:53
 12673024/170498071 [=&gt;............................] - ETA: 1:52
 12722176/170498071 [=&gt;............................] - ETA: 1:52
 12869632/170498071 [=&gt;............................] - ETA: 1:51
 13049856/170498071 [=&gt;............................] - ETA: 1:50
 13099008/170498071 [=&gt;............................] - ETA: 1:51
 13246464/170498071 [=&gt;............................] - ETA: 1:50
 13443072/170498071 [=&gt;............................] - ETA: 1:50
 13639680/170498071 [=&gt;............................] - ETA: 1:49
 13852672/170498071 [=&gt;............................] - ETA: 1:49
 14049280/170498071 [=&gt;............................] - ETA: 1:47
 14098432/170498071 [=&gt;............................] - ETA: 1:48
 14262272/170498071 [=&gt;............................] - ETA: 1:47
 14475264/170498071 [=&gt;............................] - ETA: 1:47
 14688256/170498071 [=&gt;............................] - ETA: 1:45
 14721024/170498071 [=&gt;............................] - ETA: 1:46
 14917632/170498071 [=&gt;............................] - ETA: 1:45
 14983168/170498071 [=&gt;............................] - ETA: 1:45
 15163392/170498071 [=&gt;............................] - ETA: 1:44
 15376384/170498071 [=&gt;............................] - ETA: 1:43
 15425536/170498071 [=&gt;............................] - ETA: 1:43
 15622144/170498071 [=&gt;............................] - ETA: 1:43
 15867904/170498071 [=&gt;............................] - ETA: 1:42
 16113664/170498071 [=&gt;............................] - ETA: 1:41
 16359424/170498071 [=&gt;............................] - ETA: 1:40
 16392192/170498071 [=&gt;............................] - ETA: 1:40
 16621568/170498071 [=&gt;............................] - ETA: 1:39
 16670720/170498071 [=&gt;............................] - ETA: 1:39
 16900096/170498071 [=&gt;............................] - ETA: 1:39
 17154048/170498071 [==&gt;...........................] - ETA: 1:38
 17178624/170498071 [==&gt;...........................] - ETA: 1:38
 17440768/170498071 [==&gt;...........................] - ETA: 1:37
 17489920/170498071 [==&gt;...........................] - ETA: 1:37
 17735680/170498071 [==&gt;...........................] - ETA: 1:36
 18014208/170498071 [==&gt;...........................] - ETA: 1:35
 18046976/170498071 [==&gt;...........................] - ETA: 1:35
 18325504/170498071 [==&gt;...........................] - ETA: 1:34
 18571264/170498071 [==&gt;...........................] - ETA: 1:33
 18653184/170498071 [==&gt;...........................] - ETA: 1:33
 18915328/170498071 [==&gt;...........................] - ETA: 1:32
 18980864/170498071 [==&gt;...........................] - ETA: 1:32
 19259392/170498071 [==&gt;...........................] - ETA: 1:31
 19308544/170498071 [==&gt;...........................] - ETA: 1:31
 19603456/170498071 [==&gt;...........................] - ETA: 1:30
 19890176/170498071 [==&gt;...........................] - ETA: 1:29
 19963904/170498071 [==&gt;...........................] - ETA: 1:29
 20291584/170498071 [==&gt;...........................] - ETA: 1:28
 20602880/170498071 [==&gt;...........................] - ETA: 1:27
 20668416/170498071 [==&gt;...........................] - ETA: 1:27
 20996096/170498071 [==&gt;...........................] - ETA: 1:26
 21323776/170498071 [==&gt;...........................] - ETA: 1:25
 21405696/170498071 [==&gt;...........................] - ETA: 1:25
 21749760/170498071 [==&gt;...........................] - ETA: 1:24
 22077440/170498071 [==&gt;...........................] - ETA: 1:23
 22167552/170498071 [==&gt;...........................] - ETA: 1:23
 22503424/170498071 [==&gt;...........................] - ETA: 1:22
 22568960/170498071 [==&gt;...........................] - ETA: 1:22
 22945792/170498071 [===&gt;..........................] - ETA: 1:21
 23273472/170498071 [===&gt;..........................] - ETA: 1:20
 23371776/170498071 [===&gt;..........................] - ETA: 1:20
 23732224/170498071 [===&gt;..........................] - ETA: 1:19
 23830528/170498071 [===&gt;..........................] - ETA: 1:19
 24223744/170498071 [===&gt;..........................] - ETA: 1:18
 24289280/170498071 [===&gt;..........................] - ETA: 1:18
 24698880/170498071 [===&gt;..........................] - ETA: 1:17
 25092096/170498071 [===&gt;..........................] - ETA: 1:16
 25190400/170498071 [===&gt;..........................] - ETA: 1:16
 25600000/170498071 [===&gt;..........................] - ETA: 1:15
 25681920/170498071 [===&gt;..........................] - ETA: 1:15
 26107904/170498071 [===&gt;..........................] - ETA: 1:14
 26501120/170498071 [===&gt;..........................] - ETA: 1:13
 26632192/170498071 [===&gt;..........................] - ETA: 1:12
 27058176/170498071 [===&gt;..........................] - ETA: 1:11
 27156480/170498071 [===&gt;..........................] - ETA: 1:11
 27631616/170498071 [===&gt;..........................] - ETA: 1:10
 27697152/170498071 [===&gt;..........................] - ETA: 1:10
 28172288/170498071 [===&gt;..........................] - ETA: 1:09
 28598272/170498071 [====&gt;.........................] - ETA: 1:08
 28729344/170498071 [====&gt;.........................] - ETA: 1:08
 29171712/170498071 [====&gt;.........................] - ETA: 1:07
 29335552/170498071 [====&gt;.........................] - ETA: 1:07
 29843456/170498071 [====&gt;.........................] - ETA: 1:06
 29925376/170498071 [====&gt;.........................] - ETA: 1:06
 30449664/170498071 [====&gt;.........................] - ETA: 1:05
 30908416/170498071 [====&gt;.........................] - ETA: 1:04
 31072256/170498071 [====&gt;.........................] - ETA: 1:04
 31547392/170498071 [====&gt;.........................] - ETA: 1:03
 31727616/170498071 [====&gt;.........................] - ETA: 1:02
 32235520/170498071 [====&gt;.........................] - ETA: 1:01
 32382976/170498071 [====&gt;.........................] - ETA: 1:01
 32956416/170498071 [====&gt;.........................] - ETA: 1:00
 33464320/170498071 [====&gt;.........................] - ETA: 59s 
 33644544/170498071 [====&gt;.........................] - ETA: 59s
 34168832/170498071 [=====&gt;........................] - ETA: 58s
 34381824/170498071 [=====&gt;........................] - ETA: 58s
 34922496/170498071 [=====&gt;........................] - ETA: 57s
 35086336/170498071 [=====&gt;........................] - ETA: 57s
 35708928/170498071 [=====&gt;........................] - ETA: 56s
 36265984/170498071 [=====&gt;........................] - ETA: 55s
 36462592/170498071 [=====&gt;........................] - ETA: 55s
 37036032/170498071 [=====&gt;........................] - ETA: 54s
 37232640/170498071 [=====&gt;........................] - ETA: 54s
 37822464/170498071 [=====&gt;........................] - ETA: 53s
 38051840/170498071 [=====&gt;........................] - ETA: 53s
 38723584/170498071 [=====&gt;........................] - ETA: 52s
 39362560/170498071 [=====&gt;........................] - ETA: 51s
 39559168/170498071 [=====&gt;........................] - ETA: 51s
 40198144/170498071 [======&gt;.......................] - ETA: 50s
 40411136/170498071 [======&gt;.......................] - ETA: 50s
 41050112/170498071 [======&gt;.......................] - ETA: 49s
 41295872/170498071 [======&gt;.......................] - ETA: 49s
 42049536/170498071 [======&gt;.......................] - ETA: 48s
 42704896/170498071 [======&gt;.......................] - ETA: 47s
 42950656/170498071 [======&gt;.......................] - ETA: 47s
 43655168/170498071 [======&gt;.......................] - ETA: 46s
 43900928/170498071 [======&gt;.......................] - ETA: 46s
 44589056/170498071 [======&gt;.......................] - ETA: 45s
 44867584/170498071 [======&gt;.......................] - ETA: 45s
 45670400/170498071 [=======&gt;......................] - ETA: 44s
 46391296/170498071 [=======&gt;......................] - ETA: 43s
 46653440/170498071 [=======&gt;......................] - ETA: 43s
 47407104/170498071 [=======&gt;......................] - ETA: 42s
 47652864/170498071 [=======&gt;......................] - ETA: 42s
 48455680/170498071 [=======&gt;......................] - ETA: 41s
 48750592/170498071 [=======&gt;......................] - ETA: 41s
 49487872/170498071 [=======&gt;......................] - ETA: 40s
 49782784/170498071 [=======&gt;......................] - ETA: 40s
 50601984/170498071 [=======&gt;......................] - ETA: 39s
 50847744/170498071 [=======&gt;......................] - ETA: 39s
 51748864/170498071 [========&gt;.....................] - ETA: 38s
 52568064/170498071 [========&gt;.....................] - ETA: 37s
 52862976/170498071 [========&gt;.....................] - ETA: 37s
 53780480/170498071 [========&gt;.....................] - ETA: 36s
 54042624/170498071 [========&gt;.....................] - ETA: 36s
 54943744/170498071 [========&gt;.....................] - ETA: 35s
 55255040/170498071 [========&gt;.....................] - ETA: 35s
 56172544/170498071 [========&gt;.....................] - ETA: 34s
 56434688/170498071 [========&gt;.....................] - ETA: 34s
 57450496/170498071 [=========&gt;....................] - ETA: 33s
 58335232/170498071 [=========&gt;....................] - ETA: 33s
 58695680/170498071 [=========&gt;....................] - ETA: 33s
 59695104/170498071 [=========&gt;....................] - ETA: 32s
 60014592/170498071 [=========&gt;....................] - ETA: 32s
 60989440/170498071 [=========&gt;....................] - ETA: 31s
 61341696/170498071 [=========&gt;....................] - ETA: 31s
 62316544/170498071 [=========&gt;....................] - ETA: 30s
 62660608/170498071 [==========&gt;...................] - ETA: 30s
 63676416/170498071 [==========&gt;...................] - ETA: 29s
 64004096/170498071 [==========&gt;...................] - ETA: 29s
 65118208/170498071 [==========&gt;...................] - ETA: 28s
 66134016/170498071 [==========&gt;...................] - ETA: 28s
 66543616/170498071 [==========&gt;...................] - ETA: 28s
 67674112/170498071 [==========&gt;...................] - ETA: 27s
 67993600/170498071 [==========&gt;...................] - ETA: 27s
 69148672/170498071 [===========&gt;..................] - ETA: 26s
 69492736/170498071 [===========&gt;..................] - ETA: 26s
 70639616/170498071 [===========&gt;..................] - ETA: 25s
 71000064/170498071 [===========&gt;..................] - ETA: 25s
 72179712/170498071 [===========&gt;..................] - ETA: 24s
 72523776/170498071 [===========&gt;..................] - ETA: 24s
 73736192/170498071 [===========&gt;..................] - ETA: 24s
 74080256/170498071 [============&gt;.................] - ETA: 24s
 75341824/170498071 [============&gt;.................] - ETA: 23s
 76488704/170498071 [============&gt;.................] - ETA: 22s
 76980224/170498071 [============&gt;.................] - ETA: 22s
 78225408/170498071 [============&gt;.................] - ETA: 22s
 78602240/170498071 [============&gt;.................] - ETA: 21s
 79929344/170498071 [=============&gt;................] - ETA: 21s
 80306176/170498071 [=============&gt;................] - ETA: 21s
 81633280/170498071 [=============&gt;................] - ETA: 20s
 82042880/170498071 [=============&gt;................] - ETA: 20s
 83386368/170498071 [=============&gt;................] - ETA: 19s
 83763200/170498071 [=============&gt;................] - ETA: 19s
 85155840/170498071 [=============&gt;................] - ETA: 19s
 85532672/170498071 [==============&gt;...............] - ETA: 19s
 86966272/170498071 [==============&gt;...............] - ETA: 18s
 87334912/170498071 [==============&gt;...............] - ETA: 18s
 88793088/170498071 [==============&gt;...............] - ETA: 17s
 89169920/170498071 [==============&gt;...............] - ETA: 17s
 90644480/170498071 [==============&gt;...............] - ETA: 17s
 91054080/170498071 [===============&gt;..............] - ETA: 16s
 92569600/170498071 [===============&gt;..............] - ETA: 16s
 92954624/170498071 [===============&gt;..............] - ETA: 16s
 94502912/170498071 [===============&gt;..............] - ETA: 15s
 94904320/170498071 [===============&gt;..............] - ETA: 15s
 95084544/170498071 [===============&gt;..............] - ETA: 15s
 97837056/170498071 [================&gt;.............] - ETA: 14s
 98672640/170498071 [================&gt;.............] - ETA: 14s
 99229696/170498071 [================&gt;.............] - ETA: 14s
100016128/170498071 [================&gt;.............] - ETA: 14s
100622336/170498071 [================&gt;.............] - ETA: 13s
101720064/170498071 [================&gt;.............] - ETA: 13s
102064128/170498071 [================&gt;.............] - ETA: 13s
103145472/170498071 [=================&gt;............] - ETA: 13s
103489536/170498071 [=================&gt;............] - ETA: 13s
104579072/170498071 [=================&gt;............] - ETA: 12s
104947712/170498071 [=================&gt;............] - ETA: 12s
106061824/170498071 [=================&gt;............] - ETA: 12s
106422272/170498071 [=================&gt;............] - ETA: 12s
107683840/170498071 [=================&gt;............] - ETA: 11s
107913216/170498071 [=================&gt;............] - ETA: 11s
109207552/170498071 [==================&gt;...........] - ETA: 11s
109699072/170498071 [==================&gt;...........] - ETA: 11s
110714880/170498071 [==================&gt;...........] - ETA: 11s
111452160/170498071 [==================&gt;...........] - ETA: 11s
112254976/170498071 [==================&gt;...........] - ETA: 10s
113254400/170498071 [==================&gt;...........] - ETA: 10s
113827840/170498071 [===================&gt;..........] - ETA: 10s
114663424/170498071 [===================&gt;..........] - ETA: 10s
115384320/170498071 [===================&gt;..........] - ETA: 10s
116269056/170498071 [===================&gt;..........] - ETA: 9s 
116957184/170498071 [===================&gt;..........] - ETA: 9s
117841920/170498071 [===================&gt;..........] - ETA: 9s
118530048/170498071 [===================&gt;..........] - ETA: 9s
119496704/170498071 [====================&gt;.........] - ETA: 9s
120119296/170498071 [====================&gt;.........] - ETA: 8s
121184256/170498071 [====================&gt;.........] - ETA: 8s
121774080/170498071 [====================&gt;.........] - ETA: 8s
122822656/170498071 [====================&gt;.........] - ETA: 8s
123428864/170498071 [====================&gt;.........] - ETA: 8s
124469248/170498071 [====================&gt;.........] - ETA: 7s
125067264/170498071 [=====================&gt;........] - ETA: 7s
126197760/170498071 [=====================&gt;........] - ETA: 7s
126738432/170498071 [=====================&gt;........] - ETA: 7s
127885312/170498071 [=====================&gt;........] - ETA: 7s
128409600/170498071 [=====================&gt;........] - ETA: 7s
129654784/170498071 [=====================&gt;........] - ETA: 6s
130097152/170498071 [=====================&gt;........] - ETA: 6s
131342336/170498071 [======================&gt;.......] - ETA: 6s
131973120/170498071 [======================&gt;.......] - ETA: 6s
133029888/170498071 [======================&gt;.......] - ETA: 6s
133865472/170498071 [======================&gt;.......] - ETA: 6s
134733824/170498071 [======================&gt;.......] - ETA: 5s
135684096/170498071 [======================&gt;.......] - ETA: 5s
136503296/170498071 [=======================&gt;......] - ETA: 5s
137437184/170498071 [=======================&gt;......] - ETA: 5s
138272768/170498071 [=======================&gt;......] - ETA: 5s
139337728/170498071 [=======================&gt;......] - ETA: 5s
140009472/170498071 [=======================&gt;......] - ETA: 4s
141205504/170498071 [=======================&gt;......] - ETA: 4s
141811712/170498071 [=======================&gt;......] - ETA: 4s
142974976/170498071 [========================&gt;.....] - ETA: 4s
143581184/170498071 [========================&gt;.....] - ETA: 4s
144785408/170498071 [========================&gt;.....] - ETA: 4s
145350656/170498071 [========================&gt;.....] - ETA: 3s
146694144/170498071 [========================&gt;.....] - ETA: 3s
147136512/170498071 [========================&gt;.....] - ETA: 3s
148463616/170498071 [=========================&gt;....] - ETA: 3s
149053440/170498071 [=========================&gt;....] - ETA: 3s
150265856/170498071 [=========================&gt;....] - ETA: 3s
151134208/170498071 [=========================&gt;....] - ETA: 2s
152051712/170498071 [=========================&gt;....] - ETA: 2s
153067520/170498071 [=========================&gt;....] - ETA: 2s
153886720/170498071 [==========================&gt;...] - ETA: 2s
154918912/170498071 [==========================&gt;...] - ETA: 2s
155738112/170498071 [==========================&gt;...] - ETA: 2s
156753920/170498071 [==========================&gt;...] - ETA: 2s
157556736/170498071 [==========================&gt;...] - ETA: 1s
158703616/170498071 [==========================&gt;...] - ETA: 1s
159399936/170498071 [===========================&gt;..] - ETA: 1s
160555008/170498071 [===========================&gt;..] - ETA: 1s
161210368/170498071 [===========================&gt;..] - ETA: 1s
162488320/170498071 [===========================&gt;..] - ETA: 1s
163094528/170498071 [===========================&gt;..] - ETA: 1s
164356096/170498071 [===========================&gt;..] - ETA: 0s
164995072/170498071 [============================&gt;.] - ETA: 0s
166387712/170498071 [============================&gt;.] - ETA: 0s
166846464/170498071 [============================&gt;.] - ETA: 0s
168271872/170498071 [============================&gt;.] - ETA: 0s
168812544/170498071 [============================&gt;.] - ETA: 0s
170139648/170498071 [============================&gt;.] - ETA: 0s
170500096/170498071 [==============================] - 24s 0us/step
</pre></div>
</div>
</div>
<div class="section" id="create-a-keras-ds-cnn-model">
<h2>2. Create a Keras DS-CNN model<a class="headerlink" href="#create-a-keras-ds-cnn-model" title="Permalink to this headline">¶</a></h2>
<p>The DS-CNN architecture is available in the <a class="reference external" href="../api_reference/akida_models_apis.html#cifar-10">Akida models zoo</a> along with pretrained
weights.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The pre-trained weights were obtained after training the model with
unconstrained float weights and activations for 1000 epochs</p>
</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">get_file</span>
<span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">ds_cnn_cifar10</span>

<span class="c1"># Retrieve model file from Brainchip data server</span>
<span class="n">weights_file</span> <span class="o">=</span> <span class="n">get_file</span><span class="p">(</span>
    <span class="s2">&quot;ds_cnn_cifar10.h5&quot;</span><span class="p">,</span>
    <span class="s2">&quot;http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10.h5&quot;</span><span class="p">,</span>
    <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;models/ds_cnn_cifar10&#39;</span><span class="p">)</span>

<span class="c1"># Instantiate the model and load pretrained weights</span>
<span class="n">model_keras</span> <span class="o">=</span> <span class="n">ds_cnn_cifar10</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights_file</span><span class="p">)</span>
<span class="n">model_keras</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10.h5

    8192/10836232 [..............................] - ETA: 24s
   73728/10836232 [..............................] - ETA: 11s
  270336/10836232 [..............................] - ETA: 5s 
  466944/10836232 [&gt;.............................] - ETA: 4s
  663552/10836232 [&gt;.............................] - ETA: 3s
  860160/10836232 [=&gt;............................] - ETA: 3s
 1056768/10836232 [=&gt;............................] - ETA: 3s
 1253376/10836232 [==&gt;...........................] - ETA: 3s
 1384448/10836232 [==&gt;...........................] - ETA: 3s
 1581056/10836232 [===&gt;..........................] - ETA: 3s
 1777664/10836232 [===&gt;..........................] - ETA: 3s
 1974272/10836232 [====&gt;.........................] - ETA: 3s
 2170880/10836232 [=====&gt;........................] - ETA: 2s
 2367488/10836232 [=====&gt;........................] - ETA: 2s
 2564096/10836232 [======&gt;.......................] - ETA: 2s
 2760704/10836232 [======&gt;.......................] - ETA: 2s
 2957312/10836232 [=======&gt;......................] - ETA: 2s
 3153920/10836232 [=======&gt;......................] - ETA: 2s
 3350528/10836232 [========&gt;.....................] - ETA: 2s
 3547136/10836232 [========&gt;.....................] - ETA: 2s
 3743744/10836232 [=========&gt;....................] - ETA: 2s
 3940352/10836232 [=========&gt;....................] - ETA: 2s
 4136960/10836232 [==========&gt;...................] - ETA: 2s
 4333568/10836232 [==========&gt;...................] - ETA: 2s
 4530176/10836232 [===========&gt;..................] - ETA: 2s
 4726784/10836232 [============&gt;.................] - ETA: 1s
 4923392/10836232 [============&gt;.................] - ETA: 1s
 5120000/10836232 [=============&gt;................] - ETA: 1s
 5316608/10836232 [=============&gt;................] - ETA: 1s
 5513216/10836232 [==============&gt;...............] - ETA: 1s
 5709824/10836232 [==============&gt;...............] - ETA: 1s
 5906432/10836232 [===============&gt;..............] - ETA: 1s
 6103040/10836232 [===============&gt;..............] - ETA: 1s
 6299648/10836232 [================&gt;.............] - ETA: 1s
 6496256/10836232 [================&gt;.............] - ETA: 1s
 6692864/10836232 [=================&gt;............] - ETA: 1s
 6889472/10836232 [==================&gt;...........] - ETA: 1s
 7086080/10836232 [==================&gt;...........] - ETA: 1s
 7282688/10836232 [===================&gt;..........] - ETA: 1s
 7479296/10836232 [===================&gt;..........] - ETA: 1s
 7675904/10836232 [====================&gt;.........] - ETA: 0s
 7872512/10836232 [====================&gt;.........] - ETA: 0s
 8069120/10836232 [=====================&gt;........] - ETA: 0s
 8265728/10836232 [=====================&gt;........] - ETA: 0s
 8462336/10836232 [======================&gt;.......] - ETA: 0s
 8658944/10836232 [======================&gt;.......] - ETA: 0s
 8855552/10836232 [=======================&gt;......] - ETA: 0s
 9052160/10836232 [========================&gt;.....] - ETA: 0s
 9248768/10836232 [========================&gt;.....] - ETA: 0s
 9445376/10836232 [=========================&gt;....] - ETA: 0s
 9641984/10836232 [=========================&gt;....] - ETA: 0s
 9838592/10836232 [==========================&gt;...] - ETA: 0s
10035200/10836232 [==========================&gt;...] - ETA: 0s
10231808/10836232 [===========================&gt;..] - ETA: 0s
10428416/10836232 [===========================&gt;..] - ETA: 0s
10625024/10836232 [============================&gt;.] - ETA: 0s
10821632/10836232 [============================&gt;.] - ETA: 0s
10838016/10836232 [==============================] - 3s 0us/step
Model: &quot;ds_cnn_cifar10&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0
_________________________________________________________________
conv_0 (Conv2D)              (None, 32, 32, 128)       3456
_________________________________________________________________
conv_0_BN (BatchNormalizatio (None, 32, 32, 128)       512
_________________________________________________________________
conv_0_relu (ReLU)           (None, 32, 32, 128)       0
_________________________________________________________________
separable_1 (SeparableConv2D (None, 32, 32, 128)       17536
_________________________________________________________________
separable_1_BN (BatchNormali (None, 32, 32, 128)       512
_________________________________________________________________
separable_1_relu (ReLU)      (None, 32, 32, 128)       0
_________________________________________________________________
separable_2 (SeparableConv2D (None, 32, 32, 256)       33920
_________________________________________________________________
separable_2_BN (BatchNormali (None, 32, 32, 256)       1024
_________________________________________________________________
separable_2_relu (ReLU)      (None, 32, 32, 256)       0
_________________________________________________________________
separable_3 (SeparableConv2D (None, 32, 32, 256)       67840
_________________________________________________________________
separable_3_maxpool (MaxPool (None, 16, 16, 256)       0
_________________________________________________________________
separable_3_BN (BatchNormali (None, 16, 16, 256)       1024
_________________________________________________________________
separable_3_relu (ReLU)      (None, 16, 16, 256)       0
_________________________________________________________________
separable_4 (SeparableConv2D (None, 16, 16, 512)       133376
_________________________________________________________________
separable_4_BN (BatchNormali (None, 16, 16, 512)       2048
_________________________________________________________________
separable_4_relu (ReLU)      (None, 16, 16, 512)       0
_________________________________________________________________
separable_5 (SeparableConv2D (None, 16, 16, 512)       266752
_________________________________________________________________
separable_5_maxpool (MaxPool (None, 8, 8, 512)         0
_________________________________________________________________
separable_5_BN (BatchNormali (None, 8, 8, 512)         2048
_________________________________________________________________
separable_5_relu (ReLU)      (None, 8, 8, 512)         0
_________________________________________________________________
separable_6 (SeparableConv2D (None, 8, 8, 512)         266752
_________________________________________________________________
separable_6_BN (BatchNormali (None, 8, 8, 512)         2048
_________________________________________________________________
separable_6_relu (ReLU)      (None, 8, 8, 512)         0
_________________________________________________________________
separable_7 (SeparableConv2D (None, 8, 8, 512)         266752
_________________________________________________________________
separable_7_maxpool (MaxPool (None, 4, 4, 512)         0
_________________________________________________________________
separable_7_BN (BatchNormali (None, 4, 4, 512)         2048
_________________________________________________________________
separable_7_relu (ReLU)      (None, 4, 4, 512)         0
_________________________________________________________________
separable_8 (SeparableConv2D (None, 4, 4, 1024)        528896
_________________________________________________________________
separable_8_BN (BatchNormali (None, 4, 4, 1024)        4096
_________________________________________________________________
separable_8_relu (ReLU)      (None, 4, 4, 1024)        0
_________________________________________________________________
separable_9 (SeparableConv2D (None, 4, 4, 1024)        1057792
_________________________________________________________________
separable_9_BN (BatchNormali (None, 4, 4, 1024)        4096
_________________________________________________________________
separable_9_relu (ReLU)      (None, 4, 4, 1024)        0
_________________________________________________________________
separable_10 (SeparableConv2 (None, 4, 4, 10)          19456
_________________________________________________________________
separable_10_global_avg (Glo (None, 10)                0
=================================================================
Total params: 2,681,984
Trainable params: 2,672,256
Non-trainable params: 9,728
_________________________________________________________________
</pre></div>
</div>
<p>Keras model accuracy is checked against the first <em>n</em> images of the test set.</p>
<p>The table below summarizes the expected results:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 47%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on your hardware setup, the processing time may vary.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>


<span class="c1"># Check Model performance</span>
<span class="k">def</span> <span class="nf">check_model_performances</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">potentials_keras</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">])</span>
    <span class="n">preds_keras</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">potentials_keras</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">preds_keras</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Keras inference on </span><span class="si">{</span><span class="n">num_images</span><span class="si">}</span><span class="s1"> images took </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> s.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 94.30%
Keras inference on 1000 images took 1.36 s.
</pre></div>
</div>
</div>
<div class="section" id="quantized-model">
<h2>3. Quantized model<a class="headerlink" href="#quantized-model" title="Permalink to this headline">¶</a></h2>
<p>Quantizing a model is done using <a class="reference external" href="../api_reference/cnn2snn_apis.html#quantize">CNN2SNN quantize</a>. After the call, all the
layers will have 4-bit weights and 4-bit activations.</p>
<p>This model will therefore satisfy the Akida NSoC requirements but will suffer
from a drop in accuracy due to quantization as shown in the table below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 36%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Float accuracy</p></th>
<th class="head"><p>Quantized accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>96.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>92.60 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>92.58 %</p></td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">quantize</span>

<span class="c1"># Quantize the model to 4-bit weights and activations</span>
<span class="n">model_keras_quantized</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Check Model performance</span>
<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras_quantized</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 92.60%
Keras inference on 1000 images took 2.21 s.
</pre></div>
</div>
</div>
<div class="section" id="pretrained-quantized-model">
<h2>4. Pretrained quantized model<a class="headerlink" href="#pretrained-quantized-model" title="Permalink to this headline">¶</a></h2>
<p>The Akida models zoo also contains a <a class="reference external" href="../api_reference/akida_models_apis.html#akida_models.ds_cnn_cifar10_pretrained">pretrained quantized helper</a>
that was obtained using the <a class="reference external" href="../user_guide/akida_models.html#cifar10-training-and-tuning">tune</a>
action of <code class="docutils literal notranslate"><span class="pre">akida_models</span></code> CLI on the quantized model for 100 epochs.</p>
<p>Tuning the model, that is training with a lowered learning rate, allows to
recover performances up to the initial floating point accuracy.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 27%" />
<col style="width: 34%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Float accuracy</p></th>
<th class="head"><p>Quantized accuracy</p></th>
<th class="head"><p>After tuning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>96.00 %</p></td>
<td><p>95.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>92.60 %</p></td>
<td><p>93.10 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>92.58 %</p></td>
<td><p>93.26 %</p></td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">ds_cnn_cifar10_pretrained</span>

<span class="c1"># Use a quantized model with pretrained quantized weights</span>
<span class="n">model_keras_quantized_pretrained</span> <span class="o">=</span> <span class="n">ds_cnn_cifar10_pretrained</span><span class="p">()</span>

<span class="c1"># Check Model performance</span>
<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras_quantized_pretrained</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10_wq4_aq4.hdf5

    8192/10835640 [..............................] - ETA: 24s
   73728/10835640 [..............................] - ETA: 11s
  270336/10835640 [..............................] - ETA: 5s 
  466944/10835640 [&gt;.............................] - ETA: 4s
  663552/10835640 [&gt;.............................] - ETA: 3s
  860160/10835640 [=&gt;............................] - ETA: 3s
 1056768/10835640 [=&gt;............................] - ETA: 3s
 1253376/10835640 [==&gt;...........................] - ETA: 3s
 1449984/10835640 [===&gt;..........................] - ETA: 3s
 1646592/10835640 [===&gt;..........................] - ETA: 3s
 1843200/10835640 [====&gt;.........................] - ETA: 2s
 2039808/10835640 [====&gt;.........................] - ETA: 2s
 2236416/10835640 [=====&gt;........................] - ETA: 2s
 2433024/10835640 [=====&gt;........................] - ETA: 2s
 2629632/10835640 [======&gt;.......................] - ETA: 2s
 2826240/10835640 [======&gt;.......................] - ETA: 2s
 3022848/10835640 [=======&gt;......................] - ETA: 2s
 3219456/10835640 [=======&gt;......................] - ETA: 2s
 3416064/10835640 [========&gt;.....................] - ETA: 2s
 3612672/10835640 [=========&gt;....................] - ETA: 2s
 3809280/10835640 [=========&gt;....................] - ETA: 2s
 4005888/10835640 [==========&gt;...................] - ETA: 2s
 4202496/10835640 [==========&gt;...................] - ETA: 2s
 4399104/10835640 [===========&gt;..................] - ETA: 2s
 4595712/10835640 [===========&gt;..................] - ETA: 1s
 4792320/10835640 [============&gt;.................] - ETA: 1s
 4988928/10835640 [============&gt;.................] - ETA: 1s
 5185536/10835640 [=============&gt;................] - ETA: 1s
 5382144/10835640 [=============&gt;................] - ETA: 1s
 5578752/10835640 [==============&gt;...............] - ETA: 1s
 5775360/10835640 [==============&gt;...............] - ETA: 1s
 5971968/10835640 [===============&gt;..............] - ETA: 1s
 6168576/10835640 [================&gt;.............] - ETA: 1s
 6365184/10835640 [================&gt;.............] - ETA: 1s
 6561792/10835640 [=================&gt;............] - ETA: 1s
 6758400/10835640 [=================&gt;............] - ETA: 1s
 6955008/10835640 [==================&gt;...........] - ETA: 1s
 7151616/10835640 [==================&gt;...........] - ETA: 1s
 7348224/10835640 [===================&gt;..........] - ETA: 1s
 7544832/10835640 [===================&gt;..........] - ETA: 1s
 7741440/10835640 [====================&gt;.........] - ETA: 0s
 7938048/10835640 [====================&gt;.........] - ETA: 0s
 8134656/10835640 [=====================&gt;........] - ETA: 0s
 8331264/10835640 [======================&gt;.......] - ETA: 0s
 8527872/10835640 [======================&gt;.......] - ETA: 0s
 8724480/10835640 [=======================&gt;......] - ETA: 0s
 8921088/10835640 [=======================&gt;......] - ETA: 0s
 9117696/10835640 [========================&gt;.....] - ETA: 0s
 9314304/10835640 [========================&gt;.....] - ETA: 0s
 9510912/10835640 [=========================&gt;....] - ETA: 0s
 9707520/10835640 [=========================&gt;....] - ETA: 0s
 9904128/10835640 [==========================&gt;...] - ETA: 0s
10100736/10835640 [==========================&gt;...] - ETA: 0s
10297344/10835640 [===========================&gt;..] - ETA: 0s
10493952/10835640 [============================&gt;.] - ETA: 0s
10690560/10835640 [============================&gt;.] - ETA: 0s
10838016/10835640 [==============================] - 3s 0us/step
Accuracy: 93.00%
Keras inference on 1000 images took 2.42 s.
</pre></div>
</div>
</div>
<div class="section" id="conversion-to-akida">
<h2>5. Conversion to Akida<a class="headerlink" href="#conversion-to-akida" title="Permalink to this headline">¶</a></h2>
<div class="section" id="convert-to-akida-model">
<h3>5.1 Convert to Akida model<a class="headerlink" href="#convert-to-akida-model" title="Permalink to this headline">¶</a></h3>
<p>When converting to an Akida model, we just need to pass the Keras model
and the input scaling that was used during training to <a class="reference external" href="../api_reference/cnn2snn_apis.html#convert">CNN2SNN convert</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">convert</span>

<span class="n">model_akida</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">model_keras_quantized_pretrained</span><span class="p">,</span> <span class="n">input_scaling</span><span class="o">=</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="check-hardware-compliancy">
<h3>5.2 Check hardware compliancy<a class="headerlink" href="#check-hardware-compliancy" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="../api_reference/aee_apis.html#akida.Model.summary">Model.summary()</a>
method provides a detailed description of the Model layers.</p>
<p>It also indicates hardware-incompatibilities if there are any. Hardware
compatibility can also be checked manually using
<a class="reference external" href="../api_reference/aee_apis.html#akida.compatibility.model_hardware_incompatibilities">model_hardware_incompatibilities</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_akida</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>                                       Model Summary
___________________________________________________________________________________________
Layer (type)                           Output shape   Kernel shape
===========================================================================================
conv_0 (InputConvolutional)            [32, 32, 128]  (3, 3, 3, 128)
___________________________________________________________________________________________
separable_1 (SeparableConvolutional)   [32, 32, 128]  (3, 3, 128, 1), (1, 1, 128, 128)
___________________________________________________________________________________________
separable_2 (SeparableConvolutional)   [32, 32, 256]  (3, 3, 128, 1), (1, 1, 128, 256)
___________________________________________________________________________________________
separable_3 (SeparableConvolutional)   [16, 16, 256]  (3, 3, 256, 1), (1, 1, 256, 256)
___________________________________________________________________________________________
separable_4 (SeparableConvolutional)   [16, 16, 512]  (3, 3, 256, 1), (1, 1, 256, 512)
___________________________________________________________________________________________
separable_5 (SeparableConvolutional)   [8, 8, 512]    (3, 3, 512, 1), (1, 1, 512, 512)
___________________________________________________________________________________________
separable_6 (SeparableConvolutional)   [8, 8, 512]    (3, 3, 512, 1), (1, 1, 512, 512)
___________________________________________________________________________________________
separable_7 (SeparableConvolutional)   [4, 4, 512]    (3, 3, 512, 1), (1, 1, 512, 512)
___________________________________________________________________________________________
separable_8 (SeparableConvolutional)   [4, 4, 1024]   (3, 3, 512, 1), (1, 1, 512, 1024)
___________________________________________________________________________________________
separable_9 (SeparableConvolutional)   [4, 4, 1024]   (3, 3, 1024, 1), (1, 1, 1024, 1024)
___________________________________________________________________________________________
separable_10 (SeparableConvolutional)  [1, 1, 10]     (3, 3, 1024, 1), (1, 1, 1024, 10)
___________________________________________________________________________________________
Input shape: 32, 32, 3
Backend type: Software - 1.8.8
</pre></div>
</div>
</div>
<div class="section" id="check-performance">
<h3>5.3 Check performance<a class="headerlink" href="#check-performance" title="Permalink to this headline">¶</a></h3>
<p>We check the Akida model accuracy on the first <em>n</em> images of the test
set.</p>
<p>The table below summarizes the expected results:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 39%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Keras accuracy</p></th>
<th class="head"><p>Akida accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>94.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>93.10 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>93.04 %</p></td>
</tr>
</tbody>
</table>
<p>Due to the conversion process, the predictions may be slightly different
between the original Keras model and Akida on some specific images.</p>
<p>This explains why when testing on a limited number of images the
accuracy numbers between Keras and Akida may be quite different. On the
full test set however, the two models accuracies are very close.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_images</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Check Model performance</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">raw_x_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">])</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">results</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Akida inference on </span><span class="si">{</span><span class="n">num_images</span><span class="si">}</span><span class="s1"> images took </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> s.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># For non-regression purpose</span>
<span class="k">if</span> <span class="n">num_images</span> <span class="o">==</span> <span class="mi">1000</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">accuracy</span> <span class="o">==</span> <span class="mf">0.931</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 93.10%
Akida inference on 1000 images took 7.22 s.
</pre></div>
</div>
<p>Activations sparsity has a great impact on akida inference time. One can have
a look at the average input and output sparsity of each layer using
<a class="reference external" href="../api_reference/aee_apis.html#akida.Model.get_statistics">Model.get_statistics()</a>
For convenience, it is called here on a subset of the dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print model statistics</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model statistics&quot;</span><span class="p">)</span>
<span class="n">stats</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">get_statistics</span><span class="p">()</span>
<span class="n">model_akida</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">raw_x_test</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">stat</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model statistics
Layer (type)                  output sparsity
conv_0 (InputConvolutional)   0.59
Layer (type)                  input sparsity      output sparsity     ops
separable_1 (SeparableConvolu 0.59                0.53                62663175
Layer (type)                  input sparsity      output sparsity     ops
separable_2 (SeparableConvolu 0.53                0.54                143484989
Layer (type)                  input sparsity      output sparsity     ops
separable_3 (SeparableConvolu 0.54                0.61                279008748
Layer (type)                  input sparsity      output sparsity     ops
separable_4 (SeparableConvolu 0.61                0.65                118130331
Layer (type)                  input sparsity      output sparsity     ops
separable_5 (SeparableConvolu 0.65                0.70                214518748
Layer (type)                  input sparsity      output sparsity     ops
separable_6 (SeparableConvolu 0.70                0.68                44972119
Layer (type)                  input sparsity      output sparsity     ops
separable_7 (SeparableConvolu 0.68                0.75                48254114
Layer (type)                  input sparsity      output sparsity     ops
separable_8 (SeparableConvolu 0.75                0.84                18696769
Layer (type)                  input sparsity      output sparsity     ops
separable_9 (SeparableConvolu 0.84                0.84                24647816
Layer (type)                  input sparsity      output sparsity     ops
separable_10 (SeparableConvol 0.84                0.00                260459
</pre></div>
</div>
</div>
<div class="section" id="show-predictions-for-a-random-image">
<h3>5.4 Show predictions for a random image<a class="headerlink" href="#show-predictions-for-a-random-image" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.lines</span> <span class="k">as</span> <span class="nn">lines</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span>
<span class="p">]</span>

<span class="c1"># prepare plot</span>
<span class="n">barWidth</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">pause_time</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="s1">&#39;CIFAR10 Classification by Akida Execution Engine&#39;</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">imgobj</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="c1"># Results subplots</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="s1">&#39;Actual class:&#39;</span><span class="p">)</span>
<span class="n">actual_class</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="s1">&#39;None&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="s1">&#39;Predicted class:&#39;</span><span class="p">)</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="s1">&#39;None&#39;</span><span class="p">)</span>

<span class="c1"># Take a random test image</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">true_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">pot</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">raw_x_test</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="n">rpot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pot</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">rpot</span><span class="p">,</span> <span class="n">pot</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">barWidth</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">rpot</span> <span class="o">-</span> <span class="mf">0.07</span> <span class="o">*</span> <span class="n">barWidth</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">predicted_idx</span> <span class="o">=</span> <span class="n">pot</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="n">imgobj</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">raw_x_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="k">if</span> <span class="n">predicted_idx</span> <span class="o">==</span> <span class="n">true_idx</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">get_children</span><span class="p">()[</span><span class="n">predicted_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">get_children</span><span class="p">()[</span><span class="n">predicted_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">actual_class</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">true_idx</span><span class="p">])</span>
<span class="n">predicted_class</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">predicted_idx</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Akida</span><span class="se">\&#39;</span><span class="s1">s predictions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_plot_ds_cnn_cifar10_001.png" class="sphx-glr-single-img" src="../_images/sphx_glr_plot_ds_cnn_cifar10_001.png" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  48.441 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-plot-ds-cnn-cifar10-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ef92745a1ec0281f8ff7827025975e5e/plot_ds_cnn_cifar10.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_ds_cnn_cifar10.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0fec12542cb7ba334bf6e5cc03f7c114/plot_ds_cnn_cifar10.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_ds_cnn_cifar10.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plot_transfer_learning.html" class="btn btn-neutral float-right" title="Transfer learning with MobileNet for cats vs. dogs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="plot_ds_cnn_kws.html" class="btn btn-neutral float-left" title="DS-CNN/KWS inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright 2020, BrainChip Holdings Ltd. All Rights Reserved.

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>