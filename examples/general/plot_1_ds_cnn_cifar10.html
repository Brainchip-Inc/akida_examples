<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DS-CNN CIFAR10 inference &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="MobileNet/ImageNet inference" href="plot_2_mobilenet_imagenet.html" />
    <link rel="prev" title="GXNOR/MNIST inference" href="plot_0_gxnor_mnist.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #78b3ff" >
            <a href="../../index.html">
            <img src="../../_static/akida.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                MetaTF 2.0.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/aee.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/aee.html#introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#akida-layers">Akida layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#input-format">Input Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#a-versatile-machine-learning-framework">A versatile machine learning framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/aee.html#the-sequential-model">The Sequential model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#specifying-the-model">Specifying the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#accessing-layer-parameters-and-weights">Accessing layer parameters and weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#inference">Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/aee.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/aee.html#id1">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/aee.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#cifar10-training-and-tuning">CIFAR10 training and tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#yolo-training">YOLO training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#akida-nsoc-pre-production">Akida NSoC (Pre-production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#akida-nsoc-production">Akida NSoC (Production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#id1">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#id2">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#id3">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/hw_constraints.html#id4">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/compatibility.html">Akida versions compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/compatibility.html#upgrading-models-with-legacy-quantizers">Upgrading models with legacy quantizers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/aee_apis.html">Akida Execution Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#layerstatistics">LayerStatistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#concat">Concat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#padding">Padding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#pooltype">PoolType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#learningtype">LearningType</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#hwversion">HwVersion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#compatibility">Compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#device">Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#hwdevice">HWDevice</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#sequence">Sequence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#program">Program</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#soc">soc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/aee_apis.html#powermeter">PowerMeter</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#tool-functions">Tool functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantize-layer">quantize_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#load-quantized-model">load_quantized_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#load-partial-weights">load_partial_weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#trainablestdweightquantizer">TrainableStdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizeddepthwiseconv2d">QuantizedDepthwiseConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#dense-block">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#batchnormalization-gamma-constraint">BatchNormalization gamma constraint</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pruning">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#convtiny">ConvTiny</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#general-examples">General examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_0_gxnor_mnist.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_gxnor_mnist.html#create-a-keras-gxnor-model">2. Create a Keras GXNOR model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_gxnor_mnist.html#conversion-to-akida">3. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">DS-CNN CIFAR10 inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-a-keras-ds-cnn-model">2. Create a Keras DS-CNN model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_2_mobilenet_imagenet.html">MobileNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_2_mobilenet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_mobilenet_imagenet.html#create-a-keras-mobilenet-model">2. Create a Keras MobileNet model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_mobilenet_imagenet.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_mobilenet_imagenet.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_mobilenet_imagenet.html#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_3_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_3_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_4_regression.html">Regression tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_4_regression.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_regression.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_5_transfer_learning.html">Transfer learning with MobileNet for cats vs. dogs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#load-and-preprocess-data">1. Load and preprocess data</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#modify-a-pre-trained-base-keras-model">2. Modify a pre-trained base Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#train-the-transferred-model-for-the-new-task">3. Train the transferred model for the new task</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#quantize-the-top-layer">4 Quantize the top layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#convert-to-akida">5. Convert to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_transfer_learning.html#plot-confusion-matrix">6. Plot confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_6_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#cnn2snn-tutorials">CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#load-and-reshape-mnist-dataset">1. Load and reshape MNIST dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#model-definition">2. Model definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#model-training">3. Model training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#model-fine-tuning-quantization-aware-training">5. Model fine tuning (quantization-aware training)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_0_cnn_flow.html#model-conversion">6. Model conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#quantized-activation-layer-details">3. Quantized Activation Layer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../zoo_performances.html">Model zoo performances</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#object-detection">Object detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#regression">Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#time-icon-ref-time-domain"> Time domain</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#fault-detection">Fault detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#id1">Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zoo_performances.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zoo_performances.html#id2">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #78b3ff" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Akida examples</a> &raquo;</li>
      <li>DS-CNN CIFAR10 inference</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-examples-general-plot-1-ds-cnn-cifar10-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="ds-cnn-cifar10-inference">
<span id="sphx-glr-examples-general-plot-1-ds-cnn-cifar10-py"></span><h1>DS-CNN CIFAR10 inference<a class="headerlink" href="#ds-cnn-cifar10-inference" title="Permalink to this headline"></a></h1>
<p>This tutorial uses the CIFAR-10 dataset (60k training images distributed in 10
object classes) for a classic object classification task with a network built
around the Depthwise Separable Convolutional Neural Network (DS-CNN) which is
originated from <a class="reference external" href="https://arxiv.org/pdf/1711.07128.pdf">Zhang et al (2018)</a>.</p>
<p>The goal of the tutorial is to provide users with an example of a complex model
that can be converted to an Akida model and that can be run on Akida NSoC
with an accuracy similar to a standard Keras floating point model.</p>
<section id="dataset-preparation">
<h2>1. Dataset preparation<a class="headerlink" href="#dataset-preparation" title="Permalink to this headline"></a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">cifar10</span>

<span class="c1"># Load CIFAR10 dataset</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Reshape x-data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

    16384/170498071 [..............................] - ETA: 2s
    40960/170498071 [..............................] - ETA: 7:53
    90112/170498071 [..............................] - ETA: 7:02
   204800/170498071 [..............................] - ETA: 4:41
   368640/170498071 [..............................] - ETA: 3:00
   417792/170498071 [..............................] - ETA: 3:03
   679936/170498071 [..............................] - ETA: 2:05
   811008/170498071 [..............................] - ETA: 1:58
  1007616/170498071 [..............................] - ETA: 1:43
  1220608/170498071 [..............................] - ETA: 1:34
  1417216/170498071 [..............................] - ETA: 1:27
  1646592/170498071 [..............................] - ETA: 1:21
  1843200/170498071 [..............................] - ETA: 1:17
  2056192/170498071 [..............................] - ETA: 1:13
  2252800/170498071 [..............................] - ETA: 1:10
  2482176/170498071 [..............................] - ETA: 1:07
  2678784/170498071 [..............................] - ETA: 1:05
  2908160/170498071 [..............................] - ETA: 1:03
  3137536/170498071 [..............................] - ETA: 1:01
  3366912/170498071 [..............................] - ETA: 59s 
  3596288/170498071 [..............................] - ETA: 58s
  3809280/170498071 [..............................] - ETA: 57s
  4038656/170498071 [..............................] - ETA: 56s
  4300800/170498071 [..............................] - ETA: 54s
  4546560/170498071 [..............................] - ETA: 53s
  4808704/170498071 [..............................] - ETA: 52s
  5070848/170498071 [..............................] - ETA: 51s
  5332992/170498071 [..............................] - ETA: 50s
  5611520/170498071 [..............................] - ETA: 49s
  5890048/170498071 [&gt;.............................] - ETA: 48s
  6184960/170498071 [&gt;.............................] - ETA: 47s
  6463488/170498071 [&gt;.............................] - ETA: 46s
  6774784/170498071 [&gt;.............................] - ETA: 45s
  7069696/170498071 [&gt;.............................] - ETA: 44s
  7380992/170498071 [&gt;.............................] - ETA: 43s
  7692288/170498071 [&gt;.............................] - ETA: 42s
  8003584/170498071 [&gt;.............................] - ETA: 42s
  8347648/170498071 [&gt;.............................] - ETA: 41s
  8658944/170498071 [&gt;.............................] - ETA: 40s
  9019392/170498071 [&gt;.............................] - ETA: 40s
  9363456/170498071 [&gt;.............................] - ETA: 39s
  9707520/170498071 [&gt;.............................] - ETA: 38s
 10051584/170498071 [&gt;.............................] - ETA: 38s
 10403840/170498071 [&gt;.............................] - ETA: 37s
 10756096/170498071 [&gt;.............................] - ETA: 36s
 11116544/170498071 [&gt;.............................] - ETA: 36s
 11493376/170498071 [=&gt;............................] - ETA: 35s
 11870208/170498071 [=&gt;............................] - ETA: 35s
 12263424/170498071 [=&gt;............................] - ETA: 34s
 12673024/170498071 [=&gt;............................] - ETA: 34s
 13082624/170498071 [=&gt;............................] - ETA: 33s
 13492224/170498071 [=&gt;............................] - ETA: 33s
 13918208/170498071 [=&gt;............................] - ETA: 32s
 14368768/170498071 [=&gt;............................] - ETA: 32s
 14786560/170498071 [=&gt;............................] - ETA: 31s
 15245312/170498071 [=&gt;............................] - ETA: 31s
 15720448/170498071 [=&gt;............................] - ETA: 30s
 16195584/170498071 [=&gt;............................] - ETA: 30s
 16695296/170498071 [=&gt;............................] - ETA: 29s
 17162240/170498071 [==&gt;...........................] - ETA: 29s
 17661952/170498071 [==&gt;...........................] - ETA: 28s
 18161664/170498071 [==&gt;...........................] - ETA: 28s
 18685952/170498071 [==&gt;...........................] - ETA: 27s
 19243008/170498071 [==&gt;...........................] - ETA: 27s
 19767296/170498071 [==&gt;...........................] - ETA: 26s
 20340736/170498071 [==&gt;...........................] - ETA: 26s
 20914176/170498071 [==&gt;...........................] - ETA: 25s
 21471232/170498071 [==&gt;...........................] - ETA: 25s
 22052864/170498071 [==&gt;...........................] - ETA: 24s
 22650880/170498071 [==&gt;...........................] - ETA: 24s
 23257088/170498071 [===&gt;..........................] - ETA: 24s
 23896064/170498071 [===&gt;..........................] - ETA: 23s
 24338432/170498071 [===&gt;..........................] - ETA: 24s
 24993792/170498071 [===&gt;..........................] - ETA: 23s
 25731072/170498071 [===&gt;..........................] - ETA: 23s
 27140096/170498071 [===&gt;..........................] - ETA: 22s
 27566080/170498071 [===&gt;..........................] - ETA: 21s
 28073984/170498071 [===&gt;..........................] - ETA: 21s
 28499968/170498071 [====&gt;.........................] - ETA: 21s
 29007872/170498071 [====&gt;.........................] - ETA: 21s
 29466624/170498071 [====&gt;.........................] - ETA: 21s
 29958144/170498071 [====&gt;.........................] - ETA: 21s
 30433280/170498071 [====&gt;.........................] - ETA: 20s
 30875648/170498071 [====&gt;.........................] - ETA: 20s
 31399936/170498071 [====&gt;.........................] - ETA: 20s
 31842304/170498071 [====&gt;.........................] - ETA: 20s
 32382976/170498071 [====&gt;.........................] - ETA: 20s
 32841728/170498071 [====&gt;.........................] - ETA: 20s
 33366016/170498071 [====&gt;.........................] - ETA: 19s
 33841152/170498071 [====&gt;.........................] - ETA: 19s
 34316288/170498071 [=====&gt;........................] - ETA: 19s
 34856960/170498071 [=====&gt;........................] - ETA: 19s
 35282944/170498071 [=====&gt;........................] - ETA: 19s
 35889152/170498071 [=====&gt;........................] - ETA: 19s
 36364288/170498071 [=====&gt;........................] - ETA: 18s
 36921344/170498071 [=====&gt;........................] - ETA: 18s
 37412864/170498071 [=====&gt;........................] - ETA: 18s
 37937152/170498071 [=====&gt;........................] - ETA: 18s
 38477824/170498071 [=====&gt;........................] - ETA: 18s
 38952960/170498071 [=====&gt;........................] - ETA: 18s
 39526400/170498071 [=====&gt;........................] - ETA: 18s
 39985152/170498071 [======&gt;.......................] - ETA: 17s
 40624128/170498071 [======&gt;.......................] - ETA: 17s
 41115648/170498071 [======&gt;.......................] - ETA: 17s
 41689088/170498071 [======&gt;.......................] - ETA: 17s
 42229760/170498071 [======&gt;.......................] - ETA: 17s
 42770432/170498071 [======&gt;.......................] - ETA: 17s
 43343872/170498071 [======&gt;.......................] - ETA: 17s
 43884544/170498071 [======&gt;.......................] - ETA: 16s
 44490752/170498071 [======&gt;.......................] - ETA: 16s
 44965888/170498071 [======&gt;.......................] - ETA: 16s
 45604864/170498071 [=======&gt;......................] - ETA: 16s
 46112768/170498071 [=======&gt;......................] - ETA: 16s
 46702592/170498071 [=======&gt;......................] - ETA: 16s
 47267840/170498071 [=======&gt;......................] - ETA: 16s
 47816704/170498071 [=======&gt;......................] - ETA: 15s
 48406528/170498071 [=======&gt;......................] - ETA: 15s
 48930816/170498071 [=======&gt;......................] - ETA: 15s
 49569792/170498071 [=======&gt;......................] - ETA: 15s
 50077696/170498071 [=======&gt;......................] - ETA: 15s
 50716672/170498071 [=======&gt;......................] - ETA: 15s
 50847744/170498071 [=======&gt;......................] - ETA: 15s
 52502528/170498071 [========&gt;.....................] - ETA: 14s
 52961280/170498071 [========&gt;.....................] - ETA: 14s
 53354496/170498071 [========&gt;.....................] - ETA: 14s
 53780480/170498071 [========&gt;.....................] - ETA: 14s
 54173696/170498071 [========&gt;.....................] - ETA: 14s
 54616064/170498071 [========&gt;.....................] - ETA: 14s
 55025664/170498071 [========&gt;.....................] - ETA: 14s
 55410688/170498071 [========&gt;.....................] - ETA: 14s
 55861248/170498071 [========&gt;.....................] - ETA: 14s
 56254464/170498071 [========&gt;.....................] - ETA: 14s
 56729600/170498071 [========&gt;.....................] - ETA: 14s
 57106432/170498071 [=========&gt;....................] - ETA: 14s
 57581568/170498071 [=========&gt;....................] - ETA: 14s
 57991168/170498071 [=========&gt;....................] - ETA: 14s
 58433536/170498071 [=========&gt;....................] - ETA: 14s
 58875904/170498071 [=========&gt;....................] - ETA: 14s
 59318272/170498071 [=========&gt;....................] - ETA: 13s
 59760640/170498071 [=========&gt;....................] - ETA: 13s
 60153856/170498071 [=========&gt;....................] - ETA: 13s
 60653568/170498071 [=========&gt;....................] - ETA: 13s
 61038592/170498071 [=========&gt;....................] - ETA: 13s
 61480960/170498071 [=========&gt;....................] - ETA: 13s
 61890560/170498071 [=========&gt;....................] - ETA: 13s
 62365696/170498071 [=========&gt;....................] - ETA: 13s
 62824448/170498071 [==========&gt;...................] - ETA: 13s
 63283200/170498071 [==========&gt;...................] - ETA: 13s
 63725568/170498071 [==========&gt;...................] - ETA: 13s
 64167936/170498071 [==========&gt;...................] - ETA: 13s
 64659456/170498071 [==========&gt;...................] - ETA: 13s
 65085440/170498071 [==========&gt;...................] - ETA: 13s
 65609728/170498071 [==========&gt;...................] - ETA: 13s
 66052096/170498071 [==========&gt;...................] - ETA: 12s
 66478080/170498071 [==========&gt;...................] - ETA: 12s
 66936832/170498071 [==========&gt;...................] - ETA: 12s
 67444736/170498071 [==========&gt;...................] - ETA: 12s
 67887104/170498071 [==========&gt;...................] - ETA: 12s
 68395008/170498071 [===========&gt;..................] - ETA: 12s
 68853760/170498071 [===========&gt;..................] - ETA: 12s
 69378048/170498071 [===========&gt;..................] - ETA: 12s
 69804032/170498071 [===========&gt;..................] - ETA: 12s
 70246400/170498071 [===========&gt;..................] - ETA: 12s
 70770688/170498071 [===========&gt;..................] - ETA: 12s
 71180288/170498071 [===========&gt;..................] - ETA: 12s
 71704576/170498071 [===========&gt;..................] - ETA: 12s
 72114176/170498071 [===========&gt;..................] - ETA: 12s
 72605696/170498071 [===========&gt;..................] - ETA: 12s
 73056256/170498071 [===========&gt;..................] - ETA: 11s
 73555968/170498071 [===========&gt;..................] - ETA: 11s
 74014720/170498071 [============&gt;.................] - ETA: 11s
 74481664/170498071 [============&gt;.................] - ETA: 11s
 74964992/170498071 [============&gt;.................] - ETA: 11s
 75407360/170498071 [============&gt;.................] - ETA: 11s
 75948032/170498071 [============&gt;.................] - ETA: 11s
 76390400/170498071 [============&gt;.................] - ETA: 11s
 76914688/170498071 [============&gt;.................] - ETA: 11s
 77340672/170498071 [============&gt;.................] - ETA: 11s
 77864960/170498071 [============&gt;.................] - ETA: 11s
 78323712/170498071 [============&gt;.................] - ETA: 11s
 78848000/170498071 [============&gt;.................] - ETA: 11s
 79306752/170498071 [============&gt;.................] - ETA: 11s
 79847424/170498071 [=============&gt;................] - ETA: 11s
 80289792/170498071 [=============&gt;................] - ETA: 10s
 80732160/170498071 [=============&gt;................] - ETA: 10s
 81305600/170498071 [=============&gt;................] - ETA: 10s
 81731584/170498071 [=============&gt;................] - ETA: 10s
 82272256/170498071 [=============&gt;................] - ETA: 10s
 82747392/170498071 [=============&gt;................] - ETA: 10s
 83238912/170498071 [=============&gt;................] - ETA: 10s
 83697664/170498071 [=============&gt;................] - ETA: 10s
 84254720/170498071 [=============&gt;................] - ETA: 10s
 84713472/170498071 [=============&gt;................] - ETA: 10s
 85270528/170498071 [==============&gt;...............] - ETA: 10s
 85729280/170498071 [==============&gt;...............] - ETA: 10s
 86269952/170498071 [==============&gt;...............] - ETA: 10s
 86695936/170498071 [==============&gt;...............] - ETA: 10s
 87171072/170498071 [==============&gt;...............] - ETA: 10s
 87752704/170498071 [==============&gt;...............] - ETA: 9s 
 88186880/170498071 [==============&gt;...............] - ETA: 9s
 88727552/170498071 [==============&gt;...............] - ETA: 9s
 89194496/170498071 [==============&gt;...............] - ETA: 9s
 89686016/170498071 [==============&gt;...............] - ETA: 9s
 90152960/170498071 [==============&gt;...............] - ETA: 9s
 90710016/170498071 [==============&gt;...............] - ETA: 9s
 91152384/170498071 [===============&gt;..............] - ETA: 9s
 91693056/170498071 [===============&gt;..............] - ETA: 9s
 92135424/170498071 [===============&gt;..............] - ETA: 9s
 92610560/170498071 [===============&gt;..............] - ETA: 9s
 93200384/170498071 [===============&gt;..............] - ETA: 9s
 93642752/170498071 [===============&gt;..............] - ETA: 9s
 94167040/170498071 [===============&gt;..............] - ETA: 9s
 94642176/170498071 [===============&gt;..............] - ETA: 9s
 95117312/170498071 [===============&gt;..............] - ETA: 8s
 95608832/170498071 [===============&gt;..............] - ETA: 8s
 96165888/170498071 [===============&gt;..............] - ETA: 8s
 96608256/170498071 [===============&gt;..............] - ETA: 8s
 97165312/170498071 [================&gt;.............] - ETA: 8s
 97656832/170498071 [================&gt;.............] - ETA: 8s
 98164736/170498071 [================&gt;.............] - ETA: 8s
 98689024/170498071 [================&gt;.............] - ETA: 8s
 99147776/170498071 [================&gt;.............] - ETA: 8s
 99721216/170498071 [================&gt;.............] - ETA: 8s
100179968/170498071 [================&gt;.............] - ETA: 8s
100720640/170498071 [================&gt;.............] - ETA: 8s
101179392/170498071 [================&gt;.............] - ETA: 8s
101687296/170498071 [================&gt;.............] - ETA: 8s
102178816/170498071 [================&gt;.............] - ETA: 8s
102727680/170498071 [=================&gt;............] - ETA: 7s
103161856/170498071 [=================&gt;............] - ETA: 7s
103735296/170498071 [=================&gt;............] - ETA: 7s
104243200/170498071 [=================&gt;............] - ETA: 7s
104718336/170498071 [=================&gt;............] - ETA: 7s
105275392/170498071 [=================&gt;............] - ETA: 7s
105734144/170498071 [=================&gt;............] - ETA: 7s
106323968/170498071 [=================&gt;............] - ETA: 7s
106766336/170498071 [=================&gt;............] - ETA: 7s
107323392/170498071 [=================&gt;............] - ETA: 7s
107798528/170498071 [=================&gt;............] - ETA: 7s
108322816/170498071 [==================&gt;...........] - ETA: 7s
108797952/170498071 [==================&gt;...........] - ETA: 7s
109371392/170498071 [==================&gt;...........] - ETA: 7s
109830144/170498071 [==================&gt;...........] - ETA: 7s
110387200/170498071 [==================&gt;...........] - ETA: 7s
110862336/170498071 [==================&gt;...........] - ETA: 6s
111370240/170498071 [==================&gt;...........] - ETA: 6s
111878144/170498071 [==================&gt;...........] - ETA: 6s
112336896/170498071 [==================&gt;...........] - ETA: 6s
112943104/170498071 [==================&gt;...........] - ETA: 6s
113385472/170498071 [==================&gt;...........] - ETA: 6s
113926144/170498071 [===================&gt;..........] - ETA: 6s
114401280/170498071 [===================&gt;..........] - ETA: 6s
114892800/170498071 [===================&gt;..........] - ETA: 6s
115376128/170498071 [===================&gt;..........] - ETA: 6s
115933184/170498071 [===================&gt;..........] - ETA: 6s
116367360/170498071 [===================&gt;..........] - ETA: 6s
116875264/170498071 [===================&gt;..........] - ETA: 6s
117399552/170498071 [===================&gt;..........] - ETA: 6s
117858304/170498071 [===================&gt;..........] - ETA: 6s
118431744/170498071 [===================&gt;..........] - ETA: 6s
118890496/170498071 [===================&gt;..........] - ETA: 5s
119431168/170498071 [====================&gt;.........] - ETA: 5s
119922688/170498071 [====================&gt;.........] - ETA: 5s
120414208/170498071 [====================&gt;.........] - ETA: 5s
120905728/170498071 [====================&gt;.........] - ETA: 5s
121462784/170498071 [====================&gt;.........] - ETA: 5s
121970688/170498071 [====================&gt;.........] - ETA: 5s
122511360/170498071 [====================&gt;.........] - ETA: 5s
122953728/170498071 [====================&gt;.........] - ETA: 5s
123461632/170498071 [====================&gt;.........] - ETA: 5s
123969536/170498071 [====================&gt;.........] - ETA: 5s
124395520/170498071 [====================&gt;.........] - ETA: 5s
124936192/170498071 [====================&gt;.........] - ETA: 5s
125411328/170498071 [=====================&gt;........] - ETA: 5s
125902848/170498071 [=====================&gt;........] - ETA: 5s
126377984/170498071 [=====================&gt;........] - ETA: 5s
126910464/170498071 [=====================&gt;........] - ETA: 5s
127377408/170498071 [=====================&gt;........] - ETA: 4s
127852544/170498071 [=====================&gt;........] - ETA: 4s
128376832/170498071 [=====================&gt;........] - ETA: 4s
128835584/170498071 [=====================&gt;........] - ETA: 4s
129376256/170498071 [=====================&gt;........] - ETA: 4s
129835008/170498071 [=====================&gt;........] - ETA: 4s
130293760/170498071 [=====================&gt;........] - ETA: 4s
130818048/170498071 [======================&gt;.......] - ETA: 4s
131317760/170498071 [======================&gt;.......] - ETA: 4s
131801088/170498071 [======================&gt;.......] - ETA: 4s
132325376/170498071 [======================&gt;.......] - ETA: 4s
132849664/170498071 [======================&gt;.......] - ETA: 4s
133341184/170498071 [======================&gt;.......] - ETA: 4s
133849088/170498071 [======================&gt;.......] - ETA: 4s
134299648/170498071 [======================&gt;.......] - ETA: 4s
134782976/170498071 [======================&gt;.......] - ETA: 4s
135323648/170498071 [======================&gt;.......] - ETA: 4s
135798784/170498071 [======================&gt;.......] - ETA: 3s
136306688/170498071 [======================&gt;.......] - ETA: 3s
136798208/170498071 [=======================&gt;......] - ETA: 3s
137322496/170498071 [=======================&gt;......] - ETA: 3s
137814016/170498071 [=======================&gt;......] - ETA: 3s
138289152/170498071 [=======================&gt;......] - ETA: 3s
138797056/170498071 [=======================&gt;......] - ETA: 3s
139272192/170498071 [=======================&gt;......] - ETA: 3s
139788288/170498071 [=======================&gt;......] - ETA: 3s
140238848/170498071 [=======================&gt;......] - ETA: 3s
140763136/170498071 [=======================&gt;......] - ETA: 3s
141221888/170498071 [=======================&gt;......] - ETA: 3s
141746176/170498071 [=======================&gt;......] - ETA: 3s
142245888/170498071 [========================&gt;.....] - ETA: 3s
142729216/170498071 [========================&gt;.....] - ETA: 3s
143220736/170498071 [========================&gt;.....] - ETA: 3s
143728640/170498071 [========================&gt;.....] - ETA: 3s
144203776/170498071 [========================&gt;.....] - ETA: 2s
144728064/170498071 [========================&gt;.....] - ETA: 2s
145252352/170498071 [========================&gt;.....] - ETA: 2s
145743872/170498071 [========================&gt;.....] - ETA: 2s
146284544/170498071 [========================&gt;.....] - ETA: 2s
146776064/170498071 [========================&gt;.....] - ETA: 2s
147283968/170498071 [========================&gt;.....] - ETA: 2s
147808256/170498071 [=========================&gt;....] - ETA: 2s
148316160/170498071 [=========================&gt;....] - ETA: 2s
148807680/170498071 [=========================&gt;....] - ETA: 2s
149315584/170498071 [=========================&gt;....] - ETA: 2s
149790720/170498071 [=========================&gt;....] - ETA: 2s
150315008/170498071 [=========================&gt;....] - ETA: 2s
150839296/170498071 [=========================&gt;....] - ETA: 2s
151330816/170498071 [=========================&gt;....] - ETA: 2s
151871488/170498071 [=========================&gt;....] - ETA: 2s
152379392/170498071 [=========================&gt;....] - ETA: 2s
152870912/170498071 [=========================&gt;....] - ETA: 1s
153395200/170498071 [=========================&gt;....] - ETA: 1s
153903104/170498071 [==========================&gt;...] - ETA: 1s
154394624/170498071 [==========================&gt;...] - ETA: 1s
154910720/170498071 [==========================&gt;...] - ETA: 1s
155377664/170498071 [==========================&gt;...] - ETA: 1s
155918336/170498071 [==========================&gt;...] - ETA: 1s
156459008/170498071 [==========================&gt;...] - ETA: 1s
156950528/170498071 [==========================&gt;...] - ETA: 1s
157491200/170498071 [==========================&gt;...] - ETA: 1s
157999104/170498071 [==========================&gt;...] - ETA: 1s
158490624/170498071 [==========================&gt;...] - ETA: 1s
159014912/170498071 [==========================&gt;...] - ETA: 1s
159555584/170498071 [===========================&gt;..] - ETA: 1s
160063488/170498071 [===========================&gt;..] - ETA: 1s
160571392/170498071 [===========================&gt;..] - ETA: 1s
161062912/170498071 [===========================&gt;..] - ETA: 1s
161628160/170498071 [===========================&gt;..] - ETA: 0s
162160640/170498071 [===========================&gt;..] - ETA: 0s
162652160/170498071 [===========================&gt;..] - ETA: 0s
163192832/170498071 [===========================&gt;..] - ETA: 0s
163733504/170498071 [===========================&gt;..] - ETA: 0s
164241408/170498071 [===========================&gt;..] - ETA: 0s
164765696/170498071 [===========================&gt;..] - ETA: 0s
165306368/170498071 [============================&gt;.] - ETA: 0s
165830656/170498071 [============================&gt;.] - ETA: 0s
166338560/170498071 [============================&gt;.] - ETA: 0s
166846464/170498071 [============================&gt;.] - ETA: 0s
167419904/170498071 [============================&gt;.] - ETA: 0s
167960576/170498071 [============================&gt;.] - ETA: 0s
168452096/170498071 [============================&gt;.] - ETA: 0s
169009152/170498071 [============================&gt;.] - ETA: 0s
169533440/170498071 [============================&gt;.] - ETA: 0s
170041344/170498071 [============================&gt;.] - ETA: 0s
170500096/170498071 [==============================] - 19s 0us/step

170508288/170498071 [==============================] - 19s 0us/step
</pre></div>
</div>
</section>
<section id="create-a-keras-ds-cnn-model">
<h2>2. Create a Keras DS-CNN model<a class="headerlink" href="#create-a-keras-ds-cnn-model" title="Permalink to this headline"></a></h2>
<p>The DS-CNN architecture is available in the <a class="reference external" href="../../api_reference/akida_models_apis.html#cifar-10">Akida models zoo</a> along with pretrained
weights.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The pre-trained weights were obtained after training the model with
unconstrained float weights and activations for 1000 epochs</p>
</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">get_file</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="c1"># Retrieve the float model with pretrained weights and load it</span>
<span class="n">model_file</span> <span class="o">=</span> <span class="n">get_file</span><span class="p">(</span>
    <span class="s2">&quot;ds_cnn_cifar10.h5&quot;</span><span class="p">,</span>
    <span class="s2">&quot;http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10.h5&quot;</span><span class="p">,</span>
    <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;models/ds_cnn_cifar10&#39;</span><span class="p">)</span>
<span class="n">model_keras</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
<span class="n">model_keras</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10.h5

   16384/10837696 [..............................] - ETA: 9s
  139264/10837696 [..............................] - ETA: 5s
  401408/10837696 [&gt;.............................] - ETA: 3s
  663552/10837696 [&gt;.............................] - ETA: 2s
  925696/10837696 [=&gt;............................] - ETA: 2s
 1187840/10837696 [==&gt;...........................] - ETA: 2s
 1449984/10837696 [===&gt;..........................] - ETA: 2s
 1712128/10837696 [===&gt;..........................] - ETA: 2s
 1974272/10837696 [====&gt;.........................] - ETA: 2s
 2236416/10837696 [=====&gt;........................] - ETA: 2s
 2498560/10837696 [=====&gt;........................] - ETA: 2s
 2760704/10837696 [======&gt;.......................] - ETA: 1s
 3022848/10837696 [=======&gt;......................] - ETA: 1s
 3284992/10837696 [========&gt;.....................] - ETA: 1s
 3547136/10837696 [========&gt;.....................] - ETA: 1s
 3809280/10837696 [=========&gt;....................] - ETA: 1s
 4071424/10837696 [==========&gt;...................] - ETA: 1s
 4333568/10837696 [==========&gt;...................] - ETA: 1s
 4595712/10837696 [===========&gt;..................] - ETA: 1s
 4857856/10837696 [============&gt;.................] - ETA: 1s
 5120000/10837696 [=============&gt;................] - ETA: 1s
 5382144/10837696 [=============&gt;................] - ETA: 1s
 5644288/10837696 [==============&gt;...............] - ETA: 1s
 5906432/10837696 [===============&gt;..............] - ETA: 1s
 6168576/10837696 [================&gt;.............] - ETA: 1s
 6430720/10837696 [================&gt;.............] - ETA: 1s
 6692864/10837696 [=================&gt;............] - ETA: 0s
 6955008/10837696 [==================&gt;...........] - ETA: 0s
 7217152/10837696 [==================&gt;...........] - ETA: 0s
 7479296/10837696 [===================&gt;..........] - ETA: 0s
 7741440/10837696 [====================&gt;.........] - ETA: 0s
 8003584/10837696 [=====================&gt;........] - ETA: 0s
 8265728/10837696 [=====================&gt;........] - ETA: 0s
 8527872/10837696 [======================&gt;.......] - ETA: 0s
 8790016/10837696 [=======================&gt;......] - ETA: 0s
 9052160/10837696 [========================&gt;.....] - ETA: 0s
 9314304/10837696 [========================&gt;.....] - ETA: 0s
 9576448/10837696 [=========================&gt;....] - ETA: 0s
 9838592/10837696 [==========================&gt;...] - ETA: 0s
10100736/10837696 [==========================&gt;...] - ETA: 0s
10362880/10837696 [===========================&gt;..] - ETA: 0s
10625024/10837696 [============================&gt;.] - ETA: 0s
10838016/10837696 [==============================] - 3s 0us/step

10846208/10837696 [==============================] - 3s 0us/step
Model: &quot;ds_cnn_cifar10&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0
_________________________________________________________________
rescaling (Rescaling)        (None, 32, 32, 3)         0
_________________________________________________________________
conv_0 (Conv2D)              (None, 32, 32, 128)       3456
_________________________________________________________________
conv_0_BN (BatchNormalizatio (None, 32, 32, 128)       512
_________________________________________________________________
conv_0_relu (ReLU)           (None, 32, 32, 128)       0
_________________________________________________________________
separable_1 (SeparableConv2D (None, 32, 32, 128)       17536
_________________________________________________________________
separable_1_BN (BatchNormali (None, 32, 32, 128)       512
_________________________________________________________________
separable_1_relu (ReLU)      (None, 32, 32, 128)       0
_________________________________________________________________
separable_2 (SeparableConv2D (None, 32, 32, 256)       33920
_________________________________________________________________
separable_2_BN (BatchNormali (None, 32, 32, 256)       1024
_________________________________________________________________
separable_2_relu (ReLU)      (None, 32, 32, 256)       0
_________________________________________________________________
separable_3 (SeparableConv2D (None, 32, 32, 256)       67840
_________________________________________________________________
separable_3_maxpool (MaxPool (None, 16, 16, 256)       0
_________________________________________________________________
separable_3_BN (BatchNormali (None, 16, 16, 256)       1024
_________________________________________________________________
separable_3_relu (ReLU)      (None, 16, 16, 256)       0
_________________________________________________________________
separable_4 (SeparableConv2D (None, 16, 16, 512)       133376
_________________________________________________________________
separable_4_BN (BatchNormali (None, 16, 16, 512)       2048
_________________________________________________________________
separable_4_relu (ReLU)      (None, 16, 16, 512)       0
_________________________________________________________________
separable_5 (SeparableConv2D (None, 16, 16, 512)       266752
_________________________________________________________________
separable_5_maxpool (MaxPool (None, 8, 8, 512)         0
_________________________________________________________________
separable_5_BN (BatchNormali (None, 8, 8, 512)         2048
_________________________________________________________________
separable_5_relu (ReLU)      (None, 8, 8, 512)         0
_________________________________________________________________
separable_6 (SeparableConv2D (None, 8, 8, 512)         266752
_________________________________________________________________
separable_6_BN (BatchNormali (None, 8, 8, 512)         2048
_________________________________________________________________
separable_6_relu (ReLU)      (None, 8, 8, 512)         0
_________________________________________________________________
separable_7 (SeparableConv2D (None, 8, 8, 512)         266752
_________________________________________________________________
separable_7_maxpool (MaxPool (None, 4, 4, 512)         0
_________________________________________________________________
separable_7_BN (BatchNormali (None, 4, 4, 512)         2048
_________________________________________________________________
separable_7_relu (ReLU)      (None, 4, 4, 512)         0
_________________________________________________________________
separable_8 (SeparableConv2D (None, 4, 4, 1024)        528896
_________________________________________________________________
separable_8_BN (BatchNormali (None, 4, 4, 1024)        4096
_________________________________________________________________
separable_8_relu (ReLU)      (None, 4, 4, 1024)        0
_________________________________________________________________
separable_9 (SeparableConv2D (None, 4, 4, 1024)        1057792
_________________________________________________________________
separable_9_BN (BatchNormali (None, 4, 4, 1024)        4096
_________________________________________________________________
separable_9_relu (ReLU)      (None, 4, 4, 1024)        0
_________________________________________________________________
separable_10 (SeparableConv2 (None, 4, 4, 10)          19456
_________________________________________________________________
separable_10_global_avg (Glo (None, 10)                0
=================================================================
Total params: 2,681,984
Trainable params: 2,672,256
Non-trainable params: 9,728
_________________________________________________________________
</pre></div>
</div>
<p>Keras model accuracy is checked against the first <em>n</em> images of the test set.</p>
<p>The table below summarizes the expected results:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 47%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.60 %</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on your hardware setup, the processing time may vary.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>


<span class="c1"># Check Model performance</span>
<span class="k">def</span> <span class="nf">check_model_performances</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="n">potentials_keras</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">])</span>
    <span class="n">preds_keras</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">potentials_keras</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">preds_keras</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Keras inference on </span><span class="si">{</span><span class="n">num_images</span><span class="si">}</span><span class="s1"> images took </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> s.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 94.30%
Keras inference on 1000 images took 0.72 s.
</pre></div>
</div>
</section>
<section id="quantized-model">
<h2>3. Quantized model<a class="headerlink" href="#quantized-model" title="Permalink to this headline"></a></h2>
<p>Quantizing a model is done using <a class="reference external" href="../../api_reference/cnn2snn_apis.html#quantize">cnn2snn.quantize</a>. After the call, all the
layers will have 4-bit weights and 4-bit activations.</p>
<p>This model will therefore satisfy the Akida NSoC requirements but will suffer
from a drop in accuracy due to quantization as shown in the table below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 36%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Float accuracy</p></th>
<th class="head"><p>Quantized accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>96.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>92.60 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>92.58 %</p></td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">quantize</span>

<span class="c1"># Quantize the model to 4-bit weights and activations</span>
<span class="n">model_keras_quantized</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Check Model performance</span>
<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras_quantized</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 92.60%
Keras inference on 1000 images took 0.74 s.
</pre></div>
</div>
</section>
<section id="pretrained-quantized-model">
<h2>4. Pretrained quantized model<a class="headerlink" href="#pretrained-quantized-model" title="Permalink to this headline"></a></h2>
<p>The Akida models zoo also contains a <a class="reference external" href="../../api_reference/akida_models_apis.html#akida_models.ds_cnn_cifar10_pretrained">pretrained quantized helper</a>
that was obtained using the <a class="reference external" href="../../user_guide/akida_models.html#cifar10-training-and-tuning">tune</a>
action of <code class="docutils literal notranslate"><span class="pre">akida_models</span></code> CLI on the quantized model for 100 epochs.</p>
<p>Tuning the model, that is training with a lowered learning rate, allows to
recover performances up to the initial floating point accuracy.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 27%" />
<col style="width: 34%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Float accuracy</p></th>
<th class="head"><p>Quantized accuracy</p></th>
<th class="head"><p>After tuning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>96.00 %</p></td>
<td><p>97.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>92.60 %</p></td>
<td><p>94.20 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>92.58 %</p></td>
<td><p>93.08 %</p></td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">ds_cnn_cifar10_pretrained</span>

<span class="c1"># Use a quantized model with pretrained quantized weights</span>
<span class="n">model_keras_quantized_pretrained</span> <span class="o">=</span> <span class="n">ds_cnn_cifar10_pretrained</span><span class="p">()</span>

<span class="c1"># Check Model performance</span>
<span class="n">check_model_performances</span><span class="p">(</span><span class="n">model_keras_quantized_pretrained</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from http://data.brainchip.com/models/ds_cnn/ds_cnn_cifar10_iq4_wq4_aq4.h5

   16384/10744080 [..............................] - ETA: 8s
  204800/10744080 [..............................] - ETA: 3s
  466944/10744080 [&gt;.............................] - ETA: 2s
  729088/10744080 [=&gt;............................] - ETA: 2s
  991232/10744080 [=&gt;............................] - ETA: 2s
 1253376/10744080 [==&gt;...........................] - ETA: 2s
 1515520/10744080 [===&gt;..........................] - ETA: 2s
 1777664/10744080 [===&gt;..........................] - ETA: 2s
 1900544/10744080 [====&gt;.........................] - ETA: 3s
 1916928/10744080 [====&gt;.........................] - ETA: 3s
 2031616/10744080 [====&gt;.........................] - ETA: 3s
 2236416/10744080 [=====&gt;........................] - ETA: 3s
 2498560/10744080 [=====&gt;........................] - ETA: 3s
 2760704/10744080 [======&gt;.......................] - ETA: 3s
 3022848/10744080 [=======&gt;......................] - ETA: 2s
 3284992/10744080 [========&gt;.....................] - ETA: 2s
 3547136/10744080 [========&gt;.....................] - ETA: 2s
 3809280/10744080 [=========&gt;....................] - ETA: 2s
 4071424/10744080 [==========&gt;...................] - ETA: 2s
 4333568/10744080 [===========&gt;..................] - ETA: 2s
 4595712/10744080 [===========&gt;..................] - ETA: 1s
 4857856/10744080 [============&gt;.................] - ETA: 1s
 5120000/10744080 [=============&gt;................] - ETA: 1s
 5382144/10744080 [==============&gt;...............] - ETA: 1s
 5644288/10744080 [==============&gt;...............] - ETA: 1s
 5906432/10744080 [===============&gt;..............] - ETA: 1s
 6168576/10744080 [================&gt;.............] - ETA: 1s
 6430720/10744080 [================&gt;.............] - ETA: 1s
 6692864/10744080 [=================&gt;............] - ETA: 1s
 6955008/10744080 [==================&gt;...........] - ETA: 1s
 7217152/10744080 [===================&gt;..........] - ETA: 1s
 7479296/10744080 [===================&gt;..........] - ETA: 0s
 7741440/10744080 [====================&gt;.........] - ETA: 0s
 8003584/10744080 [=====================&gt;........] - ETA: 0s
 8265728/10744080 [======================&gt;.......] - ETA: 0s
 8527872/10744080 [======================&gt;.......] - ETA: 0s
 8790016/10744080 [=======================&gt;......] - ETA: 0s
 9052160/10744080 [========================&gt;.....] - ETA: 0s
 9314304/10744080 [=========================&gt;....] - ETA: 0s
 9576448/10744080 [=========================&gt;....] - ETA: 0s
 9838592/10744080 [==========================&gt;...] - ETA: 0s
10100736/10744080 [===========================&gt;..] - ETA: 0s
10362880/10744080 [===========================&gt;..] - ETA: 0s
10625024/10744080 [============================&gt;.] - ETA: 0s
10747904/10744080 [==============================] - 3s 0us/step

10756096/10744080 [==============================] - 3s 0us/step
Accuracy: 94.20%
Keras inference on 1000 images took 0.76 s.
</pre></div>
</div>
</section>
<section id="conversion-to-akida">
<h2>5. Conversion to Akida<a class="headerlink" href="#conversion-to-akida" title="Permalink to this headline"></a></h2>
<section id="convert-to-akida-model">
<h3>5.1 Convert to Akida model<a class="headerlink" href="#convert-to-akida-model" title="Permalink to this headline"></a></h3>
<p>When converting to an Akida model, we just need to pass the Keras model
and the input scaling that was used during training to <a class="reference external" href="../../api_reference/cnn2snn_apis.html#convert">cnn2snn.convert</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">convert</span>

<span class="n">model_akida</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">model_keras_quantized_pretrained</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="check-hardware-compliancy">
<h3>5.2 Check hardware compliancy<a class="headerlink" href="#check-hardware-compliancy" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="../../api_reference/aee_apis.html#akida.Model.summary">Model.summary</a>
method provides a detailed description of the Model layers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_akida</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>                Model Summary
______________________________________________
Input shape  Output shape  Sequences  Layers
==============================================
[32, 32, 3]  [1, 1, 10]    1          11
______________________________________________

/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  return array(a, dtype, copy=False, order=order)
              SW/conv_0-separable_10 (Software)
_____________________________________________________________
Layer (type)              Output shape   Kernel shape
=============================================================
conv_0 (InputConv.)       [32, 32, 128]  (3, 3, 3, 128)
_____________________________________________________________
separable_1 (Sep.Conv.)   [32, 32, 128]  (3, 3, 128, 1)
_____________________________________________________________
                                         (1, 1, 128, 128)
_____________________________________________________________
separable_2 (Sep.Conv.)   [32, 32, 256]  (3, 3, 128, 1)
_____________________________________________________________
                                         (1, 1, 128, 256)
_____________________________________________________________
separable_3 (Sep.Conv.)   [16, 16, 256]  (3, 3, 256, 1)
_____________________________________________________________
                                         (1, 1, 256, 256)
_____________________________________________________________
separable_4 (Sep.Conv.)   [16, 16, 512]  (3, 3, 256, 1)
_____________________________________________________________
                                         (1, 1, 256, 512)
_____________________________________________________________
separable_5 (Sep.Conv.)   [8, 8, 512]    (3, 3, 512, 1)
_____________________________________________________________
                                         (1, 1, 512, 512)
_____________________________________________________________
separable_6 (Sep.Conv.)   [8, 8, 512]    (3, 3, 512, 1)
_____________________________________________________________
                                         (1, 1, 512, 512)
_____________________________________________________________
separable_7 (Sep.Conv.)   [4, 4, 512]    (3, 3, 512, 1)
_____________________________________________________________
                                         (1, 1, 512, 512)
_____________________________________________________________
separable_8 (Sep.Conv.)   [4, 4, 1024]   (3, 3, 512, 1)
_____________________________________________________________
                                         (1, 1, 512, 1024)
_____________________________________________________________
separable_9 (Sep.Conv.)   [4, 4, 1024]   (3, 3, 1024, 1)
_____________________________________________________________
                                         (1, 1, 1024, 1024)
_____________________________________________________________
separable_10 (Sep.Conv.)  [1, 1, 10]     (3, 3, 1024, 1)
_____________________________________________________________
                                         (1, 1, 1024, 10)
_____________________________________________________________
</pre></div>
</div>
</section>
<section id="check-performance">
<h3>5.3 Check performance<a class="headerlink" href="#check-performance" title="Permalink to this headline"></a></h3>
<p>We check the Akida model accuracy on the first <em>n</em> images of the test
set.</p>
<p>The table below summarizes the expected results:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 39%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>#Images</p></th>
<th class="head"><p>Keras accuracy</p></th>
<th class="head"><p>Akida accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>100</p></td>
<td><p>96.00 %</p></td>
<td><p>97.00 %</p></td>
</tr>
<tr class="row-odd"><td><p>1000</p></td>
<td><p>94.30 %</p></td>
<td><p>94.00 %</p></td>
</tr>
<tr class="row-even"><td><p>10000</p></td>
<td><p>93.66 %</p></td>
<td><p>93.04 %</p></td>
</tr>
</tbody>
</table>
<p>Due to the conversion process, the predictions may be slightly different
between the original Keras model and Akida on some specific images.</p>
<p>This explains why when testing on a limited number of images the
accuracy numbers between Keras and Akida may be quite different. On the
full test set however, the two models accuracies are very close.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_images</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Check Model performance</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">])</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="n">num_images</span><span class="p">],</span> <span class="n">results</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">accuracy</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Akida inference on </span><span class="si">{</span><span class="n">num_images</span><span class="si">}</span><span class="s1"> images took </span><span class="si">{</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> s.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># For non-regression purpose</span>
<span class="k">if</span> <span class="n">num_images</span> <span class="o">==</span> <span class="mi">1000</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">accuracy</span> <span class="o">==</span> <span class="mf">0.94</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 94.00%
Akida inference on 1000 images took 18.41 s.
</pre></div>
</div>
<p>Activations sparsity has a great impact on akida inference time. One can have
a look at the average input and output sparsity of each layer using
<a class="reference external" href="../../api_reference/aee_apis.html#akida.Model.statistics">Model.statistics</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print model statistics</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model statistics&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_akida</span><span class="o">.</span><span class="n">statistics</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model statistics

Sequence SW/conv_0-separable_10
Average framerate = 54.35 fps
Layer (type)                  output sparsity
conv_0 (InputConv.)           0.59
Layer (type)                  output sparsity
separable_1 (Sep.Conv.)       0.51
Layer (type)                  output sparsity
separable_2 (Sep.Conv.)       0.54
Layer (type)                  output sparsity
separable_3 (Sep.Conv.)       0.63
Layer (type)                  output sparsity
separable_4 (Sep.Conv.)       0.64
Layer (type)                  output sparsity
separable_5 (Sep.Conv.)       0.71
Layer (type)                  output sparsity
separable_6 (Sep.Conv.)       0.68
Layer (type)                  output sparsity
separable_7 (Sep.Conv.)       0.75
Layer (type)                  output sparsity
separable_8 (Sep.Conv.)       0.84
Layer (type)                  output sparsity
separable_9 (Sep.Conv.)       0.84
Layer (type)                  output sparsity
separable_10 (Sep.Conv.)      N/A
</pre></div>
</div>
</section>
<section id="show-predictions-for-a-random-image">
<h3>5.4 Show predictions for a random image<a class="headerlink" href="#show-predictions-for-a-random-image" title="Permalink to this headline"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.lines</span> <span class="k">as</span> <span class="nn">lines</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>
    <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span>
<span class="p">]</span>

<span class="c1"># prepare plot</span>
<span class="n">barWidth</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">pause_time</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="s1">&#39;CIFAR10 Classification by Akida Execution Engine&#39;</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax0</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">imgobj</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="c1"># Results subplots</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="s1">&#39;Actual class:&#39;</span><span class="p">)</span>
<span class="n">actual_class</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="s1">&#39;None&#39;</span><span class="p">)</span>
<span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="s1">&#39;Predicted class:&#39;</span><span class="p">)</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">ax0</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="s1">&#39;None&#39;</span><span class="p">)</span>

<span class="c1"># Take a random test image</span>
<span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">true_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">pot</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="n">rpot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pot</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">rpot</span><span class="p">,</span> <span class="n">pot</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">barWidth</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">rpot</span> <span class="o">-</span> <span class="mf">0.07</span> <span class="o">*</span> <span class="n">barWidth</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">predicted_idx</span> <span class="o">=</span> <span class="n">pot</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="n">imgobj</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="k">if</span> <span class="n">predicted_idx</span> <span class="o">==</span> <span class="n">true_idx</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">get_children</span><span class="p">()[</span><span class="n">predicted_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">get_children</span><span class="p">()[</span><span class="n">predicted_idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">actual_class</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">true_idx</span><span class="p">])</span>
<span class="n">predicted_class</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="n">label_names</span><span class="p">[</span><span class="n">predicted_idx</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Akida</span><span class="se">\&#39;</span><span class="s1">s predictions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_1_ds_cnn_cifar10_001.png" srcset="../../_images/sphx_glr_plot_1_ds_cnn_cifar10_001.png" alt="Akida's predictions" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  51.503 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-general-plot-1-ds-cnn-cifar10-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/125ef9be06bd9eb7c0743c1f6e04ce68/plot_1_ds_cnn_cifar10.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_1_ds_cnn_cifar10.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/f9ca36bf83b6c46b60549bf859b060ef/plot_1_ds_cnn_cifar10.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_1_ds_cnn_cifar10.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plot_0_gxnor_mnist.html" class="btn btn-neutral float-left" title="GXNOR/MNIST inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_2_mobilenet_imagenet.html" class="btn btn-neutral float-right" title="MobileNet/ImageNet inference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>