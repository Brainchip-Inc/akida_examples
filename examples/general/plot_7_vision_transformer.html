<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Build Vision Transformers for Akida &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=c4c4e161" />

  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/design-tabs.js?v=f930bc37"></script>
        <script src="../../_static/leadlander_tag.js?v=d65c0df8"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="PyTorch to Akida workflow" href="plot_8_global_pytorch_workflow.html" />
    <link rel="prev" title="Segmentation tutorial" href="plot_6_segmentation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#performance-measurement">Performance measurement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#keras-support">Keras support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#onnx-support">ONNX support</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#analysis-module">Analysis module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#metrics">Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#command-line">Command line</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#typical-quantization-scenario">Typical quantization scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#id3">Command-line interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-to-display-summary">Command-line interface to display summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/engine.html">Akida Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/engine.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/engine.html#engine-directory-structure">Engine directory structure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/engine.html#engine-api-overview">Engine API overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#hardwaredriver">HardwareDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#hardwaredevice">HardwareDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#shape">Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#hwversion">HwVersion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#sparse-and-input-conversion-functions">Sparse and Input conversion functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/engine.html#other-headers-in-the-api">Other headers in the API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.__version__"><code class="docutils literal notranslate"><span class="pre">__version__</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#model">Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Model"><code class="docutils literal notranslate"><span class="pre">Model</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-layers">Akida layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.InputData"><code class="docutils literal notranslate"><span class="pre">InputData</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.InputConvolutional"><code class="docutils literal notranslate"><span class="pre">InputConvolutional</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.FullyConnected"><code class="docutils literal notranslate"><span class="pre">FullyConnected</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Convolutional"><code class="docutils literal notranslate"><span class="pre">Convolutional</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.SeparableConvolutional"><code class="docutils literal notranslate"><span class="pre">SeparableConvolutional</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.InputConv2D"><code class="docutils literal notranslate"><span class="pre">InputConv2D</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Stem"><code class="docutils literal notranslate"><span class="pre">Stem</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Conv2D"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Conv2DTranspose"><code class="docutils literal notranslate"><span class="pre">Conv2DTranspose</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Dense1D"><code class="docutils literal notranslate"><span class="pre">Dense1D</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Dense2D"><code class="docutils literal notranslate"><span class="pre">Dense2D</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.DepthwiseConv2D"><code class="docutils literal notranslate"><span class="pre">DepthwiseConv2D</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.DepthwiseConv2DTranspose"><code class="docutils literal notranslate"><span class="pre">DepthwiseConv2DTranspose</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Attention"><code class="docutils literal notranslate"><span class="pre">Attention</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.VitEncoderBlock"><code class="docutils literal notranslate"><span class="pre">VitEncoderBlock</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Add"><code class="docutils literal notranslate"><span class="pre">Add</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Concatenate"><code class="docutils literal notranslate"><span class="pre">Concatenate</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.ExtractToken"><code class="docutils literal notranslate"><span class="pre">ExtractToken</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.BatchNormalization"><code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.MadNorm"><code class="docutils literal notranslate"><span class="pre">MadNorm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Shiftmax"><code class="docutils literal notranslate"><span class="pre">Shiftmax</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.Dequantizer"><code class="docutils literal notranslate"><span class="pre">Dequantizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#optimizers">Optimizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.core.Optimizer"><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.AkidaUnsupervised"><code class="docutils literal notranslate"><span class="pre">AkidaUnsupervised</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#powermeter">PowerMeter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.PowerMeter"><code class="docutils literal notranslate"><span class="pre">PowerMeter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.PowerEvent"><code class="docutils literal notranslate"><span class="pre">PowerEvent</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#np">NP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.NP.Mesh"><code class="docutils literal notranslate"><span class="pre">Mesh</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.NP.Info"><code class="docutils literal notranslate"><span class="pre">Info</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.NP.Ident"><code class="docutils literal notranslate"><span class="pre">Ident</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.NP.Type"><code class="docutils literal notranslate"><span class="pre">Type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.NP.Mapping"><code class="docutils literal notranslate"><span class="pre">Mapping</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#mapmode">MapMode</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#akida.MapMode"><code class="docutils literal notranslate"><span class="pre">MapMode</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#sparsity">Sparsity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#akida-version">Akida version</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#cnn2snn.AkidaVersion"><code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#cnn2snn.get_akida_version"><code class="docutils literal notranslate"><span class="pre">get_akida_version()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#cnn2snn.set_akida_version"><code class="docutils literal notranslate"><span class="pre">set_akida_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#conversion">Conversion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#cnn2snn.convert"><code class="docutils literal notranslate"><span class="pre">convert()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#cnn2snn.check_model_compatibility"><code class="docutils literal notranslate"><span class="pre">check_model_compatibility()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#onnx-support">ONNX support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#id2">Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#custom-patterns">Custom patterns</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantizeml.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantizeml.save_model"><code class="docutils literal notranslate"><span class="pre">save_model()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#analysis">Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#kernel-distribution">Kernel distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization-error">Quantization error</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#metrics">Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.distiller.Distiller"><code class="docutils literal notranslate"><span class="pre">Distiller</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.distiller.DeitDistiller"><code class="docutils literal notranslate"><span class="pre">DeitDistiller</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.distiller.KLDistillationLoss"><code class="docutils literal notranslate"><span class="pre">KLDistillationLoss()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#macs">MACS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.macs.get_flops"><code class="docutils literal notranslate"><span class="pre">get_flops()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.macs.display_macs"><code class="docutils literal notranslate"><span class="pre">display_macs()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-i-o">Model I/O</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.model_io.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.model_io.load_weights"><code class="docutils literal notranslate"><span class="pre">load_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.model_io.save_weights"><code class="docutils literal notranslate"><span class="pre">save_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.model_io.get_model_path"><code class="docutils literal notranslate"><span class="pre">get_model_path()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#utils">Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.utils.fetch_file"><code class="docutils literal notranslate"><span class="pre">fetch_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.utils.get_tensorboard_callback"><code class="docutils literal notranslate"><span class="pre">get_tensorboard_callback()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akida_models.utils.get_params_by_version"><code class="docutils literal notranslate"><span class="pre">get_params_by_version()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#general-examples">General examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#convert">3. Convert</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#train-for-a-few-epochs">4. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#quantize-the-model">5. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#compute-accuracy">6. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_6_segmentation.html">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_6_segmentation.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_segmentation.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_segmentation.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_segmentation.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_6_segmentation.html#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Build Vision Transformers for Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#model-selection">1. Model selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-optimization-for-akida-hardware">2. Model optimization for Akida hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-training">3. Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="#displaying-results-attention-maps">6. Displaying results Attention Maps</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_8_global_pytorch_workflow.html">PyTorch to Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_8_global_pytorch_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_8_global_pytorch_workflow.html#export">2. Export</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_8_global_pytorch_workflow.html#quantize">3. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_8_global_pytorch_workflow.html#convert">4. Convert</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_2_off_the_shelf_quantization.html">Off-the-shelf models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_2_off_the_shelf_quantization.html#workflow-overview">1. Workflow overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_2_off_the_shelf_quantization.html#data-preparation">2. Data preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_2_off_the_shelf_quantization.html#download-and-export">3. Download and export</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_2_off_the_shelf_quantization.html#quantize">4. Quantize</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_3_custom_patterns.html">Advanced ONNX models quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_3_custom_patterns.html#get-model-and-data">1. Get model and data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_3_custom_patterns.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_3_custom_patterns.html#conversion">3. Conversion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html">Tips to set Akida edge learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#deprecated-cnn2snn-tutorials">[Deprecated] CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id11">Keyword spotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id12">Classification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id14"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id15">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Akida examples</a></li>
      <li class="breadcrumb-item active">Build Vision Transformers for Akida</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-general-plot-7-vision-transformer-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="build-vision-transformers-for-akida">
<span id="sphx-glr-examples-general-plot-7-vision-transformer-py"></span><h1>Build Vision Transformers for Akida<a class="headerlink" href="#build-vision-transformers-for-akida" title="Link to this heading"></a></h1>
<p>The Vision Transformer, or ViT, is a model for image classification that employs a Transformer-like
architecture over patches of the image. An image is split into fixed-size patches, each of them are
then linearly embedded, position embeddings are added, and the resulting sequence of vectors are
fed to a standard Transformer encoder. Please refer to <a class="reference external" href="https://arxiv.org/abs/2010.11929">https://arxiv.org/abs/2010.11929</a> for further
details.</p>
<p>Akida 2.0 now supports patch and position embeddings, and the encoder block in hardware. This
tutorial explains how to build an optimized ViT using Akida models python API for Akida 2.0 hardware.</p>
<section id="model-selection">
<h2>1. Model selection<a class="headerlink" href="#model-selection" title="Link to this heading"></a></h2>
<p>There are many variants of ViT. The choice of the model is typically influenced by the tradeoff
among architecture size, accuracy, inference speed, and training capabilities.</p>
<p>The following table shows few variants of commonly used ViT:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Architecture</p></th>
<th class="head"><p>Original accuracy</p></th>
<th class="head"><p>#Params</p></th>
<th class="head"><p>Architecture</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ViT Base</p></td>
<td><p>79.90%</p></td>
<td><p>86M</p></td>
<td><p>12 heads,
12 blocks,
hidden size 768</p></td>
</tr>
<tr class="row-odd"><td><p>ViT Tiny</p></td>
<td><p>75.48%</p></td>
<td><p>5.8M</p></td>
<td><p>3 heads,
12 blocks,
hidden size 192</p></td>
</tr>
<tr class="row-even"><td><p>DeiT-dist
Tiny</p></td>
<td><p>74.17%</p></td>
<td><p>5.8M</p></td>
<td><p>3 heads,
12 blocks,
hidden size 192</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Vision Transformers support has been introduced in Akida 2.0.</p>
</div>
<p>The Akida model zoo provides tiny  ViT architectures that are optimized to run on Akida
hardware:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="../../api_reference/akida_models_apis.html#akida_models.bc_vit_ti16">ViT (tiny)</a>,</p></li>
<li><p><a class="reference external" href="../../api_reference/akida_models_apis.html#akida_models.bc_deit_ti16">DeiT-dist (tiny)</a>.</p></li>
</ul>
</div></blockquote>
<p>Both architectures have been modified so that their layers can be quantized to integer only
operations.</p>
</section>
<section id="model-optimization-for-akida-hardware">
<h2>2. Model optimization for Akida hardware<a class="headerlink" href="#model-optimization-for-akida-hardware" title="Link to this heading"></a></h2>
<p>ViT has many encoder blocks that perform self-attention to process visual data. Each encoder
block consists of many different layers. To optimally run ViT at the edge using Akida requires
transforming this encoder block in the following way:</p>
<blockquote>
<div><ul class="simple">
<li><p>replace <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">LayerNormalization</a> with
<a class="reference external" href="../../api_reference/quantizeml_apis.html#quantizeml.layers.LayerMadNormalization">LayerMadNormalization</a>,</p></li>
<li><p>replace the last <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization">LayerNormalization</a> previous
to the classification head with a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization">BatchNormalization</a>,</p></li>
<li><p>replace <a class="reference external" href="https://www.tensorflow.org/addons/api_docs/python/tfa/layers/GELU">GeLU</a>
with <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU">ReLU8</a> activations,</p></li>
<li><p>replace <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax">Softmax</a> operation in
<a class="reference external" href="../../api_reference/quantizeml_apis.html#quantizeml.layers.Attention">Attention</a> with a
<a class="reference external" href="../../api_reference/quantizeml_apis.html#quantizeml.layers.shiftmax">shiftmax</a> operation.</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Sections below show different ways to train a ViT for Akida which uses the above
transformations.</p>
</div>
</section>
<section id="model-training">
<h2>3. Model Training<a class="headerlink" href="#model-training" title="Link to this heading"></a></h2>
<p>Akida accelerates ViT model that has the transformation mentioned in Section 2. Training a ViT
that optimally runs on Akida can be made possible in the following two ways:</p>
<section id="option-1-training-a-vit-original-model-first-and-then-transforming-each-layer-incrementally">
<h3>3.1 Option 1: Training a ViT (original) model first and then transforming each layer incrementally<a class="headerlink" href="#option-1-training-a-vit-original-model-first-and-then-transforming-each-layer-incrementally" title="Link to this heading"></a></h3>
<p>First, train a ViT (original) model on a custom dataset until satisfactory accuracy. It is then
possible to transform this model into an Akida optimized one as per Section 2. The layers mentioned
in Section 2 are functionally equivalent to each of the layers present in the original model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To overcome the accuracy drop from the original when transforming the model as per
Section 2, it is recommended to replace the original layers all at once and to fine-tune
afterwards.</p>
</div>
<p>The example below shows the transformation of ViT (tiny) into an optimized model that can run on
the Akida hardware.</p>
<p>The <a class="reference external" href="https://pypi.org/project/akida-models">akida_models</a> python package provides a Command Line
Interface (CLI) to transform <a class="reference external" href="../../_modules/akida_models/transformers/model_vit.html#vit_ti16">vit_ti16</a>
and <a class="reference external" href="../../_modules/akida_models/transformers/model_deit.html#deit_ti16">deit_ti16</a> model architectures
and fine-tune them respectively.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>akida_models<span class="w"> </span>create<span class="w"> </span>vit_ti16<span class="w"> </span>-h
usage:<span class="w"> </span>akida_models<span class="w"> </span>create<span class="w"> </span>vit_ti16<span class="w"> </span><span class="o">[</span>-h<span class="o">]</span><span class="w"> </span><span class="o">[</span>-c<span class="w"> </span>CLASSES<span class="o">]</span><span class="w"> </span><span class="o">[</span>-bw<span class="w"> </span>BASE_WEIGHTS<span class="o">]</span><span class="w"> </span><span class="o">[</span>--norm<span class="w"> </span><span class="o">{</span>LN,GN1,BN,LMN<span class="o">}]</span>
<span class="w">                                    </span><span class="o">[</span>--last_norm<span class="w"> </span><span class="o">{</span>LN,BN<span class="o">}]</span><span class="w"> </span><span class="o">[</span>--softmax<span class="w"> </span><span class="o">{</span>softmax,softmax2<span class="o">}]</span>
<span class="w">                                    </span><span class="o">[</span>--act<span class="w"> </span><span class="o">{</span>GeLU,ReLU8,swish<span class="o">}]</span><span class="w"> </span><span class="o">[</span>-i<span class="w"> </span><span class="o">{</span><span class="m">224</span>,384<span class="o">}]</span>

optional<span class="w"> </span>arguments:
<span class="w">  </span>-h,<span class="w"> </span>--help<span class="w">            </span>show<span class="w"> </span>this<span class="w"> </span><span class="nb">help</span><span class="w"> </span>message<span class="w"> </span>and<span class="w"> </span><span class="nb">exit</span>
<span class="w">  </span>-c<span class="w"> </span>CLASSES,<span class="w"> </span>--classes<span class="w"> </span>CLASSES
<span class="w">                        </span>The<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>classes,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span><span class="m">1000</span>.
<span class="w">  </span>-bw<span class="w"> </span>BASE_WEIGHTS,<span class="w"> </span>--base_weights<span class="w"> </span>BASE_WEIGHTS
<span class="w">                        </span>Optional<span class="w"> </span>keras<span class="w"> </span>weights<span class="w"> </span>to<span class="w"> </span>load<span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>model,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span>None.
<span class="w">  </span>--norm<span class="w"> </span><span class="o">{</span>LN,GN1,BN,LMN<span class="o">}</span>
<span class="w">                        </span>Replace<span class="w"> </span>normalization<span class="w"> </span><span class="k">in</span><span class="w"> </span>model<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>custom<span class="w"> </span><span class="k">function</span>,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span>LN
<span class="w">  </span>--last_norm<span class="w"> </span><span class="o">{</span>LN,BN<span class="o">}</span><span class="w">   </span>Replace<span class="w"> </span>last<span class="w"> </span>normalization<span class="w"> </span><span class="k">in</span><span class="w"> </span>model<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>custom<span class="w"> </span><span class="k">function</span>,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span>LN
<span class="w">  </span>--softmax<span class="w"> </span><span class="o">{</span>softmax,softmax2<span class="o">}</span>
<span class="w">                        </span>Replace<span class="w"> </span>softmax<span class="w"> </span>operation<span class="w"> </span><span class="k">in</span><span class="w"> </span>model<span class="w"> </span>with<span class="w"> </span>custom<span class="w"> </span><span class="k">function</span>,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span>softmax
<span class="w">  </span>--act<span class="w"> </span><span class="o">{</span>GeLU,ReLU8,swish<span class="o">}</span>
<span class="w">                        </span>Replace<span class="w"> </span>activation<span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>model<span class="w"> </span>with<span class="w"> </span>custom<span class="w"> </span><span class="k">function</span>,<span class="w"> </span>by<span class="w"> </span>default<span class="w"> </span>GeLU
<span class="w">  </span>-i<span class="w"> </span><span class="o">{</span><span class="m">224</span>,384<span class="o">}</span>,<span class="w"> </span>--image_size<span class="w"> </span><span class="o">{</span><span class="m">224</span>,384<span class="o">}</span>
<span class="w">                        </span>The<span class="w"> </span>square<span class="w"> </span>input<span class="w"> </span>image<span class="w"> </span>size
</pre></div>
</div>
<p>The following shows the transformation of a vit_ti16 model architecture which was trained on ImageNet. The
same methods can be applied for other datasets.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># download the pre-trained weights</span>
wget<span class="w"> </span>https://data.brainchip.com/models/AkidaV2/vit/vit_ti16_224.h5

<span class="c1"># transformations: replace layer normalization with mad norm layer, last layer normalization</span>
<span class="c1"># with batch normalization, GeLU layer with ReLU and softmax with shiftmax layer</span>
akida_models<span class="w"> </span>create<span class="w"> </span>-s<span class="w"> </span>vit_ti16_transformed.h5<span class="w"> </span>vit_ti16<span class="w"> </span>--norm<span class="w"> </span>LMN<span class="w"> </span>--last_norm<span class="w"> </span>BN<span class="w"> </span>--act<span class="w"> </span>ReLU8<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--softmax<span class="w"> </span>softmax2<span class="w"> </span>-bw<span class="w"> </span>vit_ti16_224.h5
<span class="c1"># fine-tuning</span>
imagenet_train<span class="w"> </span>tune<span class="w"> </span>-m<span class="w"> </span>vit_ti16_transformed.h5<span class="w"> </span>-e<span class="w"> </span><span class="m">30</span><span class="w"> </span>--optim<span class="w"> </span>Adam<span class="w"> </span>--lr_policy<span class="w"> </span>cosine_decay<span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>-lr<span class="w"> </span>6e-5<span class="w"> </span>-s<span class="w"> </span>vit_ti16_transformed.h5
</pre></div>
</div>
<p>The above transformation generates a ViT model that is optimized to run efficiently on Akida hardware.
Similar steps can also be applied to deit_ti16. The table below highlights the accuracy of the original
and transformed models.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Architecture</p></th>
<th class="head"><p>Original accuracy</p></th>
<th class="head"><p>Transformed accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ViT</p></td>
<td><p>75.48%</p></td>
<td><p>74.25%</p></td>
</tr>
<tr class="row-odd"><td><p>DeiT-dist</p></td>
<td><p>74.17%</p></td>
<td><p>75.03%</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The models obtained above have floating point weights and are ready to be quantized.
See Section 4.</p>
</div>
</section>
<section id="option-2-transfer-learning-using-pre-trained-transformed-model">
<h3>3.2 Option 2: Transfer Learning using Pre-trained transformed model<a class="headerlink" href="#option-2-transfer-learning-using-pre-trained-transformed-model" title="Link to this heading"></a></h3>
<p>The <a class="reference external" href="../../api_reference/akida_models_apis.html">Akida models python package</a> has  <a class="reference external" href="../../api_reference/akida_models_apis.html#layer-blocks">APIs for ViTs</a> which provides pre-trained models for
<a class="reference external" href="../../_modules/akida_models/transformers/model_vit.html#vit_ti16">vit_ti16</a> and <a class="reference external" href="../../_modules/akida_models/transformers/model_deit.html#deit_ti16">deit_ti16</a>. These models can be used
for Transfer Learning on a custom dataset. Since the above models are already transformed, no
further transformation is required.</p>
<p>Visit our <a class="reference external" href="plot_4_transfer_learning.html">Transfer Learning Example</a> to learn more about Transfer
Learning using the <a class="reference external" href="../../api_reference/akida_models_apis.html">Akida models python package</a>. The
following code snippet downloads a pre-trained model that can be used for Transfer Learning.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following is the API download the vit_t16 model trained on ImageNet dataset</span>
<span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">fetch_file</span>
<span class="kn">from</span> <span class="nn">akida_models.model_io</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="c1"># Retrieve the float model with pretrained weights and load it</span>
<span class="n">model_file</span> <span class="o">=</span> <span class="n">fetch_file</span><span class="p">(</span>
    <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;bc_vit_ti16_224.h5&quot;</span><span class="p">,</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;https://data.brainchip.com/models/AkidaV2/vit/bc_vit_ti16_224.h5&quot;</span><span class="p">,</span>
    <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;models/akidanet_imagenet&#39;</span><span class="p">)</span>
<span class="n">model_keras</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
<span class="n">model_keras</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://data.brainchip.com/models/AkidaV2/vit/bc_vit_ti16_224.h5.

       0/23695632 [..............................] - ETA: 0s
  122880/23695632 [..............................] - ETA: 9s
  753664/23695632 [..............................] - ETA: 3s
 1531904/23695632 [&gt;.............................] - ETA: 2s
 2367488/23695632 [=&gt;............................] - ETA: 1s
 3178496/23695632 [===&gt;..........................] - ETA: 1s
 4202496/23695632 [====&gt;.........................] - ETA: 1s
 5439488/23695632 [=====&gt;........................] - ETA: 1s
 6504448/23695632 [=======&gt;......................] - ETA: 1s
 7602176/23695632 [========&gt;.....................] - ETA: 0s
 8945664/23695632 [==========&gt;...................] - ETA: 0s
10166272/23695632 [===========&gt;..................] - ETA: 0s
11214848/23695632 [=============&gt;................] - ETA: 0s
12279808/23695632 [==============&gt;...............] - ETA: 0s
13312000/23695632 [===============&gt;..............] - ETA: 0s
14245888/23695632 [=================&gt;............] - ETA: 0s
15310848/23695632 [==================&gt;...........] - ETA: 0s
16900096/23695632 [====================&gt;.........] - ETA: 0s
18407424/23695632 [======================&gt;.......] - ETA: 0s
20078592/23695632 [========================&gt;.....] - ETA: 0s
21733376/23695632 [==========================&gt;...] - ETA: 0s
23379968/23695632 [============================&gt;.] - ETA: 0s
23695632/23695632 [==============================] - 1s 0us/step
Download complete.
/usr/local/lib/python3.11/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.
  warnings.warn(
Model: &quot;vit-tiny&quot;
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input (InputLayer)          [(None, 224, 224, 3)]        0         []

 Rescale (Rescaling)         (None, 224, 224, 3)          0         [&#39;input[0][0]&#39;]

 Embedding (Conv2D)          (None, 14, 14, 192)          147648    [&#39;Rescale[0][0]&#39;]

 reshape (Reshape)           (None, 196, 192)             0         [&#39;Embedding[0][0]&#39;]

 ClassToken (ClassToken)     (None, 197, 192)             192       [&#39;reshape[0][0]&#39;]

 Transformer/PosEmbed (AddP  (None, 197, 192)             37824     [&#39;ClassToken[0][0]&#39;]
 ositionEmbs)

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;Transformer/PosEmbed[0][0]&#39;]
 /LayerNorm_0 (LayerMadNorm
 alization)

 Transformer/EncoderBlock_0  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_0  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_0  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_0  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout (Dropout)           (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             0         [&#39;dropout[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/PosEmbed[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_0  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_0/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_0/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_1 (Dropout)         (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_0/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             147648    [&#39;dropout_1[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_2 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_1  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_3 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;dropout_3[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_0/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_1/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_1/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_4 (Dropout)         (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_1/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             147648    [&#39;dropout_4[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_5 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_5[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_2  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_2  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_2  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_2  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_6 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             0         [&#39;dropout_6[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_1/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_2  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_2/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_2/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_7 (Dropout)         (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_2/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             147648    [&#39;dropout_7[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_8 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_8[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_3  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_3  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_3  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_3  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_9 (Dropout)         (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             0         [&#39;dropout_9[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_2/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_3  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_3/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_3/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_10 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_3/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             147648    [&#39;dropout_10[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_11 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_11[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_4  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_4  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_4  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_4  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_12 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             0         [&#39;dropout_12[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_3/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_4  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_4/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_4/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_13 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_4/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             147648    [&#39;dropout_13[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_14 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_14[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_5  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_5  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_5  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_5  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_15 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             0         [&#39;dropout_15[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_4/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_5  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_5/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_5/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_16 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_5/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             147648    [&#39;dropout_16[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_17 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_17[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_6  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_6  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_6  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_6  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_18 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             0         [&#39;dropout_18[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_5/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_6  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_6/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_6/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_19 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_6/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             147648    [&#39;dropout_19[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_20 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_20[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_7  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_7  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_7  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_7  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_21 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             0         [&#39;dropout_21[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_6/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_7  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_7/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_7/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_22 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_7/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             147648    [&#39;dropout_22[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_23 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_23[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_8  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_8  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_8  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_8  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_24 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             0         [&#39;dropout_24[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_7/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_8  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_8/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_8/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_25 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_8/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             147648    [&#39;dropout_25[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_26 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_26[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_0 (LayerMadNorm                                         dd_2[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_9  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (Dense)

 Transformer/EncoderBlock_9  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (Dense)

 Transformer/EncoderBlock_9  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (Dense)

 Transformer/EncoderBlock_9  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Attention                                         query[0][0]&#39;,
 )                                                                   &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (Dense)                                                  attention[0][0]&#39;]

 dropout_27 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             0         [&#39;dropout_27[0][0]&#39;,
 /add_1 (Add)                                                        &#39;Transformer/EncoderBlock_8/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_9/a
 /LayerNorm_2 (LayerMadNorm                                         dd_1[0][0]&#39;]
 alization)

 Transformer/EncoderBlock_9  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_9/L
 /MlpBlock/Dense_0 (Dense)                                          ayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_9/M
 /MlpBlock/activation (ReLU                                         lpBlock/Dense_0[0][0]&#39;]
 )

 dropout_28 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_9/M
                                                                    lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             147648    [&#39;dropout_28[0][0]&#39;]
 /MlpBlock/Dense_1 (Dense)

 dropout_29 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
                                                                    lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/a
 /add_2 (Add)                                                       dd_1[0][0]&#39;,
                                                                     &#39;dropout_29[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_9/a
 0/LayerNorm_0 (LayerMadNor                                         dd_2[0][0]&#39;]
 malization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (Dense)

 Transformer/EncoderBlock_1  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Attentio                                         /query[0][0]&#39;,
 n)                                                                  &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (Dense)                                                 /attention[0][0]&#39;]

 dropout_30 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;dropout_30[0][0]&#39;,
 0/add_1 (Add)                                                       &#39;Transformer/EncoderBlock_9/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_10/
 0/LayerNorm_2 (LayerMadNor                                         add_1[0][0]&#39;]
 malization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/Dense_0 (Dense)                                         LayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/activation (ReL                                         MlpBlock/Dense_0[0][0]&#39;]
 U)

 dropout_31 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_10/
                                                                    MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             147648    [&#39;dropout_31[0][0]&#39;]
 0/MlpBlock/Dense_1 (Dense)

 dropout_32 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
                                                                    MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
 0/add_2 (Add)                                                      add_1[0][0]&#39;,
                                                                     &#39;dropout_32[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_10/
 1/LayerNorm_0 (LayerMadNor                                         add_2[0][0]&#39;]
 malization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (Dense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (Dense)

 Transformer/EncoderBlock_1  ((None, 197, 192),           0         [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Attentio                                         /query[0][0]&#39;,
 n)                                                                  &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37056     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (Dense)                                                 /attention[0][0]&#39;]

 dropout_33 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;dropout_33[0][0]&#39;,
 1/add_1 (Add)                                                       &#39;Transformer/EncoderBlock_10/
                                                                    add_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_11/
 1/LayerNorm_2 (LayerMadNor                                         add_1[0][0]&#39;]
 malization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/Dense_0 (Dense)                                         LayerNorm_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/activation (ReL                                         MlpBlock/Dense_0[0][0]&#39;]
 U)

 dropout_34 (Dropout)        (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_11/
                                                                    MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             147648    [&#39;dropout_34[0][0]&#39;]
 1/MlpBlock/Dense_1 (Dense)

 dropout_35 (Dropout)        (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
                                                                    MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
 1/add_2 (Add)                                                      add_1[0][0]&#39;,
                                                                     &#39;dropout_35[0][0]&#39;]

 Transformer/EncoderNorm (B  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_11/
 atchNormalization)                                                 add_2[0][0]&#39;]

 ExtractToken (ExtractToken  (None, 192)                  0         [&#39;Transformer/EncoderNorm[0][0
 )                                                                  ]&#39;]

 Head (Dense)                (None, 1000)                 193000    [&#39;ExtractToken[0][0]&#39;]

==================================================================================================
Total params: 5717800 (21.81 MB)
Trainable params: 5717416 (21.81 MB)
Non-trainable params: 384 (1.50 KB)
__________________________________________________________________________________________________
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The models in Section 3 have floating point weights. Once the desired accuracy is obtained,
these models should go through quantization before converting to Akida.</p>
</div>
</section>
</section>
<section id="model-quantization">
<h2>4. Model quantization<a class="headerlink" href="#model-quantization" title="Link to this heading"></a></h2>
<p>Akida 2.0 hardware adds efficient processing of 8-bit weights and activations for Vision Transformer
models. This requires models in Section 3 to be quantized to 8-bit integer numbers. This means both
weights and activation outputs become 8-bit integer numbers. This results in a smaller  model with
minimal to no drop in accuracy and achieves improvements in latency and power when running on Akida
hardware.</p>
<p>Quantization of ViT models can be done using <a class="reference external" href="../../user_guide/quantizeml.html">QuantizeML python package</a>
using either Post Training Quantization (PTQ) or Quantization Aware Training (QAT) methods. The following
section shows quantization an example, quantization of <a class="reference external" href="../../_modules/akida_models/transformers/model_vit.html#vit_ti16">vit_ti16</a> trained on ImageNet dataset.</p>
<section id="post-training-quantization">
<h3>4.1 Post-Training Quantization<a class="headerlink" href="#post-training-quantization" title="Link to this heading"></a></h3>
<p>Using <a class="reference external" href="../../user_guide/quantizeml.html">QuantizeML python package</a>, ViT model can be quantized to
8-bit integer numbers (both weights and activation outputs). PTQ requires calibration (ideally using
reference data) which helps to determine optimal quantization ranges. To learn more about PTQ, refer
to <a class="reference external" href="../quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using QuantizeML to perform quantization</span>
<span class="kn">from</span> <span class="nn">quantizeml.models</span> <span class="kn">import</span> <span class="n">quantize</span><span class="p">,</span> <span class="n">QuantizationParams</span>

<span class="c1"># Define the quantization parameters.</span>
<span class="n">qparams</span> <span class="o">=</span> <span class="n">QuantizationParams</span><span class="p">(</span><span class="n">weight_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Quantize the model defined in Section 3.2</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="n">qparams</span><span class="o">=</span><span class="n">qparams</span><span class="p">)</span>
<span class="n">model_quantized</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.11/dist-packages/quantizeml/models/quantize.py:461: UserWarning: Quantizing per-axis with random calibration samples is not accurate.                       Set QuantizationParams.per_tensor_activations=True when calibrating with                        random samples.
  warnings.warn(&quot;Quantizing per-axis with random calibration samples is not accurate.\

   1/1024 [..............................] - ETA: 1:32:00
   6/1024 [..............................] - ETA: 12s    
  11/1024 [..............................] - ETA: 11s
  16/1024 [..............................] - ETA: 11s
  21/1024 [..............................] - ETA: 11s
  26/1024 [..............................] - ETA: 11s
  31/1024 [..............................] - ETA: 11s
  36/1024 [&gt;.............................] - ETA: 11s
  41/1024 [&gt;.............................] - ETA: 11s
  46/1024 [&gt;.............................] - ETA: 11s
  51/1024 [&gt;.............................] - ETA: 11s
  56/1024 [&gt;.............................] - ETA: 11s
  61/1024 [&gt;.............................] - ETA: 11s
  66/1024 [&gt;.............................] - ETA: 11s
  71/1024 [=&gt;............................] - ETA: 11s
  76/1024 [=&gt;............................] - ETA: 11s
  81/1024 [=&gt;............................] - ETA: 10s
  86/1024 [=&gt;............................] - ETA: 10s
  91/1024 [=&gt;............................] - ETA: 10s
  96/1024 [=&gt;............................] - ETA: 10s
 101/1024 [=&gt;............................] - ETA: 10s
 106/1024 [==&gt;...........................] - ETA: 10s
 111/1024 [==&gt;...........................] - ETA: 10s
 116/1024 [==&gt;...........................] - ETA: 10s
 121/1024 [==&gt;...........................] - ETA: 10s
 126/1024 [==&gt;...........................] - ETA: 10s
 131/1024 [==&gt;...........................] - ETA: 10s
 136/1024 [==&gt;...........................] - ETA: 10s
 141/1024 [===&gt;..........................] - ETA: 10s
 146/1024 [===&gt;..........................] - ETA: 10s
 151/1024 [===&gt;..........................] - ETA: 10s
 156/1024 [===&gt;..........................] - ETA: 10s
 161/1024 [===&gt;..........................] - ETA: 10s
 166/1024 [===&gt;..........................] - ETA: 9s 
 171/1024 [====&gt;.........................] - ETA: 9s
 176/1024 [====&gt;.........................] - ETA: 9s
 181/1024 [====&gt;.........................] - ETA: 9s
 186/1024 [====&gt;.........................] - ETA: 9s
 191/1024 [====&gt;.........................] - ETA: 9s
 196/1024 [====&gt;.........................] - ETA: 9s
 201/1024 [====&gt;.........................] - ETA: 9s
 206/1024 [=====&gt;........................] - ETA: 9s
 211/1024 [=====&gt;........................] - ETA: 9s
 216/1024 [=====&gt;........................] - ETA: 9s
 221/1024 [=====&gt;........................] - ETA: 9s
 226/1024 [=====&gt;........................] - ETA: 9s
 231/1024 [=====&gt;........................] - ETA: 9s
 236/1024 [=====&gt;........................] - ETA: 9s
 241/1024 [======&gt;.......................] - ETA: 9s
 246/1024 [======&gt;.......................] - ETA: 9s
 251/1024 [======&gt;.......................] - ETA: 8s
 256/1024 [======&gt;.......................] - ETA: 8s
 261/1024 [======&gt;.......................] - ETA: 8s
 266/1024 [======&gt;.......................] - ETA: 8s
 271/1024 [======&gt;.......................] - ETA: 8s
 276/1024 [=======&gt;......................] - ETA: 8s
 281/1024 [=======&gt;......................] - ETA: 8s
 286/1024 [=======&gt;......................] - ETA: 8s
 291/1024 [=======&gt;......................] - ETA: 8s
 296/1024 [=======&gt;......................] - ETA: 8s
 301/1024 [=======&gt;......................] - ETA: 8s
 306/1024 [=======&gt;......................] - ETA: 8s
 311/1024 [========&gt;.....................] - ETA: 8s
 316/1024 [========&gt;.....................] - ETA: 8s
 321/1024 [========&gt;.....................] - ETA: 8s
 326/1024 [========&gt;.....................] - ETA: 8s
 331/1024 [========&gt;.....................] - ETA: 8s
 336/1024 [========&gt;.....................] - ETA: 7s
 341/1024 [========&gt;.....................] - ETA: 7s
 346/1024 [=========&gt;....................] - ETA: 7s
 351/1024 [=========&gt;....................] - ETA: 7s
 356/1024 [=========&gt;....................] - ETA: 7s
 361/1024 [=========&gt;....................] - ETA: 7s
 366/1024 [=========&gt;....................] - ETA: 7s
 371/1024 [=========&gt;....................] - ETA: 7s
 376/1024 [==========&gt;...................] - ETA: 7s
 381/1024 [==========&gt;...................] - ETA: 7s
 386/1024 [==========&gt;...................] - ETA: 7s
 391/1024 [==========&gt;...................] - ETA: 7s
 396/1024 [==========&gt;...................] - ETA: 7s
 401/1024 [==========&gt;...................] - ETA: 7s
 406/1024 [==========&gt;...................] - ETA: 7s
 411/1024 [===========&gt;..................] - ETA: 7s
 416/1024 [===========&gt;..................] - ETA: 7s
 421/1024 [===========&gt;..................] - ETA: 6s
 426/1024 [===========&gt;..................] - ETA: 6s
 431/1024 [===========&gt;..................] - ETA: 6s
 436/1024 [===========&gt;..................] - ETA: 6s
 441/1024 [===========&gt;..................] - ETA: 6s
 446/1024 [============&gt;.................] - ETA: 6s
 451/1024 [============&gt;.................] - ETA: 6s
 456/1024 [============&gt;.................] - ETA: 6s
 461/1024 [============&gt;.................] - ETA: 6s
 466/1024 [============&gt;.................] - ETA: 6s
 471/1024 [============&gt;.................] - ETA: 6s
 476/1024 [============&gt;.................] - ETA: 6s
 481/1024 [=============&gt;................] - ETA: 6s
 486/1024 [=============&gt;................] - ETA: 6s
 491/1024 [=============&gt;................] - ETA: 6s
 496/1024 [=============&gt;................] - ETA: 6s
 501/1024 [=============&gt;................] - ETA: 6s
 506/1024 [=============&gt;................] - ETA: 5s
 511/1024 [=============&gt;................] - ETA: 5s
 516/1024 [==============&gt;...............] - ETA: 5s
 521/1024 [==============&gt;...............] - ETA: 5s
 526/1024 [==============&gt;...............] - ETA: 5s
 531/1024 [==============&gt;...............] - ETA: 5s
 536/1024 [==============&gt;...............] - ETA: 5s
 541/1024 [==============&gt;...............] - ETA: 5s
 546/1024 [==============&gt;...............] - ETA: 5s
 551/1024 [===============&gt;..............] - ETA: 5s
 556/1024 [===============&gt;..............] - ETA: 5s
 561/1024 [===============&gt;..............] - ETA: 5s
 566/1024 [===============&gt;..............] - ETA: 5s
 571/1024 [===============&gt;..............] - ETA: 5s
 576/1024 [===============&gt;..............] - ETA: 5s
 581/1024 [================&gt;.............] - ETA: 5s
 586/1024 [================&gt;.............] - ETA: 5s
 591/1024 [================&gt;.............] - ETA: 5s
 596/1024 [================&gt;.............] - ETA: 4s
 601/1024 [================&gt;.............] - ETA: 4s
 606/1024 [================&gt;.............] - ETA: 4s
 611/1024 [================&gt;.............] - ETA: 4s
 616/1024 [=================&gt;............] - ETA: 4s
 621/1024 [=================&gt;............] - ETA: 4s
 626/1024 [=================&gt;............] - ETA: 4s
 631/1024 [=================&gt;............] - ETA: 4s
 636/1024 [=================&gt;............] - ETA: 4s
 641/1024 [=================&gt;............] - ETA: 4s
 646/1024 [=================&gt;............] - ETA: 4s
 651/1024 [==================&gt;...........] - ETA: 4s
 656/1024 [==================&gt;...........] - ETA: 4s
 661/1024 [==================&gt;...........] - ETA: 4s
 666/1024 [==================&gt;...........] - ETA: 4s
 671/1024 [==================&gt;...........] - ETA: 4s
 676/1024 [==================&gt;...........] - ETA: 4s
 681/1024 [==================&gt;...........] - ETA: 3s
 686/1024 [===================&gt;..........] - ETA: 3s
 691/1024 [===================&gt;..........] - ETA: 3s
 696/1024 [===================&gt;..........] - ETA: 3s
 701/1024 [===================&gt;..........] - ETA: 3s
 706/1024 [===================&gt;..........] - ETA: 3s
 711/1024 [===================&gt;..........] - ETA: 3s
 716/1024 [===================&gt;..........] - ETA: 3s
 721/1024 [====================&gt;.........] - ETA: 3s
 726/1024 [====================&gt;.........] - ETA: 3s
 731/1024 [====================&gt;.........] - ETA: 3s
 736/1024 [====================&gt;.........] - ETA: 3s
 741/1024 [====================&gt;.........] - ETA: 3s
 746/1024 [====================&gt;.........] - ETA: 3s
 751/1024 [=====================&gt;........] - ETA: 3s
 756/1024 [=====================&gt;........] - ETA: 3s
 761/1024 [=====================&gt;........] - ETA: 3s
 766/1024 [=====================&gt;........] - ETA: 2s
 771/1024 [=====================&gt;........] - ETA: 2s
 776/1024 [=====================&gt;........] - ETA: 2s
 781/1024 [=====================&gt;........] - ETA: 2s
 786/1024 [======================&gt;.......] - ETA: 2s
 791/1024 [======================&gt;.......] - ETA: 2s
 796/1024 [======================&gt;.......] - ETA: 2s
 801/1024 [======================&gt;.......] - ETA: 2s
 806/1024 [======================&gt;.......] - ETA: 2s
 811/1024 [======================&gt;.......] - ETA: 2s
 816/1024 [======================&gt;.......] - ETA: 2s
 821/1024 [=======================&gt;......] - ETA: 2s
 826/1024 [=======================&gt;......] - ETA: 2s
 831/1024 [=======================&gt;......] - ETA: 2s
 836/1024 [=======================&gt;......] - ETA: 2s
 841/1024 [=======================&gt;......] - ETA: 2s
 846/1024 [=======================&gt;......] - ETA: 2s
 851/1024 [=======================&gt;......] - ETA: 2s
 856/1024 [========================&gt;.....] - ETA: 1s
 861/1024 [========================&gt;.....] - ETA: 1s
 866/1024 [========================&gt;.....] - ETA: 1s
 871/1024 [========================&gt;.....] - ETA: 1s
 876/1024 [========================&gt;.....] - ETA: 1s
 881/1024 [========================&gt;.....] - ETA: 1s
 886/1024 [========================&gt;.....] - ETA: 1s
 891/1024 [=========================&gt;....] - ETA: 1s
 896/1024 [=========================&gt;....] - ETA: 1s
 901/1024 [=========================&gt;....] - ETA: 1s
 906/1024 [=========================&gt;....] - ETA: 1s
 911/1024 [=========================&gt;....] - ETA: 1s
 916/1024 [=========================&gt;....] - ETA: 1s
 921/1024 [=========================&gt;....] - ETA: 1s
 926/1024 [==========================&gt;...] - ETA: 1s
 931/1024 [==========================&gt;...] - ETA: 1s
 936/1024 [==========================&gt;...] - ETA: 1s
 941/1024 [==========================&gt;...] - ETA: 0s
 946/1024 [==========================&gt;...] - ETA: 0s
 951/1024 [==========================&gt;...] - ETA: 0s
 956/1024 [===========================&gt;..] - ETA: 0s
 961/1024 [===========================&gt;..] - ETA: 0s
 966/1024 [===========================&gt;..] - ETA: 0s
 971/1024 [===========================&gt;..] - ETA: 0s
 976/1024 [===========================&gt;..] - ETA: 0s
 981/1024 [===========================&gt;..] - ETA: 0s
 986/1024 [===========================&gt;..] - ETA: 0s
 991/1024 [============================&gt;.] - ETA: 0s
 996/1024 [============================&gt;.] - ETA: 0s
1001/1024 [============================&gt;.] - ETA: 0s
1006/1024 [============================&gt;.] - ETA: 0s
1011/1024 [============================&gt;.] - ETA: 0s
1016/1024 [============================&gt;.] - ETA: 0s
1021/1024 [============================&gt;.] - ETA: 0s
1024/1024 [==============================] - 17s 12ms/step
Model: &quot;vit-tiny&quot;
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input (InputLayer)          [(None, 224, 224, 3)]        0         []

 Rescale (QuantizedRescalin  (None, 224, 224, 3)          0         [&#39;input[0][0]&#39;]
 g)

 Embedding (QuantizedConv2D  (None, 14, 14, 192)          147648    [&#39;Rescale[0][0]&#39;]
 )

 reshape (QuantizedReshape)  (None, 196, 192)             0         [&#39;Embedding[0][0]&#39;]

 ClassToken (QuantizedClass  (None, 197, 192)             192       [&#39;reshape[0][0]&#39;]
 Token)

 Transformer/PosEmbed (Quan  (None, 197, 192)             38208     [&#39;ClassToken[0][0]&#39;]
 tizedAddPositionEmbs)

 Transformer/EncoderBlock_0  (None, 197, 192)             768       [&#39;Transformer/PosEmbed[0][0]&#39;]
 /LayerNorm_0 (QuantizedLay
 erNormalization)

 Transformer/EncoderBlock_0  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_0  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_0  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_0  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout (QuantizedDropout)  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;dropout[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/PosEmbed[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_0  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_0/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_0  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_0/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_1 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_0/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             148032    [&#39;dropout_1[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_2 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_0/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_3 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_3[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_0/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_1/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_1/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_4 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_4[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_5 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_1/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_5[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_2  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_2  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_2  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_2  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_6 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;dropout_6[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_1/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_2  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_2/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_2  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_2/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_7 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             148032    [&#39;dropout_7[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_8 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_2/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_8[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_3  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_3  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_3  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_3  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_9 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;dropout_9[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_2/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_3  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_3/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_3  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_3/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_10 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_3/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             148032    [&#39;dropout_10[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_11 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_3/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_11[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_4  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_4  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_4  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_4  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_12 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;dropout_12[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_3/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_4  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_4/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_4  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_4/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_13 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             148032    [&#39;dropout_13[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_14 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_4/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_14[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_5  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_5  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_5  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_5  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_15 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;dropout_15[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_4/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_5  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_5/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_5  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_5/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_16 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             148032    [&#39;dropout_16[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_17 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_5/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_17[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_6  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_6  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_6  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_6  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_18 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;dropout_18[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_5/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_6  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_6/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_6  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_6/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_19 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             148032    [&#39;dropout_19[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_20 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_6/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_20[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_7  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_7  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_7  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_7  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_21 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;dropout_21[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_6/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_7  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_7/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_7  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_7/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_22 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             148032    [&#39;dropout_22[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_23 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_7/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_23[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_8  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_8  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_8  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_8  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_24 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;dropout_24[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_7/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_8  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_8/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_8  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_8/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_25 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             148032    [&#39;dropout_25[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_26 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_8/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_26[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_9  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_9  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_9  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_9  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_27 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;dropout_27[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_8/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_9/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_9  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_9/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_9  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_9/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_28 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             148032    [&#39;dropout_28[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_29 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_9/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_29[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_9/a
 0/LayerNorm_0 (QuantizedLa                                         dd_2[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (QuantizedDen
 se)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (QuantizedDense
 )

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (QuantizedDen
 se)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Quantize                                         /query[0][0]&#39;,
 dAttention)                                                         &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (QuantizedDense                                         /attention[0][0]&#39;]
 )

 dropout_30 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_30[0][0]&#39;,
 0/add_1 (QuantizedAdd)                                              &#39;Transformer/EncoderBlock_9/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_10/
 0/LayerNorm_2 (QuantizedLa                                         add_1[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/Dense_0 (Quanti                                         LayerNorm_2[0][0]&#39;]
 zedDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/activation (Qua                                         MlpBlock/Dense_0[0][0]&#39;]
 ntizedReLU)

 dropout_31 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_31[0][0]&#39;]
 0/MlpBlock/Dense_1 (Quanti
 zedDense)

 dropout_32 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_10/
 0/add_2 (QuantizedAdd)                                             add_1[0][0]&#39;,
                                                                     &#39;dropout_32[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_10/
 1/LayerNorm_0 (QuantizedLa                                         add_2[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (QuantizedDen
 se)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (QuantizedDense
 )

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (QuantizedDen
 se)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Quantize                                         /query[0][0]&#39;,
 dAttention)                                                         &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (QuantizedDense                                         /attention[0][0]&#39;]
 )

 dropout_33 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_33[0][0]&#39;,
 1/add_1 (QuantizedAdd)                                              &#39;Transformer/EncoderBlock_10/
                                                                    add_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_11/
 1/LayerNorm_2 (QuantizedLa                                         add_1[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/Dense_0 (Quanti                                         LayerNorm_2[0][0]&#39;]
 zedDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/activation (Qua                                         MlpBlock/Dense_0[0][0]&#39;]
 ntizedReLU)

 dropout_34 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_34[0][0]&#39;]
 1/MlpBlock/Dense_1 (Quanti
 zedDense)

 dropout_35 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_11/
 1/add_2 (QuantizedAdd)                                             add_1[0][0]&#39;,
                                                                     &#39;dropout_35[0][0]&#39;]

 Transformer/EncoderNorm (Q  (None, 197, 192)             1152      [&#39;Transformer/EncoderBlock_11/
 uantizedBatchNormalization                                         add_2[0][0]&#39;]
 )

 ExtractToken (QuantizedExt  (None, 192)                  0         [&#39;Transformer/EncoderNorm[0][0
 ractToken)                                                         ]&#39;]

 Head (QuantizedDense)       (None, 1000)                 193000    [&#39;ExtractToken[0][0]&#39;]

 dequantizer (Dequantizer)   (None, 1000)                 0         [&#39;Head[0][0]&#39;]

==================================================================================================
Total params: 5773912 (22.03 MB)
Trainable params: 5717416 (21.81 MB)
Non-trainable params: 56496 (220.69 KB)
__________________________________________________________________________________________________
</pre></div>
</div>
<p>The <a class="reference external" href="../../api_reference/akida_models_apis.html#akida_models.bc_vit_ti16_imagenet_pretrained">bc_vit_ti16_imagenet_pretrained helper</a>
was obtained with the same 8-bit quantization scheme but with an additional QAT step to further
improve accuracy.</p>
</section>
<section id="quantization-aware-training-optional">
<h3>4.2 Quantization Aware Training (Optional)<a class="headerlink" href="#quantization-aware-training-optional" title="Link to this heading"></a></h3>
<p>In Section 4.1, we performed PTQ and converted the weights and activation outputs to 8-bit integer numbers.
In most cases, there is no accuracy drop observed after quantization, however in cases where an accurary
drop is observed, it is possible to further fine-tune this model using QAT.</p>
<p>The model that is obtained through <a class="reference external" href="../../user_guide/quantizeml.html">QuantizeML python package</a> is an
instance of Keras. This allows the model to be fine-tuned using the original dataset to regain accuracy.</p>
<p><a class="reference external" href="../../api_reference/akida_models_apis.html">Akida models python package</a>  provides pre-trained models
for vit_ti16 and deit_ti16 that have been trained using QAT method. It can be used in the following way:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">bc_vit_ti16_imagenet_pretrained</span>

<span class="c1"># Load the pre-trained quantized model</span>
<span class="n">model_quantized</span> <span class="o">=</span> <span class="n">bc_vit_ti16_imagenet_pretrained</span><span class="p">()</span>
<span class="n">model_quantized</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://data.brainchip.com/models/AkidaV2/vit/bc_vit_ti16_224_i8_w8_a8.h5.

       0/24413248 [..............................] - ETA: 0s
  106496/24413248 [..............................] - ETA: 11s
  786432/24413248 [..............................] - ETA: 3s 
 1949696/24413248 [=&gt;............................] - ETA: 1s
 3063808/24413248 [==&gt;...........................] - ETA: 1s
 4341760/24413248 [====&gt;.........................] - ETA: 1s
 5554176/24413248 [=====&gt;........................] - ETA: 1s
 6881280/24413248 [=======&gt;......................] - ETA: 0s
 8142848/24413248 [=========&gt;....................] - ETA: 0s
 9453568/24413248 [==========&gt;...................] - ETA: 0s
10764288/24413248 [============&gt;.................] - ETA: 0s
12140544/24413248 [=============&gt;................] - ETA: 0s
13467648/24413248 [===============&gt;..............] - ETA: 0s
14663680/24413248 [=================&gt;............] - ETA: 0s
16007168/24413248 [==================&gt;...........] - ETA: 0s
17350656/24413248 [====================&gt;.........] - ETA: 0s
18628608/24413248 [=====================&gt;........] - ETA: 0s
19922944/24413248 [=======================&gt;......] - ETA: 0s
21233664/24413248 [=========================&gt;....] - ETA: 0s
22446080/24413248 [==========================&gt;...] - ETA: 0s
23953408/24413248 [============================&gt;.] - ETA: 0s
24413248/24413248 [==============================] - 1s 0us/step
Download complete.
Model: &quot;vit-tiny&quot;
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
 input (InputLayer)          [(None, 224, 224, 3)]        0         []

 Rescale (QuantizedRescalin  (None, 224, 224, 3)          0         [&#39;input[0][0]&#39;]
 g)

 Embedding (QuantizedConv2D  (None, 14, 14, 192)          147648    [&#39;Rescale[0][0]&#39;]
 )

 reshape (QuantizedReshape)  (None, 196, 192)             0         [&#39;Embedding[0][0]&#39;]

 ClassToken (QuantizedClass  (None, 197, 192)             192       [&#39;reshape[0][0]&#39;]
 Token)

 Transformer/PosEmbed (Quan  (None, 197, 192)             38208     [&#39;ClassToken[0][0]&#39;]
 tizedAddPositionEmbs)

 Transformer/EncoderBlock_0  (None, 197, 192)             768       [&#39;Transformer/PosEmbed[0][0]&#39;]
 /LayerNorm_0 (QuantizedLay
 erNormalization)

 Transformer/EncoderBlock_0  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_0  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_0  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_0/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_0  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_0/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout (QuantizedDropout)  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;dropout[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/PosEmbed[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_0  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_0/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_0  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_0/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_1 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_0/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             148032    [&#39;dropout_1[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_2 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_0/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_0  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_0/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_0/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_1/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_1/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_1/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_3 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_3[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_0/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_1/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_1/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_4 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_4[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_5 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_1/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_1/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_5[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_1/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_2  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_2  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_2  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_2/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_2  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_2/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_2/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_6 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;dropout_6[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_1/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_2  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_2/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_2  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_2/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_7 (QuantizedDropou  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             148032    [&#39;dropout_7[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_8 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_2/M
 t)                                                                 lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_2  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_2/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_8[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_2/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_3  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_3  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_3  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_3/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_3  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_3/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_3/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_9 (QuantizedDropou  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
 t)                                                                 ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;dropout_9[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_2/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_3  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_3/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_3  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_3/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_10 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_3/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             148032    [&#39;dropout_10[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_11 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_3/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_3  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_3/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_11[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_3/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_4  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_4  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_4  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_4/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_4  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_4/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_4/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_12 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;dropout_12[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_3/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_4  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_4/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_4  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_4/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_13 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             148032    [&#39;dropout_13[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_14 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_4/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_4  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_4/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_14[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_4/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_5  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_5  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_5  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_5/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_5  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_5/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_5/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_15 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;dropout_15[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_4/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_5  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_5/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_5  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_5/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_16 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             148032    [&#39;dropout_16[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_17 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_5/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_5  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_5/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_17[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_5/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_6  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_6  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_6  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_6/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_6  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_6/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_6/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_18 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;dropout_18[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_5/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_6  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_6/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_6  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_6/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_19 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             148032    [&#39;dropout_19[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_20 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_6/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_6  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_6/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_20[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_6/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_7  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_7  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_7  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_7/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_7  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_7/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_7/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_21 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;dropout_21[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_6/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_7  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_7/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_7  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_7/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_22 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             148032    [&#39;dropout_22[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_23 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_7/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_7  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_7/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_23[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_7/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_8  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_8  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_8  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_8/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_8  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_8/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_8/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_24 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;dropout_24[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_7/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_8  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_8/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_8  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_8/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_25 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             148032    [&#39;dropout_25[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_26 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_8/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_8  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_8/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_26[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_8/a
 /LayerNorm_0 (QuantizedLay                                         dd_2[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_9  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/query (QuantizedDens
 e)

 Transformer/EncoderBlock_9  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/key (QuantizedDense)

 Transformer/EncoderBlock_9  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_9/L
 /MultiHeadDotProductAttent                                         ayerNorm_0[0][0]&#39;]
 ion_1/value (QuantizedDens
 e)

 Transformer/EncoderBlock_9  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent   (None, 3, 197, 197))                  ultiHeadDotProductAttention_1/
 ion_1/attention (Quantized                                         query[0][0]&#39;,
 Attention)                                                          &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_9/M
                                                                    ultiHeadDotProductAttention_1/
                                                                    value[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_9/M
 /MultiHeadDotProductAttent                                         ultiHeadDotProductAttention_1/
 ion_1/out (QuantizedDense)                                         attention[0][0]&#39;]

 dropout_27 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                ultiHeadDotProductAttention_1/
                                                                    out[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;dropout_27[0][0]&#39;,
 /add_1 (QuantizedAdd)                                               &#39;Transformer/EncoderBlock_8/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_9/a
 /LayerNorm_2 (QuantizedLay                                         dd_1[0][0]&#39;]
 erNormalization)

 Transformer/EncoderBlock_9  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_9/L
 /MlpBlock/Dense_0 (Quantiz                                         ayerNorm_2[0][0]&#39;]
 edDense)

 Transformer/EncoderBlock_9  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_9/M
 /MlpBlock/activation (Quan                                         lpBlock/Dense_0[0][0]&#39;]
 tizedReLU)

 dropout_28 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                lpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             148032    [&#39;dropout_28[0][0]&#39;]
 /MlpBlock/Dense_1 (Quantiz
 edDense)

 dropout_29 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_9/M
 ut)                                                                lpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_9  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_9/a
 /add_2 (QuantizedAdd)                                              dd_1[0][0]&#39;,
                                                                     &#39;dropout_29[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_9/a
 0/LayerNorm_0 (QuantizedLa                                         dd_2[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (QuantizedDen
 se)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (QuantizedDense
 )

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (QuantizedDen
 se)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Quantize                                         /query[0][0]&#39;,
 dAttention)                                                         &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_10/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_10/
 0/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (QuantizedDense                                         /attention[0][0]&#39;]
 )

 dropout_30 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_30[0][0]&#39;,
 0/add_1 (QuantizedAdd)                                              &#39;Transformer/EncoderBlock_9/a
                                                                    dd_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_10/
 0/LayerNorm_2 (QuantizedLa                                         add_1[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/Dense_0 (Quanti                                         LayerNorm_2[0][0]&#39;]
 zedDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_10/
 0/MlpBlock/activation (Qua                                         MlpBlock/Dense_0[0][0]&#39;]
 ntizedReLU)

 dropout_31 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_31[0][0]&#39;]
 0/MlpBlock/Dense_1 (Quanti
 zedDense)

 dropout_32 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_10/
 ut)                                                                MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_10/
 0/add_2 (QuantizedAdd)                                             add_1[0][0]&#39;,
                                                                     &#39;dropout_32[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_10/
 1/LayerNorm_0 (QuantizedLa                                         add_2[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/query (QuantizedDen
 se)

 Transformer/EncoderBlock_1  (None, 197, 192)             37058     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/key (QuantizedDense
 )

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         LayerNorm_0[0][0]&#39;]
 tion_1/value (QuantizedDen
 se)

 Transformer/EncoderBlock_1  ((None, 197, 192),           384       [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten   (None, 3, 197, 197))                  MultiHeadDotProductAttention_1
 tion_1/attention (Quantize                                         /query[0][0]&#39;,
 dAttention)                                                         &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /key[0][0]&#39;,
                                                                     &#39;Transformer/EncoderBlock_11/
                                                                    MultiHeadDotProductAttention_1
                                                                    /value[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             37440     [&#39;Transformer/EncoderBlock_11/
 1/MultiHeadDotProductAtten                                         MultiHeadDotProductAttention_1
 tion_1/out (QuantizedDense                                         /attention[0][0]&#39;]
 )

 dropout_33 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MultiHeadDotProductAttention_1
                                                                    /out[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;dropout_33[0][0]&#39;,
 1/add_1 (QuantizedAdd)                                              &#39;Transformer/EncoderBlock_10/
                                                                    add_2[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             768       [&#39;Transformer/EncoderBlock_11/
 1/LayerNorm_2 (QuantizedLa                                         add_1[0][0]&#39;]
 yerNormalization)

 Transformer/EncoderBlock_1  (None, 197, 768)             148224    [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/Dense_0 (Quanti                                         LayerNorm_2[0][0]&#39;]
 zedDense)

 Transformer/EncoderBlock_1  (None, 197, 768)             1536      [&#39;Transformer/EncoderBlock_11/
 1/MlpBlock/activation (Qua                                         MlpBlock/Dense_0[0][0]&#39;]
 ntizedReLU)

 dropout_34 (QuantizedDropo  (None, 197, 768)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MlpBlock/activation[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             148032    [&#39;dropout_34[0][0]&#39;]
 1/MlpBlock/Dense_1 (Quanti
 zedDense)

 dropout_35 (QuantizedDropo  (None, 197, 192)             0         [&#39;Transformer/EncoderBlock_11/
 ut)                                                                MlpBlock/Dense_1[0][0]&#39;]

 Transformer/EncoderBlock_1  (None, 197, 192)             384       [&#39;Transformer/EncoderBlock_11/
 1/add_2 (QuantizedAdd)                                             add_1[0][0]&#39;,
                                                                     &#39;dropout_35[0][0]&#39;]

 Transformer/EncoderNorm (Q  (None, 197, 192)             1152      [&#39;Transformer/EncoderBlock_11/
 uantizedBatchNormalization                                         add_2[0][0]&#39;]
 )

 ExtractToken (QuantizedExt  (None, 192)                  0         [&#39;Transformer/EncoderNorm[0][0
 ractToken)                                                         ]&#39;]

 Head (QuantizedDense)       (None, 1000)                 193000    [&#39;ExtractToken[0][0]&#39;]

 dequantizer (Dequantizer)   (None, 1000)                 0         [&#39;Head[0][0]&#39;]

==================================================================================================
Total params: 5773912 (22.03 MB)
Trainable params: 5717416 (21.81 MB)
Non-trainable params: 56496 (220.69 KB)
__________________________________________________________________________________________________
</pre></div>
</div>
</section>
</section>
<section id="conversion-to-akida">
<h2>5. Conversion to Akida<a class="headerlink" href="#conversion-to-akida" title="Link to this heading"></a></h2>
<p>A model quantized through <a class="reference external" href="../../user_guide/quantizeml.html">QuantizeML python package</a> is ready to be
converted to Akida. Once the quantized model has the desired accuracy <a class="reference external" href="../../user_guide/cnn2snn.html">CNN2SNN toolkit</a>
is used for conversion to Akida. There is no further optimization required and equivalent accuracy is
observed upon converting the model to Akida.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">convert</span>

<span class="c1"># Convert the model</span>
<span class="n">model_akida</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">)</span>
<span class="n">model_akida</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>                 Model Summary
________________________________________________
Input shape    Output shape  Sequences  Layers
================================================
[224, 224, 3]  [1, 1, 1000]  1          14
________________________________________________

_______________________________________________________________________
Layer (type)                          Output shape   Kernel shape

================= SW/Embedding-dequantizer (Software) =================

Embedding (Stem)                      [1, 197, 192]  (16, 16, 3, 192)
_______________________________________________________________________
VitEncoderBlock_2 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_3 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_4 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_5 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_6 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_7 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_8 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_9 (VitEncoderBlock)   [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_10 (VitEncoderBlock)  [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_11 (VitEncoderBlock)  [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_12 (VitEncoderBlock)  [1, 197, 192]  N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
_______________________________________________________________________
VitEncoderBlock_13 (VitEncoderBlock)  [1, 1, 1000]   N/A
  norm_mha                                           N/A
  query                                              (192, 192)
  key                                                (192, 192)
  value                                              (192, 192)
  attention                                          N/A
  attention_projection                               (192, 192)
  skip_connection_1                                  N/A
  norm_mlp                                           N/A
  mlp_1                                              (192, 768)
  mlp_2                                              (768, 192)
  skip_connection_2                                  N/A
  batch_norm                                         N/A
  extract_token                                      N/A
  head                                               (192, 1000)
_______________________________________________________________________
dequantizer (Dequantizer)             [1, 1, 1000]   N/A
_______________________________________________________________________
</pre></div>
</div>
</section>
<section id="displaying-results-attention-maps">
<h2>6. Displaying results Attention Maps<a class="headerlink" href="#displaying-results-attention-maps" title="Link to this heading"></a></h2>
<p>Instead of showing predictions, here we propose to show attention maps on an image. This is
derived from <a class="reference external" href="https://arxiv.org/abs/2005.00928">Abnar et al. attention rollout</a> as shown in the
following <a class="reference external" href="https://keras.io/examples/vision/probing_vits/#method-ii-attention-rollout">Keras tutorial</a>. This aims to
highlight the model abilities to focus on relevant parts in the input image.</p>
<p>Just like for the <a class="reference external" href="plot_1_akidanet_imagenet.html#sphx-glr-examples-general-plot-1-akidanet-imagenet-py">AkidaNet example</a>, ImageNet
images are not publicly available, this example uses a set of 10 copyright free images that were
found on Google using ImageNet class names.</p>
<p>Get the preprocessed sample images:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">akida_models.imagenet</span> <span class="kn">import</span> <span class="n">get_preprocessed_samples</span>

<span class="c1"># Model specification and hyperparameters</span>
<span class="n">NUM_CHANNELS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">IMAGE_SIZE</span> <span class="o">=</span> <span class="mi">224</span>

<span class="n">NUM_IMAGES</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Load the preprocessed images</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_preprocessed_samples</span><span class="p">(</span><span class="n">IMAGE_SIZE</span><span class="p">,</span> <span class="n">NUM_CHANNELS</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">NUM_IMAGES</span><span class="si">}</span><span class="s1"> images loaded and preprocessed.&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>10 images loaded and preprocessed.
</pre></div>
</div>
<p>Build and display the attention map for one selected sample:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">quantizeml.layers</span> <span class="kn">import</span> <span class="n">ClassToken</span><span class="p">,</span> <span class="n">Attention</span>
<span class="kn">from</span> <span class="nn">quantizeml.tensors</span> <span class="kn">import</span> <span class="n">FixedPoint</span>
<span class="kn">from</span> <span class="nn">quantizeml.models.transforms.transforms_utils</span> <span class="kn">import</span> <span class="n">get_layers_by_type</span>


<span class="k">def</span> <span class="nf">build_attention_map</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
    <span class="c1"># Get the Attention layers list</span>
    <span class="n">attentions</span> <span class="o">=</span> <span class="n">get_layers_by_type</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Attention</span><span class="p">)</span>

    <span class="c1"># Calculate the number of tokens and deduce the grid size</span>
    <span class="n">num_tokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">ly</span><span class="p">,</span> <span class="n">ClassToken</span><span class="p">)</span> <span class="k">for</span> <span class="n">ly</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
    <span class="n">grid_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">num_tokens</span><span class="p">))</span>

    <span class="c1"># Get the attention weights from each transformer</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">la</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">la</span> <span class="ow">in</span> <span class="n">attentions</span><span class="p">]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># Converts to float if needed</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">to_float</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">FixedPoint</span><span class="p">)</span> <span class="k">else</span> <span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Heads number</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">num_layers</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Average the attention weights across all heads</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">reshaped</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># To account for residual connections, we add an identity matrix to the attention matrix and</span>
    <span class="c1"># re-normalize the weights.</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">reshaped</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">reshaped</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">reshaped</span> <span class="o">=</span> <span class="n">reshaped</span> <span class="o">/</span> <span class="n">reshaped</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

    <span class="c1"># Recursively multiply the weight matrices</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">reshaped</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">reshaped</span><span class="p">)):</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">reshaped</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">n</span><span class="p">])</span>

    <span class="c1"># Attention from the output token to the input space</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid_size</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">mask</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>


<span class="c1"># Using a specific image for which attention map is easier to observe</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span>

<span class="c1"># Compute the attention map</span>
<span class="n">attention_float</span> <span class="o">=</span> <span class="n">build_attention_map</span><span class="p">(</span><span class="n">model_keras</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
<span class="n">attention_quantized</span> <span class="o">=</span> <span class="n">build_attention_map</span><span class="p">(</span><span class="n">model_quantized</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>

<span class="c1"># Display the attention map</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Float&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">attention_float</span><span class="p">)</span>

<span class="n">ax3</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Quantized&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">attention_quantized</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Attention masks&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_7_vision_transformer_001.png" srcset="../../_images/sphx_glr_plot_7_vision_transformer_001.png" alt="Attention masks, Original, Float, Quantized" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - ETA: 0s
1/1 [==============================] - 7s 7s/step

1/1 [==============================] - ETA: 0s
1/1 [==============================] - 51s 51s/step
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (4 minutes 4.565 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-general-plot-7-vision-transformer-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/05650343d25ad287b6cecb0e9a3a3ef5/plot_7_vision_transformer.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_7_vision_transformer.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/eff8033b2bd356f7a111980b79134365/plot_7_vision_transformer.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_7_vision_transformer.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/d640942335c0e3d7e4102fe2452b82d9/plot_7_vision_transformer.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_7_vision_transformer.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plot_6_segmentation.html" class="btn btn-neutral float-left" title="Segmentation tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_8_global_pytorch_workflow.html" class="btn btn-neutral float-right" title="PyTorch to Akida workflow" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>