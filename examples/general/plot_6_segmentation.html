<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Segmentation tutorial &mdash; Akida Examples  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Build Vision Transformers for Akida" href="plot_7_vision_transformer.html" />
    <link rel="prev" title="YOLO/PASCAL-VOC detection tutorial" href="plot_5_voc_yolo_detection.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #989898" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/MetaTF_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                Akida, 2nd Generation
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#supported-configurations">Supported configurations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#programming-interface">Programming interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#the-akida-model">The Akida Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#akida-layers">Akida layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#model-hardware-mapping">Model Hardware Mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#devices">Devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#model-mapping">Model mapping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#advanced-mapping-details-and-hardware-devices-usage">Advanced Mapping Details and Hardware Devices Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#performance-measurement">Performance measurement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida.html#using-akida-edge-learning">Using Akida Edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida.html#compiling-a-layer">Compiling a layer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/quantizeml.html">QuantizeML toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#the-fixedpoint-representation">The FixedPoint representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#quantization-flow">Quantization flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#compatibility-constraints">Compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#model-loading">Model loading</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#command-line-interface">Command line interface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#quantize-cli">quantize CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#config-cli">config CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#check-cli">check CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/quantizeml.html#insert-rescaling-cli">insert_rescaling CLI</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/quantizeml.html#supported-layer-types">Supported layer types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-flow">Conversion flow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#conversion-compatibility">Conversion compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/cnn2snn.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#typical-quantization-scenario">Typical quantization scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#id3">Command-line interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../user_guide/akida_models.html#akidanet-training">AkidaNet training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-for-model-evaluation">Command-line interface for model evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#command-line-interface-to-evaluate-model-macs">Command-line interface to evaluate model MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#id1">Layer Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/akida_models.html#handling-akida-1-0-and-akida-2-0-specificities">Handling Akida 1.0 and Akida 2.0 specificities</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_apis.html">Akida runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer">Layer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id1">Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#mapping">Mapping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v1-layers">Akida V1 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#akida-v2-layers">Akida V2 layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#layer-parameters">Layer parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#layertype">LayerType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#padding">Padding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pooltype">PoolType</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#optimizers">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#sequence">Sequence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id2">Sequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#backendtype">BackendType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#pass">Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#device">Device</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id3">Device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#hwversion">HwVersion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#hwdevice">HWDevice</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#id4">HWDevice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#socdriver">SocDriver</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#clockmode">ClockMode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#powermeter">PowerMeter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#np">NP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_apis.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#sparsity">Sparsity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#akida-version">Akida version</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#conversion">Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#legacy-quantization-api">Legacy quantization API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#utils">Utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#constraint">Constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/quantizeml_apis.html">QuantizeML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#layers">Layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#reshaping">Reshaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#activations">Activations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#attention">Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#normalization">Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#convolution">Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#depthwise-convolution">Depthwise convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#separable-convolution">Separable convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dense">Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#skip-connection">Skip connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#pooling">Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#shiftmax">Shiftmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transformers">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#rescaling">Rescaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#dropout">Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantizers">Quantizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization-parameters">Quantization parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#calibration">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#recording">Recording</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#models">Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#transforms">Transforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#quantization">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#id1">Calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#utils">Utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#tensors">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qtensor">QTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#fixedpoint">FixedPoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/quantizeml_apis.html#qfloat">QFloat</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#cnn-blocks">CNN blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers-blocks">Transformers blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transposed-blocks">Transposed blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#detection-block">Detection block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#helpers">Helpers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gamma-constraint">Gamma constraint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#unfusing-separableconvolutional">Unfusing SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#extract-samples">Extract samples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#knowledge-distillation">Knowledge distillation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#macs">MACS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-i-o">Model I/O</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#utils">Utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidanet">AkidaNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#yolo">YOLO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#pointnet">PointNet++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#gxnor">GXNOR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#centernet">CenterNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#akidaunet">AkidaUNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../api_reference/akida_models_apis.html#transformers">Transformers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#general-examples">General examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_0_global_workflow.html">Global Akida workflow</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#create-and-train">1. Create and train</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#quantize">2. Quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#convert">3. Convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_0_global_workflow.html#gxnor-mnist">4. GXNOR/MNIST</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_1_akidanet_imagenet.html">AkidaNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#pretrained-quantized-model">2. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#conversion-to-akida">3. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_1_akidanet_imagenet.html#hardware-mapping-and-performance">4. Hardware mapping and performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_2_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_2_ds_cnn_kws.html#confusion-matrix">5. Confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_3_regression.html">Age estimation (regression) example</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-the-utkface-dataset">1. Load the UTKFace Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_3_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_4_transfer_learning.html">Transfer learning with AkidaNet for PlantVillage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#get-a-trained-akidanet-base-model">2. Get a trained AkidaNet base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#add-a-classification-head-to-the-model">3. Add a classification head to the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#freeze-the-base-model">4. Freeze the base model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#train-for-a-few-epochs">5. Train for a few epochs</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#quantize-the-model">6. Quantize the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_4_transfer_learning.html#compute-accuracy">7. Compute accuracy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_5_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_5_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Segmentation tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-a-pre-trained-quantized-keras-model">3. Load a pre-trained quantized Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="#segment-a-single-image">5. Segment a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_7_vision_transformer.html">Build Vision Transformers for Akida</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#model-selection">1. Model selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#model-optimization-for-akida-hardware">2. Model optimization for Akida hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#model-training">3. Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#conversion-to-akida">5. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_7_vision_transformer.html#displaying-results-attention-maps">6. Displaying results Attention Maps</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#quantization">Quantization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html">Advanced QuantizeML tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html#defining-a-quantization-scheme">1. Defining a quantization scheme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_0_advanced_quantizeml.html#calibration">2. Calibration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html">Upgrading to Akida 2.0</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#workflow-differences">1. Workflow differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#models-architecture-differences">2. Models architecture differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../quantization/plot_1_upgrading_to_2.0.html#using-akidaversion">3. Using <code class="docutils literal notranslate"><span class="pre">AkidaVersion</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_1_edge_learning_kws.html#edge-learning">5. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#deprecated-cnn2snn-tutorials">[Deprecated] CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#understanding-quantized-activation">3. Understanding quantized activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cnn2snn/plot_1_advanced_cnn2snn.html#how-to-deal-with-too-high-scale-factors">4. How to deal with too high scale factors</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo_performance.html">Model zoo performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../model_zoo_performance.html#akida-1-0-models">Akida 1.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#image-icon-ref-image-domain"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#classification">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#object-detection">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#regression">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#face-recognition">Face recognition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#audio-icon-ref-audio-domain"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#keyword-spotting">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#pointcloud-icon-ref-point-cloud"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id1">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../model_zoo_performance.html#akida-2-0-models">Akida 2.0 models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id2"> Image domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id3">Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id6">Object detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id7">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id8">Face recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#segmentation">Segmentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id10"> Audio domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id11">Keyword spotting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../model_zoo_performance.html#id12"> Point cloud</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../model_zoo_performance.html#id13">Classification</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #989898" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Akida Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Akida examples</a></li>
      <li class="breadcrumb-item active">Segmentation tutorial</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-general-plot-6-segmentation-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="segmentation-tutorial">
<span id="sphx-glr-examples-general-plot-6-segmentation-py"></span><h1>Segmentation tutorial<a class="headerlink" href="#segmentation-tutorial" title="Permalink to this headline"></a></h1>
<p>This example demonstrates image segmentation with an Akida-compatible model as
illustrated through person segmentation using the <a class="reference external" href="https://github.com/anilsathyan7/Portrait-Segmentation">Portrait128 dataset</a>.</p>
<p>Using pre-trained models for quick runtime, this example shows the evolution of
model performance for a trained keras floating point model, a keras quantized and
Quantization Aware Trained (QAT) model, and an Akida-converted model. Notice that
the performance of the original keras floating point model is maintained throughout
the model conversion flow.</p>
<section id="load-the-dataset">
<h2>1. Load the dataset<a class="headerlink" href="#load-the-dataset" title="Permalink to this headline"></a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">get_file</span>

<span class="c1"># Download validation set from Brainchip data server, it contains 10% of the original dataset</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">get_file</span><span class="p">(</span><span class="s2">&quot;val.tar.gz&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;https://data.brainchip.com/dataset-mirror/portrait128/val.tar.gz&quot;</span><span class="p">,</span>
                     <span class="n">cache_subdir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;datasets&quot;</span><span class="p">,</span> <span class="s2">&quot;portrait128&quot;</span><span class="p">),</span>
                     <span class="n">extract</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">data_path</span><span class="p">),</span> <span class="s2">&quot;val&quot;</span><span class="p">)</span>
<span class="n">x_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;val_img.npy&quot;</span><span class="p">))</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;val_msk.npy&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">steps</span> <span class="o">=</span> <span class="n">x_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">32</span>

<span class="c1"># Visualize some data</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="nb">id</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="nb">id</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_val</span><span class="p">[</span><span class="nb">id</span> <span class="o">+</span> <span class="n">col</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="nb">id</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span> <span class="o">*</span> <span class="n">y_val</span><span class="p">[</span><span class="nb">id</span> <span class="o">+</span> <span class="n">col</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Image, mask and masked image&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_6_segmentation_001.png" srcset="../../_images/sphx_glr_plot_6_segmentation_001.png" alt="Image, mask and masked image" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://data.brainchip.com/dataset-mirror/portrait128/val.tar.gz

     8192/267313385 [..............................] - ETA: 0s
   196608/267313385 [..............................] - ETA: 1:09
   671744/267313385 [..............................] - ETA: 40s 
  1073152/267313385 [..............................] - ETA: 37s
  1499136/267313385 [..............................] - ETA: 36s
  1925120/267313385 [..............................] - ETA: 34s
  2359296/267313385 [..............................] - ETA: 34s
  2809856/267313385 [..............................] - ETA: 33s
  3260416/267313385 [..............................] - ETA: 33s
  3702784/267313385 [..............................] - ETA: 32s
  4153344/267313385 [..............................] - ETA: 32s
  4612096/267313385 [..............................] - ETA: 31s
  5070848/267313385 [..............................] - ETA: 31s
  5529600/267313385 [..............................] - ETA: 31s
  5996544/267313385 [..............................] - ETA: 31s
  6504448/267313385 [..............................] - ETA: 30s
  6995968/267313385 [..............................] - ETA: 30s
  7471104/267313385 [..............................] - ETA: 30s
  7979008/267313385 [..............................] - ETA: 29s
  8486912/267313385 [..............................] - ETA: 29s
  9003008/267313385 [&gt;.............................] - ETA: 29s
  9510912/267313385 [&gt;.............................] - ETA: 29s
 10043392/267313385 [&gt;.............................] - ETA: 28s
 10567680/267313385 [&gt;.............................] - ETA: 28s
 11091968/267313385 [&gt;.............................] - ETA: 28s
 11632640/267313385 [&gt;.............................] - ETA: 27s
 12173312/267313385 [&gt;.............................] - ETA: 27s
 12713984/267313385 [&gt;.............................] - ETA: 27s
 13271040/267313385 [&gt;.............................] - ETA: 27s
 13828096/267313385 [&gt;.............................] - ETA: 27s
 14385152/267313385 [&gt;.............................] - ETA: 26s
 14942208/267313385 [&gt;.............................] - ETA: 26s
 15515648/267313385 [&gt;.............................] - ETA: 26s
 16089088/267313385 [&gt;.............................] - ETA: 26s
 16678912/267313385 [&gt;.............................] - ETA: 25s
 17268736/267313385 [&gt;.............................] - ETA: 25s
 17858560/267313385 [=&gt;............................] - ETA: 25s
 18448384/267313385 [=&gt;............................] - ETA: 25s
 19021824/267313385 [=&gt;............................] - ETA: 25s
 19611648/267313385 [=&gt;............................] - ETA: 24s
 20201472/267313385 [=&gt;............................] - ETA: 24s
 20791296/267313385 [=&gt;............................] - ETA: 24s
 21381120/267313385 [=&gt;............................] - ETA: 24s
 21970944/267313385 [=&gt;............................] - ETA: 24s
 22560768/267313385 [=&gt;............................] - ETA: 24s
 23150592/267313385 [=&gt;............................] - ETA: 24s
 23740416/267313385 [=&gt;............................] - ETA: 23s
 24330240/267313385 [=&gt;............................] - ETA: 23s
 24920064/267313385 [=&gt;............................] - ETA: 23s
 25509888/267313385 [=&gt;............................] - ETA: 23s
 26099712/267313385 [=&gt;............................] - ETA: 23s
 26689536/267313385 [=&gt;............................] - ETA: 23s
 27279360/267313385 [==&gt;...........................] - ETA: 23s
 27869184/267313385 [==&gt;...........................] - ETA: 23s
 28459008/267313385 [==&gt;...........................] - ETA: 22s
 29048832/267313385 [==&gt;...........................] - ETA: 22s
 29638656/267313385 [==&gt;...........................] - ETA: 22s
 30228480/267313385 [==&gt;...........................] - ETA: 22s
 30818304/267313385 [==&gt;...........................] - ETA: 22s
 31408128/267313385 [==&gt;...........................] - ETA: 22s
 31997952/267313385 [==&gt;...........................] - ETA: 22s
 32587776/267313385 [==&gt;...........................] - ETA: 22s
 33177600/267313385 [==&gt;...........................] - ETA: 22s
 33767424/267313385 [==&gt;...........................] - ETA: 22s
 34357248/267313385 [==&gt;...........................] - ETA: 21s
 34930688/267313385 [==&gt;...........................] - ETA: 21s
 35471360/267313385 [==&gt;...........................] - ETA: 21s
 36012032/267313385 [===&gt;..........................] - ETA: 21s
 36552704/267313385 [===&gt;..........................] - ETA: 21s
 37093376/267313385 [===&gt;..........................] - ETA: 21s
 37650432/267313385 [===&gt;..........................] - ETA: 21s
 38207488/267313385 [===&gt;..........................] - ETA: 21s
 38764544/267313385 [===&gt;..........................] - ETA: 21s
 39337984/267313385 [===&gt;..........................] - ETA: 21s
 39911424/267313385 [===&gt;..........................] - ETA: 21s
 40484864/267313385 [===&gt;..........................] - ETA: 21s
 41074688/267313385 [===&gt;..........................] - ETA: 21s
 41664512/267313385 [===&gt;..........................] - ETA: 21s
 42254336/267313385 [===&gt;..........................] - ETA: 20s
 42844160/267313385 [===&gt;..........................] - ETA: 20s
 43433984/267313385 [===&gt;..........................] - ETA: 20s
 44023808/267313385 [===&gt;..........................] - ETA: 20s
 44613632/267313385 [====&gt;.........................] - ETA: 20s
 45203456/267313385 [====&gt;.........................] - ETA: 20s
 45793280/267313385 [====&gt;.........................] - ETA: 20s
 46383104/267313385 [====&gt;.........................] - ETA: 20s
 46972928/267313385 [====&gt;.........................] - ETA: 20s
 47562752/267313385 [====&gt;.........................] - ETA: 20s
 48152576/267313385 [====&gt;.........................] - ETA: 20s
 48742400/267313385 [====&gt;.........................] - ETA: 20s
 49332224/267313385 [====&gt;.........................] - ETA: 20s
 49922048/267313385 [====&gt;.........................] - ETA: 20s
 50511872/267313385 [====&gt;.........................] - ETA: 19s
 51101696/267313385 [====&gt;.........................] - ETA: 19s
 51691520/267313385 [====&gt;.........................] - ETA: 19s
 52281344/267313385 [====&gt;.........................] - ETA: 19s
 52871168/267313385 [====&gt;.........................] - ETA: 19s
 53460992/267313385 [====&gt;.........................] - ETA: 19s
 54050816/267313385 [=====&gt;........................] - ETA: 19s
 54640640/267313385 [=====&gt;........................] - ETA: 19s
 55230464/267313385 [=====&gt;........................] - ETA: 19s
 55820288/267313385 [=====&gt;........................] - ETA: 19s
 56410112/267313385 [=====&gt;........................] - ETA: 19s
 56999936/267313385 [=====&gt;........................] - ETA: 19s
 57589760/267313385 [=====&gt;........................] - ETA: 19s
 58179584/267313385 [=====&gt;........................] - ETA: 19s
 58556416/267313385 [=====&gt;........................] - ETA: 19s
 59326464/267313385 [=====&gt;........................] - ETA: 18s
 59867136/267313385 [=====&gt;........................] - ETA: 18s
 60391424/267313385 [=====&gt;........................] - ETA: 18s
 60932096/267313385 [=====&gt;........................] - ETA: 18s
 61472768/267313385 [=====&gt;........................] - ETA: 18s
 62029824/267313385 [=====&gt;........................] - ETA: 18s
 62586880/267313385 [======&gt;.......................] - ETA: 18s
 63143936/267313385 [======&gt;.......................] - ETA: 18s
 63717376/267313385 [======&gt;.......................] - ETA: 18s
 64290816/267313385 [======&gt;.......................] - ETA: 18s
 64864256/267313385 [======&gt;.......................] - ETA: 18s
 65454080/267313385 [======&gt;.......................] - ETA: 18s
 66043904/267313385 [======&gt;.......................] - ETA: 18s
 66633728/267313385 [======&gt;.......................] - ETA: 18s
 67223552/267313385 [======&gt;.......................] - ETA: 18s
 67813376/267313385 [======&gt;.......................] - ETA: 18s
 68403200/267313385 [======&gt;.......................] - ETA: 18s
 68993024/267313385 [======&gt;.......................] - ETA: 18s
 69582848/267313385 [======&gt;.......................] - ETA: 17s
 70172672/267313385 [======&gt;.......................] - ETA: 17s
 70762496/267313385 [======&gt;.......................] - ETA: 17s
 71352320/267313385 [=======&gt;......................] - ETA: 17s
 71942144/267313385 [=======&gt;......................] - ETA: 17s
 72531968/267313385 [=======&gt;......................] - ETA: 17s
 73121792/267313385 [=======&gt;......................] - ETA: 17s
 73711616/267313385 [=======&gt;......................] - ETA: 17s
 74301440/267313385 [=======&gt;......................] - ETA: 17s
 74891264/267313385 [=======&gt;......................] - ETA: 17s
 75481088/267313385 [=======&gt;......................] - ETA: 17s
 76070912/267313385 [=======&gt;......................] - ETA: 17s
 76660736/267313385 [=======&gt;......................] - ETA: 17s
 77250560/267313385 [=======&gt;......................] - ETA: 17s
 77840384/267313385 [=======&gt;......................] - ETA: 17s
 78430208/267313385 [=======&gt;......................] - ETA: 17s
 79020032/267313385 [=======&gt;......................] - ETA: 16s
 79609856/267313385 [=======&gt;......................] - ETA: 16s
 80199680/267313385 [========&gt;.....................] - ETA: 16s
 80789504/267313385 [========&gt;.....................] - ETA: 16s
 81379328/267313385 [========&gt;.....................] - ETA: 16s
 81969152/267313385 [========&gt;.....................] - ETA: 16s
 82558976/267313385 [========&gt;.....................] - ETA: 16s
 83148800/267313385 [========&gt;.....................] - ETA: 16s
 83738624/267313385 [========&gt;.....................] - ETA: 16s
 84328448/267313385 [========&gt;.....................] - ETA: 16s
 84852736/267313385 [========&gt;.....................] - ETA: 16s
 85229568/267313385 [========&gt;.....................] - ETA: 16s
 85786624/267313385 [========&gt;.....................] - ETA: 16s
 86163456/267313385 [========&gt;.....................] - ETA: 16s
 86573056/267313385 [========&gt;.....................] - ETA: 16s
 86982656/267313385 [========&gt;.....................] - ETA: 16s
 87392256/267313385 [========&gt;.....................] - ETA: 16s
 87801856/267313385 [========&gt;.....................] - ETA: 16s
 88244224/267313385 [========&gt;.....................] - ETA: 16s
 88686592/267313385 [========&gt;.....................] - ETA: 16s
 89128960/267313385 [=========&gt;....................] - ETA: 16s
 89571328/267313385 [=========&gt;....................] - ETA: 16s
 90030080/267313385 [=========&gt;....................] - ETA: 16s
 90488832/267313385 [=========&gt;....................] - ETA: 16s
 90947584/267313385 [=========&gt;....................] - ETA: 16s
 91406336/267313385 [=========&gt;....................] - ETA: 16s
 91865088/267313385 [=========&gt;....................] - ETA: 16s
 92323840/267313385 [=========&gt;....................] - ETA: 16s
 92798976/267313385 [=========&gt;....................] - ETA: 16s
 93306880/267313385 [=========&gt;....................] - ETA: 16s
 93814784/267313385 [=========&gt;....................] - ETA: 16s
 94322688/267313385 [=========&gt;....................] - ETA: 15s
 94830592/267313385 [=========&gt;....................] - ETA: 15s
 95338496/267313385 [=========&gt;....................] - ETA: 15s
 95846400/267313385 [=========&gt;....................] - ETA: 15s
 96354304/267313385 [=========&gt;....................] - ETA: 15s
 96894976/267313385 [=========&gt;....................] - ETA: 15s
 97435648/267313385 [=========&gt;....................] - ETA: 15s
 97976320/267313385 [=========&gt;....................] - ETA: 15s
 98516992/267313385 [==========&gt;...................] - ETA: 15s
 99074048/267313385 [==========&gt;...................] - ETA: 15s
 99614720/267313385 [==========&gt;...................] - ETA: 15s
100171776/267313385 [==========&gt;...................] - ETA: 15s
100745216/267313385 [==========&gt;...................] - ETA: 15s
101318656/267313385 [==========&gt;...................] - ETA: 15s
101892096/267313385 [==========&gt;...................] - ETA: 15s
102465536/267313385 [==========&gt;...................] - ETA: 15s
103038976/267313385 [==========&gt;...................] - ETA: 15s
103596032/267313385 [==========&gt;...................] - ETA: 15s
104153088/267313385 [==========&gt;...................] - ETA: 15s
104710144/267313385 [==========&gt;...................] - ETA: 15s
105267200/267313385 [==========&gt;...................] - ETA: 14s
105824256/267313385 [==========&gt;...................] - ETA: 14s
106381312/267313385 [==========&gt;...................] - ETA: 14s
106938368/267313385 [===========&gt;..................] - ETA: 14s
107495424/267313385 [===========&gt;..................] - ETA: 14s
108052480/267313385 [===========&gt;..................] - ETA: 14s
108609536/267313385 [===========&gt;..................] - ETA: 14s
109166592/267313385 [===========&gt;..................] - ETA: 14s
109723648/267313385 [===========&gt;..................] - ETA: 14s
110297088/267313385 [===========&gt;..................] - ETA: 14s
110886912/267313385 [===========&gt;..................] - ETA: 14s
111476736/267313385 [===========&gt;..................] - ETA: 14s
112066560/267313385 [===========&gt;..................] - ETA: 14s
112656384/267313385 [===========&gt;..................] - ETA: 14s
113246208/267313385 [===========&gt;..................] - ETA: 14s
113836032/267313385 [===========&gt;..................] - ETA: 14s
114425856/267313385 [===========&gt;..................] - ETA: 14s
115015680/267313385 [===========&gt;..................] - ETA: 14s
115605504/267313385 [===========&gt;..................] - ETA: 13s
116195328/267313385 [============&gt;.................] - ETA: 13s
116785152/267313385 [============&gt;.................] - ETA: 13s
117374976/267313385 [============&gt;.................] - ETA: 13s
117964800/267313385 [============&gt;.................] - ETA: 13s
118554624/267313385 [============&gt;.................] - ETA: 13s
119144448/267313385 [============&gt;.................] - ETA: 13s
119734272/267313385 [============&gt;.................] - ETA: 13s
120324096/267313385 [============&gt;.................] - ETA: 13s
120913920/267313385 [============&gt;.................] - ETA: 13s
121323520/267313385 [============&gt;.................] - ETA: 13s
122109952/267313385 [============&gt;.................] - ETA: 13s
122650624/267313385 [============&gt;.................] - ETA: 13s
123191296/267313385 [============&gt;.................] - ETA: 13s
123731968/267313385 [============&gt;.................] - ETA: 13s
124289024/267313385 [============&gt;.................] - ETA: 13s
124846080/267313385 [=============&gt;................] - ETA: 13s
125403136/267313385 [=============&gt;................] - ETA: 13s
125976576/267313385 [=============&gt;................] - ETA: 12s
126550016/267313385 [=============&gt;................] - ETA: 12s
127123456/267313385 [=============&gt;................] - ETA: 12s
127713280/267313385 [=============&gt;................] - ETA: 12s
128303104/267313385 [=============&gt;................] - ETA: 12s
128892928/267313385 [=============&gt;................] - ETA: 12s
129482752/267313385 [=============&gt;................] - ETA: 12s
130056192/267313385 [=============&gt;................] - ETA: 12s
130646016/267313385 [=============&gt;................] - ETA: 12s
131235840/267313385 [=============&gt;................] - ETA: 12s
131825664/267313385 [=============&gt;................] - ETA: 12s
132415488/267313385 [=============&gt;................] - ETA: 12s
133005312/267313385 [=============&gt;................] - ETA: 12s
133595136/267313385 [=============&gt;................] - ETA: 12s
134184960/267313385 [==============&gt;...............] - ETA: 12s
134774784/267313385 [==============&gt;...............] - ETA: 12s
135364608/267313385 [==============&gt;...............] - ETA: 12s
135954432/267313385 [==============&gt;...............] - ETA: 11s
136544256/267313385 [==============&gt;...............] - ETA: 11s
137134080/267313385 [==============&gt;...............] - ETA: 11s
137723904/267313385 [==============&gt;...............] - ETA: 11s
138313728/267313385 [==============&gt;...............] - ETA: 11s
138903552/267313385 [==============&gt;...............] - ETA: 11s
139493376/267313385 [==============&gt;...............] - ETA: 11s
140083200/267313385 [==============&gt;...............] - ETA: 11s
140673024/267313385 [==============&gt;...............] - ETA: 11s
141262848/267313385 [==============&gt;...............] - ETA: 11s
141852672/267313385 [==============&gt;...............] - ETA: 11s
142442496/267313385 [==============&gt;...............] - ETA: 11s
143032320/267313385 [===============&gt;..............] - ETA: 11s
143622144/267313385 [===============&gt;..............] - ETA: 11s
144211968/267313385 [===============&gt;..............] - ETA: 11s
144801792/267313385 [===============&gt;..............] - ETA: 11s
145391616/267313385 [===============&gt;..............] - ETA: 11s
145981440/267313385 [===============&gt;..............] - ETA: 11s
146571264/267313385 [===============&gt;..............] - ETA: 10s
146866176/267313385 [===============&gt;..............] - ETA: 10s
147865600/267313385 [===============&gt;..............] - ETA: 10s
148422656/267313385 [===============&gt;..............] - ETA: 10s
148979712/267313385 [===============&gt;..............] - ETA: 10s
149536768/267313385 [===============&gt;..............] - ETA: 10s
150093824/267313385 [===============&gt;..............] - ETA: 10s
150650880/267313385 [===============&gt;..............] - ETA: 10s
151224320/267313385 [===============&gt;..............] - ETA: 10s
151797760/267313385 [================&gt;.............] - ETA: 10s
152371200/267313385 [================&gt;.............] - ETA: 10s
152944640/267313385 [================&gt;.............] - ETA: 10s
153534464/267313385 [================&gt;.............] - ETA: 10s
154124288/267313385 [================&gt;.............] - ETA: 10s
154714112/267313385 [================&gt;.............] - ETA: 10s
155303936/267313385 [================&gt;.............] - ETA: 10s
155893760/267313385 [================&gt;.............] - ETA: 10s
156483584/267313385 [================&gt;.............] - ETA: 10s
157073408/267313385 [================&gt;.............] - ETA: 9s 
157663232/267313385 [================&gt;.............] - ETA: 9s
158253056/267313385 [================&gt;.............] - ETA: 9s
158842880/267313385 [================&gt;.............] - ETA: 9s
159432704/267313385 [================&gt;.............] - ETA: 9s
160022528/267313385 [================&gt;.............] - ETA: 9s
160628736/267313385 [=================&gt;............] - ETA: 9s
161218560/267313385 [=================&gt;............] - ETA: 9s
161808384/267313385 [=================&gt;............] - ETA: 9s
162398208/267313385 [=================&gt;............] - ETA: 9s
162807808/267313385 [=================&gt;............] - ETA: 9s
163528704/267313385 [=================&gt;............] - ETA: 9s
164020224/267313385 [=================&gt;............] - ETA: 9s
164511744/267313385 [=================&gt;............] - ETA: 9s
165019648/267313385 [=================&gt;............] - ETA: 9s
165527552/267313385 [=================&gt;............] - ETA: 9s
166035456/267313385 [=================&gt;............] - ETA: 9s
166559744/267313385 [=================&gt;............] - ETA: 9s
167084032/267313385 [=================&gt;............] - ETA: 9s
167608320/267313385 [=================&gt;............] - ETA: 9s
168148992/267313385 [=================&gt;............] - ETA: 9s
168689664/267313385 [=================&gt;............] - ETA: 8s
169230336/267313385 [=================&gt;............] - ETA: 8s
169771008/267313385 [==================&gt;...........] - ETA: 8s
170328064/267313385 [==================&gt;...........] - ETA: 8s
170885120/267313385 [==================&gt;...........] - ETA: 8s
171458560/267313385 [==================&gt;...........] - ETA: 8s
172032000/267313385 [==================&gt;...........] - ETA: 8s
172605440/267313385 [==================&gt;...........] - ETA: 8s
173178880/267313385 [==================&gt;...........] - ETA: 8s
173768704/267313385 [==================&gt;...........] - ETA: 8s
174358528/267313385 [==================&gt;...........] - ETA: 8s
174948352/267313385 [==================&gt;...........] - ETA: 8s
175538176/267313385 [==================&gt;...........] - ETA: 8s
176128000/267313385 [==================&gt;...........] - ETA: 8s
176717824/267313385 [==================&gt;...........] - ETA: 8s
177307648/267313385 [==================&gt;...........] - ETA: 8s
177897472/267313385 [==================&gt;...........] - ETA: 8s
178487296/267313385 [===================&gt;..........] - ETA: 8s
179077120/267313385 [===================&gt;..........] - ETA: 7s
179666944/267313385 [===================&gt;..........] - ETA: 7s
180256768/267313385 [===================&gt;..........] - ETA: 7s
180846592/267313385 [===================&gt;..........] - ETA: 7s
181436416/267313385 [===================&gt;..........] - ETA: 7s
182026240/267313385 [===================&gt;..........] - ETA: 7s
182616064/267313385 [===================&gt;..........] - ETA: 7s
183205888/267313385 [===================&gt;..........] - ETA: 7s
183828480/267313385 [===================&gt;..........] - ETA: 7s
184418304/267313385 [===================&gt;..........] - ETA: 7s
185008128/267313385 [===================&gt;..........] - ETA: 7s
185597952/267313385 [===================&gt;..........] - ETA: 7s
186187776/267313385 [===================&gt;..........] - ETA: 7s
186777600/267313385 [===================&gt;..........] - ETA: 7s
187367424/267313385 [====================&gt;.........] - ETA: 7s
187957248/267313385 [====================&gt;.........] - ETA: 7s
188547072/267313385 [====================&gt;.........] - ETA: 7s
189136896/267313385 [====================&gt;.........] - ETA: 7s
189726720/267313385 [====================&gt;.........] - ETA: 7s
190316544/267313385 [====================&gt;.........] - ETA: 6s
190906368/267313385 [====================&gt;.........] - ETA: 6s
191496192/267313385 [====================&gt;.........] - ETA: 6s
192086016/267313385 [====================&gt;.........] - ETA: 6s
192659456/267313385 [====================&gt;.........] - ETA: 6s
193200128/267313385 [====================&gt;.........] - ETA: 6s
193740800/267313385 [====================&gt;.........] - ETA: 6s
194281472/267313385 [====================&gt;.........] - ETA: 6s
194822144/267313385 [====================&gt;.........] - ETA: 6s
195379200/267313385 [====================&gt;.........] - ETA: 6s
195936256/267313385 [====================&gt;.........] - ETA: 6s
196509696/267313385 [=====================&gt;........] - ETA: 6s
197083136/267313385 [=====================&gt;........] - ETA: 6s
197656576/267313385 [=====================&gt;........] - ETA: 6s
198230016/267313385 [=====================&gt;........] - ETA: 6s
198803456/267313385 [=====================&gt;........] - ETA: 6s
199393280/267313385 [=====================&gt;........] - ETA: 6s
199983104/267313385 [=====================&gt;........] - ETA: 6s
200572928/267313385 [=====================&gt;........] - ETA: 6s
201162752/267313385 [=====================&gt;........] - ETA: 5s
201752576/267313385 [=====================&gt;........] - ETA: 5s
202293248/267313385 [=====================&gt;........] - ETA: 5s
202883072/267313385 [=====================&gt;........] - ETA: 5s
203472896/267313385 [=====================&gt;........] - ETA: 5s
204062720/267313385 [=====================&gt;........] - ETA: 5s
204652544/267313385 [=====================&gt;........] - ETA: 5s
205242368/267313385 [======================&gt;.......] - ETA: 5s
205832192/267313385 [======================&gt;.......] - ETA: 5s
206422016/267313385 [======================&gt;.......] - ETA: 5s
207011840/267313385 [======================&gt;.......] - ETA: 5s
207601664/267313385 [======================&gt;.......] - ETA: 5s
208191488/267313385 [======================&gt;.......] - ETA: 5s
208781312/267313385 [======================&gt;.......] - ETA: 5s
209371136/267313385 [======================&gt;.......] - ETA: 5s
209960960/267313385 [======================&gt;.......] - ETA: 5s
210550784/267313385 [======================&gt;.......] - ETA: 5s
211140608/267313385 [======================&gt;.......] - ETA: 5s
211730432/267313385 [======================&gt;.......] - ETA: 5s
212320256/267313385 [======================&gt;.......] - ETA: 4s
212910080/267313385 [======================&gt;.......] - ETA: 4s
213499904/267313385 [======================&gt;.......] - ETA: 4s
214089728/267313385 [=======================&gt;......] - ETA: 4s
214679552/267313385 [=======================&gt;......] - ETA: 4s
215269376/267313385 [=======================&gt;......] - ETA: 4s
215859200/267313385 [=======================&gt;......] - ETA: 4s
216449024/267313385 [=======================&gt;......] - ETA: 4s
217038848/267313385 [=======================&gt;......] - ETA: 4s
217563136/267313385 [=======================&gt;......] - ETA: 4s
218103808/267313385 [=======================&gt;......] - ETA: 4s
218628096/267313385 [=======================&gt;......] - ETA: 4s
219168768/267313385 [=======================&gt;......] - ETA: 4s
219709440/267313385 [=======================&gt;......] - ETA: 4s
220250112/267313385 [=======================&gt;......] - ETA: 4s
220807168/267313385 [=======================&gt;......] - ETA: 4s
221364224/267313385 [=======================&gt;......] - ETA: 4s
221921280/267313385 [=======================&gt;......] - ETA: 4s
222461952/267313385 [=======================&gt;......] - ETA: 4s
223019008/267313385 [========================&gt;.....] - ETA: 3s
223576064/267313385 [========================&gt;.....] - ETA: 3s
224133120/267313385 [========================&gt;.....] - ETA: 3s
224706560/267313385 [========================&gt;.....] - ETA: 3s
225296384/267313385 [========================&gt;.....] - ETA: 3s
225886208/267313385 [========================&gt;.....] - ETA: 3s
226476032/267313385 [========================&gt;.....] - ETA: 3s
227065856/267313385 [========================&gt;.....] - ETA: 3s
227655680/267313385 [========================&gt;.....] - ETA: 3s
228245504/267313385 [========================&gt;.....] - ETA: 3s
228835328/267313385 [========================&gt;.....] - ETA: 3s
229425152/267313385 [========================&gt;.....] - ETA: 3s
230014976/267313385 [========================&gt;.....] - ETA: 3s
230604800/267313385 [========================&gt;.....] - ETA: 3s
231194624/267313385 [========================&gt;.....] - ETA: 3s
231784448/267313385 [=========================&gt;....] - ETA: 3s
232374272/267313385 [=========================&gt;....] - ETA: 3s
232964096/267313385 [=========================&gt;....] - ETA: 3s
233553920/267313385 [=========================&gt;....] - ETA: 3s
234143744/267313385 [=========================&gt;....] - ETA: 2s
234733568/267313385 [=========================&gt;....] - ETA: 2s
235323392/267313385 [=========================&gt;....] - ETA: 2s
235913216/267313385 [=========================&gt;....] - ETA: 2s
236503040/267313385 [=========================&gt;....] - ETA: 2s
237092864/267313385 [=========================&gt;....] - ETA: 2s
237682688/267313385 [=========================&gt;....] - ETA: 2s
238272512/267313385 [=========================&gt;....] - ETA: 2s
238862336/267313385 [=========================&gt;....] - ETA: 2s
239452160/267313385 [=========================&gt;....] - ETA: 2s
240041984/267313385 [=========================&gt;....] - ETA: 2s
240631808/267313385 [==========================&gt;...] - ETA: 2s
241221632/267313385 [==========================&gt;...] - ETA: 2s
241745920/267313385 [==========================&gt;...] - ETA: 2s
242515968/267313385 [==========================&gt;...] - ETA: 2s
243056640/267313385 [==========================&gt;...] - ETA: 2s
243597312/267313385 [==========================&gt;...] - ETA: 2s
244137984/267313385 [==========================&gt;...] - ETA: 2s
244695040/267313385 [==========================&gt;...] - ETA: 2s
245252096/267313385 [==========================&gt;...] - ETA: 1s
245792768/267313385 [==========================&gt;...] - ETA: 1s
246349824/267313385 [==========================&gt;...] - ETA: 1s
246923264/267313385 [==========================&gt;...] - ETA: 1s
247496704/267313385 [==========================&gt;...] - ETA: 1s
248070144/267313385 [==========================&gt;...] - ETA: 1s
248659968/267313385 [==========================&gt;...] - ETA: 1s
249249792/267313385 [==========================&gt;...] - ETA: 1s
249839616/267313385 [===========================&gt;..] - ETA: 1s
250429440/267313385 [===========================&gt;..] - ETA: 1s
251019264/267313385 [===========================&gt;..] - ETA: 1s
251609088/267313385 [===========================&gt;..] - ETA: 1s
252198912/267313385 [===========================&gt;..] - ETA: 1s
252788736/267313385 [===========================&gt;..] - ETA: 1s
253378560/267313385 [===========================&gt;..] - ETA: 1s
253968384/267313385 [===========================&gt;..] - ETA: 1s
254558208/267313385 [===========================&gt;..] - ETA: 1s
255148032/267313385 [===========================&gt;..] - ETA: 1s
255737856/267313385 [===========================&gt;..] - ETA: 1s
256327680/267313385 [===========================&gt;..] - ETA: 0s
256917504/267313385 [===========================&gt;..] - ETA: 0s
257507328/267313385 [===========================&gt;..] - ETA: 0s
258097152/267313385 [===========================&gt;..] - ETA: 0s
258686976/267313385 [============================&gt;.] - ETA: 0s
259276800/267313385 [============================&gt;.] - ETA: 0s
259866624/267313385 [============================&gt;.] - ETA: 0s
260456448/267313385 [============================&gt;.] - ETA: 0s
261046272/267313385 [============================&gt;.] - ETA: 0s
261636096/267313385 [============================&gt;.] - ETA: 0s
262225920/267313385 [============================&gt;.] - ETA: 0s
262815744/267313385 [============================&gt;.] - ETA: 0s
263405568/267313385 [============================&gt;.] - ETA: 0s
263995392/267313385 [============================&gt;.] - ETA: 0s
264585216/267313385 [============================&gt;.] - ETA: 0s
265175040/267313385 [============================&gt;.] - ETA: 0s
265764864/267313385 [============================&gt;.] - ETA: 0s
266354688/267313385 [============================&gt;.] - ETA: 0s
266944512/267313385 [============================&gt;.] - ETA: 0s
267313385/267313385 [==============================] - 24s 0us/step
</pre></div>
</div>
</section>
<section id="load-a-pre-trained-native-keras-model">
<h2>2. Load a pre-trained native Keras model<a class="headerlink" href="#load-a-pre-trained-native-keras-model" title="Permalink to this headline"></a></h2>
<p>The model used in this example is AkidaUNet. It has an AkidaNet (0.5) backbone to extract
features combined with a succession of <a class="reference external" href="../../api_reference/akida_models_apis.html#akida_models.layer_blocks.sepconv_transpose_block">separable transposed convolutional</a>
blocks to build an image segmentation map. A pre-trained floating point keras model is
downloaded to save training time.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The “transposed” convolutional feature is new in Akida 2.0.</p></li>
<li><p>The “separable transposed” operation is realized through the combination of a QuantizeML custom
<a class="reference external" href="../../api_reference/quantizeml_apis.html#quantizeml.layers.DepthwiseConv2DTranspose">DepthwiseConv2DTranspose</a> layer
with a standard pointwise convolution.</p></li>
</ul>
</div>
<p>The performance of the model is evaluated using both pixel accuracy and <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryIoU">Binary IoU</a>. The pixel
accuracy describes how well the model can predict the segmentation mask pixel by pixel
and the Binary IoU takes into account how close the predicted mask is to the ground truth.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">get_file</span>
<span class="kn">from</span> <span class="nn">akida_models.model_io</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="c1"># Retrieve the model file from Brainchip data server</span>
<span class="n">model_file</span> <span class="o">=</span> <span class="n">get_file</span><span class="p">(</span><span class="s2">&quot;akida_unet_portrait128.h5&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;https://data.brainchip.com/models/AkidaV2/akida_unet/akida_unet_portrait128.h5&quot;</span><span class="p">,</span>
                      <span class="n">cache_subdir</span><span class="o">=</span><span class="s1">&#39;models&#39;</span><span class="p">)</span>

<span class="c1"># Load the native Keras pre-trained model</span>
<span class="n">model_keras</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
<span class="n">model_keras</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://data.brainchip.com/models/AkidaV2/akida_unet/akida_unet_portrait128.h5

   8192/4493952 [..............................] - ETA: 0s
 212992/4493952 [&gt;.............................] - ETA: 1s
 598016/4493952 [==&gt;...........................] - ETA: 0s
1335296/4493952 [=======&gt;......................] - ETA: 0s
1867776/4493952 [===========&gt;..................] - ETA: 0s
2408448/4493952 [===============&gt;..............] - ETA: 0s
2949120/4493952 [==================&gt;...........] - ETA: 0s
3473408/4493952 [======================&gt;.......] - ETA: 0s
4030464/4493952 [=========================&gt;....] - ETA: 0s
4489216/4493952 [============================&gt;.] - ETA: 0s
4493952/4493952 [==============================] - 0s 0us/step
Model: &quot;akida_unet&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input (InputLayer)          [(None, 128, 128, 3)]     0

 rescaling (Rescaling)       (None, 128, 128, 3)       0

 conv_0 (Conv2D)             (None, 64, 64, 16)        432

 conv_0/BN (BatchNormalizati  (None, 64, 64, 16)       64
 on)

 conv_0/relu (ReLU)          (None, 64, 64, 16)        0

 conv_1 (Conv2D)             (None, 64, 64, 32)        4608

 conv_1/BN (BatchNormalizati  (None, 64, 64, 32)       128
 on)

 conv_1/relu (ReLU)          (None, 64, 64, 32)        0

 conv_2 (Conv2D)             (None, 32, 32, 64)        18432

 conv_2/BN (BatchNormalizati  (None, 32, 32, 64)       256
 on)

 conv_2/relu (ReLU)          (None, 32, 32, 64)        0

 conv_3 (Conv2D)             (None, 32, 32, 64)        36864

 conv_3/BN (BatchNormalizati  (None, 32, 32, 64)       256
 on)

 conv_3/relu (ReLU)          (None, 32, 32, 64)        0

 dw_separable_4 (DepthwiseCo  (None, 16, 16, 64)       576
 nv2D)

 pw_separable_4 (Conv2D)     (None, 16, 16, 128)       8192

 pw_separable_4/BN (BatchNor  (None, 16, 16, 128)      512
 malization)

 pw_separable_4/relu (ReLU)  (None, 16, 16, 128)       0

 dw_separable_5 (DepthwiseCo  (None, 16, 16, 128)      1152
 nv2D)

 pw_separable_5 (Conv2D)     (None, 16, 16, 128)       16384

 pw_separable_5/BN (BatchNor  (None, 16, 16, 128)      512
 malization)

 pw_separable_5/relu (ReLU)  (None, 16, 16, 128)       0

 dw_separable_6 (DepthwiseCo  (None, 8, 8, 128)        1152
 nv2D)

 pw_separable_6 (Conv2D)     (None, 8, 8, 256)         32768

 pw_separable_6/BN (BatchNor  (None, 8, 8, 256)        1024
 malization)

 pw_separable_6/relu (ReLU)  (None, 8, 8, 256)         0

 dw_separable_7 (DepthwiseCo  (None, 8, 8, 256)        2304
 nv2D)

 pw_separable_7 (Conv2D)     (None, 8, 8, 256)         65536

 pw_separable_7/BN (BatchNor  (None, 8, 8, 256)        1024
 malization)

 pw_separable_7/relu (ReLU)  (None, 8, 8, 256)         0

 dw_separable_8 (DepthwiseCo  (None, 8, 8, 256)        2304
 nv2D)

 pw_separable_8 (Conv2D)     (None, 8, 8, 256)         65536

 pw_separable_8/BN (BatchNor  (None, 8, 8, 256)        1024
 malization)

 pw_separable_8/relu (ReLU)  (None, 8, 8, 256)         0

 dw_separable_9 (DepthwiseCo  (None, 8, 8, 256)        2304
 nv2D)

 pw_separable_9 (Conv2D)     (None, 8, 8, 256)         65536

 pw_separable_9/BN (BatchNor  (None, 8, 8, 256)        1024
 malization)

 pw_separable_9/relu (ReLU)  (None, 8, 8, 256)         0

 dw_separable_10 (DepthwiseC  (None, 8, 8, 256)        2304
 onv2D)

 pw_separable_10 (Conv2D)    (None, 8, 8, 256)         65536

 pw_separable_10/BN (BatchNo  (None, 8, 8, 256)        1024
 rmalization)

 pw_separable_10/relu (ReLU)  (None, 8, 8, 256)        0

 dw_separable_11 (DepthwiseC  (None, 8, 8, 256)        2304
 onv2D)

 pw_separable_11 (Conv2D)    (None, 8, 8, 256)         65536

 pw_separable_11/BN (BatchNo  (None, 8, 8, 256)        1024
 rmalization)

 pw_separable_11/relu (ReLU)  (None, 8, 8, 256)        0

 dw_separable_12 (DepthwiseC  (None, 4, 4, 256)        2304
 onv2D)

 pw_separable_12 (Conv2D)    (None, 4, 4, 512)         131072

 pw_separable_12/BN (BatchNo  (None, 4, 4, 512)        2048
 rmalization)

 pw_separable_12/relu (ReLU)  (None, 4, 4, 512)        0

 dw_separable_13 (DepthwiseC  (None, 4, 4, 512)        4608
 onv2D)

 pw_separable_13 (Conv2D)    (None, 4, 4, 512)         262144

 pw_separable_13/BN (BatchNo  (None, 4, 4, 512)        2048
 rmalization)

 pw_separable_13/relu (ReLU)  (None, 4, 4, 512)        0

 dw_sepconv_t_0 (DepthwiseCo  (None, 8, 8, 512)        5120
 nv2DTranspose)

 pw_sepconv_t_0 (Conv2D)     (None, 8, 8, 256)         131328

 pw_sepconv_t_0/BN (BatchNor  (None, 8, 8, 256)        1024
 malization)

 pw_sepconv_t_0/relu (ReLU)  (None, 8, 8, 256)         0

 dropout (Dropout)           (None, 8, 8, 256)         0

 dw_sepconv_t_1 (DepthwiseCo  (None, 16, 16, 256)      2560
 nv2DTranspose)

 pw_sepconv_t_1 (Conv2D)     (None, 16, 16, 128)       32896

 pw_sepconv_t_1/BN (BatchNor  (None, 16, 16, 128)      512
 malization)

 pw_sepconv_t_1/relu (ReLU)  (None, 16, 16, 128)       0

 dropout_1 (Dropout)         (None, 16, 16, 128)       0

 dw_sepconv_t_2 (DepthwiseCo  (None, 32, 32, 128)      1280
 nv2DTranspose)

 pw_sepconv_t_2 (Conv2D)     (None, 32, 32, 64)        8256

 pw_sepconv_t_2/BN (BatchNor  (None, 32, 32, 64)       256
 malization)

 pw_sepconv_t_2/relu (ReLU)  (None, 32, 32, 64)        0

 dropout_2 (Dropout)         (None, 32, 32, 64)        0

 dw_sepconv_t_3 (DepthwiseCo  (None, 64, 64, 64)       640
 nv2DTranspose)

 pw_sepconv_t_3 (Conv2D)     (None, 64, 64, 32)        2080

 pw_sepconv_t_3/BN (BatchNor  (None, 64, 64, 32)       128
 malization)

 pw_sepconv_t_3/relu (ReLU)  (None, 64, 64, 32)        0

 dropout_3 (Dropout)         (None, 64, 64, 32)        0

 dw_sepconv_t_4 (DepthwiseCo  (None, 128, 128, 32)     320
 nv2DTranspose)

 pw_sepconv_t_4 (Conv2D)     (None, 128, 128, 16)      528

 pw_sepconv_t_4/BN (BatchNor  (None, 128, 128, 16)     64
 malization)

 pw_sepconv_t_4/relu (ReLU)  (None, 128, 128, 16)      0

 dropout_4 (Dropout)         (None, 128, 128, 16)      0

 head (Conv2D)               (None, 128, 128, 1)       17

 sigmoid_act (Activation)    (None, 128, 128, 1)       0

=================================================================
Total params: 1,058,865
Trainable params: 1,051,889
Non-trainable params: 6,976
_________________________________________________________________
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.metrics</span> <span class="kn">import</span> <span class="n">BinaryIoU</span>

<span class="c1"># Compile the native Keras model (required to evaluate the metrics)</span>
<span class="n">model_keras</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">BinaryIoU</span><span class="p">(),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Check Keras model performance</span>
<span class="n">_</span><span class="p">,</span> <span class="n">biou</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model_keras</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Keras binary IoU / pixel accuracy: </span><span class="si">{</span><span class="n">biou</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Keras binary IoU / pixel accuracy: 0.9455 / 97.28%
</pre></div>
</div>
</section>
<section id="load-a-pre-trained-quantized-keras-model">
<h2>3. Load a pre-trained quantized Keras model<a class="headerlink" href="#load-a-pre-trained-quantized-keras-model" title="Permalink to this headline"></a></h2>
<p>The next step is to quantize and potentially perform Quantize Aware Training (QAT) on the
Keras model from the previous step. After the Keras model is quantized to 8-bits for
all weights and activations, QAT is used to maintain the performance of the quantized
model. Again, a pre-trained model is downloaded to save runtime.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">akida_models</span> <span class="kn">import</span> <span class="n">akida_unet_portrait128_pretrained</span>

<span class="c1"># Load the pre-trained quantized model</span>
<span class="n">model_quantized_keras</span> <span class="o">=</span> <span class="n">akida_unet_portrait128_pretrained</span><span class="p">()</span>
<span class="n">model_quantized_keras</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://data.brainchip.com/models/AkidaV2/akida_unet/akida_unet_portrait128_i8_w8_a8.h5.

      0/4520576 [..............................] - ETA: 0s
 212992/4520576 [&gt;.............................] - ETA: 1s
 704512/4520576 [===&gt;..........................] - ETA: 0s
1114112/4520576 [======&gt;.......................] - ETA: 0s
1531904/4520576 [=========&gt;....................] - ETA: 0s
1974272/4520576 [============&gt;.................] - ETA: 0s
2424832/4520576 [===============&gt;..............] - ETA: 0s
2883584/4520576 [==================&gt;...........] - ETA: 0s
3309568/4520576 [====================&gt;.........] - ETA: 0s
3751936/4520576 [=======================&gt;......] - ETA: 0s
4177920/4520576 [==========================&gt;...] - ETA: 0s
4520576/4520576 [==============================] - 1s 0us/step
Model: &quot;akida_unet&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input (InputLayer)          [(None, 128, 128, 3)]     0

 rescaling (QuantizedRescali  (None, 128, 128, 3)      0
 ng)

 conv_0 (QuantizedConv2D)    (None, 64, 64, 16)        448

 conv_0/relu (QuantizedReLU)  (None, 64, 64, 16)       32

 conv_1 (QuantizedConv2D)    (None, 64, 64, 32)        4640

 conv_1/relu (QuantizedReLU)  (None, 64, 64, 32)       64

 conv_2 (QuantizedConv2D)    (None, 32, 32, 64)        18496

 conv_2/relu (QuantizedReLU)  (None, 32, 32, 64)       128

 conv_3 (QuantizedConv2D)    (None, 32, 32, 64)        36928

 conv_3/relu (QuantizedReLU)  (None, 32, 32, 64)       128

 dw_separable_4 (QuantizedDe  (None, 16, 16, 64)       704
 pthwiseConv2D)

 pw_separable_4 (QuantizedCo  (None, 16, 16, 128)      8320
 nv2D)

 pw_separable_4/relu (Quanti  (None, 16, 16, 128)      256
 zedReLU)

 dw_separable_5 (QuantizedDe  (None, 16, 16, 128)      1408
 pthwiseConv2D)

 pw_separable_5 (QuantizedCo  (None, 16, 16, 128)      16512
 nv2D)

 pw_separable_5/relu (Quanti  (None, 16, 16, 128)      256
 zedReLU)

 dw_separable_6 (QuantizedDe  (None, 8, 8, 128)        1408
 pthwiseConv2D)

 pw_separable_6 (QuantizedCo  (None, 8, 8, 256)        33024
 nv2D)

 pw_separable_6/relu (Quanti  (None, 8, 8, 256)        512
 zedReLU)

 dw_separable_7 (QuantizedDe  (None, 8, 8, 256)        2816
 pthwiseConv2D)

 pw_separable_7 (QuantizedCo  (None, 8, 8, 256)        65792
 nv2D)

 pw_separable_7/relu (Quanti  (None, 8, 8, 256)        512
 zedReLU)

 dw_separable_8 (QuantizedDe  (None, 8, 8, 256)        2816
 pthwiseConv2D)

 pw_separable_8 (QuantizedCo  (None, 8, 8, 256)        65792
 nv2D)

 pw_separable_8/relu (Quanti  (None, 8, 8, 256)        512
 zedReLU)

 dw_separable_9 (QuantizedDe  (None, 8, 8, 256)        2816
 pthwiseConv2D)

 pw_separable_9 (QuantizedCo  (None, 8, 8, 256)        65792
 nv2D)

 pw_separable_9/relu (Quanti  (None, 8, 8, 256)        512
 zedReLU)

 dw_separable_10 (QuantizedD  (None, 8, 8, 256)        2816
 epthwiseConv2D)

 pw_separable_10 (QuantizedC  (None, 8, 8, 256)        65792
 onv2D)

 pw_separable_10/relu (Quant  (None, 8, 8, 256)        512
 izedReLU)

 dw_separable_11 (QuantizedD  (None, 8, 8, 256)        2816
 epthwiseConv2D)

 pw_separable_11 (QuantizedC  (None, 8, 8, 256)        65792
 onv2D)

 pw_separable_11/relu (Quant  (None, 8, 8, 256)        512
 izedReLU)

 dw_separable_12 (QuantizedD  (None, 4, 4, 256)        2816
 epthwiseConv2D)

 pw_separable_12 (QuantizedC  (None, 4, 4, 512)        131584
 onv2D)

 pw_separable_12/relu (Quant  (None, 4, 4, 512)        1024
 izedReLU)

 dw_separable_13 (QuantizedD  (None, 4, 4, 512)        5632
 epthwiseConv2D)

 pw_separable_13 (QuantizedC  (None, 4, 4, 512)        262656
 onv2D)

 pw_separable_13/relu (Quant  (None, 4, 4, 512)        1024
 izedReLU)

 dw_sepconv_t_0 (QuantizedDe  (None, 8, 8, 512)        6144
 pthwiseConv2DTranspose)

 pw_sepconv_t_0 (QuantizedCo  (None, 8, 8, 256)        131328
 nv2D)

 pw_sepconv_t_0/relu (Quanti  (None, 8, 8, 256)        512
 zedReLU)

 dropout (QuantizedDropout)  (None, 8, 8, 256)         0

 dw_sepconv_t_1 (QuantizedDe  (None, 16, 16, 256)      3072
 pthwiseConv2DTranspose)

 pw_sepconv_t_1 (QuantizedCo  (None, 16, 16, 128)      32896
 nv2D)

 pw_sepconv_t_1/relu (Quanti  (None, 16, 16, 128)      256
 zedReLU)

 dropout_1 (QuantizedDropout  (None, 16, 16, 128)      0
 )

 dw_sepconv_t_2 (QuantizedDe  (None, 32, 32, 128)      1536
 pthwiseConv2DTranspose)

 pw_sepconv_t_2 (QuantizedCo  (None, 32, 32, 64)       8256
 nv2D)

 pw_sepconv_t_2/relu (Quanti  (None, 32, 32, 64)       128
 zedReLU)

 dropout_2 (QuantizedDropout  (None, 32, 32, 64)       0
 )

 dw_sepconv_t_3 (QuantizedDe  (None, 64, 64, 64)       768
 pthwiseConv2DTranspose)

 pw_sepconv_t_3 (QuantizedCo  (None, 64, 64, 32)       2080
 nv2D)

 pw_sepconv_t_3/relu (Quanti  (None, 64, 64, 32)       64
 zedReLU)

 dropout_3 (QuantizedDropout  (None, 64, 64, 32)       0
 )

 dw_sepconv_t_4 (QuantizedDe  (None, 128, 128, 32)     384
 pthwiseConv2DTranspose)

 pw_sepconv_t_4 (QuantizedCo  (None, 128, 128, 16)     528
 nv2D)

 pw_sepconv_t_4/relu (Quanti  (None, 128, 128, 16)     32
 zedReLU)

 dropout_4 (QuantizedDropout  (None, 128, 128, 16)     0
 )

 head (QuantizedConv2D)      (None, 128, 128, 1)       17

 dequantizer (Dequantizer)   (None, 128, 128, 1)       0

 sigmoid_act (Activation)    (None, 128, 128, 1)       0

=================================================================
Total params: 1,061,601
Trainable params: 1,047,905
Non-trainable params: 13,696
_________________________________________________________________
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compile the quantized Keras model (required to evaluate the metrics)</span>
<span class="n">model_quantized_keras</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">BinaryIoU</span><span class="p">(),</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Check Keras model performance</span>
<span class="n">_</span><span class="p">,</span> <span class="n">biou</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">model_quantized_keras</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Keras quantized binary IoU / pixel accuracy: </span><span class="si">{</span><span class="n">biou</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">acc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Keras quantized binary IoU / pixel accuracy: 0.9399 / 97.01%
</pre></div>
</div>
</section>
<section id="conversion-to-akida">
<h2>4. Conversion to Akida<a class="headerlink" href="#conversion-to-akida" title="Permalink to this headline"></a></h2>
<p>Finally, the quantized Keras model from the previous step is converted into an Akida
model and its performance is evaluated. Note that the original performance of the keras
floating point model is maintained throughout the conversion process in this example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cnn2snn</span> <span class="kn">import</span> <span class="n">convert</span>

<span class="c1"># Convert the model</span>
<span class="n">model_akida</span> <span class="o">=</span> <span class="n">convert</span><span class="p">(</span><span class="n">model_quantized_keras</span><span class="p">)</span>
<span class="n">model_akida</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>                  Model Summary
_________________________________________________
Input shape    Output shape   Sequences  Layers
=================================================
[128, 128, 3]  [128, 128, 1]  1          36
_________________________________________________

_____________________________________________________________________________
Layer (type)                               Output shape    Kernel shape

====================== SW/conv_0-dequantizer (Software) =====================

conv_0 (InputConv2D)                       [64, 64, 16]    (3, 3, 3, 16)
_____________________________________________________________________________
conv_1 (Conv2D)                            [64, 64, 32]    (3, 3, 16, 32)
_____________________________________________________________________________
conv_2 (Conv2D)                            [32, 32, 64]    (3, 3, 32, 64)
_____________________________________________________________________________
conv_3 (Conv2D)                            [32, 32, 64]    (3, 3, 64, 64)
_____________________________________________________________________________
dw_separable_4 (DepthwiseConv2D)           [16, 16, 64]    (3, 3, 64, 1)
_____________________________________________________________________________
pw_separable_4 (Conv2D)                    [16, 16, 128]   (1, 1, 64, 128)
_____________________________________________________________________________
dw_separable_5 (DepthwiseConv2D)           [16, 16, 128]   (3, 3, 128, 1)
_____________________________________________________________________________
pw_separable_5 (Conv2D)                    [16, 16, 128]   (1, 1, 128, 128)
_____________________________________________________________________________
dw_separable_6 (DepthwiseConv2D)           [8, 8, 128]     (3, 3, 128, 1)
_____________________________________________________________________________
pw_separable_6 (Conv2D)                    [8, 8, 256]     (1, 1, 128, 256)
_____________________________________________________________________________
dw_separable_7 (DepthwiseConv2D)           [8, 8, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_7 (Conv2D)                    [8, 8, 256]     (1, 1, 256, 256)
_____________________________________________________________________________
dw_separable_8 (DepthwiseConv2D)           [8, 8, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_8 (Conv2D)                    [8, 8, 256]     (1, 1, 256, 256)
_____________________________________________________________________________
dw_separable_9 (DepthwiseConv2D)           [8, 8, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_9 (Conv2D)                    [8, 8, 256]     (1, 1, 256, 256)
_____________________________________________________________________________
dw_separable_10 (DepthwiseConv2D)          [8, 8, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_10 (Conv2D)                   [8, 8, 256]     (1, 1, 256, 256)
_____________________________________________________________________________
dw_separable_11 (DepthwiseConv2D)          [8, 8, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_11 (Conv2D)                   [8, 8, 256]     (1, 1, 256, 256)
_____________________________________________________________________________
dw_separable_12 (DepthwiseConv2D)          [4, 4, 256]     (3, 3, 256, 1)
_____________________________________________________________________________
pw_separable_12 (Conv2D)                   [4, 4, 512]     (1, 1, 256, 512)
_____________________________________________________________________________
dw_separable_13 (DepthwiseConv2D)          [4, 4, 512]     (3, 3, 512, 1)
_____________________________________________________________________________
pw_separable_13 (Conv2D)                   [4, 4, 512]     (1, 1, 512, 512)
_____________________________________________________________________________
dw_sepconv_t_0 (DepthwiseConv2DTranspose)  [8, 8, 512]     (3, 3, 512, 1)
_____________________________________________________________________________
pw_sepconv_t_0 (Conv2D)                    [8, 8, 256]     (1, 1, 512, 256)
_____________________________________________________________________________
dw_sepconv_t_1 (DepthwiseConv2DTranspose)  [16, 16, 256]   (3, 3, 256, 1)
_____________________________________________________________________________
pw_sepconv_t_1 (Conv2D)                    [16, 16, 128]   (1, 1, 256, 128)
_____________________________________________________________________________
dw_sepconv_t_2 (DepthwiseConv2DTranspose)  [32, 32, 128]   (3, 3, 128, 1)
_____________________________________________________________________________
pw_sepconv_t_2 (Conv2D)                    [32, 32, 64]    (1, 1, 128, 64)
_____________________________________________________________________________
dw_sepconv_t_3 (DepthwiseConv2DTranspose)  [64, 64, 64]    (3, 3, 64, 1)
_____________________________________________________________________________
pw_sepconv_t_3 (Conv2D)                    [64, 64, 32]    (1, 1, 64, 32)
_____________________________________________________________________________
dw_sepconv_t_4 (DepthwiseConv2DTranspose)  [128, 128, 32]  (3, 3, 32, 1)
_____________________________________________________________________________
pw_sepconv_t_4 (Conv2D)                    [128, 128, 16]  (1, 1, 32, 16)
_____________________________________________________________________________
head (Conv2D)                              [128, 128, 1]   (1, 1, 16, 1)
_____________________________________________________________________________
dequantizer (Dequantizer)                  [128, 128, 1]   N/A
_____________________________________________________________________________
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Check Akida model performance</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">pots</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">x_val</span><span class="p">[</span><span class="n">s</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">label_batch</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[</span><span class="n">s</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">pots_batch</span> <span class="o">=</span> <span class="n">model_akida</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">label_batch</span>
        <span class="n">pots</span> <span class="o">=</span> <span class="n">pots_batch</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">labels</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">))</span>
        <span class="n">pots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">pots</span><span class="p">,</span> <span class="n">pots_batch</span><span class="p">))</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">pots</span><span class="p">)</span>

<span class="n">m_binary_iou</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryIoU</span><span class="p">(</span><span class="n">target_class_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">m_binary_iou</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="n">binary_iou</span> <span class="o">=</span> <span class="n">m_binary_iou</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">m_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">()</span>
<span class="n">m_accuracy</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">m_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akida binary IoU / pixel accuracy: </span><span class="si">{</span><span class="n">binary_iou</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> / </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># For non-regression purpose</span>
<span class="k">assert</span> <span class="n">binary_iou</span> <span class="o">&gt;</span> <span class="mf">0.9</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Akida binary IoU / pixel accuracy: 0.9388 / 97.01%
</pre></div>
</div>
</section>
<section id="segment-a-single-image">
<h2>5. Segment a single image<a class="headerlink" href="#segment-a-single-image" title="Permalink to this headline"></a></h2>
<p>For visualization of the person segmentation performed by the Akida model, display a
single image along with the segmentation produced by the original floating point model
and the ground truth segmentation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Estimate age on a random single image and display Keras and Akida outputs</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x_val</span><span class="p">[</span><span class="nb">id</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">keras_out</span> <span class="o">=</span> <span class="n">model_keras</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="n">akida_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model_akida</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">)))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">keras_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Keras segmentation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">akida_out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Akida segmentation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y_val</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Expected segmentation&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_6_segmentation_002.png" srcset="../../_images/sphx_glr_plot_6_segmentation_002.png" alt="Keras segmentation, Akida segmentation, Expected segmentation" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  35.512 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-general-plot-6-segmentation-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/fde4b9eca70c6794f9842a0ad4e330ed/plot_6_segmentation.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_6_segmentation.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/7ad177709637a0d6363cd8cc169b3f8c/plot_6_segmentation.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_6_segmentation.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plot_5_voc_yolo_detection.html" class="btn btn-neutral float-left" title="YOLO/PASCAL-VOC detection tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_7_vision_transformer.html" class="btn btn-neutral float-right" title="Build Vision Transformers for Akida" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, BrainChip Holdings Ltd. All Rights Reserved.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>