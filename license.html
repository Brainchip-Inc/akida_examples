

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>License &mdash; Akida Examples  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-rendered-html.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Tips to set Akida learning parameters" href="examples/edge/plot_2_edge_learning_parameters.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #3f51b5" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/akida.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                Akida 1.8.13
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#quick-installation">Quick installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#running-examples">Running examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="user_guide/user_guide.html">User guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="user_guide/getting_started.html">Getting started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/getting_started.html#for-beginners">For beginners</a></li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/getting_started.html#for-users-familiar-with-deep-learning">For users familiar with deep-learning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide/aee.html">Akida user guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/aee.html#the-akida-execution-engine">The Akida Execution Engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#id1">1. The Spiking Neural Network model</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#id2">2. Input data format</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#id3">3. Determine training mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#id4">4. Interpreting outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/aee.html#neural-network-model">Neural Network model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#specifying-the-neural-network-model">Specifying the Neural Network model</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#saving-and-loading">Saving and loading</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#input-layer-types">Input layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#data-processing-layer-types">Data-Processing layer types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/aee.html#id5">Using Akida Unsupervised Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#learning-constraints">Learning constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#compiling-a-layer">Compiling a layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/aee.html#id6">Learning parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide/cnn2snn.html">CNN2SNN toolkit</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/cnn2snn.html#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#conversion-workflow">Conversion workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#typical-training-scenario">Typical training scenario</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#design-compatibility-constraints">Design compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#quantization-compatibility-constraints">Quantization compatibility constraints</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#command-line-interface">Command-line interface</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/cnn2snn.html#layers-considerations">Layers Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#supported-layer-types">Supported layer types</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#cnn2snn-quantization-aware-layers">CNN2SNN Quantization-aware layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#training-only-layers">Training-Only Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#first-layers">First Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/cnn2snn.html#id6">Final Layers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/cnn2snn.html#tips-and-tricks">Tips and Tricks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide/akida_models.html">Akida models zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/akida_models.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/akida_models.html#command-line-interface-for-model-creation">Command-line interface for model creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/akida_models.html#command-line-interface-for-model-training">Command-line interface for model training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#cifar10-training-and-tuning">CIFAR10 training and tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#utk-face-training">UTK Face training</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#kws-training">KWS training</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#yolo-training">YOLO training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/akida_models.html#id1">Layer Blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#conv-block"><code class="docutils literal notranslate"><span class="pre">conv_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#dense-block"><code class="docutils literal notranslate"><span class="pre">dense_block</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/akida_models.html#separable-conv-block"><code class="docutils literal notranslate"><span class="pre">separable_conv_block</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide/hw_constraints.html">Hardware constraints</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/hw_constraints.html#akida-nsoc-pre-production">Akida NSoC (Pre-production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#convolutional">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#fullyconnected">FullyConnected</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="user_guide/hw_constraints.html#akida-nsoc-production">Akida NSoC (Production)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#id1">InputConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#id2">Convolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#id3">SeparableConvolutional</a></li>
<li class="toctree-l4"><a class="reference internal" href="user_guide/hw_constraints.html#id4">FullyConnected</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="user_guide/compatibility.html">Akida versions compatibility</a><ul>
<li class="toctree-l3"><a class="reference internal" href="user_guide/compatibility.html#upgrading-models-with-legacy-quantizers">Upgrading models with legacy quantizers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api_reference/api_reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api_reference/aee_apis.html">Akida Execution Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#layer">Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#layerstatistics">LayerStatistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#inputdata">InputData</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#inputconvolutional">InputConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#fullyconnected">FullyConnected</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#convolutional">Convolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#separableconvolutional">SeparableConvolutional</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#concat">Concat</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#dense">Dense</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#backend">Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#convolutionmode">ConvolutionMode</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#poolingtype">PoolingType</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#learningtype">LearningType</a></li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/aee_apis.html#compatibility">Compatibility</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api_reference/cnn2snn_apis.html">CNN2SNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api_reference/cnn2snn_apis.html#tool-functions">Tool functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantize">quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantize-layer">quantize_layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#convert">convert</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#check-model-compatibility">check_model_compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#load-quantized-model">load_quantized_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#load-partial-weights">load_partial_weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizers">Quantizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#weightquantizer">WeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#linearweightquantizer">LinearWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#stdweightquantizer">StdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#trainablestdweightquantizer">TrainableStdWeightQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#maxquantizer">MaxQuantizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#maxperaxisquantizer">MaxPerAxisQuantizer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantized-layers">Quantized layers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizedconv2d">QuantizedConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizeddepthwiseconv2d">QuantizedDepthwiseConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizeddense">QuantizedDense</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizedseparableconv2d">QuantizedSeparableConv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizedactivation">QuantizedActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#activationdiscreterelu">ActivationDiscreteRelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/cnn2snn_apis.html#quantizedrelu">QuantizedReLU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api_reference/akida_models_apis.html">Akida models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api_reference/akida_models_apis.html#layer-blocks">Layer blocks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#conv-block">conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#separable-conv-block">separable_conv_block</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#dense-block">dense_block</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="api_reference/akida_models_apis.html#model-zoo">Model zoo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#mobilenet">Mobilenet</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#ds-cnn">DS-CNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#vgg">VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reference/akida_models_apis.html#yolo">YOLO</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples/index.html#general-examples">General examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_0_gxnor_mnist.html">GXNOR/MNIST inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_0_gxnor_mnist.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_0_gxnor_mnist.html#load-the-pre-trained-akida-model">2. Load the pre-trained Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_0_gxnor_mnist.html#show-predictions-for-a-single-image">3. Show predictions for a single image</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_0_gxnor_mnist.html#check-performance">4. Check performance</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html">DS-CNN CIFAR10 inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html#create-a-keras-ds-cnn-model">2. Create a Keras DS-CNN model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_1_ds_cnn_cifar10.html#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html">MobileNet/ImageNet inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html#create-a-keras-mobilenet-model">2. Create a Keras MobileNet model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html#quantized-model">3. Quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html#pretrained-quantized-model">4. Pretrained quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_2_mobilenet_imagenet.html#conversion-to-akida">5. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_3_ds_cnn_kws.html">DS-CNN/KWS inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_3_ds_cnn_kws.html#load-the-preprocessed-dataset">1. Load the preprocessed dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_3_ds_cnn_kws.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_3_ds_cnn_kws.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_3_ds_cnn_kws.html#conversion-to-akida">4. Conversion to Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_4_regression.html">Regression tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_4_regression.html#load-the-dataset">1. Load the dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_4_regression.html#load-a-pre-trained-native-keras-model">2. Load a pre-trained native Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_4_regression.html#load-a-pre-trained-quantized-keras-model-satisfying-akida-nsoc-requirements">3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_4_regression.html#conversion-to-akida">4. Conversion to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_4_regression.html#estimate-age-on-a-single-image">5. Estimate age on a single image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html">Transfer learning with MobileNet for cats vs. dogs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#transfer-learning-process">Transfer learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#load-and-preprocess-data">1. Load and preprocess data</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#modify-a-pre-trained-base-keras-model">2. Modify a pre-trained base Keras model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#train-the-transferred-model-for-the-new-task">3. Train the transferred model for the new task</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#quantize-the-top-layer">4 Quantize the top layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#convert-to-akida">5. Convert to Akida</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_5_transfer_learning.html#plot-confusion-matrix">6. Plot confusion matrix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html">YOLO/PASCAL-VOC detection tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#preprocessing-tools">2. Preprocessing tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#model-architecture">3. Model architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#performance">5. Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/general/plot_6_voc_yolo_detection.html#conversion-to-akida">6. Conversion to Akida</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="examples/index.html#cnn2snn-tutorials">CNN2SNN tutorials</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html">CNN conversion flow tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html#load-and-reshape-mnist-dataset">1. Load and reshape MNIST dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html#model-definition">2. Model definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html#model-quantization">4. Model quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html#model-fine-tuning-quantization-aware-training">5. Model fine tuning (quantization-aware training)</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_0_cnn_flow.html#model-conversion">6. Model conversion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/cnn2snn/plot_1_advanced_cnn2snn.html">Advanced CNN2SNN tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_1_advanced_cnn2snn.html#design-a-cnn2snn-quantized-model">1. Design a CNN2SNN quantized model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_1_advanced_cnn2snn.html#weight-quantizer-details">2. Weight Quantizer Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/cnn2snn/plot_1_advanced_cnn2snn.html#quantized-activation-layer-details">3. Quantized Activation Layer Details</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="examples/index.html#edge-examples">Edge examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples/edge/plot_0_edge_learning_vision.html">Akida vision edge learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_0_edge_learning_vision.html#dataset-preparation">1. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_0_edge_learning_vision.html#prepare-akida-model-for-learning">2. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_0_edge_learning_vision.html#edge-learning-with-akida">3. Edge learning with Akida</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html">Akida edge learning for keyword spotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html#edge-learning-process">1. Edge learning process</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html#dataset-preparation">2. Dataset preparation</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html#prepare-akida-model-for-learning">3. Prepare Akida model for learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html#learn-with-akida-using-the-training-set">4. Learn with Akida using the training set</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_1_edge_learning_kws.html#edge-learning">4. Edge learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples/edge/plot_2_edge_learning_parameters.html">Tips to set Akida learning parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_2_edge_learning_parameters.html#akida-learning-parameters">1. Akida learning parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_2_edge_learning_parameters.html#create-akida-model">2. Create Akida model</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_2_edge_learning_parameters.html#estimate-the-required-number-of-weights-of-the-trainable-layer">3. Estimate the required number of weights of the trainable layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples/edge/plot_2_edge_learning_parameters.html#estimate-the-number-of-neurons-per-class">4. Estimate the number of neurons per class</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Brainchip-Inc/akida_examples/releases">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://support.brainchip.com/portal/home">Support</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Akida Examples</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>License</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="license">
<h1>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h1>
<p>BRAINCHIP SOFTWARE END USER LICENSE AGREEMENT</p>
<p>PLEASE READ THIS END USER LICENSE AGREEMENT (“LICENSE”) CAREFULLY BEFORE
DOWNLOADING OR USING THE SOFTWARE. BY DOWNLOADING OR USING THE SOFTWARE, YOU ARE
AGREEING TO BE BOUND BY THE TERMS OF THIS LICENSE. IF YOU DO NOT AGREE TO THE
TERMS OF THIS LICENSE, PROMPTLY DELETE THE UNUSED SOFTWARE FROM YOUR COMPUTER OR
DEVICE.</p>
<p>1.License Granted.</p>
<p>The application, demonstration, and other software accompanying this License,
whether on disk, in read-only memory, or on any other media (“BRAINCHIP’s
Software”) and the related documentation are licensed to you by BRAINCHIP, INC.
(“BRAINCHIP”) for your personal internal use only (with no rights to resell,
transfer, assign, or sublicense), and you shall not use BRAINCHIP’s Software to
process or permit it be used to process data for any third party, or to be used
in the operation of a service bureau. BRAINCHIP is the licensor under this
License Agreement. You own, rent, or use free-of-charges the medium on which
BRAINCHIP’s Software is recorded, but BRAINCHIP and/or BRAINCHIP’s Licensor(s)
retain title to BRAINCHIP’s Software and related documentation. This License
allows you to use BRAINCHIP’s Software on a single hardware support and only
make one copy of BRAINCHIP’s Software in machine-readable form for backup
purposes only. You must reproduce on such a copy BRAINCHIP’s copyright notice
and any other proprietary legends that were on the original copy of BRAINCHIP’s
Software.</p>
<p>2.Restrictions.</p>
<p>BRAINCHIP’s Software contains copyrighted material, trade secrets, and other
proprietary material. In order to protect that proprietary material, you may not
decompile, reverse engineer, disassemble, or otherwise reduce BRAINCHIP’s
Software to a human-perceivable form; copy, modify, network, rent, lease, loan,
or distribute BRAINCHIP’s Software; or create derivative works based upon
BRAINCHIP’s Software in whole or in part other than as expressly permitted in
writing by BRAINCHIP. You agree that BRAINCHIP shall own all derivative works
and improvements to BRAINCHIP’s Software. You shall not use BRAINCHIP’s Software
to program any device other than BRAINCHIP devices. You may not publish or
disclose the results of any benchmarking or testing of BRAINCHIP’s Software
without the prior written permission of BRAINCHIP. You may not sublicense,
assign, or transfer BRAINCHIP’s Software.</p>
<p>3.Termination.</p>
<p>This License is effective until terminated. You may terminate this License at
any time by destroying BRAINCHIP’s Software and related documentation, and all
copies thereof. This License will terminate immediately without notice from
BRAINCHIP if you fail to comply with any provision of this License. Upon
termination you must destroy BRAINCHIP’s Software and related documentation
and all copies thereof. Upon termination you shall remain subject to the
provisions, restrictions, and exclusions in this License Agreement and shall
have no right to any refund of any amounts paid for BRAINCHIP’s Software. No
termination shall release you from liability for any breach of this License
Agreement.</p>
<p>4.Export Law Assurances.</p>
<p>You agree and certify that neither BRAINCHIP’s Software, nor any other technical
data received from BRAINCHIP, nor the direct product thereof, will be shipped,
transferred, or exported, directly or indirectly, to any country in violation
of any applicable law.  You agree to comply with all restrictions and export
controls imposed by the laws and regulations of the United States and any other
applicable jurisdiction.</p>
<p>5.Disclaimer of Warranty on BRAINCHIP’s Software.</p>
<p>You expressly acknowledge and agree that the use of BRAINCHIP’s Software is at
your sole risk. BRAINCHIP’s Software and related documentation are provided
“AS IS” and without warranty of any kind.</p>
<p>BRAINCHIP AND BRAINCHIP’S LICENSOR(S) DISCLAIM ALL WARRANTIES, CONDITIONS, AND
REPRESENTATIONS (EXPRESS OR IMPLIED, ORAL OR WRITTEN) WITH RESPECT TO
BRAINCHIP’S SOFTWARE AND RELATED DOCUMENTATION, INCLUDING, BUT NOT LIMITED TO,
IMPLIED WARRANTIES AND/OR CONDITIONS OF MERCHANTABILITY OR FITNESS FOR A
PARTICULAR PURPOSE OR NON-INFRINGEMENT OR NON-INTERFERENCE. BRAINCHIP DISCLAIMS
ALL WARRANTIES THAT FUNCTIONS CONTAINED IN BRAINCHIP’S SOFTWARE WILL MEET YOUR
REQUIREMENTS, OR THAT THE OPERATION OF BRAINCHIP’S SOFTWARE WILL BE
UNINTERRUPTED OR ERROR-FREE, OR THAT DEFECTS IN BRAINCHIP’S SOFTWARE WILL BE
CORRECTED, OR THAT BRAINCHIP’S SOFTWARE WILL NOT BE VULNERABLE TO INTRUSION OR
ATTACK. FURTHERMORE, BRAINCHIP DOES NOT WARRANT OR MAKE ANY REPRESENTATIONS
REGARDING THE USE OR THE RESULTS OF THE USE OF BRAINCHIP’S SOFTWARE OR RELATED
DOCUMENTATION IN TERMS OF THEIR CORRECTNESS, ACCURACY, RELIABILITY, OR
OTHERWISE. NO COURSE OF DEALING OR ORAL OR WRITTEN INFORMATION OR ADVICE GIVEN
BY BRAINCHIP OR A BRAINCHIP-AUTHORIZED REPRESENTATIVE SHALL CREATE A WARRANTY OR
REPRESENTATION. SHOULD BRAINCHIP SOFTWARE PROVE DEFECTIVE, YOU (AND NOT
BRAINCHIP OR A BRAINCHIP-AUTHORIZED REPRESENTATIVE) SHALL ASSUME THE ENTIRE
COST OF ALL NECESSARY SERVICING, REPAIRS, OR CORRECTIONS.</p>
<p>EXCEPT AS EXPRESSLY PROVIDED TO THE CONTRARY IN THIS LICENSE, ALL CONDITIONS,
WARRANTIES, AND REPRESENTATIONS EXPRESSED OR IMPLIED BY STATUTE, LAW, OR
OTHERWISE IN RELATION TO BRAINCHIP’S SOFTWARE ARE HEREBY DISCLAIMED AND
EXCLUDED, AND BRAINCHIP SHALL BE UNDER NO LIABILITY FOR ANY LOSS, DAMAGE, OR
INJURY, DIRECT OR INDIRECT, RESULTING FROM DEFECTIVE MATERIAL, FAULTY
WORKMANSHIP, OR OTHERWISE.</p>
<p>BRAINCHIP MAKES NO WARRANTIES, REPRESENTATIONS, OR GUARANTEES REGARDING USAGE OF
BRAINCHIP’S SOFTWARE IN COMPLIANCE WITH GDPR REGULATIONS. YOU SHOULD CONSULT
WITH YOUR LEGAL COUNSEL TO ENSURE YOUR USE OF BRAINCHIP’S SOFTWARE IS IN
COMPLIANCE WITH GDPR REGULATIONS OR ANY OTHER LOCAL LAWS AND REGULATIONS.</p>
<p>THE TERMS OF THIS DISCLAIMER DO NOT AFFECT OR PREJUDICE THE STATUTORY RIGHTS OF
A CONSUMER ACQUIRING BRAINCHIP’S SOFTWARE NOT IN THE COURSE OF BUSINESS, NOR DO
THEY LIMIT OR EXCLUDE ANY LIABILITY FOR DEATH OR PERSONNAL INJURY CAUSED BY
BRAINCHIP’S NEGLIGENCE.</p>
<p>6.Limitation of Liability.</p>
<p>UNDER NO CIRCUMSTANCES SHALL BRAINCHIP BE LIABLE FOR ANY INCIDENTAL, SPECIAL,
INDIRECT, EXEMPLARY, OR CONSEQUENTIAL DAMAGES, LOST PROFITS,  OR DAMAGES DUE TO
BUSINESS INTERRUPTION, DISCLOSURE OF PERSONALLY IDENTIFYING INFORMATION,
CORRUPTION OF DATA, OR LOSS OF INFORMATION, ARISING OUT OF OR RELATING TO THE
USE OR INABILITY TO USE BRAINCHIP’S SOFTWARE OR RELATED DOCUMENTATION, BASED ON
ANY THEORY OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT,
NEGLIGENCE, STRICT LIABILITY, VIOLATION OF PUBLIC POLICY, OR EQUITY, AND
REGARDLESS OF WHETHER BRAINCHIP OR A BRAINCHIP-AUTHORIZED REPRESENTATIVE WAS
ADVISED OF THE POSSIBILITY OF ANY OF THE FOREGOING.</p>
<p>IN NO EVENT SHALL BRAINCHIP’S TOTAL LIABILITY TO YOU FOR ALL DAMAGES,
LIABILITIES, LOSSES, EXPENSES, CLAIMS, AND CAUSES OF ACTION BASED ON ANY THEORY
OF LIABILITY, INCLUDING, WITHOUT LIMITATION, CONTRACT, TORT, NEGLIGENCE, STRICT
LIABILITY, VIOLATION OF PUBLIC POLICY, OR EQUITY, EXCEED THE AMOUNT PAID BY YOU
FOR BRAINCHIP’S SOFTWARE.</p>
<p>7.Controlling Law and Severability.</p>
<p>This License shall be governed by and construed in accordance with the laws of
the State of California, U.S.A., applicable to contracts made in and fully
performed in the State of California, U.S.A., without giving effect to conflict
of law principles that would cause the application of laws of any other
jurisdiction. The United Nations Convention on Contracts for the International
Sales of Goods shall not apply to this License. If for any reason a court of
competent jurisdiction finds any provision of this License, or portion thereof,
to be unenforceable, that provision of the License shall be enforced so as to
give effect to the original intent of the parties as closely as possible to the
fullest extent permitted by applicable law, and all other provisions of this
License shall continue in full force and effect.</p>
<p>8.Entire Agreement.</p>
<p>This License constitutes and contains the entire agreement and understanding
between you and BRAINCHIP concerning the subject matter hereof.  This License
supersedes and replaces all prior negotiations, representations, promises,
understandings, proposals, and agreements, whether written or oral, between you
and BRAINCHIP concerning the subject matters addressed herein, and it is a fully
integrated document. No amendment to or modification of this License will be
binding unless in writing and signed by a duly authorized representative of
BRAINCHIP.</p>
<p>9.Acknowledgment.</p>
<p>You acknowledge that you have read and understand this License and agree to be
bound by these terms and conditions.</p>
<p>Should you have any questions concerning this License, please contact:</p>
<p>Brainchip, Inc., 65 Enterprise, Aliso Viejo, CA 92656 (United States) or write
to <a class="reference external" href="mailto:sales&#37;&#52;&#48;brainchipinc&#46;com">sales<span>&#64;</span>brainchipinc<span>&#46;</span>com</a></p>
<p>Copyright 2020, BrainChip Holdings Ltd. All rights reserved.</p>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="examples/edge/plot_2_edge_learning_parameters.html" class="btn btn-neutral float-left" title="Tips to set Akida learning parameters" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, BrainChip Holdings Ltd. All Rights Reserved.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>