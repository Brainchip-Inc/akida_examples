{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Akida vision edge learning\n\nThis tutorial demonstrates the Akida NSoC **edge learning** capabilities using\nits built-in learning algorithm.\nIt focuses on an image classification example, where an existing Akida network\nis re-trained to be able to classify images from 4 new classes.\n\nJust a few samples (few-shot learning) of the new classes are sufficient\nto augment the Akida model with extra classes, while preserving high accuracy.\n\nPlease refer to the [keyword spotting (KWS) tutorial](plot_1_edge_learning_kws.html)_\nfor edge learning documentation, parameters fine tuning and steps details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset preparation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport tensorflow_datasets as tfds\n\nfrom akida import FullyConnected\nfrom akida_models import fetch_file\n\n# Retrieve TensorFlow `coil100 <https://www.tensorflow.org/datasets/catalog/coil100>`__\n# dataset (explicit download because file location changed and TFDS is not up to date).\nfname = fetch_file(fname='coil-100.zip', cache_subdir='datasets/coil-100', extract=True,\n                   origin=\"https://data.brainchip.com/dataset-mirror/coil-100/coil-100.zip\")\nfdir = os.path.dirname(fname)\ndl_and_prepare = {'download_config': tfds.download.DownloadConfig(manual_dir=fdir)}\nds, ds_info = tfds.load('coil100:2.*.*', split='train', with_info=True, data_dir=fdir,\n                        download_and_prepare_kwargs=dl_and_prepare)\nprint(ds_info.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the 4 cup objects that will be used as new classes\nobject_ids = [15, 17, 24, 42]\nobject_dict = {k: [] for k in object_ids}\nfor data in ds:\n    object_id = data['object_id'].numpy()\n    if object_id in object_dict.keys():\n        object_dict[object_id].append(data['image'].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n# Display one image per selected object\nf, axarr = plt.subplots(1, len(object_dict))\ni = 0\nfor k in object_dict:\n    axarr[i].axis('off')\n    axarr[i].imshow(object_dict[k][0])\n    axarr[i].set_title(k, fontsize=10)\n    i += 1\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Akida model for learning\n\n.. Note:: Edge learning is only supported for Akida 1.0 models for now.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models import akidanet_edge_imagenet_pretrained\nfrom cnn2snn import convert, set_akida_version, AkidaVersion\n\n# Load a pre-trained model\nwith set_akida_version(AkidaVersion.v1):\n    model_keras = akidanet_edge_imagenet_pretrained()\n\n# Convert it to Akida\nmodel_ak = convert(model_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida import AkidaUnsupervised\n\n# Replace the last layer by a classification layer\nnum_classes = len(object_dict)\nnum_neurons_per_class = 1\nnum_weights = 350\nmodel_ak.pop_layer()\nlayer_fc = FullyConnected(name='akida_edge_layer',\n                          units=num_classes * num_neurons_per_class,\n                          activation=False)\nmodel_ak.add(layer_fc)\nmodel_ak.compile(optimizer=AkidaUnsupervised(num_weights=num_weights,\n                                             num_classes=num_classes,\n                                             learning_competition=0.1))\nmodel_ak.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Edge learning with Akida\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom tensorflow.image import resize_with_crop_or_pad\nfrom time import time\n\n# Learn objects in num_shots shot(s)\nnum_shots = 1\nfor i in range(len(object_ids)):\n    start = time()\n    train_images = object_dict[object_ids[i]][:num_shots]\n    for image in train_images:\n        padded_image = resize_with_crop_or_pad(image, 224, 224)\n        model_ak.fit(np.expand_dims(padded_image, axis=0), i)\n    end = time()\n    print(f'Learned object {object_ids[i]} (class {i}) with \\\n            {len(train_images)} sample(s) in {end-start:.2f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import statistics as stat\n\n# Check accuracy against remaining samples\naccuracy = []\nfor i in range(len(object_ids)):\n    test_images = object_dict[object_ids[i]][num_shots:]\n    predictions = np.zeros(len(test_images))\n    for j in range(len(test_images)):\n        padded_image = resize_with_crop_or_pad(test_images[j], 224, 224)\n        predictions[j] = model_ak.predict_classes(np.expand_dims(padded_image,\n                                                                 axis=0),\n                                                  num_classes=num_classes)\n    accuracy.append(100 * np.sum(predictions == i) / len(test_images))\n    print(f'Accuracy testing object {object_ids[i]} (class {i}) with \\\n            {len(test_images)} sample(s): {accuracy[i]:.2f}%')\n\nmean_accuracy = stat.mean(accuracy)\nprint(f'Mean accuracy: {mean_accuracy:.2f}%')\n\n# For non-regression purposes\nassert mean_accuracy > 94"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}