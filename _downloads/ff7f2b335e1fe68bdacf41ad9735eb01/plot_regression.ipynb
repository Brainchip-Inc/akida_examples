{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nRegression tutorial\n==================================================\n\nThis tutorial demonstrates that hardware-compatible Akida models can perform\nregression tasks at the same accuracy level as a native CNN network.\n\nThis is illustrated through an age estimation problem using the\n`UTKFace dataset <https://susanqq.github.io/UTKFace/>`__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Load the dataset\n~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models.utk_face.preprocessing import load_data\n\n# Load the dataset using akida_models preprocessing tool\nx_train, y_train, x_test, y_test = load_data()\n\n# For CNN Keras training and inference, the data is normalized\ninput_scaling = (127, 127)\nx_test_keras = (x_test.astype('float32') - input_scaling[1]) / input_scaling[0]\n\n# For Akida inference, use uint8 raw data\nx_test_akida = x_test.astype('uint8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Load a pre-trained native Keras model\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe model is a simplified version inspired from `VGG <https://arxiv.org/abs/1409.1556>`__\narchitecture. It consists of a succession of convolutional and pooling layers\nand ends with two fully connected layers that outputs a single value\ncorresponding to the estimated age. This model architecture is compatible with\nthe `design constraints <https://doc.brainchipinc.com/user_guide/cnn2snn.html#design-compatibility-constraints>`__\nbefore quantization. It is the starting point for a model runnable on the\nAkida NSoC.\n\nThe pre-trained native Keras model loaded below was trained on 300 epochs.\nThe model file is available on the BrainChip data server.\n\nThe performance of the model is evaluated using the \"Mean Absolute Error\"\n(MAE). The MAE, used as a metric in regression problem, is calculated as an\naverage of absolute differences between the target values and the predictions.\nThe MAE is a linear score, i.e. all the individual differences are equally\nweighted in the average.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import get_file\nfrom tensorflow.keras.models import load_model\n\n# Retrieve the model file from the BrainChip data server\nmodel_file = get_file(\"vgg_utk_face.h5\",\n                      \"http://data.brainchip.com/models/vgg/vgg_utk_face.h5\",\n                      cache_subdir='models')\n\n# Load the native Keras pre-trained model\nmodel_keras = load_model(model_file)\nmodel_keras.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compile the native Keras model (required to evaluate the MAE)\nmodel_keras.compile(optimizer='Adam', loss='mae')\n\n# Check Keras model performance\nmae_keras = model_keras.evaluate(x_test_keras, y_test, verbose=0)\n\nprint(\"Keras MAE: {0:.4f}\".format(mae_keras))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Load a pre-trained quantized Keras model satisfying Akida NSoC requirements\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe above native Keras model is quantized and fine-tuned to get a quantized\nKeras model satisfying the\n`Akida NSoC requirements <https://doc.brainchipinc.com/user_guide/hw_constraints.html>`__.\nThe first convolutional layer of our model uses 8-bit weights and other\nlayers are quantized using 2-bit weights. All activations are 2 bits.\n\nThe pre-trained model was obtained after two fine-tuning episodes:\n\n* the model is first quantized and fine-tuned with 4-bit weights and\n  activations (first convolutional weights are 8 bits)\n* the model is then quantized and fine-tuned with 2-bit weights and\n  activations (first convolutional weights are still 8 bits).\n\nThe table below summarizes the \"Mean Absolute Error\" (MAE) results obtained\nafter every training episode.\n\n+---------+----------------+---------------+------+--------+\n| Episode | Weights Quant. | Activ. Quant. | MAE  | Epochs |\n+=========+================+===============+======+========+\n| 1       | N/A            | N/A           | 5.80 | 300    |\n+---------+----------------+---------------+------+--------+\n| 2       | 8/4 bits       | 4 bits        | 5.79 | 30     |\n+---------+----------------+---------------+------+--------+\n| 3       | 8/2 bits       | 2 bits        | 6.15 | 30     |\n+---------+----------------+---------------+------+--------+\n\nHere, we directly load the pre-trained quantized Keras model using the\nakida_models helper.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models import vgg_utk_face_pretrained\n\n# Load the pre-trained quantized model\nmodel_quantized_keras = vgg_utk_face_pretrained()\nmodel_quantized_keras.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compile the quantized Keras model (required to evaluate the MAE)\nmodel_quantized_keras.compile(optimizer='Adam', loss='mae')\n\n# Check Keras model performance\nmae_quant = model_quantized_keras.evaluate(x_test_keras, y_test, verbose=0)\n\nprint(\"Keras MAE: {0:.4f}\".format(mae_quant))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Conversion to Akida\n~~~~~~~~~~~~~~~~~~~~~~\n\nThe quantized Keras model is now converted into an Akida model.\nAfter conversion, we evaluate the performance on the UTKFace dataset.\n\nSince activations sparsity has a great impact on Akida inference time, we\nalso have a look at the average input and output sparsity of each layer on\na subset of the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cnn2snn import convert\n\n# Convert the model\nmodel_akida = convert(model_quantized_keras, input_scaling=input_scaling)\nmodel_akida.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n# Check Akida model performance\ny_akida = model_akida.evaluate(x_test_akida)\n\n# Compute and display the MAE\nmae_akida = np.sum(np.abs(y_test.squeeze() - y_akida.squeeze())) / len(y_test)\nprint(\"Akida MAE: {0:.4f}\".format(mae_akida))\n\n# For non-regression purpose\nassert abs(mae_keras - mae_akida) < 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Print model statistics\nprint(\"Model statistics\")\nstats = model_akida.get_statistics()\nmodel_akida.evaluate(x_test_akida[:20])\nfor _, stat in stats.items():\n    print(stat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's summarize the MAE performance for the native Keras, the quantized Keras\nand the Akida model.\n\n+-----------------+------+\n| Model           | MAE  |\n+=================+======+\n| native Keras    | 5.80 |\n+-----------------+------+\n| quantized Keras | 6.15 |\n+-----------------+------+\n| Akida           | 6.21 |\n+-----------------+------+\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Estimate age on a single image\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n# Estimate age on a random single image and display Keras and Akida outputs\nid = np.random.randint(0, len(y_test) + 1)\nage_keras = model_keras.predict(x_test_keras[id:id + 1])\n\nplt.imshow(x_test_akida[id], interpolation='bicubic')\nplt.xticks([]), plt.yticks([])\nplt.show()\n\nprint(\"Keras estimated age: {0:.1f}\".format(age_keras.squeeze()))\nprint(\"Akida estimated age: {0:.1f}\".format(y_akida[id].squeeze()))\nprint(f\"Actual age: {y_test[id].squeeze()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}