{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# GXNOR/MNIST inference\n\nThe MNIST dataset is a handwritten digits database. It has a training\nset of 60,000 samples, and a test set of 10,000 samples. Each sample\ncomprises a 28x28 pixel image and an associated label.\n\nThis tutorial illustrates how to use a pre-trained Akida model to process the\nMNIST dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset preparation\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.datasets import mnist\n\n# Retrieve MNIST dataset\n(train_set, train_label), (test_set, test_label) = mnist.load_data()\n\n# Add a dimension to images sets as akida expects 4 dimensions inputs\ntrain_set = np.expand_dims(train_set, -1)\ntest_set = np.expand_dims(test_set, -1)\n\n# Display a few images from the test set\nf, axarr = plt.subplots(1, 4)\nfor i in range(0, 4):\n    axarr[i].imshow(test_set[i].reshape((28, 28)), cmap=cm.Greys_r)\n    axarr[i].set_title('Class %d' % test_label[i])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load the pre-trained Akida model\n\nThe pre-trained neural network model is available on\n`Brainchip data server <http://data.brainchip.com/models/gxnor/>`_\nYou only need to pass this .fbz file to the Akida Execution Engine in order\nto instantiate the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida import Model\n\nfrom tensorflow.keras.utils import get_file\n\n# Load provided model configuration file\nmodel_file = get_file(\"gxnor_mnist.fbz\",\n                      \"http://data.brainchip.com/models/gxnor/gxnor_mnist.fbz\",\n                      cache_subdir='models/gxnor')\nmodel_akida = Model(model_file)\nmodel_akida.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Show predictions for a single image\n\nNow try processing a single image, say, the first image in the dataset\nthat we looked at above:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Test a single example\nsample_image = 0\nimage = test_set[sample_image]\noutputs = model_akida.evaluate(image.reshape(1, 28, 28, 1))\nprint('Input Label: %i' % test_label[sample_image])\n\nf, axarr = plt.subplots(1, 2)\naxarr[0].imshow(test_set[sample_image].reshape((28, 28)), cmap=cm.Greys_r)\naxarr[0].set_title('Class %d' % test_label[sample_image])\naxarr[1].bar(range(10), outputs.squeeze())\naxarr[1].set_xticks(range(10))\nplt.show()\n\nprint(outputs.squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the output from the model, printed above. As is typical in\nbackprop trained models, the final layer here comprises a\n'fully-connected or 'dense' layer, with one neuron per class in the\ndata (here, 10). The goal of training is to maximize the response of the\nneuron corresponding to the label of each training sample, while\nminimizing the responses of the other neurons.\n\nIn the bar chart above, you can see the outputs from all 10 neurons. It\nis easy to see that neuron 7 responds much more strongly than the\nothers. The first sample is indeed a number 7.\n\nCheck this for some of the other samples by editing the value of\nsample_image in the script above (anything from 0 to 9999).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Check performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n\n# Check performance against num_samples samples\nnum_samples = 10000\n\nresults = model_akida.predict(test_set[:int(num_samples)], 10)\naccuracy = accuracy_score(test_label[:num_samples], results[:num_samples])\nf1 = f1_score(test_label[:num_samples],\n              results[:num_samples],\n              average='weighted')\n\n# For non-regression purpose\nassert accuracy > 0.99\n\n# Print model statistics\nprint(\"Model statistics\")\nstats = model_akida.get_statistics()\nfor _, stat in stats.items():\n    print(stat)\n\n# Display results\nprint(\"Accuracy: \" + \"{0:.2f}\".format(100 * accuracy) + \"% / \" + \"F1 score: \" +\n      \"{0:.2f}\".format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on the number of samples you run, you should find a\nperformance of around 99% (99.07% if you run all 10000 samples).\n\nNote that classification here is done simply by identifying the neuron\nwith the highest activation level. Slightly higher performance is\nactually possible for this model implementation (~99.1 %) if a very\nslightly more complex final classification is applied (with a single\nadditional integer subtraction per neuron), but for simplicity we leave\nthose details aside here. See the cnn2snn training framework for a full\ndescription.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}