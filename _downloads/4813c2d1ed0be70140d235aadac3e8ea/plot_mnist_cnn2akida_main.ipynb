{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nInference on MNIST\n==================\n\nThe Akida Execution Engine includes a powerful native learning\nalgorithm. However, it is also possible to train an Akida-compatible\nmodel externally, using specialized deep-learning techniques, and to\nthen implement that model within the Akida Execution Engine as an\nefficient inference-only tool using the `CNN2SNN\ntoolkit <../../user_guide/cnn2snn.html>`__. In this tutorial, you will\nsimply load one such pre-trained model, use it to process the MNIST\ndataset, and look at how to make sense of the outputs.\n\nThe MNIST dataset is a handwritten digits database. It has a training\nset of 60,000 samples, and a test set of 10,000 samples. Each sample\ncomprises a 28x28 pixel image and an associated label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Loading the MNIST dataset\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Various imports needed for the tutorial\nimport os\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport warnings\nfrom tensorflow.keras.utils import get_file\nfrom tensorflow.keras.datasets import mnist\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# Filter warnings\nwarnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n\n# Akida specific imports\nfrom akida import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Retrieve MNIST dataset\n(train_set, train_label), (test_set, test_label) = mnist.load_data()\n\n# Add a dimension to images sets as akida expects 4 dimensions inputs\ntrain_set = np.expand_dims(train_set, -1)\ntest_set = np.expand_dims(test_set, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Look at some images from the test dataset\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Display a few images from the test set\nf, axarr = plt.subplots(1, 4)\nfor i in range (0, 4):\n    axarr[i].imshow(test_set[i].reshape((28,28)), cmap=cm.Greys_r)\n    axarr[i].set_title('Class %d' % test_label[i])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Load the pre-trained Akida model\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe pre-trained neural network model is included in the models/cnn2snn\ndirectory. You only need to pass this .fbz file to the Akida Execution\nEngine in order to instantiate the model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load provided model configuration file\nmodel_file = get_file(\"gxnor_mnist.fbz\",\n                      \"http://data.brainchip.com/models/gxnor/gxnor_mnist.fbz\",\n                      cache_subdir='models/gxnor')\nmodel_akida = Model(model_file)\nprint (model_file + ' loaded...')\nmodel_akida.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Classify a single image\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNow try processing a single image, say, the first image in the dataset\nthat we looked at above:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Test a single example\nsample_image = 0\nimage = test_set[sample_image]\noutputs = model_akida.evaluate(image.reshape(1,28,28,1))\nprint('Input Label: %i' % test_label[sample_image])\n\nf, axarr = plt.subplots(1, 2)\naxarr[0].imshow(test_set[sample_image].reshape((28,28)), cmap=cm.Greys_r)\naxarr[0].set_title('Class %d' % test_label[sample_image])\naxarr[1].bar(range(10),outputs.squeeze())\naxarr[1].set_xticks(range(10))\nplt.show()\n\nprint(outputs.squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the output from the model, printed above. As is typical in\nbackprop trained models, the final layer here comprises a\n'fully-connected or 'dense' layer, with one neuron per class in the\ndata (here, 10). The goal of training is to maximize the response of the\nneuron corresponding to the label of each training sample, while\nminimizing the responses of the other neurons.\n\nIn the bar chart above, you can see the outputs from all 10 neurons. It\nis easy to see that neuron 7 responds much more strongly than the\nothers. The first sample is indeed a number 7.\n\nCheck this for some of the other samples by editing the value of\nsample_image in the script above (anything from 0 to 9999).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Check performance across a number of samples\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWe've included a utility to test performance across a large number of\nsamples. You can run this below.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Check performance against num_samples samples\nnum_samples = 10000\n\nresults = model_akida.predict(test_set[:int(num_samples)], 10)\naccuracy = accuracy_score(test_label[:num_samples], results[:num_samples])\nf1 = f1_score(test_label[:num_samples],\n               results[:num_samples],\n               average='weighted')\n\n# For non-regression purpose\nassert accuracy > 0.99\n\n# Print model statistics\nprint(\"Model statistics\")\nstats = model_akida.get_statistics()\nmodel_akida.predict(test_set[:20], 10)\nfor _, stat in stats.items():\n    print(stat)\n\n# Display results\nprint(\"Accuracy: \"+\"{0:.2f}\".format(100*accuracy)+\"% / \"\n       +\"F1 score: \"+\"{0:.2f}\".format(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on the number of samples you run, you should find a\nperformance of around 99% (99.35% if you run all 10000 samples).\n\nNote that classification here is done simply by identifying the neuron\nwith the highest activation level. Slightly higher performance is\nactually possible for this model implementation (~99.1 %) if a very\nslightly more complex final classification is applied (with a single\nadditional integer subtraction per neuron), but for simplicity we leave\nthose details aside here. See the cnn2snn training framework for a full\ndescription.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}