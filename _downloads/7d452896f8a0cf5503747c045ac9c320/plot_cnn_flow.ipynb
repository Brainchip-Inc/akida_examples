{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCNN conversion flow tutorial\n============================\n\nThis tutorial illustrates how to use the CNN2SNN toolkit to **convert CNN\nnetworks to SNN networks** compatible with the **Akida NSoC** in a few steps.\nYou can refer to our `CNN2SNN toolkit user guide\n<https://doc.brainchipinc.com/user_guide/cnn2snn.html>`__ for further\nexplanation.\n\nThe CNN2SNN tool is based on Keras, TensorFlow high-level API for building and\ntraining deep learning models.\n\n.. Note:: Please refer to TensorFlow  `tf.keras.models\n          <https://www.tensorflow.org/api_docs/python/tf/keras/models>`__\n          module for model creation/import details and `TensorFlow\n          Guide <https://www.tensorflow.org/guide>`__ for details of how\n          TensorFlow works.\n\n          MNIST example below is light enough so you do not need a `GPU\n          <https://www.tensorflow.org/install/gpu>`__ to run the CNN2SNN\n          tool.\n\n![](../img/cnn2snn_flow_small.jpg)\n\n   :scale: 35 %\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Load and reshape MNIST dataset\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAfter loading, we make 2 transformations on the dataset:\n\n1. Reshape the sample content data (x values) into a num_samples x width x\n   height x channels matrix.\n\n.. Note:: At this point, we'll set aside the raw data for testing our\n          converted model in the Akida Execution Engine later.\n\n2. Rescale the 8-bit loaded data to the range 0-to-1 for training.\n\n.. Note:: Input data normalization is a common step dealing with CNN\n          (rationale is to keep data in a range that works with selected\n          optimizers, some reading can be found\n          `here <https://www.jeremyjordan.me/batch-normalization/>`__.\n\n          This shift makes almost no difference in the current example, but\n          for some datasets rescaling the absolute values (and also shifting\n          to zero-mean) can make a really major difference.\n\n          Also note that we store the scaling values ``input_scaling`` for\n          use when preparing the model for the Akida Execution Engine. The\n          implementation of the Akida neural network allows us to completely\n          skip the rescaling step (i.e. the Akida model should be fed with\n          the raw 8-bit values) but that does require information about what\n          scaling was applied prior to training - see below for more details.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\nfrom tensorflow import keras\n\n# Load MNIST dataset\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n# Reshape x-data\nx_train = x_train.reshape(60000, 28, 28, 1)\nx_test = x_test.reshape(10000, 28, 28, 1)\n\n# Set aside raw test data for use with Akida Execution Engine later\nraw_x_test = x_test.astype('uint8')\nraw_y_test = y_test\n\n# Rescale x-data\na = 255\nb = 0\ninput_scaling = (a, b)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train = (x_train - b) / a\nx_test = (x_test - b) / a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Model definition\n~~~~~~~~~~~~~~~~~~~\n\nNote that at this stage, there is nothing specific to the Akida NSoC.\nThis start point is very much a completely standard CNN as defined\nwithin `Keras <https://www.tensorflow.org/api_docs/python/tf/keras>`__.\n\nAn appropriate model for MNIST (inspired by `this\nexample <https://www.tensorflow.org/model_optimization/guide/quantization/training_example#train_a_model_for_mnist_without_quantization_aware_training>`__)\nmight look something like the following:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_keras = keras.models.Sequential([\n    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=(28, 28, 1)),\n    keras.layers.MaxPool2D(),\n    keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.Conv2D(filters=64, kernel_size=3, padding='same'),\n    keras.layers.MaxPool2D(padding='same'),\n    keras.layers.BatchNormalization(),\n    keras.layers.ReLU(),\n    keras.layers.Flatten(),\n    keras.layers.Dense(10)\n], 'mnistnet')\n\nmodel_keras.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model defined above is compatible for conversion into an Akida model, i.e.\nthe model doesn't include any layers or operations that aren't Akida-compatible\n(please refer to the `CNN2SNN toolkit <../user_guide/cnn2snn.html>`__ documentation for full\ndetails):\n\n* Standard Conv2D and Dense layers are supported\n* Hidden layers must be followed  by a ReLU layer.\n* BatchNormalization must always happen before activations.\n* Convolutional blocks can optionally be followed by a MaxPooling.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Model training\n^^^^^^^^^^^^^^^^^^\n\nBefore going any further, train the model and get its performance.\nThe created model should have achieved a test accuracy a little over 99% after\n10 epochs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_keras.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n\nmodel_keras.fit(x_train, y_train, epochs=10, validation_split=0.1)\n\nscore = model_keras.evaluate(x_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Model quantization\n~~~~~~~~~~~~~~~~~~~~~\n\nWe can now turn to quantization to get a discretized version of the model,\nwhere the weights and activations are quantized so as to be suitable for\nimplementation in the Akida NSoC.\n\nFor this, we just have to quantize the Keras model using the\n`quantize <../api_reference/cnn2snn_apis.html#quantize>`_\nfunction. Here, we decide to quantize to the maximum allowed bitwidths for\nthe first layer weights (8-bit), the subsequent layer weights (4-bit) and the\nactivations (4-bit).\n\nThe quantized model is a Keras model where the neural layers (Conv2D, Dense)\nand the ReLU layers are replaced with custom CNN2SNN quantized layers\n(QuantizedConv2D, QuantizedDense, QuantizedReLU). All Keras API functions\ncan be applied on this new model: ``summary()``, ``compile()``, ``fit()``. etc.\n\n.. Note:: The ``quantize`` function folds the batch normalization layers into\n          the corresponding neural layer. The new weights are computed\n          according to this folding operation.\n\n.. Note:: The CNN2SNN toolkit provides the\n          `check_model_compatibility <../api_reference/cnn2snn_apis.html#check-model-compatibility>`__\n          function to ensure that the quantized model is compatible with the\n          Akida NSoC. If the model is not fully compatible, substitutes will\n          be needed for the relevant layers/operations (guidelines included\n          in the documentation).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cnn2snn import quantize, check_model_compatibility\n\nmodel_quantized = quantize(model_keras,\n                           input_weight_quantization=8,\n                           weight_quantization=4,\n                           activ_quantization=4)\nmodel_quantized.summary()\n\nprint(\"Model compatible for Akida conversion:\",\n      check_model_compatibility(model_quantized, input_is_sparse=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the quantized model accuracy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_quantized.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n\nscore = model_quantized.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy after 8-4-4 quantization:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we used the maximum allowed bitwidths for weights and activations, the\naccuracy of the quantized model is equivalent to the one of the base model,\nbut for lower bitwidth, the quantization  usually introduces a performance drop.\n\nLet's try this time with 2-bit for weights and 1-bit for activations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_quantized = quantize(model_keras,\n                           weight_quantization=2,\n                           activ_quantization=1)\n\nmodel_quantized.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer='adam',\n    metrics=['accuracy'])\n\nscore = model_quantized.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy after 2-2-1 quantization:', score[1])\n\n# To recover the original model accuracy, a quantization-aware training phase\n# is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Model fine tuning (quantization-aware training)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis quantization-aware training (fine tuning) allows to cover the\nperformance drop due to the quantization step.\n\nNote that since this step is a fine tuning, the number of epochs can be\nlowered, compared to the training from scratch of the standard model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_quantized.fit(x_train, y_train, epochs=5, validation_split=0.1)\n\nscore = model_quantized.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy after fine tuning:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Model conversion\n~~~~~~~~~~~~~~~~~~\n\nAfter having obtained a quantized model with satisfactory performance, it can\nbe converted to a model suitable to be used in the Akida NSoC in inference\nmode. The `convert <../api_reference/cnn2snn_apis.html#convert>`__\nfunction returns a model in Akida format, ready for the Akida NSoC or the\nAkida Execution Engine.\n\n.. Note:: One needs to supply the coefficients used to rescale the input\n          dataset before the training - here ``input_scaling``.\n\nAs with Keras, the summary() method provides a textual representation of the\nAkida model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cnn2snn import convert\n\nmodel_akida = convert(model_quantized, input_scaling=input_scaling)\nmodel_akida.summary()\n\nresults = model_akida.predict(raw_x_test)\naccuracy = (raw_y_test == results).mean()\n\nprint('Test accuracy after conversion:', accuracy)\n\n# For non-regression purpose\nassert accuracy > 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on the number of samples you run, you should find a\nperformance of around 98% (better results can be achieved using more\nepochs for training).\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}