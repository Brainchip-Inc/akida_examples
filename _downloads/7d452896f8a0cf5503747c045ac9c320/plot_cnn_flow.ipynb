{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCNN conversion flow tutorial\n============================\n\nThe CNN2SNN tool is based on Keras, TensorFlow high-level API for building and\ntraining deep learning models.\n\n.. Note:: Please refer to TensorFlow  `tf.keras.models\n          <https://www.tensorflow.org/api_docs/python/tf/keras/models>`__\n          module for model creation/import details and `TensorFlow\n          Guide <https://www.tensorflow.org/guide>`__ for details of how\n          TensorFlow works.\n\n**CNN2SNN tool** allows you to **convert CNN networks to SNN networks**\ncompatible with the **Akida NSoC** in a few steps.\n\n.. Note:: MNIST example below is light enough so you do not need a `GPU\n          <https://www.tensorflow.org/install/gpu>`__ to run the CNN2SNN\n          tool.\n\n![](../img/cnn2snn_flow_small.png)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. System configuration\n~~~~~~~~~~~~~~~~~~~~~~~\n\n1.1 Load CNN2SNN tool dependencies\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# System imports\nimport os\nimport sys\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom tempfile import TemporaryDirectory\n\n# TensorFlow imports\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, MaxPooling2D, Activation, ReLU, Flatten, Input\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.2 Load and reshape MNIST dataset\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAfter loading, we make 3 transformations on the dataset:\n\n1. Reshape the sample content data (x values) into a num_samples x width x\n   height x channels matrix.\n\n.. Note:: At this point, we'll set aside the raw data for testing our\n          converted model in the Akida Execution Engine later\n\n2. Rescale the 8-bit loaded data to the range 0-to-1 for training.\n\n.. Note:: This shift makes almost no difference in the current example, but\n          for some datasets rescaling the absolute values (and also shifting\n          to zero-mean) can make a really major difference.\n\n          Also note that we store the scaling values ``input_scaling`` for\n          use when preparing the model for the Akida Execution Engine. The\n          implementation of the Akida neural network allows us to completely\n          skip the rescaling step (i.e. the Akida model should be fed with\n          the raw 8-bit values) but that does require information about what\n          scaling was applied prior to training - see below for more details.\n\n3. Transform the loaded labels from a scalar representation (single integer\nvalue per sample) to a one-hot vector representation, appropriate for use\nwith the squared hinge loss function used in the current model.\n\n.. Note:: Input data normalization is a common step dealing with CNN\n          (rationale is to keep data in a range that works with selected\n          optimizers, some interesting reading can be found\n          `here <https://www.jeremyjordan.me/batch-normalization/>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Reshape x-data\nx_train = x_train.reshape(60000, 28, 28, 1)\nx_test = x_test.reshape(10000, 28, 28, 1)\n\n# Set aside raw test data for use with Akida Execution Engine later\nraw_x_test = x_test.astype('uint8')\nraw_y_test = y_test\n\n# Rescale x-data\na = 255\nb = 0\ninput_scaling = (a, b)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train = (x_train - b) / a\nx_test = (x_test - b) / a\n\n# Transform scalar labels to one-hot representation, scaled to +/- 1 appropriate for squared hinge loss function\ny_train = to_categorical(y_train, 10) * 2 - 1\ny_test = to_categorical(y_test, 10) * 2 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.3 Set training parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nSet some training parameters used across the different training sessions:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set dataset relative training parameters\nepochs = 5\nbatch_size = 128\n\n# Set the learning rate parameters\nlr_start = 1e-3\nlr_end = 1e-4\nlr_decay = (lr_end / lr_start)**(1. / epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Model creation and performance check\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n2.1 Model creation\n^^^^^^^^^^^^^^^^^^\n\nNote that at this stage, there is nothing specific to the Akida NSoC.\nThis start point is very much a completely standard CNN as defined\nwithin `Keras <https://www.tensorflow.org/api_docs/python/tf/keras>`__.\n\nAn appropriate model for MNIST (inspired by `this\npaper <https://arxiv.org/pdf/1705.09283.pdf>`__) might look something\nlike the following:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img_input = Input(shape=(28, 28, 1))\nx = Conv2D(filters=32,\n           kernel_size=(5, 5),\n           padding='same',\n           use_bias=False,\n           data_format='channels_last')(img_input)\nx = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\nx = BatchNormalization()(x)\nx = ReLU(6.)(x)\n\nx = Conv2D(filters=32, kernel_size=(5, 5), padding='same', use_bias=False)(x)\nx = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\nx = BatchNormalization()(x)\nx = ReLU(6.)(x)\n\nx = Conv2D(filters=32, kernel_size=(5, 5), padding='same', use_bias=False)(x)\nx = BatchNormalization()(x)\nx = ReLU(6.)(x)\n\nx = Flatten()(x)\nx = Dense(512, use_bias=False)(x)\nx = BatchNormalization()(x)\nx = ReLU(6.)(x)\nx = Dense(10, use_bias=False)(x)\n\nmodel_keras = Model(img_input, x, name='mnistnet')\n\nopt = Adam(lr=lr_start)\nmodel_keras.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])\nmodel_keras.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. Note:: Adam optimizer is commonly used, more details can be found\n          `here <https://arxiv.org/abs/1609.04747>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.2 Performance check\n^^^^^^^^^^^^^^^^^^^^^\n\nBefore going any further, check the current model performance as a\nbenchmark for CNN2SNN conversion.\nThe created model should achieve a test accuracy a little over 99% after\n5 epochs:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "callbacks = []\nlr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay**e)\ncallbacks.append(lr_scheduler)\nhistory = model_keras.fit(x_train,\n                          y_train,\n                          batch_size=batch_size,\n                          epochs=epochs,\n                          verbose=1,\n                          validation_data=(x_test, y_test),\n                          callbacks=callbacks)\nscore = model_keras.evaluate(x_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Model Akida-compatibility check and changes\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n3.1 Compatibility check\n^^^^^^^^^^^^^^^^^^^^^^^\n\nThe first step is to ensure that the model as defined doesn't include\nany layers or operations that aren't Akida-compatible (please refer to\nthe `CNN2SNN toolkit <../user_guide/cnn2snn.html>`__ documentation for full\ndetails):\n\n* Standard Conv2D and Dense layers are supported (note that\n  there is currently no support for skip, recursive and parallel layers).\n* Each of these trainable core layers except for the last one must be followed\n  by an Activation layer.\n* All blocks can optionally include a BatchNormalization layer.\n* Convolutional blocks can optionally include a MaxPooling type layer.\n\n.. Note:: This configuration of layers (Conv/Dense + BatchNormalization +\n          Activation) constitutes the basic building block of\n          Akida-compatible models and is widely used in deep learning.\n\nIf the model defined is not fully compatible with the Akida NSoC,\nsubstitutes will be needed for the relevant layers/operations\n(guidelines included in the documentation).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.2 Model adaptation\n^^^^^^^^^^^^^^^^^^^^\n\nAs noted above, the basic building blocks of Akida compatible models\nactually comprise a trio of layers: Conv/Dense + BatchNormalization +\nActivation (with, optionally, pooling). The CNN2SNN tool provides a set\nof functions that simplify using these building blocks, and subsequently\nenable easy application of Brainchip's custom quantization functions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models.quantization_blocks import conv_block, dense_block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code illustrates how to express the MNIST model defined\nabove using the functions provided by Brainchip. A couple of points to\navoid confusion when you look through it:\n\n* The ``weight_quantization`` in each block isn't used here, but will be used\n  later to apply a quantization method to the model weights.\n* The ``block_id`` is just used for naming the layers, and will be good\n  practice in enabling reloading of partially trained models in more advanced\n  training cases.\n* Note that in the final block, we set the nonlinearity\n  ``activ_quantization`` to ``None``. In that case, the block has no\n  Activation layer, and the output is simply the output from the\n  BatchNormalization layer.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Removes all the nodes left over from the previous model and free memory\nK.clear_session()\n\n# Define the model.\n# The commented code shows the sets of layers in the original definition\n# that are being replaced by the provided conv_block and dense_blocks here\n\nimg_input = Input(shape=(28, 28, 1))\n\n# x = Conv2D(filters=32,\n#            kernel_size=(5, 5),\n#            padding='same',\n#            use_bias=False,\n#            data_format='channels_last')(img_input)\n# x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n# x = BatchNormalization()(x)\n# x = ReLU(6.)(x)\nx = conv_block(img_input,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_0',\n               pooling='max',\n               add_batchnorm=True)\n\n# x = Conv2D(filters=32,\n#            kernel_size=(5, 5),\n#            padding='same',\n#            use_bias=False)(x)\n# x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n# x = BatchNormalization()(x)\n# x = ReLU(6.)(x)\nx = conv_block(x,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_1',\n               pooling='max',\n               add_batchnorm=True)\n\n# x = Conv2D(filters=32,\n#            kernel_size=(5, 5),\n#            padding='same',\n#            use_bias=False)(x)\n# x = BatchNormalization()(x)\n# x = ReLU(6.)(x)\nx = conv_block(x,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_2',\n               add_batchnorm=True)\n\nx = Flatten()(x)\n\n# x = Dense(512,\n#           use_bias=False)(x)\n# x = BatchNormalization()(x)\n# x = ReLU(6.)(x)\nx = dense_block(x,\n                units=512,\n                use_bias=False,\n                name='dense_2',\n                add_batchnorm=True)\n\n# x = Dense(10,\n#           use_bias=False)(x)\n# x = BatchNormalization()(x)\nx = dense_block(x,\n                units=10,\n                use_bias=False,\n                name='dense_3',\n                activ_quantization=None)\n\nmodel_keras = Model(img_input, x, name='mnistnet')\n\nopt = Adam(lr=lr_start)\nmodel_keras.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])\nmodel_keras.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.3 Performance check\n^^^^^^^^^^^^^^^^^^^^^\n\nCheck modifed model performance:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "callbacks = []\nlr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay**e)\ncallbacks.append(lr_scheduler)\nhistory = model_keras.fit(x_train,\n                          y_train,\n                          batch_size=batch_size,\n                          epochs=epochs,\n                          verbose=1,\n                          validation_data=(x_test, y_test),\n                          callbacks=callbacks)\nscore = model_keras.evaluate(x_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the model weights as ``mnistnet_act_fp_wgt_fp.hdf5`` to reload\nthem as init weights for the quantization step:\n\n.. Note:: This is not mandatory but helps with training speed.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "temp_dir = TemporaryDirectory()\nmodel_keras.save_weights(\n    os.path.join(temp_dir.name, 'mnistnet_act_fp_wgt_fp.hdf5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Model quantization and training\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n4.1 Quantize the model\n^^^^^^^^^^^^^^^^^^^^^^\n\nWe can now turn to training a discretized version of the model, where\nthe weights and activations are quantized so as to be suitable for\nimplementation in the Akida NSoC.\n\nFor this, we just have to change very slightly the definition of the\nmodel used above, changing just the values of ``weight_quantization``\nand ``activ_quantization`` used for the blocks (but still with no output\nnonlinearity for the final block). Additionally, we'll initialise the\nmodel using the set of pre-trained weights that we just saved (not so\nimportant here, but for more complex datasets can make a huge difference\nboth to the accuracy level ultimately achieved and to the speed of\nconvergence).\n\nNote that, for more challenging datasets, it may also be useful to make\nstepwise changes towards a fully quantized model - e.g. by first\ntraining with only the activations quantized, re-saving, and then adding\nthe quantized weights. Additionally, the toolkit documentation describes\nhow one can go further, optimizing the degree of sparsity in the model\nto reduce computational cost while maintaining accuracy. In this first\nexample however, we'll stick to a one step conversion (mainly because\nthe MNIST dataset simply isn't complex enough to see the benefit of the\nadvanced techniques).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Removes all the nodes left over from the previous model and free memory\nK.clear_session()\n\nimg_input = Input(shape=(28, 28, 1))\nx = conv_block(img_input,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_0',\n               weight_quantization=2,\n               activ_quantization=1,\n               pooling='max',\n               add_batchnorm=True)\nx = conv_block(x,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_1',\n               weight_quantization=2,\n               activ_quantization=1,\n               pooling='max',\n               add_batchnorm=True)\nx = conv_block(x,\n               filters=32,\n               kernel_size=(5, 5),\n               padding='same',\n               use_bias=False,\n               name='conv_2',\n               weight_quantization=2,\n               activ_quantization=1,\n               add_batchnorm=True)\nx = Flatten()(x)\nx = dense_block(x,\n                units=512,\n                use_bias=False,\n                name='dense_2',\n                weight_quantization=2,\n                activ_quantization=1,\n                add_batchnorm=True)\nx = dense_block(x,\n                units=10,\n                use_bias=False,\n                name='dense_3',\n                weight_quantization=2,\n                activ_quantization=None)\n\nmodel_keras = Model(img_input, x, name='mnistnet_quantized')\nlr_start = 1e-3\nopt = Adam(lr=lr_start)\nmodel_keras.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])\nmodel_keras.summary()\n\n# Reload previously computed weights as init weights for the quantization step\nload_status = model_keras.load_weights(\n    os.path.join(temp_dir.name, 'mnistnet_act_fp_wgt_fp.hdf5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.2 Performance check\n^^^^^^^^^^^^^^^^^^^^^\n\nRe-train and save the quantized model:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "callbacks = []\nlr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay**e)\ncallbacks.append(lr_scheduler)\nhistory = model_keras.fit(x_train,\n                          y_train,\n                          batch_size=batch_size,\n                          epochs=epochs,\n                          verbose=1,\n                          validation_data=(x_test, y_test),\n                          callbacks=callbacks)\nscore = model_keras.evaluate(x_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Convert trained model for Akida and test\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n5.1 Final conversion\n^^^^^^^^^^^^^^^^^^^^\n\nConvert the quantized model to a version suitable to be used in the Akida NSoC\nin inference mode:\n\n.. Note:: One needs to supply the coefficients used to rescale the input\n          dataset before the training - here ``input_scaling``.\n\nAs with Keras, the summary() method provides a textual representation of the\nmodel.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cnn2snn import convert\n\nmodel_akida = convert(model_keras, input_scaling=input_scaling)\nmodel_akida.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2 Performances check with the Akida Execution Engine\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n\nresults = model_akida.predict(raw_x_test[:num_samples])\naccuracy = accuracy_score(raw_y_test[:num_samples], results[:num_samples])\n\nprint(\"Accuracy: \" + \"{0:.2f}\".format(100 * accuracy) + \"%\")\n\n# For non-regression purpose\nassert accuracy > 0.95\n\n# Print model statistics\nprint(\"Model statistics\")\nstats = model_akida.get_statistics()\nmodel_akida.predict(raw_x_test[:20])\nfor _, stat in stats.items():\n    print(stat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Depending on the number of samples you run, you should find a\nperformance of around 99% (better results can be achieved using more\nepochs for training).\n\n.. Note:: Akida-compatible model first layer type is ``InputConvolutional``\n          and holds underlying data to spike conversion (please refer to\n          `Akida Execution Engine documentation\n          <../user_guide/aee.html>`__ for more details).\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}